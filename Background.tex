\section{Introduction to Distributed Systems}

A distributed system, broadly construed, is a collection of
independent entities that cooperate to solve a problem that cannot be
individually solved \cite{kshemkalyani_singhal_2008}. Here we are
concerned with the sorts of distributed systems involved in civil
aviation in the context of disaster response scenarios like combating
wildfires and providing hurricane relief. In these scenarios, entities
like emergency responders, firefighters, crewed and uncrewed aircraft
teams, air traffic controllers, and other personnel cooperate to solve
shared tasks like navigating safely, delivering resources,
extinguishing fires, and collecting and sharing data. A paramount
concern in all of our use cases is that the system must ensure strong
safety guarantees.

Safely coordinating the actions of distributed agents is a challenge
for distributed computing. Singhal and Shivaratri
\cite{10.5555/562065} characterized a distributed computing system as
\begin{quotation}
  A collection of computers that do not share common memory or a
  common physical clock, that communicate by message passing over a
  communication network, and where each computer has its own memory
  and runs its own operating system.
\end{quotation}
``Computers" here should be understood broadly, taken to include
aircraft systems like ADS-B, portable communications equipment,
satellites, vehicle-mounted personal computers, or smartphones carried
by firefighters in the field.

Absence of a common memory implies that all communication between
system nodes takes place over the network, rather than by writing data
to mutually accessible memory. In general, and particularly during
disaster response scenarios, message delivery is neither guaranteed
nor instantaneous. For example, two firefighting ground teams may not
be able to communicate with each other over a radio network if the
teams are separated by a tall ridgeline. Handling these sorts of
challenges gracefully---for example, automatically redirecting a
nearby drone to route messages over the ridgeline---requires
sophisticated distributed applications that can tolerate a chaotic
operating environment and network.

A highly centralized network topology relying on a small number of
central nodes to coordinate and pass messages would be too brittle for
our intended use cases. Such a setup could allow, for instance, the
failure of a centrally-located node to wreak havoc on the rest of the
network, perhaps triggering cascading failures throughout the
system. Instead our model is that ground-based and airborne agents
interact as clients over an ad-hoc mesh-style network, say one
supported by the deployment of portable communication towers. We
imagine that messages are routed in a somewhat or entirely
decentralized, peer-to-peer fashion, as such a setup would be more
resilient in the face of an unpredictable environment. Compared to,
say, a datacenter's fiber-optic local area network, there are fewer
guarantees about how reliably messages can be transmitted between any
two clients.

As manifest in results like Brewer's CAP theorem, below, the
imperfections in network impose theoretical and practical limitations
to how well one can coordinate distributed agents, and how quickly. To
discuss the nature of these challenges more formally, we turn to the
topic of consistency among replicas of data objects.

\subsection{Strong consistency models}

The basic challenge of a distributed computing system is to provide
the illusion that many computers act ``as a single coherent computer''
\cite{TanenbaumSteen07} that handles the requests of every client
simultaneously. Presenting such an illusion requires coordination over
the network, so much of system coherence boils down to hiding the
effects of the unreliable network from the user.\footnote{Network
delays are a primary obstacle to coordination, but not the only
one. For instance, the fact that we do not assume nodes share
synchronized clocks makes it more challenging to enforce a global
total order of operations.}

Among the most basic distributed applications is \emph{data
replication}. In such an application, nodes maintain local replicas of
some globally shared state. For simplicity, we discuss an example
which replicates a key-value store of natural numbers, but this could
be any other kind of data structure like a FIFO queue. The application
affords clients the ability to read and/or update the data from any
node. Handling these requests requires nodes to spend time
coordinating with other nodes, e.g. to propagate updates throughout
the system, or to lookup the most up-to-date value to return to the
client. Therefore each request has a start time (when the request is
first received) and strictly greater end time (when the response is
sent back to the client).

The figure below shows a sequence diagram of two clients interacting
with a distributed system. The vertical axis represents real
(i.e. wall-clock) time, which increases in the downward
direction. Both clients send write requests to update the natural
number associated with $x$. The reader should note that the requests
overlap in real time, with the second client's request accepted before
the first client's request has returned. After both requests are
handled, both nodes issue read requests for the same value $x$. Client
1 reads $x$ as having value $a \in \mathbb{N}$, while Client 2 reads
$b \in \mathbb{N}$.

\begin{figure}
  \includegraphics[scale=0.6]{Sequence Diagram.png}
  \caption{A sequence of read/write requests. A consistency model constrains the possible values of $a$ and $b$.}
\end{figure}

A \emph{consistency model} is a constraint on the allowable system
responses to these sorts of request histories. In this example, a
model constrains the possible values of $a$ and $b$. The strongest
workable consistency model is atomic consistency \cite{}, also known
as linearizability.\footnote{In the context of isolated database
transactions, the analogous condition is called strict serializability
or serializability with external order.} The intuition is that to an
outside observer, a linearizable system processes requests exactly as
if they were all being handled by one node, though not always in the
order they requests were received. For instance, two consecutive read
requests must return the same value, assuming no intermediate updates
take place between the two requests. When requests are seen to
overlap, such as the updates in our example, linearizability specifies
no order on their execution. In other words, the system must act as if
during some moment while processing the request, the update instantly
took effect, but this order doesn't have to be the order in which a
request was received if they are processed concurrently.

Applied to our example, linearizability allows either write request to
take effect before the other, but they both take effect before $a$ is
read by Client 1, so $a$ must be $1$ or $2$. $b$ must have the same
value as $a$, since it is read after reading $a$ and there are no
intermediate updates to $x$. Linearizability would be violated if $b
\neq a$ because an external observer could infer the clients are
operating on different, inconsistent copies of $x$.

Enforcing linearizability imposes appreciable performance overheads on
a system, as no agent can complete an update until the update has been
propagated to all other agents. Consequently, issues with a small
number of nodes can have a disproportionately disruptive impact on the
entire distributed application. Unsurprisingly, real-world frameworks
frequently consider models weaker than linearizability.

One weaker model, but one still regarded as a form of ``strong''
consistency, is sequential consistency \cite{}. Here, we weaken the
requirement that effects appear to happen in an order consistent with
wall clock time. The new requirement is that the effects \emph{from a
single client} must occur in their specified order (i.e. program
order), but requests from two different clients may appear to happen
in any order, even if they don't occur concurrently in real
time. Sequential consistency would require that both $a$ and $b$ can
be either 1 or 2, with no correlation. While a real-time observer can
observe behavior that looks inconsistent with real time, the basic
intuition is that if a history is always compatible with some temporal
order that \emph{could} have happened, this is all a programmer needs
to reason about the correctness of their applications. Linearizability
implies sequential consistency, and is sometimes called sequential
consistency plus (compatibility with) external order.

Both forms of strong consistency, atomic and sequential, are too
stringent to require from many applications, especially in an
unreliable communications environment, due to performance overheads.
The next section discusses this tradeoff.

\subsection{The consistency/availability tradeoff}

Real-world systems often fall short of behaving as a single perfectly
coherent system. The root of this phenomenon is that there exists a
deep and well-understood tradeoff between system coherence and system
performance. Enforcing consistency comes at the cost of additional
communications, and communications impose overheads, often ones that
can be unpredictable. The network may also fail to deliver messages or
rearrange their order. All of these present obstacles to consistency,
particularly if the system should also exhibit good performance.

Brewer observed that there is a fundamental tension between
consistency, availability, and partition-tolerance.
\cite{2000brewerCAP}. This tradeoff was precisely stated and proved in
2002 by Gilbert and Lynch \cite{2002gilbertlynchCAP}. To summarize
this theorem, we start by defining these terms.

\paragraph{Consistency}

Consistency in Gilbert and Lynch is defined as atomic consistency
(linearizability). The CAP theorem can be also generalized to
sequential consistency \cite{}.

\paragraph{Availability}

A CAP-available system is one that will definitely respond to every
client request at some point in the future. In particular, in the
event of a network partition that prevents messages from being
delivered, the system cannot indefinitely suspend processing requests
until the network recovers, as we do not assume partitions eventually
recover. In real applications we also care about the \emph{speed} with
which requests are handled, but the CAP theorem demonstrates there are
already obstacles to ensuring that every request is handled
\emph{eventually}.

\paragraph{Partition-tolerance}

A partition tolerant system continues to function, and ensure whatever
guarantees it is meant to provide, in the face of arbitrary partitions
in the network. Note that partitions may never recover, say if a
critical communications link is permanently severed.

\begin{theorem}[CAP Theorem]
In the presense of indefinite network partitions, a distributed system
cannot guarantee both atomic consistency and availability.
\end{theorem}

The proof is not complicated. Indeed, it is almost trivial. We give
only a sketch here, leaving the interested reader to consult Gilbert
and Lynch \cite{}. In the example above, suppose the two clients have
their requests served by two different system nodes, and suppose these
nodes cannot pass messages due to an indefinite network
partition. Linearizability requires that $a$ is $1$ or $2$ and $b =
a$.  Clearly $a$ cannot be $2$ if there is no communication between
the two clients. But clearly $b$ cannot be $1$ for the same reason.
To avoid violating the condition $b = a$ we could suppose the system
indefinitely delays responding to the read requests, but this violates
our requirement that system nodes eventually respond to
clients. Therefore, $P$ implies we cannot have both $C$ and $A$.

While the proof of the CAP theorem is rather trivial, its
interpretation is subtle and has been the subject of considerable
popular discussion \cite{}. It is sometimes assumed that the CAP theorem
claims that a distributed system can only offer two of the properties
C, A, and P. Actually, real-world systems can offer tolerable levels
of consistency, availability, and partition-resilience, as all three
of these concepts are highly idealized in the statement of the
theorem. The theorem constrains, but does not prohibit the existence
of, applications that apply some degree of all three features.

One way the the CAP theorem is idealized is that it defines
consistency as linearizability, a very strong condition. In practice
one often tolerates weaker levels of consistency. Also, network
partitions are often not as dramatic as an indefinite total
communications blackout. Real-world conditions in our context are
likely more chaotic, featuring many smaller disruptions and delays and
sometimes larger ones. Communications between different clients may be
affected differently, with nearby agents generally likely to have
better communication channels between them than agents that are far
apart. Finally, CAP-availability is a suprisingly weak condition. It
only requires that requests are handled eventually. In a truly highly
available system, we expect requests to be handled quickly almost
always. Altogether, the extremes of C, A, and P in the CAP theorem are
not reflective of most real-world applications.

The tension between consistency and availability is well-understood
\cite{10.1145/5505.5508}. It is a prototypical example of an even
broader tension in distributed systems: that between safey and
liveness properties \cite{2012perspectivesCAP}. These terms can be
understood as follows.

\paragraph{Safety}
Safety properties ensure that a system avoids doing something ``bad''
like violating a consistency invariant. Taken to the extreme, one way
to ensure safety is to do nothing. For instance, we could enforce
safety by never responding to read requests in order to avoid offering
information that is inconsistent with that of other nodes.

\paragraph{Liveness}
Liveness properties ensure that a system will eventually do something
``good'', like respond to a client. Taken to the extreme, one very
lively behavior would be to immediately respond to user requests,
without taking any steps to make sure this response is consistent with
that of other nodes.

Note that in our use cases, one can imagine that an unresponsive
system could indeed be considered ``unsafe.'' The distinction between
the two here is that safety constrains a system's allowable responses
to clients, if one is even given, while liveness requires giving
responses.

Because of the tension between them, building applications that
provide both of these features is challenging. The basic takeaway is
that if we want to increase how quickly a system can respond to
requests, at some point we must relax our constraints on what the
system is allowed to return.

\subsection{Optimistic consistency models}
One way of ``subverting CAP,'' often applied with highly available
applications, is to consider \emph{optimistic} notions of consistency.  A
possible response to the CAP theorem is to consider weaker consistency
models. A particularly weak class is broadly known as "optimistic
consistency," so named because this model rests on the assumption that
partitions are relatively rare and the system will provide acceptable
levels of consistency in its average use case---but the priority is to
favor high availability rather than to enforce consistency.

We shall explain that these models are inappropriate for
safety-critical systems, which motivates our consideration of
continuous consistency in Section \cite{}.

\begin{itemize}
  \item For example, we can consider an extremely optimistic approach for
  the scenario discussed above, with the aim to always provide maximum
  availability, even during a total partition. We use a mechanism to
  detect when a partition occurs and when it is recovered from. After,
  we work to merge information after the partition has passed. For
  example, we may combine all increments and decrements to a value,
  saving them in a \emph{write log}. That is, we maintain a history of
  individual increments or decrements. After a partition, every node
  broadcasts its entire write log to all other parties, so that every
  node sees and applies all updates.

  \item The problem with optimistic consistency, and with weak consistency
  models in general, is that generally they do not provide a way to
  bound the system's inconsistency, generally seeking instead to
  emphasize system performance and providing only as much consistency
  as the network happens to allow. In our previous example, values may
  diverge wildly during the partition. In a datacenter, we could
  estimate the likelihood and duration of a typical partition, and
  derive probabilistic bounds on how widely two replicas may diverge
  in practice. For instance, empirical observations may show that a
  typical network partition lasts less than 2 hours, during which time
  replicas tend to drift apart by approximately $X$ amount, and this
  might be acceptable.

  \item But this doesn't work in the environments considered in this
  memo---there is no a priori "typical" network or usage pattern, and
  no robust way to restrict observable levels of
  inconsistency. Without such bounds, we cannot rely on the
  approximate consistency of replicas without comprising safety. This
  makes optimistic consistency inappropriate for safety-critical
  systems.

  \item We want to bound inconsistency. Since we can't make things perfect,
  this will have to be traded for availability. The next topic
  considers how we may bound inconsistency without necessarily
  imposing the significant coordination penalty required to enforce
  strong consistency.

\end{itemize}

In light of both the CAP theorem and the safety-critical nature of our
intended use cases, we now enumerate several desiderata we might
expect from distributed applications.

\subsection{Desiderata for distributed applications}

This section lists three desirable features of distributed systems and
frameworks for reasoning about or implementing them. We chose this set
based on the particular details of civil aviation and disaster
response, where safety is a high priority and usage/communication
patterns may be unpredictable. These desiderata can be understood
narrowly for the specific application of data replication, but these
same considerations can be applied to any distributed application,
such as the sheaf-theoretic data fusion in Section \cite{}.

\subsubsection*{D1: Quantifiable bounds on inconsistency}

\emph{A distributed application should quantify the amount of consistency
it delivers. That is, it should (1) provide a mathematical way of
measuring inconsistency, and (2) bound this value while the system is
available.}

The CAP theorem implies that an available data replication application
cannot bound inconsistency in all circumstances. When bounded
inconsistency cannot be guaranteed, a system satisfying D1 may become
unavailable. A reasonable alternative behavior would be to continue
providing some form of availability, but alert the user that due to
network and system use conditions the requisite level of consistency
cannot be guaranteed by the application, leaving the user with the
choice to assess the risk and continue using the system with a weaker
inconsistency bound.

\subsubsection*{D2: Accommodation of heterogeneous nodes}

\emph{An application should not assume that there is a typical system
node. Instead, the system should accomdate a diverse range of
heterogeneous clients presenting different capabilities, tasks, and
risk-factors.}

One can expect a variety of hardware in the field. For example,
wildfires often involve responses from many different fire
departments, and it must be assumed that they are not always using
identical systems. Different participants in the system may be solving
different tasks, with different levels of access to the network, and
they present different risks. Therefore, one should hope for
frameworks that are as general as possible to accomodate a wide
variety of clients.

\subsubsection*{D3: Optimization for an geodistributed wide area network}

\emph{An application should be optimized for the sorts of
communication patterns that occur in geodistributed wide area networks
(WANs) under real-world conditions.}

Consider two incidents. Wouldn't want to enforce needless global
consistency, particularly if the agents in one area do not have the
same consistency requirements for another area.

Network throughput has some (perhaps approximately linear)
relationship with throughput. Communications patterns are likely far
from uniform too. In fact, these two things likely coincide---it is
often that nodes which are nearby have a stronger need to coordinate
their actions than nodes which are far away. For example, consider
manoeauvering airplanes to avoid crash.

A distributed framework should be able to handle this.
