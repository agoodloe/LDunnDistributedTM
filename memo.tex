% !TeX document-id = {beb7ced9-b3cd-42b2-b16a-3ed3c633a1d9}
\documentclass[]             % options: RDPonly, coveronly, nocover
{NASA}                       %   plus standard article class options
%\DeclareRobustCommand{\mmodels}{\mathrel{|}\joinrel\Relbar}

\usepackage[utf8]{inputenc}
\usepackage{setspace}
\usepackage{csquotes}
\usepackage{hyperref}
\usepackage{amsmath, amssymb, amscd, amsthm, amsfonts}
\usepackage{mathtools}
\usepackage{graphicx}
\usepackage{hyperref}
\usepackage{amsthm}
\usepackage[english]{babel}
\usepackage{stmaryrd}
\usepackage{proof}
\usepackage{tikz-cd}
\tikzcdset{scale cd/.style={every label/.append style={scale=#1},
    cells={nodes={scale=#1}}}}
% Added for subfigures
\usepackage{caption}
\usepackage{subcaption}
\usepackage{afterpage}
\usepackage{comment}
\usepackage{rotating}%sidewaysfigure
\usepackage{pdflscape}%alt to sidewaysfigure

\newtheorem{theorem}{Theorem}[section]
\newtheorem{corollary}{Corollary}[theorem]
\newtheorem{lemma}[theorem]{Lemma}
\theoremstyle{definition}
\newtheorem{example}{Example}[section]
\newtheorem{definition}{Definition}[section]
\include{macros.tex}

% Globally redefine pgfpicture to use \Large fonts
\let\origpgfpicture=\pgfpicture
\def\pgfpicture{\origpgfpicture\small}

% Try loading this package to prevent so much hyphenation
% as recommended by https://stackoverflow.com/questions/1609837/latex-breaking-up-too-many-words
\usepackage{microtype}

\title{Distributed Systems Challenges in Public Safety Networks}

\author{Lawrence Dunn and Alwyn E. Goodloe}

\AuthorAffiliation{Lawrence Dunn \\ Department of Computer and Information
  Science \\ University of Pennsylvania \\ Philadelphia, PA \\ Alwyn Goodloe\\                                          % for cover page
  NASA Langley Research Center, Hampton, Virginia
}
\NasaCenter{Langley Research Center\\Hampton, Virginia 23681-2199}
\Type{TM}                    % TM, TP, CR, CP, SP, TT
\SubjectCategory{64}         % two digit number
\LNumber{XXXXX}              % Langley L-number
\Number{XXXXXX}              % Report number
\Month{12}                   % two digit number
\Year{2022}                  % four digit number
\SubjectTerms{Distributed Systems, Formal Methods, Logic, }     % 4-5 comma separated words
\Pages{46}                   % all the pages from the front to back covers
\DatesCovered{}              % 10/2000--9/2002
\ContractNumber{}            % NAS1-12345
\GrantNumber{}               % NAG1-1234
\ProgramElementNumber{}
\ProjectNumber{}             % NCC1-123
\TaskNumber{}                % Task 123
\WorkUnitNumber{}            % 123-45-67-89
\SupplementaryNotes{}
\Acknowledgment{The work was conducted during a summer internship at the NASA Langley Research Center in the Safety-Critical Avionics Systems Branch focusing on distributed computing  issues arising in the Safety Demonstrator challenge in the NASA Aeronautics System Wide Safety (SWS) program.}

%Added for Pandoc
\providecommand{\tightlist}{%
  \setlength{\itemsep}{0pt}\setlength{\parskip}{0pt}}


\abstract{The System Wide Safety (SWS) program has been investigating
  how crewed and uncrewed aircraft can safely operate in shared
   airspace. Enforcing safety requirements for distributed agents
  requires coordination by passing messages over a communication
  network. Unfortunately, the operational environment will not admit
  reliable high-bandwidth communication between all agents,
  introducing theoretical and practical obstructions to global
  consistency that make it more difficult to maintain safety-related
  invariants. Taking disaster response scenarios, particularly
  wildfire suppression, as a motivating use case, this self-contained
  memo discusses some of the distributed systems challenges involved
  in system-wide safety through a pragmatic lens. We survey topics
  ranging from consistency models and network architectures to data
  replication and data fusion, in each case focusing on the practical
  relevance of topics in the literature to the sorts of scenarios and
  challenges we expect from our use case.  }

\begin{document}
\newpage
\setcounter{tocdepth}{2}
\tableofcontents
\newpage

\section{Introduction}
\label{introduction}
Civil aviation has traditionally focused primarily on the efficient
and safe transportation of people and goods via the airspace. Despite
the inherent risks, the application of sound engineering practices and
conservative operating procedures has made flying the safest mode of
transport today. Now the desire not to compromise this safety makes it
difficult to integrate unmanned vehicles into the airspace, accomodate
emerging applications, and keep pace with unprecedented recent growth
in commercial aviation. To that end, the System Wide Safety (SWS)
project of the NASA Aeronautics' Airspace Operations and Safety
Program (AOSP) has been investigating technologies and methods by
which crewed and uncrewed aircraft may safely operate in shared
airspace.

This memo surveys topics in computing that are relevant to maintaining
system-wide safety across large, physically distributed data and
communication systems. It aims to be self-contained and accessible to
a technical audience without a deep background in distributed
systems. Our primary motivating use cases have been taken from civil
emergency response scenarios, especially wildfire suppression and
hurricane relief, primarily for three reasons. First, improved
technology for wildfire suppression, especially related to
communications and data sharing, is frequently cited as a national
priority \cite{pcast2023}.  Second, the rules for operating in the US
national airspace are typically relaxed during natural disasters and
relief efforts, so this is a suitable setting for testing new
technologies. Finally, this setting is an excellent microcosm for the
sorts of general challenges faced by other, non-emergency
applications.

If there is a central theme uniting the sections of this manuscript,
it is \emph{continuity} in the sense considered by
topology.\footnote{For a typical introductory textbook see
  \cite{mendelson2012introduction}.} The systems we consider will be
subject to harsh operating conditions that limit how well they can
perform---for example, wireless communication is typically less
reliable during inclement weather. To build a system that is
predictable (clearly a prerequisite for safety), one must ensure the
system is flexible enough to perform reasonably well under a wide
variety of adverse conditions. In other words, the behavior of a safe
system should in some sense be a \emph{continuous} function of its
inputs and environment. This sort of robust design is particularly
challenging because distributed systems designers are forced to make
delicate tradeoffs between competing objectives, most famously between
performance and consistency, the topic of Section
\ref{sec:background}.

\subsection{Summaries of the sections}
\label{summaries-of-the-sections}

Sections \ref{sec:disaster-response}--\ref{sec:desiderata} contain
background material on disaster response, distributed systems, and the
specifics of our use case. The critical takeaway of these sections is
that system-wide safety is, at least in part, a computer science
problem, indeed a software problem, and not ``just'' a matter of
engineering better hardware. Sections
\ref{sec:networking}--\ref{sec:data-fusion} survey particular topics
from the distributed systems literature, proceeding from lower-level
considerations to higher-level ones; these sections may be read
independently of each other. Below we summarize each section.

Section \ref{sec:disaster-response} starts with a pragmatic summary of
disaster response and some of the relevant computing challenges in
that setting. We aim to justify and explain the role of distributed
systems theory in system-wide safety by citing real examples
encountered in disaster response scenarios.

Section \ref{sec:background} is an introduction to distributed
systems, culminating in a illustrative result: the ``CAP'' theorem(s)
for the atomic and sequential consistency models (Theorems
\ref{thm:cap} and \ref{thm:cap-sequential}, respectively). CAP is
considered a ``negative'' result, meaning it proves something cannot
be done. The CAP theorem proves that strong consistency for a
distributed system makes systemwide network performance an upper bound
on the availability of a system to do useful work for clients, which
for our purposes is an unacceptable restriction. The practical
significance of CAP is that in emergency response environments, agents
will always act with incomplete information about the global system, a
key motivation for Section \ref{sec:continuous-consistency}.

Section \ref{sec:desiderata} refines our assumptions and identifies
desirable properties of systems for our use case. We use these points to
frame the discussion of systems and protocols in subsequent sections.

Section \ref{sec:networking} examines networking considerations. Our
vision of future emergency communication networks integrates concepts
from delay/disruption-tolerant networks (DTN) and mobile ad-hoc
networks (MANET) to provide digital communications that are robust to
a turbulent operational environment. We also examine the state of
software-defined networking (SDN). SDN is an emerging field that puts
networking protocols on the same footing as ordinary computer
programs. In theory, this should furnish computer networking with all
the benefits of modern software engineering, such as reprogrammable
hardware, rapid iteration, version control, and especially formal
verification.

Section \ref{sec:continuous-consistency} describes a hypothetical
application that might be used in a disruption-heavy network: a data
replication service built on Yu and Vahdat's theory of ``conits"
(short for ``consistency unit'') \cite{2002tact}. This framework
realizes a \emph{continuous} consistency model in the sense that, as
typically configured, it provides neither strong consistency nor
guaranteed high-availability, but rather a quantifiable and
controllable tradeoff between the two. The key idea is that many
applications can tolerate inconsistency among replicas of a data item
if an upper bound on the divergence between replicas is enforced. A
conit-based database replication framework would allow system
designers to define units of replicated data whose consistency is of
interest, enforce policies bounding inconsistency between replicas of
these items, and even dynamically tune these policies on the fly. We
believe that only a conit-based replication infrastructure can provide
the strict guarantees required for safety-related systems while also
tolerating the adverse environments and real-world limitations of the
systems we have in mind.

Section \ref{sec:data-fusion} concerns data fusion. Now and in the
future, agents in disaster scenarios will make decisions informed by
many different kinds of information. Efficient integration,
processing, filtering, and dissemination of this information will be
necessary to avoid ``swimming in sensors and drowning in data''
\cite{2010:magnuson}.  This task is especially challenging because
agents will often work with incomplete or out of date information, and
different sources of the same data may be contradictory, e.g. first
responders may receive contradictory reports about whether a structure
is occupied. One promising trend in this space, which we briefly
introduce in this section, is the development of sheaf theory as a
natural mathematical model for data fusion
\cite{2017robinsonCanonical}. Sheaf theory provides a rigorous
framework for discussing how heterogeneous sources of noisy data can
be integrated into a coherent picture, and can formally measure how
well this task has been achieved.

We conclude in Section \ref{sec:conclusion} by recapping some of the
main themes in this document and highlighting areas where design
decisions at various levels must be made to build a system that is
tuned to the exact conditions we can expect from real-world
scenarios. Such decisions might be informed by a combination of
simulation and experimentation in the field.

\section{Coordination Challenges in Disaster Response}
\label{sec:disaster-response}
This section explains aspects of disaster response, particularly
firefighting, that motivate the remainder of this document. We
describe how real-world environments give rise to foundational
challenges that must be addressed through the application of
distributed computing principles. Even deploying the best
communications technology cannot avoid the fundamental computer
scientific problems raised when distributed agents must coordinate
their actions over a widespread area.

Disaster response settings, such as wildfire suppression or hurricane
relief, are marked by systemic communications challenges. A 2023
report by the President’s Council of Advisors on Science and
Technology (PCAST) cites the need to address ``the vulnerabilities and
shortfalls in wildland firefighter communications, connectivity, and
technology interoperability'' in their top recommendation
\cite{pcast2023} for wildland firefighting modernization. Many of
these shortfalls can be partly attributed to factors inherent to
disaster response: remote locations, difficult terrain, damaged
infrastructure, harsh weather, and limited power, to name a few.

Field agents generally face high message loss, distorted signals, and
unpredictable latencies when communicating. A conservative view
suggests preparing for the worst performance at critical times:
network difficulties often coincide with the sorts of conditions that
demand urgent, reliable contact. Disasters often damage and degrade
the communications infrastructure, and sudden overwhelming demand can
often overwhelms a network completely. This was starkly evident in the
immediate aftermath of the September $11^\textrm{th}$ terrorist
attacks, when sudden user demand and severed trunk cables crippled New
York public cell phone networks, including dedicated networks for
first responders \cite{2011:Reardon}. These failures later became the
impetus for the creation of FirstNet \cite{2021:firstnet,
2021:firstnet2}, a national public safety broadband network (NPSBN).

An unreliable network presents a challenge for coordinating
distributed agents. Coherent decision-making and coordinated action
require consistency, i.e.~agreement, among data shared between
agents. We shall make this somewhat vague notion more precise in
Section \ref{sec:background}, but the intuition is clear: it is very
important for everyone to agree which firetrucks should respond to
which scenes, where the helicopter should land, which tasks should be
prioritized, or which radio frequencies have been reserved for
which purposes. Stronger standards for consistency are more difficult to
maintain than relaxed ones because they require exchanging more
information in less time, putting a heavier burden on the
network. When a communications link is slow, system components that
need to coordinate may have to pause and wait, diminishing the
efficacy of the system. In response, standards for consistency may have to be relaxed, which presents its own issues.

\subsection{Communication and Safety}
\label{communication-and-safety}
We shall turn our attention to the fundamental nature of the consistency/latency tradeoff from a safety
perspective. Operational safety requires agents to gather information about their
environment and react to it quickly and systematically. This
information is transmitted over communication networks, so a poor
communications environment is a safety problem. Poor communication
forces agents to choose between delays in sending and receiving
information or acting with only limited knowledge, but inaction and
uninformed action are both problematic. This observation turns out to
be related to a deep computer science phenomenon generally known as the
safety/liveness tradeoff.

As a running example, we consider the use of firefighting airtankers,
the largest of which are the Very Large Airtankers (VLATs), defined as
those carrying more than 8,000 gallons of water or fire retardant
\cite{2019:airtankerops}. The largest VLATs can deposit more than
20,000 gallons, weighing about 170,000 pounds, in a single ``drop.''
In the United States today, a typical policy is to perform drops from
a mere 250 feet above the tree canopy \cite{2019:airtankerops}, though
it is common to hear of drops performed from lower altitudes. Such a
maneuver can easily crush a ground vehicle \cite{2019:stickney}. A
2018 accident led to the death of one firefighter and the injury of
three others when an 87-foot Douglas Fir tree was knocked down by an
unexpectedly forceful drop from a Boeing 747-400 Supertanker
\cite{2018:calfire}.

\begin{figure}[h]
  \label{fig:airtanker}
  \centering
  \includegraphics[scale=0.4]{images/dc10.jpg}
  \caption{A DC-10 airtanker, rated for 9,400 gallons, drops retardant above Greer, Arizona. \citationneeded.}
\end{figure}
% https://www.flickr.com/photos/apachesitgreavesnf/5837741382
% Also appears at https://www.nifc.gov/resources/aircraft/airtankers

Increasingly, wildland firefighters are using tactical applications on
ordinary cellphones to coordinate their activities in the field. The Android Team Awareness Kit (ATAK), initially developed by the American military in 2010 and released (in a stripped-down version) for civilian use, has seen particularly widespread adoption. One possible use of ATAK would be to systematically track the GPS locations of firefighters on the ground for safety monitoring purposes. A seemingly reasonable policy then would be to prohibit VLATs from performing a drop if its computers do not have up-to-date information about the location of firefighters on the ground.

Unfortunately, system-wide safety is not so easily achieved, as information from agents in the field may be
difficult or impossible to gather for a wide variety of reasons. The wildland firefighting environment is frequently GPS-denied: heavy smoke, multipath effects, and so on can easily prevent a consumer-grade cellphone from obtaining reliable GPS coordinates. Additionally, factors like a damaged radio tower or environmental obstructions (e.g. a tall mountain) can prevent communications between the air and
ground. Such conditions would prevent a VLAT's computers from knowing the locations of ground agents, in which case rigid enforcement of the safety policy would prevent them from operating. Of course, simply grounding the VLATs would itself be a safety challenge, since they are a major tool in controlling wildfires.

The previous scenario exemplifies a classic tradeoff between opposing goals in computer science:
system \emph{safety} (which in this context takes on a narrow technical meaning) and system \emph{availability} or \emph{liveness}. In
the distributed computing context, safety properties guarantee that a
system will not perform an action that violates a constraint. An
exemplary safety property could look like the following:
\begin{quote}
  \interlinepenalty=10000 % Punish pagebreaks inside this quote!
  $\textbf{P}_\textrm{safe}$: Ground agents are known to be at least
  100 feet outside the drop zone, and this information is current to
  within 30 seconds, or airtankers will not perform a drop.
\end{quote}
By contrast, liveness properties stipulate that the system will
certainly perform requested actions, typically within some time
bound. An exemplary liveness property might be the following:
\begin{quote}
  $\textbf{P}_\textrm{live}$: A VLAT on the ground will takeoff and
  perform a drop within 20 minutes of receiving a request from an
  incident commander.
\end{quote}
(In an interview with PBS \cite{2021:aerialfirefighting}, the Chief of Flight Operations for Cal Fire cited 20
	minutes as an upper bound on the response time for aerial firefighting units
	within designated responsibility areas.)

Safety and liveness are frequently dual mandates: safety, in the technical sense
used here, is a requirement for a system to \textbf{never} to perform certain
actions, while liveness is a requirement to \textbf{always} perform
certain actions. The tension between these ideals means they often
cannot be guaranteed simultaneously. Such is the case in our example:
if firefighters are unable to broadcast their locations to the pilot,
then one of \(\textbf{P}_\textrm{safe}\) or \(\textbf{P}_\textrm{live}\) must be sacrificed to maintain the other.

It is worth emphasizing a slight linguistic idiosyncrasy exhibited above, specifically by $\textbf{P}_\textrm{live}$:
liveness properties---not just ``safety'' properties---can
be relevant to human safety. Thus, the narrow technical meaning of
safety properties for computing systems does not capture the whole
meaning of System Wide Safety. The tension between ``safety'' (in the narrow sense) and liveness is a more-or-less unavoidable challenge for any distributed computing system relevant to human safety (in the ordinary sense).

Besides the safety/liveness tradeoff, the previous example exhibits
two other themes common in the field of distributed systems, both of which will be revisited throughout this document. We pause to draw attention to them.

\paragraph{Epistemology}
Observe that the issue in the VLAT example does not simply disappear
if no ground personnel are actually within 100 feet of a drop
zone. That is, it is not simply a matter of whether a danger is
factually present. To guarantee \(\textbf{P}_\textrm{safe}\), an
airtanker's actions must be restricted when its computers do not
\emph{know} whether an action would violate
\(\textbf{P}_\textrm{safe}\)---knowledge of the fact, and not merely
the fact of it, is the crucial part. In philosophical terms, the logic
of distributed agents is inherently an \emph{epistemic} one, meaning
it must take into account not just what is true but what is known. The
need to share knowledge is what drives communication and puts a burden
on the network.

\paragraph{Discontinuity}
The properties $\mathbf{P}_\textrm{safe}$ and
$\mathbf{P}_\textrm{live}$ are inflexible, all-or-nothing
propositions. The complexity of the operational environment demands
considering more flexible kinds of properties. Suppose that agents are
known to be $500$ feet outside the drop zone, the extra margin meaning
they are well away from any danger, but the information is only
current to within 35 seconds. Clearly this is good enough information
to authorize a drop, but strictly speaking the 5-second difference is
a violation of $\mathbf{P}_\textrm{safe}$. When safety properties are
this rigid, the system's behavior becomes overly sensitive to the
particulars of the environment and therefore difficult to predict,
which is precisely the kind of \emph{discontinuity} that we aim to
prevent. Our goal is to build reliable systems that perform well in a
wide range of circumstances.

\subsection{Communication Patterns in the Field}
\label{communication-in-practice}

We now consider some of the communication patterns that occur in
wildland firefighting. The layman reader may be surprised to learn
that the state of the art is somewhat primitive, which is partly
attributable to the fact that very little permanent infrastructure
exists in this setting. This fact is also what makes wildfires an
interesting and generalizable example for other kinds of civil
disaster environments.

One trend we will draw attention to is a kind of ``geospatial locality
of reference'' principle that system designers should take into
account. By this, we mean the happy coincidence of two observations
which, if not exactly guaranteed rules, are at least approximately
true in many circumstances. The first observation is simple:
\begin{quote}
  $\textbf{O}_1$: Agents with the most urgent need to
  coordinate their actions will tend to be located closer to each
  other and require the same kinds of information.
\end{quote}
The second observation is as follows:
\begin{quote}
  $\textbf{O}_2$: Agents that are located closer together
  will tend to have more reliable communications between them than
  agents that are far apart. Conversely, information that must travel
  a long distance tends to be delayed or degrade in quality.
\end{quote}

We will refer to the concomitance of these two facts as simply the
``locality'' principle. The reason the locality principle is crucial
is that, as we see in Section \ref{sec:background}, there are major
theoretical and practical limits to how well \emph{all} agents in the
system can share \emph{all} information with each other, i.e. how well
a system can achieve global consistency. As luck would have it, in
many cases this will not be required: it will be often be enough for
\emph{some} agents to share \emph{some} information with each other, a
fact that raises opportunities to optimize scare network resources. Of
course, this does raise the question of how to decide which
information must be shared with whom, and how to use this knowledge to
best exploit the communication network. We will revisit this question,
without the pretense of answering it conclusively, throughout Sections
\ref{sec:networking}, \ref{sec:continuous-consistency} and
\ref{sec:data-fusion}. For now, we resume our examination of what
communication patterns look like today.

\paragraph{Communication on the ground}
In the field, communication between firefighters and other agents is
often facilitated by handheld (analog) land-mobile radios, which are
inherently limited in their battery life, bandwidth, effective range,
and ability to work around environmental factors like foliage and
smoke.

As an alternative to using a radio, it is common for wildland
firefighters in the field simply to shout commands and notifications
to nearby personnel. This is a clear manifestation of the locality
principle: a substantial amount of communication occurs directly
between nearby firefighters working on the same or closely related
tasks, and in some cases they are so nearby they can communicate
without any network infrastructure at all. In a future environment
where agents might be equipped with body-worn sensors and heads-up
displays (HUDs) \citationneeded, this sort of local communication
might be facilitated by simple low-power technologies such as
Bluetooth, without the need for more sophisticated (and heavy)
equipment.

Communication over a long distance requires infrastructural support,
such as the use of cell towers and repeater stations. Typically,
disaster response environments have scarce permanent infrastructure:
in a wildland fire setting, perhaps a few repeaters mounted to a
nearby watch tower. Ad-hoc infrastructure, such as cells on wheels
(COWs) or cells on light trucks (COLTs)---i.e. portable cellular towers---can sometimes be deployed on an as-needed basis if the location
allows for it. Similar kinds of equipment can also be mounted to backpacks and carried into the field by specially-trained agents.

An extremely common issue is making sure that all
equipment is properly configured, for instance that all radios are
listening on the correct frequencies, particularly when different
agencies and groups need to interoperate (another problem highlighted
during the September $11^\textrm{th}$ attacks).

\begin{figure}[t]
  \centering
  \includegraphics[scale=0.085]{images/ironside.jpg}
  \caption{The Ironside Mountain lookout and radio repeater station, destroyed in the 2021
    Monument fire, shown with protective foil on August
    $10^\textrm{th}$, 2015 during the 2015 River Complex fire. This
    particular fire burned 77,077 acres over 77 days. \citationneeded}
  \label{fig:ironside}
\end{figure}
%https://web.archive.org/web/20150923190323/http://inciweb.nwcg.gov/incident/photograph/4431/44/45122/

Use of centralized infrastructure comes with the potential for
widespread failure when the infrastructure breaks down. For example,
in California, the Ironside Mountain lookout/repeater station, seen in
Figure \ref{fig:ironside}, was destroyed during the 2021 Monument
Fire, which burned approximately 223,124 acres over 88 days
\cite{2021:monumentfire}. The Ironside Mountain station had strategic
importance, being located on a tall ridge. According to a video blog
from a volunteer firefighter involved in the incident \cite{2022:mechfire},
% See also https://web.archive.org/web/20220809061927/https://www.youtube.com/watch?v=4F2dDKMgAME
its loss prevented communication between operators on different sides
of the ridge, in networking parlance creating a \emph{partition} that
lasted until crews could ascend the ridge to deploy a temporary
station:
\begin{quote}
  ``When {[}the Ironside Mountain lookout station{]} burned down the
  radio repeater went with it. And so communications were lost across
  the fire\ldots{} one side of the fire couldn't talk to the other
  side\ldots.  So it was kind of a critical job to get that road
  cleared so that the radio crews could go back up there and set up a
  temporary radio tower.''
\end{quote}
A scenario where communication between two groups is completely
severed is exactly the sort of thing considered by the CAP theorem in
Section \ref{sec:background}.

\paragraph{Vehicles on the ground}
Large numbers of ground vehicles---sometimes on the order of 100 during a major response---are involved in wildfire suppression. Besides various types of firetrucks, bulldozers and similar vehicles are commonly used to control the landscape and perimeter of the fire. An advantage of vehicles is that they can carry
heavier and higher-power communications equipment than a human. For instance, a vehicle could be equipped with a BGAN or VSAT satellite terminal or cellular equipment as mentioned previously. Additionally equipping the vehicle with something like a wireless local area network (WLAN) base station, i.e. WiFi access point, would let the vehicle serve as a bridge between agents in the field and central coordinators such as incident commanders or 911 dispatchers.

\paragraph{Communication in the air}
Wildland firefighting increasingly involves the use of helicopters and
fixed wing aircraft. Civil aviation has traditionally employed simpler
communication patterns than this use case demands. For instance,
aircraft equipped with Automatic Dependent Surveillance-Broadcast
(ADS-B) monitor their location using GPS and periodically broadcast
this information to air traffic controllers and nearby aircraft. This
sort of scheme has worked well in traditional applications, where
pilots typically only monitor the general locations of a few nearby
aircraft. The locality principle is exhibited here, too: aircraft have
the highest need to coordinate when they are physically close and
therefore in range of each other's ADS-B broadcasts.

In our setting, a large number or aircraft, easily a half dozen or
more, may need to operate in a small area, near complex terrain,
during adverse conditions, often at low altitude. In other words, the
demands are many and the margins for error are small. This sort of use
case calls for more sophisticated coordination schemes between
airborne and ground-based elements than solutions like ADS-B provide
by themselves.

\paragraph{Message relaying}
As aircraft generally have better line-of-site to ground crews than
ground crews have to each other, firefighters sometimes relay messages
to air-based units over the radio, which in turn is relayed back down
to other ground units. The locality principle comes into play for this
sort of message relaying scheme, but in the negative direction:
relaying allows knowledge to travel farther but requires more resources and effort,
and the extended reach comes at the cost of introducing delays and
possible degradation of message quality, as in the classic game of
``telephone.'' Hence, this mode of communication has generally been reserved for
more critical information.

The Communications Program of the Civil Air Patrol (a civilian
auxiliary of the U.S. Air Force) is sometimes deployed to provide
communications for firefighters on the ground using airplane-mounted
radio repeaters. Air-based repeaters are better than the ``telephone''
scheme in the previous paragraph as they do not require as much human
intervention to receive and re-transmit information. That is, this
form of relaying is more \emph{transparent}. In this future, this sort
of service could be provided autonomously by repeaters mounted to
unmanned aerial vehicles (UAVs), which might perform additional
functions such as tracking the fire perimeter.

In Section \ref{sec:networking} we imagine a resilient ad-hoc digital
network built from handheld and ground- and air-vehicle-mounted
devices, permanent base stations, portable temporary infrastructure,
and so on. In effect, this would be a high-tech modernization of the
sort of informal relay schemes operating today over traditional radio
channels.

%More generally, future systems should transparently facilitate
%exchanging information between agents in a decentralized fashion that
%is robust to the failure of any one component.

\subsection{Data Collection and Processing}
\label{towards-the-future}
%So far we have said a lot about the state of disaster response
%today. A distributed system for this sort of challenge should be
%designed for the kinds of environments and conditions expected in the
%near- to medium-term future, so we briefly turn our attention to some
%of our expectations for this topic.

Perhaps the most prominent expectation for future disaster response
events is a heavy reliance on \emph{data} gathered from both humans and various types of sensors. Besides improvements to
communications that facilitate information sharing, we expect advances
in machine intelligence to greatly influence how this data is
processed and used.

Agents in disaster response environments will be both
producers and consumers of data, and this data will need to processed
by humans and machines in ways that agents can readily make sense of
to support their decision-making. Our background research indicated
many different kinds of data that could be valuable for
responders, just some of which are listed here:
\begin{itemize}
\item Free-form communication, especially recorded voice messages
  broadcast to many agents at once, which may need to be processed by
  machines to extract the most pertinent information into a more
  actionable format
\item The exact or estimated location of victims, firefighters,
  vehicles, hazards, etc.
\item Medical information gathered from victims, perhaps stored in and
  collected from electronic triage tags \cite{2009:triagetag}
\item Data about current and predicted fire or weather patterns
\item Topographic information about the terrain, highlighting for
  instance the location of rivers and roads that could form a fire
  control line
\item Planned escape routes, rendezvous points, safety zones, and
  landing zones
\item Availability and dispatching of assets, e.g.~ambulances,
  airtankers, or crews on standby, such as the prototype application
  considered by Monares et al. \cite{2011:monares}
\end{itemize}
In a perfect environment, such information would be shared with all
necessary agents in whole and instantly. In reality, agents will be
presented with information that is sometimes incomplete, out of date,
or contradictory---all problems that are further exacerbated by an
unreliable network. A competing concern is that the information
presented will be \emph{overcomplete}, filled with petty details that
distract agents from their important tasks.

In some ways, future systems for disaster response will bear
resemblence to future systems for warfighting, such as the conceptual
\emph{Internet of Battle Things} (IoBT) \cite{2016:iobt}. To quote from that paper,
agents ``under extreme cognitive and physical stress'' will be subject
to a highly dynamic and dangerous environment. Various kinds of
technology will assist humans by providing data to support
sensemaking, but a contraindicating concern will be flooding agents with a
``massive, complex, confusing, and potentially
deceptive\footnote{While deliberately adversarial network behavior
seems like less of a concern for disaster response agents than
warfighters, we conjecture that a similar ``fog of war'' may
lead to confusing or contradictory reports that share similarities
with intentionally deceptive behavior.} ocean of information.'' To
avoid ``swimming in sensors and drowning in data''
\cite{2010:magnuson}:
\begin{quote}
``Humans seek well-formed, reasonably-sized, essential information
  that is highly relevant to their cognitive needs, such as effective
  indications and warnings that pertain to their current situation and
  mission.'' \cite{2016:iobt}
\end{quote}

One feature of the Internet of Battle Things worth highlighting is ``the
adversarial nature of the environment.'' To some extent this adversial
behavior is common also to disaster response. We previously cited a
real-world example of a critical communications station destroyed by
wildfire, perhaps not unlike an attack by enemy forces. In a video
interview with a member of the volunteer rescue group Cajun Navy
\citationneeded, one volunteer indicated it was very common to hear
rumors, for example that gunshots were being fired at rescuers
in a particular area, which were later found to be presumably false. Whether malicious or well-intentioned, the
proliferation of false information in this chaotic environment can
be considered a kind of adversarial behavior. Thus, battlefields and civil disaster response environments might have more in common than a superficial examination might suggest.

Setting aside the possibility of offensive behavior like signal
jamming, communications in disaster response environments might even
be less reliable than in the battlefield, requiring a greater emphasis
on the preservation of scarce network resources. Certainly a group of
(say) volunteer firefighters would have fewer resources than a
tactical military unit, making do with commercial off-the-shelf (COTS)
equipment rather than best in class hardware like sophisticated
handheld satellite links. High bandwidth channels will often be in
short supply, while adverse conditions like inclement weather are
assumed.

Given the heavy reliance on data and the scarcity of reliable
communication channels, we expect a complex interaction between the
high-level needs of distributed applications (e.g. an application for
sharing real time weather data) and low-level concerns about network
resources. This is because only the applications have enough
information to determine which data is the most important and must be
shared with whom first, while only the network-level protocols have
enough information and control to make prudent use of scarce network
availability. While there is a generally accepted wisdom in computing
(the end-to-end principle \citationneeded) that applications should be
relatively agnostic about network considerations---or conversely that
network protocols ought to be transparent to applications---our
setting calls for mechanisms allowing the two layers to have what
might be a great deal of influence over the other. This interaction
between the network and applications will be considered in more detail
in Sections \ref{sec:networking}, \ref{sec:continuous-consistency},
and \ref{sec:data-fusion}.

Consider a centralized data fusion application that runs in an edge
data center \citationneeded that might be managed by a wireless
carrier, a cloud hyperscaler, or government agency like NIFC. This
application could detect critical events like a fire crossing a
control line (a phenomenon called \emph{slopover}) and alert ground
responders. It might also warn responders who have strayed too far
from an escape route or safety zone. These are high-priority
notifications, so it would be worthwhile to allocate scarce network
resources to convey them to the relevant parties in real-time.

On the other hand, while it may be beneficial for each firefighter to
have real-time information about the GPS location of every other
firefighter, this may not always be critical. If transmitting this
data strains the network, then perhaps only the general location of
other crews or nearby teams should be sent. If the network is
extremely constrained, communication may be restricted to only
information strictly relevant to preserving life to ensure this is
delivered swiftly and reliably. Thus, network allocation is a dynamic
calculation influenced both by the criticality of the information and
the availability of network bandwidth at any a particular
location. Advanced systems should provide mechanisms like Quality of
Service (QoS) indicators to allow prioritizing certain
communication. Such mechanisms can be incorporated into a control loop
where applications generate feedback that drives the decision-making
process in lower-level parts of the network.

\section{Introduction to Distributed Systems}
\label{sec:background}
In this section, we distill two core topics in the theory of
distributed systems: causality and timekeeping, along with shared
memory consistency.  Our discussion is primarily informed by the
manuscripts of Coulouris et al.  \cite{coulouris2005distributed} and
Kshemkalyani and Singhal \cite{kshemkalyani_singhal_2008}. We focus on
building applications relevant to the scenarios described in Section
\ref{sec:disaster-response}, aiming to highlight obstacles and
strategies for developing distributed systems that can endure the
delays and disruptions inherent to these communication-challenged
environments. Readers wishing for a condensed summary of the main
highlights may skip to Section \label{ssec:background-summary}.

At its core, a distributed system is a network of independent entities
working together to solve problems too complex for any one part to
tackle alone. From a bird’s-eye view, the systems we envision are
intricate and complex, made up of diverse, interconnected elements:
field agents like firefighters, their handheld devices, airborne and
ground vehicles loaded with communication and computing tools, swarms
of sensors and IoT devices, and so on. These decentralized components
operate alongside more centralized hubs: data fusion centers, incident
commanders, public safety answering points (PSAPs), and emergency
operations centers (EOCs). We imagine these components being woven
together by a patchwork of communication technologies ranging from
analog and digital radios to Bluetooth, Wi-Fi, LTE, 5G, satellite
links, and ad-hoc mesh networks like Meshtastic \citationneeded and
DECT-2020 NR \citationneeded. Together, the systems form a dynamic
mosaic of elements cooperating to save lives and protect proprty.

Given the unpredictable nature of the environment and the locality
principle outlined in Section \ref{sec:disaster-response},
communication between edge components---such as field operators---and
centralized hubs is often inconsistent, sometimes available only
intermittently. As a result, information flow is subject to
appreciable delays compared to the timescale of critical events like a
fire shifting direction or a dangerous condition being detected. In
other words, the computing landscape is unmistakably
\emph{distributed}. Singhal and Shivaratri \cite{10.5555/562065}
define a distributed computing system as:
\begin{quote}
  ``A collection of computers that do not share common
  memory or a common physical clock, that communicate by message
  passing over a communication network, and where each computer has
  its own memory and runs its own operating system.''
\end{quote}
This stands in contrast to a centralized computing environment, where
processes can seamlessly share data through common memory, and memory
access times are considered negligible.

For our use cases, message-passing latencies are not only significant
but unpredictable and difficult to control. As a result, we can safely
assume that some parts of the wider system will not have
instantaneous, complete knowledge of every new piece of
information. Only a few components, if any, will be able to maintain a
global systemwide awareness. While deploying additional network
resources in the field—such as COWs (Cells on Wheels) and COLTs (Cells
on Light Trucks)—can help, the inherently distributed nature of the
environment cannot be fully overcome or abstracted away. This reality
must be embedded in the design of the software and networking
architecture itself. Typically, this manifests in a shared
`middleware' layer to coordinate the numerous moving parts, ensuring
they function as a unified system.

The fragmented flow of information presents several challenges for
system designers. Foundationally, one of the primary computer science
problems is that unpredictable latencies make it difficult for
components to maintain a common understanding about the global
sequence of events. For similar reasons, it becomes challenging for
processes to synchronize and agree on shared values, such as the
current number of firetrucks available for dispatch. The remainder of
this section will delve into these issues with more technical depth,
while later sections will examine how some of these challenges can be
reflected in the middleware design.

\subsection{The challenge of physical  synchrony}
\label{ssec:causality}
A lot of challenges in distributed computing could be
straightforwardly overcome if we assume that all participants have
instantaneous access to a common time base, i.e.  synchronized
clocks. Let us explore why fine-grained synchronization is not a
tenable assumption, at least not for all purposes.

Physical clocks, especially consumer-grade ones, suffer from
\emph{drift}, which is to say they do not all run at the same
rate. Experienced IT administrators will testify that clocks can also
be prone to misconfiguration. An incorrect date, time, timezone, or
daylight saving time policy setting is a common source of IT issues,
typically causing time-based security mechanisms like TLS
authentication \citationneeded to misbehave. Consider also that
devices may spend a long time sitting unpowered in storage without
maintaining an always-on clock. For these sorts of reasons, we would
not want to rest the integrity of a safety-related system on the
assumption that a numerous and diverse assortment of devices have
precisely synchronized internal clocks.

Clock drift can be corrected for using, for instance, signals from GPS
satellites, but as mentioned in Section \ref{sec:disaster-response},
civil disaster environments are frequently GPS-denied: factors like
mountainous terrain, heavy smoke, and subterranean operations can lead
to errors or block signals entirely. Protocols like the Network Time
Protocol (NTP) \cite{rfc1119} work to bring clocks into
synchronization with respect to an authoritative source. Over a
moderately challenged connection, NTP typically achieves synchrony to
within values on the order of 100ms \citationneeded, but it is not
clear the level of synchrony that can be expected from NTP in the
sorts of use cases we have in mind. A field device initialized without
internet access may have no idea what the time is, but it must still
operate.

For our use case, what seems most important about time is that
\emph{the future cannot influence the past}
\cite{1989mattern}. Fortunately, this sort of invariant can be
enforced with mechanisms that do not rely on measuring real
time. Below, we explain how so-called logical clocks can be used to
measure and enforce a key relation between events, this being their
\emph{causal precedence}.


\subsection{Message Passing and Causality}
\label{ssec:message-passing}
We model a distributed system abstractly as a fixed set
$\mathcal{P} = \{P_1, P_2, \ldots P_n\}$ of \emph{processes} which
undergo atomic (indivisible) state changes known as
\emph{events}. Events are divided into three types: internal events,
representing state changes inside a single process, and send and
receive events corresponding to messages passed between processes. It
may be helpful to imagine processes as radios and messages as audio
broadcasts, though the framework we are using is abstract and applies
to any kind of communication technology. To draw out the core issues
surrounding messaging, the diagrams in this section do not depict any
internal events.

Throughout the section, processes and networks are opaque blackboxes,
which concentrates our attention on the ramifications of unpredictable
network latencies. We implicitly assume the reliable asynchronous
network model: when a message is sent between processes, it certainly
arrives at some point in the future, but we cannot say anything about
when or in what order compared to other messages. At times, we
consider the possibility that a message may never arrive. The choice
depends on which networking technology (or which layer of the OSI
networking model \citationneeded) is under consideration.

Figure \ref{fig:message-latencies} illustrates a series of time
diagrams for messages exchanged between three processes: $P_1$, $P_2$,
and $P_3$. The $x$-axis represents the flow of real time from left to
right, which each process represented by a worldline depicting the
events occurring within that process. Each message, $m$, originates
from a send event $\msend{}$, marking the moment the message is
dispatched across the network by its source process. The delivery of
the message corresponds to a receive event, $\mrecv{}$. For now we
assume messages have a single receiver. We write subscripts on
messages to distinguish them for clarity, but these are not inherent
to the messages themselves.

\begin{figure}[p]
  \setlength\belowcaptionskip{5ex}
  \begin{subfigure}{1\textwidth}
    \centering
    \input{images/pgf/mpEx1.pgf}
    \caption{$P_1$ has a somewhat lower-latency connection to $P_2$ than to $P_3$}
    \label{fig:message-latencies-a}
  \end{subfigure}
  \begin{subfigure}{1\textwidth}
    \centering \input{images/pgf/mpEx2.pgf}
    \caption{$P_1$ has a much lower-latency connection to $P_2$ than to $P_3$}
    \label{fig:message-latencies-b}
  \end{subfigure}
  \caption{Message-passing time diagram examples}
  \label{fig:message-latencies}
\end{figure}

In these diagrams, arrows connect corresponding send and receive
events, with their diagonal slant representing the latencies
experienced as messages traverse the network. Because messages arrive
with varying delays, they might arrive in a different order than they
were sent in. In Figure \ref{fig:message-latencies-a}, for example,
$P_1$ sends messages $m_2$ and $m_4$ sequentially, but $m_4$ arrives
before $m_2$, which might occur if $P_1$ and $P_3$ are separated by a
high-latency communication link. In Figure
\ref{fig:message-latencies-b}, $m_1$ is the first message sent but the
last to be delivered, potentially indicating a deteriorating link
between $P_1$ and $P_3$, perhaps due to increased distance or
inclement weather.

For many applications, it is critical to maintain a natural ordering
of events known as \emph{causal precedence}, or Lamport's ``happens
before'' relation \cite{1978:lamportclocks}. To formalize this, we
first consider the intuitive way to order events within a
\emph{single} process:
\begin{definition}
  For two events $e$ and $e'$ occurring in process $P_i$, we
  write $e <_{P_i} e'$ if $e$ occurs before $e'$ in $P_i$'s
  worldline.
\end{definition}
The previous definition is local to one process and unambiguous, as we
assume events within a process occur at discrete, non-overlapping
points in time. To extend this to a system-wide definition of causal
precedence, we relate corresponding send and receive events, then take
the transitive closure of the relation.

\begin{definition}[Causal precedence]
  \label{def:causalprecedence}
  We define a binary relation $\to$ on the set of events as follows:
  \[e \to e' \iff
  \begin{cases}
    e <_{P_i} e' \textrm{ for some process $P_i$}
    \textbf{ or} \\
    e = \msend{} \textrm{ and } e' =\mrecv{}
    \textbf{ or} \\
    \textrm{there is some } e'' \textrm{ such that } e \to e'' \textrm{ and } e'' \to e'
  \end{cases}
  \]
  If $e \to e'$, we say $e$ has \emph{causal precedence over} $e'$ or
  \emph{happens before} $e'$.
\end{definition}
Visually, $e \to e'$ holds when one can put a finger on $e$ in the
diagram and trace a ``path of causality'' to $e'$ by following
worldlines or arrows. We use the notation $e \not \to e'$ to mean
$e \to e'$ does not hold. Note that $e \not \to e'$ does not imply
$e' \to e$.

Incidentally, ``causal precedence'' and ``happens before'' can be
misnomers, as $e \to e'$ only conveys the possibility that information
from $e$ could have influenced $e'$. If information from event $e$
might have influenced $e'$, then it is crucial that applications avoid
situations where, from the user's point of view, it appears that $e'$
happened before $e$. For example, this proscription means an
application cannot let an ``answer'' appear before the underlying
``question''. This is what is meant by not letting the future affect
the past.

\begin{example}
  Figure \ref{fig:causal-precedence} illustrates the causal precedence
  relation corresponding to the time diagrams in Figure
  \ref{fig:message-latencies}. For readability we suppress redundant
  transitive arrows. The visual difference between Figures
  \ref{fig:message-latencies-b} and \ref{fig:message-co-b} reflects
  the fact that causal order only captures a logical relationship
  between events, but does not reflect their absolute time or within
  which process they occurred.
\end{example}

Mathematically, causal precedence is an irreflexive partial order:
\emph{irreflexive} because $e \not \to e$ (an event does not precede
itself), and \emph{partial} because any two events $e$ and $e'$ may
satisfy neither $e \to e'$ nor $e' \to e$. Events $e$ and $e'$ that
are not related by causality are said to be \emph{logically
  synchronous}, denoted $\sync{e}{e'}$. Note that logical
synchronicity is not usually transitive, meaning it is possible to
have $\sync{e}{e'}$ and $\sync{e'}{e''}$ but not $\sync{e}{e''}$. For
example,
\begin{itemize}
\item In Figure \ref{fig:message-co-a}, $\sync{\mrecv{1}}{\mrecv{2}}$
  and $\sync{\mrecv{2}}{\msend{4}}$, but $\mrecv{1} \to \msend{4}$.
\item In Figure \ref{fig:message-co-b}, $\msend{1}$ is logically synchronous
with every event except $\mrecv{1}$, but those other events are
totally ordered by causality and not synchronous with each
other.
\end{itemize}
Relations like $\sync{}{}$ that are reflexive and symmetric but
not necessarily transitive are sometimes called \emph{compatibility
  relations}.

\begin{figure}
  \begingroup
  \setlength\belowcaptionskip{4ex}
  \begin{subfigure}{1\textwidth}
    \centering
    \input{images/pgf/mpEx1CO.pgf}
    \caption{Causal precedence among the events in Figure \ref{fig:message-latencies-a}}
    \label{fig:message-co-a}
  \end{subfigure}
  \endgroup
  \begin{subfigure}{1\textwidth}
    \centering
    \input{images/pgf/mpEx2CO.pgf}
    \caption{Causal precedence among the events in Figure \ref{fig:message-latencies-b}}
    \label{fig:message-co-b}
  \end{subfigure}
  \caption{Causal precedence relations for Figure \ref{fig:message-latencies} (transitive arrows not shown)}
  \label{fig:causal-precedence}
\end{figure}

\subsection{Virtual Clocks}
\label{ssec:timestamps}
Distributed applications systematically track causality by employing
\emph{logical} clocks, which measure the logical flow of time by
timestamping events with (possibly sets of) non-negative integers that
are advanced according to certain rules. The three major variants are
scalar, vector, and matrix clocks, which form a kind of
spectrum. Scalar clocks are simple but provide coarse-grained
information, while vector and matrix clocks track increasingly more
precise information at the cost of greater administrative overheads.

All processes timestamp their events using their local clocks. For
each event $e$, let $C(e)$ denote the timestamp attached to that
event. The fundamental property we want to satisfy is that if $e$
causally precedes $e'$, it should receive a lesser timestamp. This is
called the clock consistency condition, commonly just called the clock condition.

\begin{definition}
  A system of timestamps satisfies the \emph{clock consistency
  condition} if the following monotonicity property holds:
  \[ \textrm{For all events $e$ and $e'$, } e \to e' \implies C(e) < C(e') \label{eq:mp}\tag{CC} \]
\end{definition}

This notation states that if one event causally precedes another, then
the earlier one receives a lesser timestamp. Somewhat subtly, the
clock condition does \emph{not} imply that we can decide if events are
causally related by comparing timestamps. It may be helpful to express
\eqref{eq:mp} in terms of the following logically equivalent
condition.
\[ \textrm{For all events $e$ and $e'$, }C(e) \leq C(e') \implies e'
  \not\to e \label{eq:mp-conv}\tag{CC$'$} \]

If this condition is true, we can be sure that a particular sequence
of events $e_1, e_2, e_3\ldots$ does \emph{not} violate causal
precedence (i.e., does not list any event $e$ before another event
that could have influenced $e$) by checking that
$C(e_{i}) \leq C(e_{i+1})$ for all $i$. We emphasize that this does
not give us a definite way to tell whether two events are in fact
causally related.

For some applications it is important to determine conclusively
whether events are causally related. In this case, one is led to
consider the following stronger requirement from a system of logical
timestamps.
\begin{definition}
  An event-timestamping mechanism satisfies the \emph{strong} clock   condition if the following property holds.
  \[ \textrm{For all events $e$ and $e'$, } e \to e' \iff C(e) < C(e') \label{eq:sc}\tag{SC} \]
  Note that $\iff$ is notation for ``if and only if,'' i.e. logical equivalence.
\end{definition}
Below we see one logical clock protocol that satisfies the weaker
clock condition, and two that satisfy the stronger condition.

\subsubsection{Scalar clocks}
\label{sssec:scalar-clocks}
\begin{figure}
  \setlength\belowcaptionskip{5ex}

  \begin{subfigure}{1\textwidth}
    \centering \input{images/pgf/mpEx1Sc.pgf}
    \caption{Figure \ref{fig:message-latencies-a} redepicted with scalar clocks}
    \label{fig:message-latencies-scalar-a}
  \end{subfigure}

  \begin{subfigure}{1\textwidth}
    \centering \input{images/pgf/mpEx2Sc.pgf}
    \caption{Figure \ref{fig:message-latencies-b} redepicted with scalar clocks}
    \label{fig:message-latencies-scalar-b}
  \end{subfigure}

  \caption{Scalar clock examples}
  \label{fig:message-latencies-scalar}
\end{figure}

Lamport's scalar clocks \cite{1978:lamportclocks} require each
process $P_i$ to maintain a single non-negative scalar value $C_i$,
initialized to $0$. The clock follows two simple update rules:
\begin{enumerate}
\item[\textbf{R1}:] Before a message is sent or an internal event occurs, $P_i$
  increments its clock:
  \[C_i := C_i + 1.\]
  The new value serves as the event's timestamp and, for messages, is ``piggybacked''
  as part of its metadata.
\item[\textbf{R2}:] When $P_i$ receives a message with timestamp $C$, it
  updates $C_i$ as such:
  \[C_i := \max(C, C_i) + 1.\]
  The value is the receive event's timestamp.
\end{enumerate}

\begin{example}
  Figure \ref{fig:message-latencies-scalar} depicts the same events in
  Figure \ref{fig:message-latencies} with scalar timestamps (shown in
  parentheses) assigned to each event. Piggybacked timestamps are
  shown as labels on the message arrows.
\end{example}

Scalar clocks satisfy the clock condition \eqref{eq:mp}. This can be
observed by tracing the path of causality between related events and
seeing that the clock is incremented at each step. However, they do
not satisfy \eqref{eq:sc}.  While $e$ having a lesser timestamp than
$e'$ rules out $e' \to e$, it does not imply $e \to e'$. For instance,
in Figure \ref{fig:message-latencies-scalar-b}, $\msend{1}$ has a
globally minimal timestamp value of $1$, but it does not causally
precede all events with timestamps greater than $1$, or indeed any
event except $\mrecv{1}$.

\subsubsection{Vector clocks}
\label{sssec:vector-clocks}
The strong clock condition \eqref{eq:sc} cannot hold either using
scalar clocks or even synchronized physical clocks. This is because
both mechanisms assign timestamps whose values form a total order---meaning any
two distinct timestamps $C_1, C_2$ satisfy either $C_1 < C_2$ or $C_2 < C_1$.

A clock protocol that uses a total order cannot enforce the strong
clock condition. For logically synchronous events $\sync{e}{e'}$,
neither $e \to e'$ nor $e' \to e$ holds, so strong consistency and the
total order property would require $C(e) = C(e')$. This is an
impossible requirement because logical concurrency is not
transitive. For instance, recall that in Figure
\ref{fig:message-latencies-b}, $\msend{1}$ is logically synchronous
with every event except $\mrecv{1}$. This would require assigning them
all the same timestamp, which contradicts the fact they are not
synchronous with each other. The solution is to let timestamps from a
partial order, where distinct timestamps $C_1$ and $C_2$ do not have
to satisfy either $C_1 < C_2$ or $C_1 > C_2$.

\begin{figure}
  \setlength\belowcaptionskip{5ex}

  \begin{subfigure}{1\textwidth}
    \centering
    \input{images/pgf/mpEx1Vec.pgf}
    \caption{Figure \ref{fig:message-latencies-a} redepicted with vector clocks}
    \label{fig:message-latencies-vector-a}
  \end{subfigure}

  \vspace{4ex}

  \begin{subfigure}{1\textwidth}
    \centering \input{images/pgf/mpEx2Vec.pgf}
    \caption{Figure \ref{fig:message-latencies-b} redepicted with vector clocks}
    \label{fig:message-latencies-vector-b}
  \end{subfigure}

  \caption{Vector clock examples}
  \label{fig:message-latencies-vector}
\end{figure}
\afterpage{\clearpage}

Vector clocks store one scalar value for each process in the system,
which forms a partial order when vectors are compared
component-wise. If the system is comprised of $N$ processes, $P_i$
maintains a vector $\vt_i[1 \ldots N]$ of non-negative integers, with
all values initialized to $0$. The $i^\textrm{th}$ component, or
$\vt_i[i]$, is called $P_i$'s local time, while the remaining
components are used to estimate other processes' local times. Vector
clocks have two update rules:
\begin{enumerate}
\item[\textbf{R1}:] Before an internal event occurs or a new message is sent, $P_i$
  increments its local time according to the rule:
  \[\vt_i[i] := \vt_i[i] + 1.\]
  The (entire) updated $\vt_i$ is the event's timestamp and is piggybacked with outgoing messages.
\item[\textbf{R2}:] When $P_i$ receives a message with timestamp
  $\vt$, $\vt_i$ is updated according to
  \[\vt_i[x] := \max(\vt[x], \vt_i[x]) \quad \textrm{for all $x = 1\ldots N$}.\]
  After this, $P_i$ increments its local time:
  \[ \vt_i[i] := \vt_i[i] + 1.\]
  The final vector is the timestamp of the receive event.
\end{enumerate}
These rules are more intuitively understood by demonstration.

\begin{example}
  Figure \ref{fig:message-latencies-vector} depicts the same events as
  Figure \ref{fig:message-latencies-scalar} with vector timestamps.
\end{example}

For all $j \neq i$, $\vt_i[j]$ represents $P_i$'s \emph{estimate} of
$P_j$'s local time, or $\vt_j[j]$. This estimate is always a lower
bound, since $P_j$'s local time may advance without $P_i$'s knowledge,
but $P_i$ never updates $\vt_i[j]$ ahead of $P_j$'s actual local
time. $P_i$ learns about updates to $P_j$'s local time through
piggybacked timestamp vectors, which allow $P_i$ to learn about
$P_j$'s time without communicating directly with $P_j$.

Vector timestamps are compared component-wise. This forms a partial
order because one vector may be greater than another in some
components but less than it in others.

\begin{definition}[Vector comparison]
  Let $v, w$ be two vector clocks. We define the following relations:
  \begin{align*}
             v = w &\iff \forall i, v[i] = w[i] \\
  v \preccurlyeq w &\iff \forall i, v[i] \leq w[i] \\
         v \prec w &\iff v \preccurlyeq w \textrm{ and } \exists i, v[i] < w[i] \\
            \syncts{v}{w} &\iff \textrm{ neither } v \prec w \textrm{ nor } v \succ w
  \end{align*}
  That is, $v \prec w$ if all of $w$'s components are at least as
  great as $v$'s, and at least one of its components is strictly
  greater. When two non-equal vectors are compared, and neither is
  greater than the other, we write $\syncts{v}{w}$ and say the vectors
  are \emph{incomparable}.
\end{definition}

 is justified by the fact that vector
clocks satisfy \ref{eq:sc}, so these otherwise distinct notions will
coincide.

\begin{lemma}
  Vector clocks satisfy the strong clock consistency condition. That
  is, where $C(e)$ is the vector timestamp of an event, then
  \[ e \to e' \iff C(e) \prec C(e'). \]
  From this it follows that for non-equal events $e$ and $e'$ we have
  \[\sync{e}{e'} \iff {C(e) \texttt{\#}\,C(e')}. \]% This isn't typesetting right
\end{lemma}

For reasons of space we omit a proof of the preceding lemma, though
the reader may find it enlighting to formalize the details.

\subsubsection{Matrix clocks}
\label{sssec:matrix-clocks}
If a vector clock stores both a local time and a lower bound estimate
of every other process's local time, then a matrix clock stores a
local vector clock and a lower bound estimate of every other process's
vector clock. Each process $P_i$ stores an $N\times{}N$ matrix
$\vt_i$, initialized to all zeros, with the following
interpretation. The $i^{\textrm{th}}$ row from the top, $\vt_i[i, -]$,
stores $P_i$'s vector time. All other rows $\vt_i[j,-]$ store $P_i$'s
estimate of $P_j$'s vector time. Matrix timestamps are piggybacked
with messages, and the receiver uses the sender's vector clock to
update their own vector clock as usual, and takes the pointwise
maximum of all other rows.

\begin{enumerate}
\item[\textbf{R1}:] Before a new message is sent, $\vt_i[i]$ is updated according to the rule
  \[\vt_i[i,i] := \vt_i[i,i] + 1.\]
  The entire updated matrix $\vt_i$ is piggybacked with the message.
\item[\textbf{R2}:] When a message is received from $P_j$ with a piggybacked timestamp $\vt$,
  $\vt_i$ is updated according to two cases
  \begin{enumerate}
  \item Update the row $\vt_i[i, -]$ according to
    \[\vt_i[i, k] := \max(\vt_i[i,k], \vt[j, k]) \quad \textrm{for all $k = 1\ldots N$}.\]
  \item Update all other rows $\vt_i[j', -]$ according to
    \[\vt_i[j', k] := \max(\vt_i[j',k], \vt[j', k]) \quad \textrm{for all $k = 1\ldots N$}.\]
  \end{enumerate}
  After this, $P_i$ advances its own local time according to the rule
  \[ \vt_i[i,i] := \vt_i[i,i] + 1.\]
  This new matrix is the timestamp attached to the receive event.
\end{enumerate}

\begin{figure}[p]
  \begingroup
  \setlength\belowcaptionskip{4ex}
  \begin{subfigure}{1\textwidth}
    \input{images/pgf/mpEx1Mat.pgf}%
    \caption{Matrix clock timestamps for the events in Figure \ref{fig:message-latencies-a}}
    \label{fig:message-latencies-matrix-a}
  \end{subfigure}
  \begin{subfigure}{1\textwidth}
    \input{images/pgf/mpEx2Mat.pgf}%
    \caption{Matrix clock timestamps for the events in Figure \ref{fig:message-latencies-b}}
    \label{fig:message-latencies-matrix-b}
  \end{subfigure}
  \caption{Figure \ref{fig:message-latencies} depicted with matrix clocks}
  \label{fig:message-latencies-matrix}
  \endgroup
\end{figure}

\begin{example}
  Figure \ref{fig:message-latencies-matrix} depicts the same events as
  Figures \ref{fig:message-latencies-scalar} and
  \ref{fig:message-latencies-vector} with matrix timestamps. By
  comparison to Figure \ref{fig:message-latencies-vector}, observe
  that that rows of the form $\vt_i[i,-]$ act like ordinary vector
  clocks.
\end{example}

In Section \ref{sec:background}, we mentioned the epistemic nature of
reasoning about distributed systems: a process can only make decisions
based on what it \emph{knows}, which is usually a strict subset of all
(system-wide) truths. In many cases, it is important to take into
account a kind of second-order knowledge: what does a process know
about what other processes know? One major utility of vector and
matrix clocks is that they can be be used to track which facts known
to one process are also known to another processes. When this is of
interest, it is often because a process wants to compute which facts
are known to \emph{all} other processes. In Section
\ref{sec:continuous-consistency} we will see an example of how this
works in practice in the context of replicating a database over a
disruption-heavy network.

\begin{comment}
Suppose a group of processes collaborate to replicate updates to a
shared data structure. We imagine that all updates are submitted by
users to some process, say $P_O$ ($O$ for ``origin''), whereupon it is
timestamped with $P_O$'s local time (value $\vt_O[O,O]$) and with the
value $O$ to indicate which process originally accepted the update
from a user. As an invariant, we ensure that no process $P_j$ updates
its estimate $\vt_j[j, O]$ of $O$'s local time to a value $t$ until
$P_j$ has been informed about all updates submitted to $P_O$ with
timestamps less than or equal to $t$. With these assumptions, any
process $P_i$ can use the value $\vt_i[j, O]$ as a lower bound
estimate of which updates originating from $P_O$ have already been
seen by $P_j$. In particular, once we have the
condition
\[ \textrm{for all $j$}, \vt_i[j, O] \geq t
\]
for some logical time $t$, $P_i$ can be sure that all other processes
have seen all updates with timestamps less than or equal to $t$
originating at $P_O$. Using this principle, matrix clocks have been
used to discard obsolete information during database replication
\cite{1987:sarinlynch}. In Section \ref{sec:continuous-consistency} we
will see an example of how this sort of scheme can be applied in
practice.
\end{comment}

\subsection{Message Ordering}
Coulouris et al. \cite{coulouris2005distributed} aptly summarized why
it is a problem for unpredictable network latencies to cause messages
to arrive in a different order than they were sent in.
\begin{quote}
  ``This lack of an ordering guarantee is not satisfactory for many
  applications. For example, in a nuclear power plant it may be
  important that events signifying threats to safety conditions and
  events signifying actions by control units are observed in the same
  order by all processes in the system.''
\end{quote}
In this section, we explore different paradigms for message ordering
in distributed systems. As with clocks and timestamps, the choice of
which ordering guarantee to use depends on the needs of the
application. We later generalize the discussion by admitting messages
sent to multiple recipients at once, such as in a group chat
application, where ensuring predictable message ordering is critical.

When ordering is important, applications do not show messages to the
user immediately when they come in from the network---the network can
deliver messages in unexpected and undesirable orders, after all. The
\emph{arrival} time of a message is when it is received from the
network, but instead of acting on it right away, an application may
buffer an arrived message while waiting for other messages (such as
ones with an earlier causal precedence) to ``catch up.'' When a
message is ready to be presented to the user, it is
\emph{delivered}. By waiting to deliver some messages, we can ensure
the stream of messages in order of their delivery satisfies particular
guarantees.

\subsubsection{FIFO ordering}
A modest requirement is the \emph{first-in, first-out} (FIFO)
condition, which stipulates that on any logical communication link
between two processes in the system, messages arrive in the order they
were sent. The restrictive phrase here is ``any logical communication
link''---by definition there is one link for any \emph{pair} of
processes. Hence, FIFO does not impose any conditions on messages
unless they are from the same sender and to the same recipient.

\begin{definition}[FIFO delivery]
  \label{def:fifo}
  The FIFO ordering guarantee is defined by the following condition. Let
  $P_i$ and $P_j$ be any two processes and $m_1$ and $m_2$ be two
  messages sent from $P_i$ to $P_j$. Then
  $\msend{1} \to \msend{2} \implies \mrecv{1} \to \mrecv{2}$.
\end{definition}

The Internet Protocol (IPv4 or IPv6) by itself does not provide FIFO
semantics. In the OSI model, FIFO ordering is often provided by the
transport layer, in practice usually in the form of the transmission
control protocol or TCP. (The other classic internet transport, the
user datagram protocol or UDP, does not provide any ordering or
reliability guarantees). Applications built on top of TCP or a similar
transport can take therefore take FIFO for granted. Providing FIFO can
be as simple as marking messages sent from $P$ to $P'$ with
consecutive numbers $(1,2,3\ldots)$. If message $1$ arrives and then
$3$ arrives, $P'$ infers that $2$ is lagging behind, delivering $1$ to
the user immediately but withholding delivery of $3$ until after $2$
is received and delivered.

The guarantees provided by FIFO are minimal because they only apply on
a per-link basis: every link requires its own numbering scheme, so
message numbers cannot be meaningfully compared across different
links. To compare messages globally requires something like causal
order, below.

\begin{figure}[p]
  \setlength\abovecaptionskip{0ex}
  \setlength\belowcaptionskip{4ex}
  \begin{subfigure}[t]{0.475\textwidth}
    \centering
    \input{images/pgf/ordEx1.pgf}
    \caption{A non-FIFO execution}
    \label{fig:ordex-non-fifo}
  \end{subfigure}
  \begin{subfigure}[t]{0.475\textwidth}
  \centering
  \input{images/pgf/ordEx2.pgf}
  \caption{A CO (therefore FIFO) execution}
  \label{fig:ordex-co-1}
\end{subfigure}
\begin{subfigure}[b]{0.475\textwidth}
  \centering
  \input{images/pgf/ordEx3.pgf}
  \caption{A CO execution}
  \label{fig:ordex-co-2}
\end{subfigure}
\begin{subfigure}[b]{0.475\textwidth}
  \centering
  \input{images/pgf/ordEx6.pgf}
  \caption{A CO execution}
  \label{fig:ordex-co-3}
\end{subfigure}
\begin{subfigure}[b]{0.475\textwidth}
  \centering
  \input{images/pgf/ordEx5.pgf}
  \caption{A FIFO and non-CO execution}
  \label{fig:ordex-non-co-1}
\end{subfigure}\hfill
\begin{subfigure}[b]{0.475\textwidth}
  \centering
  \input{images/pgf/ordEx4.pgf}
  \caption{A FIFO and non-CO execution}
  \label{fig:ordex-non-co-2}
\end{subfigure}
\caption{Message ordering examples}
\label{fig:message-ordering}
\end{figure}

\subsubsection{Causal ordering}
Causal order is an order guarantee consistent with causal precedence
of events. A network provides causally ordered (CO) delivery if it
satisfies the following property.
\begin{definition}[CO delivery]
  \label{def:causalorder}
  For any process $P_\mathrm{dest}$ in the system, if we consider all
  messages $m$ and $n$ sent to $P_\mathrm{dest}$ (possibly by
  different senders), if $\msend{} \to n^\textrm{send}$ then
  $\mrecv{} \to n^\textrm{recv}$. That is, each destination receives
  messages in an order consistent with causality between their send
  events.
\end{definition}
Unlike FIFO, the CO condition enforces a partial order among messages
with (in general) different senders. In mathematical terms, if we for
each process $P_{\mathrm{dest}}$, the function mapping send events to
corresponding receive events at $P_{\mathrm{dest}}$ must be monotonic
with respect to causal precedence.

\begin{example}
  Figure \ref{fig:message-ordering} demonstrates different message
  ordering conditions. We make a few observations for emphasis.

  \begin{itemize}
    \tightlist
  \item \ref{fig:ordex-non-fifo} violates FIFO because messages $m_1$
    and $m_2$ are both sent from $P_1$ to $P_2$, but the arrive in the wrong order.
  \item \ref{fig:ordex-co-1} satisfies CO and therefore FIFO. Messages
    $m_1$ and $m_2$ arrive in the opposite order but they are sent to
    different destinations.
  \item \ref{fig:ordex-non-co-1} violates CO because the send event of
    $m_1$ happens before that of $m_3$ via the chain
    $\msend{1} \to \msend{2} \to \mrecv{2} \to \msend{3}$ but
    $\mrecv{3} \to \mrecv{1}$.
  \item \ref{fig:ordex-non-co-2} violates CO because it is equivalent to
    \ref{fig:ordex-non-co-1} with the roles of $P_2$ and $P_3$ swapped.
  \end{itemize}
\end{example}

\subsection{Multicasting and Broadcasting}
We now extend the above definitions to the group communication setting
by allowing messages to have multiple recipients. For simplicity, we
suppose messages are broadcast to all other recipients, though the
definitions can easily generalize to ``multicast'' scenarios where
messages are sent to a subset of recipients.

One way to implement broadcasting is to sending distinct network
messages which, for present purposes, we would treat as a single
unit. Alternatively, we can lean on the network itself for assistance,
sending a single message specially marked as a broadcast, relying on
lower-level protocols in the network to distribute a copy to each
recipient. Regardless of implementation, the challenge and importance
of ensuring consistent message ordering across an entire group is a
paramount concern.

The FIFO and CO broadcast conditions are adapted from Definitions
\ref{def:fifo} and \ref{def:causalorder}. Additionally, we introduce
the notion of total ordering (TO) below.

\begin{definition}[FIFO broadcast]
  \label{def:fifo-bcast}
  A broadcast primitive satisfies the FIFO semantics if it satisfies
  the following condition. For any process $P_i$, if $P_i$ broadcasts
  $m_1$ before $m_2$, then all recipients receive $m_1$ before $m_2$.
\end{definition}

\begin{definition}[CO broadcast]
  \label{def:causalorder-bcast}
  A broadcast primitive satisfies CO semantics if for any broadcasts
  $m$ and $n$, if $\msend{} \to n^{\textrm{send}}$, then all
  destinations deliver $\mrecv{}$ before $n^{\textrm{recv}}$.
\end{definition}
In the above definition, the happens before relation is defined just
as in the unicast (non-broadcast) setting by following a path of
causality along worldlines and message arrows.

\begin{figure}[h]
  \centering \input{images/pgf/mpEx3.pgf}
  \caption{Broadcast example that satisfies FIFO but violates CO}
  \label{fig:broadcast-fifo-1}
\end{figure}

\begin{example}
  In Figure \ref{fig:broadcast-fifo-1}, causal order is violated. Imagine the following conversation:
  \begin{itemize}
    \tightlist
  \item [$P_1$]: ``I need an ambulance at location A.''
  \item [$P_2$]: ``Understood, the last ambulance has been dispatched.''
  \end{itemize}
  However, $P_3$ receives $P_2$'s response before $P_1$'s request, resulting in this conflicting view:
  \begin{itemize}
    \tightlist
  \item [$P_2$]: ``Understood, the last ambulance has been dispatched.''
  \item [$P_1$]: ``I need an ambulance at location A.''
  \end{itemize}
  From $P_3$'s perspective, $P_1$ appears to be requesting resources
  that are no longer available. The sort of conflict can lead to
  confusion, with requests being duplicated or going
  unanswered. Tracking causal order is crucial to avoid such resource
  misallocations.
\end{example}

A total order broadcast ensures that all recipients receive the
messages in the same order. This order is not required to satisfy any
particular constraints except that all recipients agree on it. Such a
model is appropriate when it is more important that everyone agrees on
a common order of events but the order itself is not necessarily
critical.

\begin{definition}[TO broadcast]
  \label{def:totalorderbroadcast} For any processes $P$ and $P'$ and
  messages $m$ and $m'$ that arrive at \emph{both} destinations, $m$
  arrives before $m'$ at both processes or $m'$ arrives before $m$ at
  both processes.
\end{definition}

\begin{figure}[p]
  \setlength\belowcaptionskip{5ex}
  \begin{subfigure}{1\textwidth}
    \centering
    \input{images/pgf/bcastEx1.pgf}
    \caption{Broadcast example that satisfies FIFO but violates CO and TO}
    \label{fig:bcast-order-examples-1}
  \end{subfigure}
  \begin{subfigure}{1\textwidth}
    \centering
    \input{images/pgf/bcastEx2.pgf}
    \caption{Broadcast example that satisfies CO but violates TO}
    \label{fig:bcast-order-examples-2}
  \end{subfigure}
  \begin{subfigure}{1\textwidth}
    \centering
    \input{images/pgf/bcastEx3.pgf}
    \caption{Broadcast example that satisfies TO but violates FIFO}
    \label{fig:bcast-order-examples-3}
  \end{subfigure}
  \caption{Multicast ordering examples}
  \label{fig:bcast-ordering-examples}
\end{figure}

\begin{example}
Figure \ref{fig:bcast-ordering-examples} depicts examples of broadcast
message orders.
\begin{itemize}
  \tightlist
\item Figure \ref{fig:bcast-order-examples-1} trivially satisfies FIFO
  because no process sends more than one multicast, but causality is
  violated because $\msend{1} \to \mrecv{1,4} \to \msend{2}$, but
  $P_2$ receives $m_2$ before $m_1$. Total order is also violated
  because $P_2$ and $P_3$ receive the messages in opposite orders.
\item Figure \ref{fig:bcast-order-examples-2} violates TO for the same
  reason above, but satisfies causality because the two send events
  have no causal relation.
\item Figure \ref{fig:bcast-order-examples-3}
  satisfies TO, but $m_2$ arrives at both processes before $m_1$ so
  FIFO is violated.
\end{itemize}
\end{example}

\paragraph{Self-delivered messages}
In some contexts one considers broadcast primitives that include the
original sender among the recipients of a message. For simplicity, the
examples in this section have not shown this sort of self-delivery,
but it is useful in many cases. A typical use case is that
participants are using a total order broadcast to maintain local
replicas of a state machine that can be advanced by any participating
process by announcing updates. An example of this usage is presented
in Section \ref{sec:continuous-consistency}, where the goal is to
maintain distributed replicas of a database over a disruption-heavy
network, which can improve the performance of system applications.

%When a site wishes to update the shared data, it
%announces its intention using a totally ordered (say) broadcast that
%includes the sender in the list of recipients. To ensure consistency,
%we only actually modify our replica of the database when we hear about
%updates, including our own, over the totally ordered broadcast
%channel. In this manner, we can ensure all sites participating in the
%database replication reflect all updates in the same order, thus
%maintaining consistency.


\subsection{Shared Memory}
\label{ssec:shared-memory}
Desiging a distributed application using direct message passing can be
challenging due to the complexity of managing the low-level details
surrounding message ordering and reliability. A more abstract
approach, the \emph{distributed shared memory} (DSM) framework,
simplifies this task by allowing programmers to think in terms of
reading and writing to memory locations instead of sending messages
over a network.

The defining feature of DSM is that it allows all processes to
interact as if they had access to a single, unified proof of shared
memory---just like processes running on a single computer---despite
being spread across different, physically separated computers.  This
seamless experience (at least \emph{mostly} seamless---more on that in
a bit) is facilitated by a middleware layer inside the process called
the \emph{memory manager}, which handles all read and write requests
submitted by an application. In the background, not directly visible
to the application, the memory manager coordinates with other
instances over the network to maintain the illusion of a shared
state---what first responders would call a ``common operating
picture.''

We mention that DSM is only ``mostly'' seamless because, like all nice
things in distributed systems, there is a catch: usually, the memory
manager does not necessarily return the most up-to-date values of
memory locations. Indeed, we shall see that different processes can
write conflicting values to one memory location at the same time, it
is not clear a priori what it means for a value to be ``up-to-date''
in the first place. For developers, understanding the semantics of the
virtual memory layer---what consistency guarantees are provided by the
memory manager---is crucial to build applications that function
correctly while providing reliable performance. As introduced in
Section \ref{sec:disaster-response}, the design space is generally
marked by a tradeoff between stronger consistency guarantees and
faster performance.

\begin{figure}
    \centering
    \input{images/pgf/smEx1NoEdges.pgf}
    \caption{Time diagram for memory operations}
    \label{fig:smEx1}
\end{figure}

\newcommand{\Op}{\mathrm{Op}}

Figure \ref{fig:smEx1} depicts an exemplary time diagram for the
shared memory abstraction, similar to those for message passing. Two
kinds of operations are shown: \emph{reads} and \emph{writes}. A read
operation, $\mathsf{R}(x)$, retrieves the value stored at (virtual)
location $x$, which returns some value $v$. When we want to indicate
the value returned by the read, we write $\memreadVal{x}{v}$. A write
operation, $\memwrite{x}{v}$, indicates writing value $v$ to memory
location $x$, which in code might be written as something like
$x := v$.

An arbitrary read or write operation, $\Op$, spans the duration from
when the operation is invoked by the application ($\memstart{\Op}$),
to when it finished ($\memstop{\Op}$), returning either the read value
or an acknowledgment of the write request. Between the start and stop
times, the memory management layer is usually coordinating in the
background with other processes over the network, say by looking up
the current value of a memory location, but this is not shown in the
diagrams. The entire sequence of requests across all processes forms
what we call a \emph{history}. If $H$ is a history, we write $H|_P$ to
mean just the sequence of operations happen on process $P$, called the
\emph{local history} of $P$.

\subsection{Semantics and consistency}
In a sequential application running on a single computer, it is clear
how read and write requests should be interpreted. A read request
$\memread{x}$ should return the most recent value $v$ that was written
to $x$ by a write $\memwrite{x}{v}$ (or some default value if no such
write exists, but we will not consider such examples). This is
unambiguous because we assume that in a single process, operations do
not overlap in time, so there is always a sense of which one happened
first. In a transactional database, this property can be achieved
using standard \emph{serialization} mechanisms.
\begin{figure}
  \input{images/pgf/smEx0.pgf}
  \caption{Memory operations on a single process}
  \label{fig:smEx0}
\end{figure}

\begin{example}
  \label{exmpl:updatesoneprocess}
  Consider Figure \ref{fig:smEx0}, depicting just a single
  process. Since there is no ambiguity in the order of events, it is
  clear that this process should execute in the following order.
  \[ \memwrite{x}{0} \to \memwrite{y}{5} \to \underline{\memreadVal{x}{0}} \to \memwrite{x}{3} \to \underline{\memreadVal{y}{5}} \to \underline{\memreadVal{x}{3}}. \]
  Note read requests (underlined with their results shown) return the value of most recent write operation to each location.
\end{example}

In a distributed system, operations on different processes can run
concurrently, so there is no obvious way to arrange events into a
total order that all processes can agree on. Consequently, the notion
of ``most recent'' operation is ambiguous, so it does not even make
sense to say that read requests always return the most recent written
value.

\begin{example}
  \label{exmpl:concurrentupdates}
  Consider Figure \ref{fig:smEx2}. Two writes are depicted that overlap
  in physical time, making it unclear whether $\memwrite{x}{3}$ or $\memwrite{x}{5}$
  should be considered as happening first.
\end{example}

\begin{figure}
  \input{images/pgf/smEx2.pgf}
  \caption{Concurrent updates by two processes}
  \label{fig:smEx2}
\end{figure}

Consider two features shown in Example \ref{exmpl:concurrentupdates}.
First, there are three operations that write to the value $x$. For a
period of time, $P_1$ and $P_2$ are both writing to location $x$ at
the same time. Second, these operations are immediately followed by
several read requests, whose return values are not shown in the
diagram. A memory model answers the question, ``Which values might be
returned by each of these read requests.'' Such a model would have to
answer several questions, like the following ones:
\begin{enumerate}
\item Do the read operations on $P_1$ and $P_2$ have to return the same value?
\item Can the second read operation at $P_2$ return a different value
  than the first one?
\item Is it ever possible for any of the $\memread{x}$ operations to
  return the value 4?
\end{enumerate}

It is possible to consider different ways of answering these
questions. The strictest widely used memory model, called
\emph{linearizability} and formally defined in the next section, would
require that all read operations return the same value, which must be
either $3$ or $5$. We shall see that this model is in fact too strict
for our use case, so programmers must face the possibility for less
rigidly prescribed behavior from the memory manager. An application
designed for one memory model may misbehave if executed in an
environment that implements a different one, while on the other hand,
a stricter memory model may result in poor application
performance. Thus, choosing a memory model requires balancing the
needs and expectations of the application against its performance
characteristics, including its usage patterns and networking
environment.

To resolve the ambiguity caused by overlapping memory operations, one
might attempt to assign timestamps to them, and use this to define
some global total order based on when the operations occur. However,
this would require sufficiently fine-grained timestamps from
synchronized clocks, which is usually an infeasible assumption. We
encountered this same challenge in Section \ref{ssec:causality}, where
we were lead to define a global partial order (causal precedence),
partly in reaction to the fact that we cannot use physical timestamps
to arrange all systemwide events into a total order. A roughly similar
concept, used in the DSM setting, is that of \emph{external
  order}. Intuitively, it is the partial order that orders
non-overlapping events by their physical times, but does not assign an
ordering to events whose executions overlap in physical time.
\begin{definition}[External order]
  Let $H$ be a history. An operation $\Op^1$ \emph{externally
    precedes} operation $\Op^2$ if
  $\memstop{\Op^1} < \memstart{\Op^2}$. This induces an irreflexive
  partial order on $H$ called external order.
\end{definition}
The definition states that one operation externally precedes another
if it stops before the other is invoked. Note that we are comparing
events in terms of real, physical time: external order is the partial
order that would be expected by an outside observer who can see
operations executing globally in real time.

\begin{figure}
  \centering
  \input{images/pgf/smEx1DAG.pgf}
  \caption{External order relation among operations in Figure \ref{fig:smEx1}}
  \label{fig:smEx1DAG}
\end{figure}

Figure \ref{fig:smEx1DAG} shows the external order among the
operations in Figure \ref{fig:smEx1} in the form of a directed
acyclic graph (DAG).


\begin{definition}[Physical concurrency]
  Consider two operations $\Op^1$ and $\Op^2$. If neither externally
  precedes the other, in another words if there is some moment in time
  during which both operations are executing, the operations are said
  to be \emph{physically concurrent}, written $\concurrent{\Op^1}{\Op^2}$.
\end{definition}

\subsection{Strong Consistency Models}
\label{ssec:strong-consistency}
This section considers the two major memory models usually said
to provide ``strong'' consistency: linearizability and sequential
consistency. Both models require that the global history aligns with
(read: returns values consistent with) some total sequential arrangement of the operations, with processes maintaining a shared understanding of which operations occur
in which order. Where the models differ is in how they constrain which
sequential arrangements are allowed.


\subsubsection{Linearizability}
\label{sssec:linearizability}

\emph{Linearizability}, a sort of gold standard for memory
consistency, can be concisely defined as a system that acts like
``each operation applied by concurrent processes takes effect
instantaneously at some point between its invocation and response.''
\cite{10.1145/78969.78972} The same condition is known by other names
like atomic consistency, strict consistency, and external
consistency. It means almost the same thing as strict serializability,
except the latter terminology is used to discuss transactional
databases and implies other database-related guarantees.

More formally, a linearizable history is defined by three features.
\begin{definition}[Linearizable history]
  \label{def:linearizable}
  A \emph{linearizable history} is one satisfying the following three rules.
\begin{enumerate}
  \tightlist
\item \textbf{Global Agreement on Order}: All processes behave as if
  they are observing a single, global, consistent sequence of
  operations.
\item \textbf{Correct Responses}: Responses are correct, meaning a read request
  \(\memreadVal{x}{a}\) returns the value of the most recent write request
  \(\memwrite{x}{a}\) to \(x\) in the aforementioned global order.
\item \textbf{Consistent with External Order}: The global sequence of
  events is consistent with external order: if $\memstop{\Op^1} < \memstart{\Op^2}$,
  the global order must include $\Op^1$ before $\Op^2$.
\end{enumerate}
\end{definition}

The previous definition is concerned with individual executions of an
application. When only linearizable executions are permitted by the
memory manager, the entire system is said to be linearizable.

\begin{definition}[Linearizable system]
  A DSM application is linearizable if all possible executions of the
  application are linearizable according to Definition \ref{def:linearizable}.
\end{definition}

Consider Figure \ref{fig:smEx2} again. If the distributed system is
using a linearizable memory manager, then the requirement of global
agreement requires $P_1$ and $P_2$ to agree on the logical order of
write events. The requirement of consistency with external order means
that $\memwrite{x}{4}$ must be ordered before $\memwrite{x}{3}$ and
$\memwrite{x}{5}$, but the latter operations can be logically
sequenced in any order, as long as $P_1$ and $P_2$ agree. They must
return responses that are consistent with this common operating
picture, which constrains the system to one of two possibilities: all
the read operations return $3$, or they all return $5$. These
possibilities are illustrated in Figure \ref{fig:smEx3}.

A visually intuitive way of approaching linearizability is by defining
it in terms of \emph{linearization points.}

\begin{definition}
  A \emph{linearization point} $t \in [\memstart{\Op}, \memstop{\Op}]$
  for an operation $\Op$ is a time between the event's invocation and
  response at which time the operation appears to take effect in whole
  and instantaneously. A \emph{linearization} of a history is an
  assignment of linearization points consistent with the values
  returned by the operations.
\end{definition}

Figure \ref{fig:smEx3} shows the two possible linearizable executions
of Figure \ref{fig:smEx2} along with consistent choice of
linearization points shown in yellow.  shown in Figure
\ref{fig:smEx3}.

\begin{figure}
  %\setlength\belowcaptionskip{4ex}
  \begin{subfigure}{1\textwidth}
    \centering
    \input{images/pgf/smEx3L1.pgf}
    \caption{A linearization where the read operations return 3}
    \label{fig:smEx3-a}
  \end{subfigure}
  \begin{subfigure}{1\textwidth}
    \input{images/pgf/smEx3L2.pgf}
        \caption{A linearization where the read operations return 5}
    \label{fig:smEx3-b}
  \end{subfigure}
  \caption{Two possible linearizations of Figure \ref{fig:smEx2} with linearization points shown in yellow}
  \label{fig:smEx3}
\end{figure}

\subsubsection{Sequential consistency}
\label{sequential-consistency}

Linearizability offers very strong guarantees related to real-time
constraints. There are many scenarios where this level of rigor is
unnecessary. A more relaxed model, sequential consistency, provides
comparably strong guarantees but does not impose the same constraints
with respect to external order. First, we define a \emph{sequential
  history} as any way of arranging read and write requests into a
linear sequence.

\begin{definition}[Sequential history]
  Let $H$ be a history of memory operations. A \emph{sequential
    history} of $H$ is any choice of total order among the events in
  $H$.
\end{definition}

Next we define \emph{program order}. This is a partial order among
operations that imposes constraints on operations in the same
process. Recall that because operations in a single process do not
overlap, this definition is unambiguous.

\begin{definition}[Program order]
  An operation $\Op^1$ precedes another operation $\Op^2$ in program
  order if the events occur in the same process and
  $\memstop{\Op^1} < \memstart{\Op^2}$.
\end{definition}

The difference between program order and external order is that
program order does not impose any constraints on operations that do
not occur in the same process.

A sequentially consistent system guarantees that any history is
consistent with some sequential history that respects \emph{program
  order}. Otherwise, the definition follows the same structure as that
for linearizability.

%\begin{definition}[Legal sequential history]
%Let $H$ be a history of invocation/response events occurring on a set
%of processes $\{P_i\}_{i = 1 \ldots N}$. A \emph{sequential history}
%of $H$ is any choice of total order among the events in $H$---that is,
%a rearrangement of the operations as to ensure none of them overlap in
%time. If each $P_i$ issues
%$r_i$-many requests for some non-negative integer $r_i$, observe there
%are a total of
%\[
%\frac{\left(\sum_{i = 1}^N r_i\right)!}{\prod_{i = 1}^N r_i!}
%\]
%possible sequential histories.
%\end{definition}

\begin{definition}[Sequentially consistent history]
  \label{def:linearizable}
  A \emph{sequentially consistent history} is one satisfying the following three rules.
\begin{enumerate}
  \tightlist
\item \textbf{Global Agreement on Order}: All processes behave as if
  they are observing a single, global, consistent sequence of
  operations.
\item \textbf{Correct Responses}: Responses are correct, meaning a read request
  \(\memreadVal{x}{a}\) returns the value of the most recent write request
  \(\memwrite{x}{a}\) to \(x\) in the aforementioned global order.
\item \textbf{Consistent with Program Order}: The global sequence of
  events is consistent with program order: if
  $\memstop{\Op^1} < \memstart{\Op^2}$ and $\Op^1$ and $\Op^2$ run in
  the same process, the global order must include $\Op^1$ before
  $\Op^2$.
\end{enumerate}
\end{definition}

\begin{figure}[p]
  %\setlength\belowcaptionskip{5ex}
  \begin{subfigure}{1\textwidth}
    \centering
    \input{images/pgf/smEx4S1.pgf}
    \caption{Sequentially consistent example where $P_1$ and $P_2$ read different values}
    \label{fig:smEx4-a}
  \end{subfigure}
  \begin{subfigure}{1\textwidth}
    \input{images/pgf/smEx4S2.pgf}
    \caption{Sequentially consistent example where $P_2$ observes $x$ with a value of $4$}
    \label{fig:smEx4-b}
  \end{subfigure}
  \caption{Sequentially consistent but nonlinearizable executions of Figure \ref{fig:smEx2}}
  \label{fig:smEx4}
\end{figure}
\begin{figure}[p]
  %\setlength\belowcaptionskip{5ex}
  \begin{subfigure}{1\textwidth}
    \centering
    \input{images/pgf/smEx4S3.pgf}
    \caption{}
    \label{fig:smEx4L2}
  \end{subfigure}
  \begin{subfigure}{1\textwidth}
    \input{images/pgf/smEx4S4.pgf}
    \caption{}
    \label{fig:smEx4S2}
  \end{subfigure}
  \caption{Two non-sequentially-consistent executions of Figure \ref{fig:smEx2}}
  \label{fig:smEx4-alt}
\end{figure}

Visually, we can think of sequential consistency as organizing
operations like beads on a string. The worldline of each process is
like its own ``string,'' while the operations occurring in that
process are like ``beads''. Beads on the same string can move forward
or backward in time, but they cannot overtake each other; this
corresponds to respecting the program order of operations. However,
beads on different strings---representing operations from different
processes---are free to slide past each other. Sequential consistency
constrains the application to be consistent with some total order of
operations that can be produced by rearranging them in this fashion.

\begin{example}
  Figure \ref{fig:smEx3} depicts two nonlinearizable, sequentially
  consistent executions of the same operations depicted in Figure
  \ref{fig:smEx2}. In Figure \ref{fig:smEx3-a}, by ``sliding'' all the
  operations in $P_2$ along their worldline so that they occur after
  the operations in $P_1$, we arrive at a sequentially consistent
  history where $P_1$ and $P_2$ read different values for $x$. By a
  similar sliding, we can also produce a sequentially consistent
  history in Figure \ref{fig:smEx3-b} where the second read operation
  in $P_2$ returns $4$ after the first one reads $5$, despite the fact
  that in \emph{real time}, $\memwrite{x}{4}$ occurs \emph{before}
  $\memwrite{x}{5}$.
\end{example}

Since external order imposes more constraints than program order, a
linearizable system is always sequentially consistent. Hence, the
executions in Figure \ref{fig:smEx3} are sequentially consistent.
\begin{lemma}
  \label{lem:linearsequential}
  A linearizable execution is sequentially consistent.
\end{lemma}

The converse of Lemma \ref{lem:linearsequential} does not hold. The
executions in Figure \ref{fig:smEx3} are sequentially consistent but
not linearizable---as noted earlier, the only two linearizable
executions require all three read operations to return the same value
for $x$.

It may seem strange to allow executions, like those in Figure
\ref{fig:smEx3}, that seem to defy the real time order of
operations. However, sequential consistency is a very intuitive
property for programmers to reason about. Consider this: A programmer
designs an two-process distributed application that executes the
operations shown in Figure \ref{fig:smEx1}. Before the application is
actually executed, we do not know the exact moment in time that each
operation will run, since the processes might run at different speeds
(they run on distinct computers, after all). If the processes and
operations run at certain speeds, then the executions shown in
\ref{fig:smEx3-a} and \ref{fig:smEx3-b} are possible. Thus,
sequentially consistent systems are always consistent with some way
the system could have executed in real time.


% Processes in a sequentially consistent system are required to agree
% on a total order of events, presenting the illusion of a shared
% database from an application programmer's point of view. However,
% this order need not be given by external order. Instead, the only
% requirement is that sequential history must agree with process
% order, i.e.~the events from each process must occur in the same
% order as in they do in the process.  This is nearly the definition
% of linearizability, except that external order has been replaced
% with merely program order. We immediately get the following lemma.


\begin{comment}
  It may seem strange to consider executions such as the one shown in
  REF in which operations appear to take effect at different times for
  different processes, or at times that do not agree with external
  order. The reader should remember that in the background, these
  processes would be engaged in message-passing over the network and
  are therefore subject to all the complexities previous discussed in
  Section \ref{sec:message-passing}, including delayed and
  out-of-order messages. Looser requirements by the memory model
  impose fewer constraints on the message passing layer requiring less
  coordination, and allowing for greater performance.
\end{comment}

\subsection{The CAP Theorem}
Real-world systems rarely function as a perfectly coherent,
integrated, cohesive system. The gap between idealized system behavior
and real-world behavior stems from a well-understood and fundamental
tradeoff between coherence and performance. The more ``coherence'' we
demand from the system, the more processes have to communicate over
the network, whose unpredictable delays impose overheads that degrade
performance. Conversely, the more we demand immediate answers from our
system, the less time a process has to communicate with other
processes, so the system as a whole does not seem as coherent and
unified to end users.

This tradeoff is made fully stark by considering the possibility that
the network suffers from a partition, which prevents some processes
from communicating with others.

\begin{definition}[Network partition] A \emph{network partition} is a
span of time where some nodes are unable to communicate with another
set of nodes on the network.
\end{definition}

In 1999, Fox and Brewer \cite{1999foxbrewer} articulated a formal
tradeoff between three desirable properties of distributed systems:
consistency, availability, and an ability to function during network
partitions. This observation was formalized and rigorously proven by
Gilbert and Lynch \cite{2002gilbertlynchCAP} in 2002. Despite its
prominence at the heart of distributed systems, and the fact that its
proof is fairly straightforward, the CAP theorem is sometimes
misunderstood, so it is worth clarifying its key terms.

\begin{description}
\item[Consistency] Gilbert and Lynch define consistency as
  linearizability.
\item[Availability] A CAP-available system responds to every client
  request (a read or write operation) in a finite time.
\item[Partition tolerance] A partition-tolerant system continues to
  function in the face of arbitrary partitions inthe network.
\end{description}

In the last case, the possibility is allowed that a partition never
recovers. This could happen if a critical communications cable is
permanently severed, for instance.

The CAP theorem is the simple observation that a distributed system
cannot guarantee all three properties simultaneously. A system that
operates during network partitions cannot ensure both linearizability
and availability. We give only the informal sketch here, leaving the
interested reader to consult the more formal analysis by Gilbert and
Lynch. The main assumption of the proof is that a process's behavior
cannot be affected by messages that are sent to it but never received.

\begin{theorem}[The CAP Theorem]
  \label{thm:cap}
  If indefinite network partitions are possible, then a distributed
  system cannot guarantee both linearizability and
  eventual availability.
\end{theorem}
\begin{proof}
  Consider again the execution in Figure \ref{fig:smEx2}. We have seen
  that there are only two possible linearizations of this history, and
  both of them require all reads to return the same value, either $3$
  or $5$. Now suppose the network suffers from a partition so that
  $P_1$ and $P_2$ cannot communicate. There are two possibilities:
  \begin{enumerate}
  \item The processes could proceed despite the lack of
    communication. In this case, because processes do not otherwise
    affect each other, $P_1$ could not see the $\memwrite{x}{5}$
    operation and its read must return the value $3$. Likewise, $P_2$
    does not see $\memwrite{x}{3}$ and its reads return $5$.
  \item The processes might detect that the network is unavailable and
    refuse to respond to read requests. This ensures the processes do
    not return inconsistent answers. However, there is no guarantee
    that all requests will eventually be handled, since the partition
    might never recover.
  \end{enumerate}

  Thus, we cannot have both linearizable consistency and
  availability. More precisely, to ensure both of these properties, we
  would have to assume the network never suffers from partitions, but
  this is unrealistic. Section \ref{sec:disaster-response} cited a
  real-world example where a wildfire caused a communications
  partition.
\end{proof}


The proof above assumes that the standard of consistency is
linearizability. This raises the question of whether the weaker notion
of sequential consistency can be used to avoid the ramifications of
the CAP theorem. Unfortunately the answer is negative: sequential
consistency is also CAP-unavailabile.

\begin{lemma}[CAP for sequential consistency]
  \label{thm:cap-sequential}
  An eventually-available system cannot provide sequential consistency
  in the presense of network partitions.
\end{lemma}
\begin{proof}
  The proof is an adaptation of Theorem \ref{thm:cap}. Suppose $P_1$
  and $P_2$ form of CAP-available distributed system and consider the
  following execution: $P_1$ reads $x$, then assigns $y$ the value
  $1$. $P_2$ reads $y$, then assigns $x$ the value $1$. (Note that
  this is the sequence of requests shown in Figure
  \ref{fig:nonsequential1}, but we make no assumptions about the
  values returned by the read requests). By availability, we know the
  requests will be handled (with responses sent back to clients) after
  a finite amount of time. Now suppose $P_1$ and $P_2$ are separated
  by a partition so they cannot read each other's writes during this
  process. For contradiction, suppose the execution is equivalent to a
  sequential order.

  If $\memwrite{y}{1}$ precedes $\memread{y}$ in the sequential order,
  then $\memread{y}$ would be constrained to return to $1$. But $P_2$
  cannot pass information to $P_1$, so this is ruled out. To avoid
  this situation, suppose the sequential order places $\memread{y}$
  before $\memwrite{y}{1}$, in which case $\memread{y}$ could
  correctly return the initial value of $0$. However, by transitivity
  the $\memread{x}$ event would occur after $\memwrite{x}{1}$ event,
  so it would have to return $1$. But there is no way to pass this
  information from $P_1$ to $P_2$. Thus, any attempt to consistently
  order the requests would require commuting $\memwrite{y}{1}$ with
  $\memread{x}$ or $\memwrite{x}{1}$ with $\memread{y}$, which would
  violate program order.
\end{proof}

\subsubsection{Consequences of CAP}
\label{interpretation-of-the-cap-theorem}
While the CAP theorem is theoretically simple, its implications are
more nuanced than they may appear \cite{2012CAP12Years}. A common
oversimplification is that the CAP theorem is represents a ``choose 2
of 3'' scenario: a system designer can choose at most two of
consistency, availability, and partition resilience. In fact, real
systems may balance weaker forms of all three properties. The CAP
theorem only rules out the combination of all three properties when
each of them is defined in an idealized, rigid way.

In practice, applications often settle for weaker levels of
consistency than linearizability or sequential consistency. We shall
see an example in the next section. Resilience to network partitions
typically requires coping with intermittent, rather than indefinite,
communications failures. Finally, availability is best measured in
terms of actual response time as experienced by the user, and not the
mere assurance that a request will ``eventually'' be handled. Thus,
each of these dimensions is actually quantitative in nature, rather
than an all-or-nothing proposition.

The locality principle is also highly relevant when considering
implications of the CAP theorem for a real system: the closer agents
are located, the more reliable their communications will be (in
general), and the more applications can provide consistency and
availability for operations that only require coordinating with nearby
agents. At short time scales, operations that only require local
coordination are common.

\subsection{Causal Consistency}
\emph{Causal} consistency\citationneeded is a weaker memory model than
sequential consistency. Whereas sequential consistency requires the
system as a whole to behave as if all write operations take place in
some total order (which must also respect program order), causal
consistency allows different processes to behave as if they witnessed
past write operations take effect in different orders. Only write
operations related by \emph{causally precedence} are required to take
effect in a common order across all processes: ``reads respect the
order of causally related writes.'' \citationneeded

We have not defined what causal precedence means for memory
operations. The notion is similar in its motivation to causal
precedence in message-passing framework (Definition
\ref{def:causalprecedence}) and the idea of causal broadcast
\citationneeded..., but the definition of causally related memory
operations is not as simple as that of causal precedence among
messages. In message passing, a receive event is always associated
with a unique send event, but multiple processes can write the same
value to the same memory location, and for a later operation that
reads this value, it is not clear which write ``caused'' it. For this
purpose we define a \emph{writes-into} order.

\begin{definition}[Writes-into order]
  Let $H$ be a history of memory operations. We are treating $H$ as a
  \emph{multiset}, meaning for example that two operations of the form
  $\memwrite{x}{v}$ are considered distinct if they happen at
  different times or inside different processes. A ``writes into''
  order $\writesinto$ is any binary relation among the operations
  in $H$ that satisfies the following conditions:
  \begin{itemize}
  \item All pairs of operations related by $\writesinto$ are of
    the form $\memwrite{x}{v} \writesinto \memreadVal{x}{v}$ for
    memory some location $x$ and value $v$.
  \item For each operation of the form $\memreadVal{x}{v}$, there is
    exactly one write operation in $H$ that
    $\memwrite{x}{v} \writesinto \memreadVal{x}{v}$
  \end{itemize}
\end{definition}
\citationneeded give a slightly more complex definition allowing
operations that can read uninitialized memory locations---those
returning a default value because there is no prior write to that
location. For simplicity we assume each memory location is written to
before it is read.

\begin{definition}[Causality order on memory operations]
  \label{def:memorycausalprecedence}
  For a given writes-into order $\writesinto$ on
  $H$, the associated \emph{causality order}
  $\causalityorder$ is the transitive closure of the union of
  $\writesinto$ and program order. That is, if $\Op \causalityorder
  \Op'$, then one of the following holds:
  \begin{itemize}
  \item $\Op \programorder{i} \Op'$ for $P_i$
  \item $\Op \writesinto \Op'$
  \item There is some $\Op''$ such that $\Op \causalityorder \Op''$ and $\Op'' \causalityorder \Op'$
  \end{itemize}
  By \emph{fiat}, we also require that $\causalityorder$ must not be cyclic, meaning their are no ``causality loops'' like $\Op \causalityorder \Op' \causalityorder \Op$.
  If $\Op \causalityorder \Op'$, we say $\Op$ causally precedes $\Op'$.
\end{definition}

We can now define causally consistent executions of memory
operations. For a history $H$ and each process $P_i$, let $A_i$ be
union of $H|_P$ and the set of all writes in $H$. In other words,
$A_i$ is the local history of $P_i$ plus any write operation on any
other process.

\begin{definition}[Causal consistency]
  \label{def:causalconsistency}
  An execution is causally consistent if each $P_i$ behaves as if it
  observes some serialization of $A_i$ consistent with $\causalityorder$.
\end{definition}

Notably, Definition \ref{def:causalconsistency} does not require that
all processes behave as if they are observing the \emph{same}
serialization.

\begin{figure}
  \begin{subfigure}{1\textwidth}
    \centering
    \input{images/pgf/smEx4S3.pgf}
    \caption{}
    \label{fig:smEx1L1}
  \end{subfigure}

  \begin{subfigure}{1\textwidth}
    \input{images/pgf/smEx4S4.pgf}
    \caption{}
    \label{fig:smEx5}
  \end{subfigure}

  \caption{PLACEHOLDER: Causally consistent and inconsistent executions}
  \label{fig:smCausal}
\end{figure}
\clearpage

Causal consistency not subject to the limits of the CAP theorem.

\begin{lemma}[Causal consistency is CAP-available]
  \label{thm:cap-causal}
  Causal consistency can be enforced during network partitions. That
  is, causal consistency is not subject to the CAP thereom.
\end{lemma}
\begin{proof}
  Consider processes that execute read and write operations purely
  locally. That is, they never send messages to other processes and
  they only read to their own writes. In this situation, the causal
  relation generated by Definition \ref{def:memorycausalprecedence} is
  essentially unique: operations at $P_i$ are causally preceded by the
  previous operations at $P_i$, and no others. In the absence of a
  non-trivial causal order, causal consistency imposes no constraints
  and the execution is vacuously consistent.
\end{proof}

Unfortunately, the proof of the prior lemma has more to do the
weakness of the promises made causal consistency. The example allows
different processes to deviate arbitrary far from consistency, in the
sense that no processes need to agree on any of the updates applied to
the database. The effect is that causal consistency is too weak to
apply any kind of bound on divergence, which suggests it is not strong
enough for the kinds of safetly-related applications we have in mind.

\subsection{Section Summary}
\label{ssec:background-summary}
This discussion has explored the key challenges involved in building
distributed systems that connect geographically dispersed components
over unpredictable networks. The variability in message delays,
particularly in the context of broadcasts sent to multiple recipients,
can result in messages that arrive in different orders.  This
situation can lead to chaos if a message-ordering discipline is not
imposed.

To mitigate the effects described above, distributed systems must
track the causal precedence relation between events. Because physical
clocks are not generally reliable enough for this purpose, especially
at fine time scales, logical clocks---scalar, vector, and matrix
clocks---are typically used, each with a different tradeoff in terms
of precision of the information tracked and the administrative and
messaging overhead. If groups can change dynamically, as in our use
cases, then additional group membership protocols are needed to ensure
that all processes know which other processes are participating in the
system at any moment.

Programmers may find it easier to frame distributed applications in
terms of reading and writing from a shared pool of virtual memory,
rather than sending messages, by employing the distributed shared
memory or DSM abstraction. However, the fact that many processes can
access the same virtual memory locations at the same time makes it
challenging to maintain systemwide coherence. Strong consistency
models like linearizability and sequential consistency provide the
illusion of a single, unified source of truth, but the CAP theorem
makes it virtually impossible to guarantee these properties over
chaotic, disruption-prone networks. Weaker models like causal
consistency are not subject to the same limitations, but they do not
enforce any limits bounding how far apart data replicas can
diverge. This renders weaker models potentially unsuitable for
safety-critical applications like we aim to build.

In summary, there is no free lunch in distributed systems. Designing
resilient distributed systems for emergency response scenarios
requires a careful balancing act between competing properties that is
carefully calibrated to the use case and the operational environment.

\section{Timestamped Anti-entropy}

\newcommand{\ack}[2]{\textsf{ack}_{#1}\left(#2\right)}
\newcommand{\summary}[2]{\textsf{summary}_{#1}\left(#2\right)}
\newcommand{\summaryVec}[1]{\textsf{summary}_{#1}}
\newcommand{\commitline}[1]{\textsf{commit}_{#1}}
\newcommand{\globalcommit}{\textsf{globalcommit}}
\newcommand{\knowncommit}[1]{\textsf{purgeline}_{#1}}
\newcommand{\WL}[1]{\textsf{WL}_{#1}}
\newcommand{\WLat}[2]{\textsf{WL}_{#1}\left(#2\right)}
\newcommand{\W}{\textbf{\textsf{Writes}}}
\newcommand{\Unseen}[1]{\textsf{Unseen}_{#1}}
\newcommand{\UnseenEst}[2]{\textsf{EstUnseen}_{#1}{\left(#2\right)}}
\newcommand{\AllProc}{\mathcal{P}}
\newcommand{\currenttime}[1]{\textsf{currenttime}_{#1}}

In this section we summarize Golding's timestamped anti-entropy (TSAE)
protocol for eventual consistency \citationneeded. TSAE is a
middleware-level protocol that provides reliable group messaging over
a lower-level network. Depending on the implementation details, which
are determined by the needs of the higher-level application, TSAE can
provide any of the message ordering guarantees discussed in Section
\ref{}. For instance, TSAE can be used to implement a totally ordered
group broadcast service that communicates by passing unicast messages
over a TCP/IP network, where the TCP/IP component only guarantees FIFO
ordering by itself.

The reliability of TSAE means every message is eventually delivered to
every functioning group member, assuming the underlying network does
not suffer from permanent partitions. A canonical use of TSAE is to
replicate some kind of database at multiple sites. As TSAE only
provides a messaging service, this usage scenario does not dictate
whether to prefer availability or consistency during a partition. We
return to this discussion in Section \ref{ref} which unites the
preceding and present material.

The basic idea of TSAE is simple if we assume principals have
approximately synchronized clocks. All principals maintain a write log
containing messages sent by themselves are other principals. All
entries are tagged with the principal identifier and a timestamp. As
an invariant, if a write log contains a message $m$ originating from
$P$, then it also contains every message originating at $P$ sent
earlier than $m$ (i.e. having a lesser timestamp). Hence, the write
log at any moment is completely determined by knowing the gre


\subsection{Assumptions and data structures}

\subsubsection{Assumptions}

\[
  \textbf{A1}: \textrm{The set of group members is static and known to every member.}
\]
In particular, we assume member knows their own identity. This
statement is necessary because in a dynamic group environment,
mechanisms are required to assign unique identifiers to principals and
inform them of this assignment. For instance, in a typical
TCP/IP-based network, a central DHCP service assigns IP addresses to
computers when they added to the network, ensuring there are no
conflicts.

TSAE can be augmented with a service that provides dynamic group
membership, ensuring all members are informed of changes to the
membership list. See Golding.

\[
  \textbf{A2}: \textrm{Members have approximately synchronized physical clocks}
\]

The clock resolution must be fine-grained enough for each principal to
assign unique timestamps to all important events (e.g. receiving a
message) occurring in that process. We assume clocks are pairwise
synchronized to within some fixed $\delta$, which requires some
mechanism like NTP to correct for clock drift. Messages originating
from processes with fast clocks may experience a $\delta$-length
latency after they are received before they are delivered to the
application.

The assumption of clock synchronization can be weakened. Section 5.4.4
of Golding \citationneeded discusses a form of matrix-based
acknowledgement vectors. This requires no synchronization but adds
storage and protocol overhead. For the applications we have in mind
(database replication over a heavily disrupted ad-hoc network), we
expect sufficiently fine clock synchronization is indeed realistic in
many cases, provided timekeeping mechanisms like GPS signals or NTP
are available often enough to correct for drift.

\subsubsection{Message Log}

Messages are added to the message log when they are received. The
message log is linear, and typically the order will differ among
principals. (Nonetheless the message \emph{delivery} can enforce
things like a total order.)

\begin{itemize}
\item When a message originates at process $P$, $P$ tags it with $(P, \currenttime{P})$
\end{itemize}

Messages are always transmitted in batches. For instance, if $A$
updates $B$, $A$ will send $B$ the entire set of messages sent by $C$
that $A$ estimates $B$ has not heard. If this batch includes a message
with timestamp $t$, then it also includes every other message sent by
$C$ with timestamp less than $t$. Below, this corresponds to the
\emph{coverage property}.

\subsubsection{Clock vectors}

\subsubsection{Invariants}

\subsection{The algorithm}

Each process $P_i$ has access to an approximately synchronized physical clock
The data structures maintain by each process:

\begin{itemize}
\item The \emph{message log}, a queue of timestamped messages received by the host
\item The \emph{summary} vector, containing a \emph{physical} clock value for each host
\item The \emph{acknowledgement} vector,\ an additional set of $n$ clock values
\end{itemize}

The summary vector is much like the vector clocks of Section \ref{},
except they store physical timestamps rather than logical ones. That
is to say, whenever $P$ timestamps some event it reads the current
physical time. As usual, summary vectors will be piggybacked used by
the receiver to update their vector pointwise.

The message log contains a queue of the messages seen by $P$ sent by
any process.

%\textbf{Invariant}: If the message log of $A$ contains a message with
%timestamp $(B, t)$, then it also contains every message whose
%timestamp is $(B, t')$ where $t' < t$.


\begin{description}
\item[Coverage Property] $A$ has seen all from $B$ whose timestamps are less
  than the maximum timestamp of any message $A$ received from $B$
  \[ \WLat{A}{B} \overset{covg.}{=} \{w \in \WLat{B}{B} | w.t \leq \summary{A}{B} \} \]
\item[Acknowledgement Property] $A$'s commit line is less than or equal to the minimum value in $A$'s summary vector. It's ackowledgement entry for $B$ is a lower bound estimate of $B$'s commit line.
  \begin{align*}
    \ack{A}{A} &\overset{ack}{\leq} \min_{i \in \AllProc} \left(\summary{A}{i}\right) \\
    \ack{A}{B} &\overset{ack}{\leq} \ack{B}{B}
  \end{align*}
\end{description}

As a corollary, all messages in $\WLat{A}{A}$ (i.e. all the ones
originating at $A$) have a timestamp less than
$\summary{A}{A}$. Whenever the TSAE protocol needs to read the value
of $\summaryVec{A}$, it first updates $\summary{A}{A}$ to
$\currenttime{A}$. The key property of $\summary{A}{A}$ is that it
always greater than the maximum timestamp in $\WLat{A}{A}$. It is also
less than $\currenttime{A}$---otherwise a newly message accepted would
be timestamped with $\currenttime{A}$ and violate the previous
inequality.

For all intents and purposes $\ack{A}{A}$ is the minimum value
timestamp in the summary vector of $A$. For implementors, it would
suffice that $\ack{A}{A}$ is always less than this value to avoid
constantly iterating over the summary vector to compute the minimum,
as long as $\ack{A}{A}$ is periodically updated.

\newpage
\begin{landscape}
  \begin{figure}%For some reason this empty figure adds vertical whitespace that makes the next figure positioned similarly to the ones that follow it.
  \end{figure}
  \begin{figure}[h]
    \centering
    \includegraphics[width=1.4\textwidth]{images/tsae/TSAE1.png}
    \caption{TSAE at time $t=1$. $A$ has originated a single message with timestamp $t=1$, but $B$ and $C$ have not received it.}
    \label{fig:tsae1}
  \end{figure}
  \begin{figure}[h]
    \centering
    \includegraphics[width=1.4\textwidth]{images/tsae/TSAE2.png}
    \caption{TSAE at time $t=2$. $B$ and $C$ have both accepted messages with timestamp $t=2$.}
    \label{fig:tsae2}
  \end{figure}
  \begin{figure}[h]
    \centering
    \includegraphics[width=1.4\textwidth]{images/tsae/TSAE3.png}
    \caption{TSAE at time $t=3$. $B$ has accepted another message with timestamp $t = 3$. At this moment we assume $A$ and $B$ initiate an anti-entropy session and exchange summary vectors $\langle 3,0,0\rangle$ and $\langle 0,3,0 \rangle$, which they use to determine which messages have not been seen by the other, shown in shaded boxes.}
    \label{fig:tsae3}
  \end{figure}
  \begin{figure}[h]
    \centering
    \includegraphics[width=1.4\textwidth]{images/tsae/TSAE4.png}
    \caption{TSAE at time $t=4$. $A$ and $B$ have finished their TSAE session. Concurrently, $B$ accepted a new message with timestamp $t=4$. Neither $A$ nor $B$ can update their commit line past $0$, because they both contain $\summary{}{C} = 0$, indicating they have not seen any messages from $C$. At this moment we assume $A$ and $C$ initiate a TSAE session and decide to exchange the shaded messages.}
    \label{fig:tsae4}
  \end{figure}
  \begin{figure}[h]
    \centering
    \includegraphics[width=1.4\textwidth]{images/tsae/TSAE5.png}
    \caption{TSAE at time $t=5$. $A$ and $C$ have finished their TSAE session. While $A$ was sending messages to $C$ it also accepted a new message with timestamp $t=5$. $A$ and $C$ can both update their commit lines to $3$, because they have seen all messages with timestamps less than or equal to $3$. However, their purge lines remain at $0$, because their acknowlegment vectors satisfy $\ack{\!}{B} = 0$, indicating their (accurate) estimate of $B$'s commit line. In particular, it would be unsafe for them to purge the message with stamp $(C, 2)$ because then $B$ would never receive it. At this moment we assume $B$ and $C$ initiate a TSAE session and decide to exchange the shaded messages.}
    \label{fig:tsae5}
  \end{figure}
  \begin{figure}[h]
    \centering
    \includegraphics[width=1.4\textwidth]{images/tsae/TSAE6.png}
    \caption{TSAE at time $t=6$. $A$ accepted a new message. $B$ and $C$ have finished their TSAE session. $B$ and $C$ can both update their commit lines to $4$, because they know they have seen all messages with timestamp less than $4$. However, their purge lines remain at $3$, because their acknowlegment vectors satisfy $\ack{}{A} = 3$, and in particular they cannot purge the message $(B, 4)$ because $A$ has not seen it. $A$ does not purge any messages, because it underestimates $B$'s commit line as $\ack{A}{B} = 0$, so $A$ believes it's possible that $B$ has not received $(C, 2)$.}
    \label{fig:tsae6}
  \end{figure}

\begin{comment}
  \begin{figure}[h]
    \centering
  \begin{subfigure}[b]{0.5\textwidth}
    \centering
    \includegraphics[width=0.9\textwidth]{images/tsae/Process A Message Log.png}
    \caption{Cellular network topology}
    \label{fig:centralized}
  \end{subfigure}
  \begin{subfigure}[b]{0.5\textwidth}
    \centering
    \includegraphics[width=0.9\textwidth]{images/tsae/Process B Message Log.png}
    \caption{Ad-hoc network topology}
    \label{fig:decentralized}
  \end{subfigure}
  \begin{subfigure}[b]{0.5\textwidth}
    \centering
    \includegraphics[width=0.9\textwidth]{images/tsae/Process B Message Log.png}
    \caption{Ad-hoc network topology}
    \label{fig:decentralized}
  \end{subfigure}
  \caption{States of processes $A$ and $B$ before an anti-entropy session}
  \label{fig:nettopology}
\end{figure}
\begin{figure}[h]
  \centering
  \begin{subfigure}[b]{0.5\textwidth}
    \centering
    \includegraphics[width=\textwidth]{images/tsae/Process A Message Log.png}
    \caption{Cellular network topology}
    \label{fig:centralized}
  \end{subfigure}
  \begin{subfigure}[b]{0.5\textwidth}
    \centering
    \includegraphics[width=1\textwidth]{images/tsae/Process B Message Log.png}
    \caption{Ad-hoc network topology}
    \label{fig:decentralized}
  \end{subfigure}
  \begin{subfigure}[b]{0.5\textwidth}
    \centering
    \includegraphics[width=1\textwidth]{images/tsae/Process B Message Log.png}
    \caption{Ad-hoc network topology}
    \label{fig:decentralized}
  \end{subfigure}
  \caption{States of processes $A$ and $B$ before an anti-entropy session}
  \label{fig:nettopology}
\end{figure}
\newpage
\begin{figure}[h]
  \centering
  \begin{subfigure}[b]{0.5\textwidth}
    \centering
    \includegraphics[width=\textwidth]{images/tsae/Process A Message Log.png}
    \caption{Cellular network topology}
    \label{fig:centralized}
  \end{subfigure}
  \begin{subfigure}[b]{0.5\textwidth}
    \centering
    \includegraphics[width=1\textwidth]{images/tsae/Process B Message Log.png}
    \caption{Ad-hoc network topology}
    \label{fig:decentralized}
  \end{subfigure}
  \begin{subfigure}[b]{0.5\textwidth}
    \centering
    \includegraphics[width=1\textwidth]{images/tsae/Process B Message Log.png}
    \caption{Ad-hoc network topology}
    \label{fig:decentralized}
  \end{subfigure}
  \caption{States of processes $A$ and $B$ before an anti-entropy session}
  \label{fig:nettopology}
\end{figure}
\end{comment}
\end{landscape}
\clearpage

\subsubsection{Message delivery}

\subsubsection{Message purging}

\subsection{Properties of TSAE}

\begin{definition}
  We provide a couple shorthand definitions
\begin{description}
  \item[Global writes] The set of all writes submitted to any replica
    \[ \W \equiv \bigcup_{i \in \AllProc} \WL{A}\]
  \item[Unseen Writes] The set of global writes not seen by a particular replica
    \[\Unseen{A} \equiv \W \setminus \WL{A} \]
  \item[Estimated Unseen Writes] $A$'s estimate of writes unseen by $B$
    \[\UnseenEst{A}{B} \equiv \{w \in \WL{A} | w.t > \ack{A}{B} \} \]
  \item[Commit line] The commit line at $A$ is $A$'s own
    acknowledgement timestamp and provides a lower bound estimate of
    messages seen by $A$
    \[\commitline{A} \equiv \ack{A}{A}\]
  \item[Global commit line] The global commit line is the minimum
    value of any process's ackowledgement timestamp and provides an
    upper bound of messages seen by anyone
    \[ \globalcommit \equiv \min_{i \in \AllProc} \left( \commitline{A} \right) \]
  \item[Purge line] $A$'s purge line is $A$'s upper bound estimate of the global commit line
    \[ \knowncommit{A} \equiv \min_{i \in \AllProc} \left( \ack{A}{i} \right) \]
  \end{description}
\end{definition}


%    \item[Acknowledgement Property] $A$'s acknowledgment entry for $B$ is a lower bound estimate of $B$'s commit line
%      \[\ack{A}{B} \leq \ack{B}{B} \equiv \commitline{B}\]

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{corollary}
  \label{cor:commitline}
  $A$ has seen all writes with timestamps less than or equal to its commit line. That is,
  \[w.t \leq \commitline{A} \implies w.t \in \WL{A}.\]
\end{corollary}
\begin{proof}
  Consider a message $w$ originating at $B$ with timestamp $w.t \leq \commitline{A}$.
  Then \[w.t \leq  \commitline{A} \equiv \ack{A}{A} \overset{ack}{\leq} \min_{i \in \AllProc}\left(\summary{A}{i}\right) \leq \summary{A}{B}.\]
  By the coverage property, $w.t \in \WLat{A}{B}$.
\end{proof}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

In particular, a message with a timestamp less than or equal to $\globalcommit$ has been seen by everyone.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{corollary}
  \label{cor:purgeline}
  $A$'s purgeline is a lower bound of the global commit line.
\end{corollary}
\begin{proof}
  First we observe that $A$'s purgeline is a lower bound of every process's commit line
  \[\knowncommit{A} \equiv \min_{i \in \AllProc} \left( \ack{A}{i} \right) \leq \ack{A}{B} \overset{ack}{\leq} \commitline{B}
  \]
  But the global commit line is the minimum (greatest lower bound) of all commit lines, so we have
  \[ \knowncommit{A} \leq \globalcommit. \]
\end{proof}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{corollary}[Log purging]
  \label{cor:purge}
  $A$ can safely discard from its write log all messages whose timestamp is less than or equal to $\knowncommit{A}$.
\end{corollary}
\begin{proof}
  We have $w.t \leq \knowncommit{A} \leq \commitline{B} \implies w \in \WL{B}$ by combining Corollaries \ref{cor:pugreline} and \ref{cor:commitline}.
  Consequently, $w$ has been seen by every other process and will not be exchanged during any future anti-entropy sessions.
\end{proof}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{corollary}
  \label{cor:unseenest}
  $A$'s estimate of writes unseen by $B$ form an over-approximation of $B$'s true unseen writes.
\end{corollary}
\begin{proof}
  Consider a message $w$ sent by $C$ (where possibly $C = A$ or $C = B$). We must show
  $w \in \Unseen{B}$ implies $w \in \UnseenEst{A}{B}$.  If $w \in \left(\W \setminus \WL{B}\right)$ then we have
  \[ \summary{B}{C} < w.t\]
  (Otherwise $w \in \WLat{B}{C} \subset \WL{B}$ by the coverage property.)
  We conclude by the following inequality.
  \[\ack{A}{B} \overset{ack}{\leq} \ack{B}{B} \overset{ack}{\leq} \min_{i \in \AllProc} \left(\summary{B}{i}\right) < \summary{B}{C} < w.t\]
\end{proof}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

The contrapositive of Corollary \ref{cor:unseenest} is that $A$'s
write log contains a message with timestamp $w.t \leq \ack{A}{B}$,
then $A$ knows $B$ has already received this message.

\subsection{Conit definitions}


\newcommand{\UnseenWeight}[1]{\textsf{Unseen}_{#1}}
\newcommand{\UnseenWeightEst}[2]{\textsf{EstUnseen}_{#1}{\left(#2\right)}}


\begin{definition}
  We provide a couple shorthand definitions
\begin{description}
  \item[Total Weight] $\textsf{NumWeight}(W) = \sum_{w \in W} \textsf{numweight}{\left(w\right)}$
  \item[Unseen Numerical Weight] $\textsf{UnseenNumWeight}_{A} = \textsf{NumWeight}\left(\Unseen{A}\right)$
  \item[CorrectHistory] $\WL{A}|_{\mathcal{F}} \cap \WL{\mathsf{ideal}}|_{\mathcal{F}}$
  \item[IncorrectHistory] $\WL{A} - \left(WL{A}|_{\mathcal{F}} \cap \WL{\mathsf{ideal}}|_{\mathcal{F}}\right)$
  \item[Unseen Order Weight] $\textsf{OrdWeight}\left(\Unseen{A}\right)$
  \item[Estimated Unseen Positive Weight] $\textsf{NumWeight}\left(\{w \in \Unseen{A} | w.\textsf{numweight} \geq 0 \}\right)$
  \item[Estimated Unseen Negative Weight] $\textsf{NumWeight}\left(\{w \in \Unseen{A} | w.\textsf{numweight} \leq 0 \}\right)$
  \end{description}
\end{definition}




\section{Continuous Consistency}
\label{sec:continuous-consistency}
Strong (i.e. atomic or sequential) consistency, as defined in Section
\ref{ssec:strong-consistency}, is an all-or-nothing proposition: an
application provides strong consistency or it does not. Because of
considerations such as the CAP theorem, this sort of guarantee is an
unrealistic requirement for our setting. Causal consistency (Section
\ref{ssec:causal-consistency}) and other kinds of weaker assumptions
are tenable, but by themselves they provide no upper bound on the
divergence between replicas of data items. Because of the
safety-related nature of our system, we would like to do better than
this.

This section summarizes the key ideas behind \emph{continuous}
consistency, particularly the conit (``consistency unit'') model
proposed by Yu and Vahdat
\cite{2000tact,2000tactalgorithms,10.5555/1251229.1251250,DBLP:conf/icdcs/YuV01,2002tact},
designed to strike a balance between generality and
practicality. Continuous consistency is motivated by the observation
that for many real-world applications, it is evidently acceptable to
work with data that is only consistent to within some error bound
$\epsilon \geq 0$. It is not immediately obvious what this means
formally, but loosely speaking one hopes to measure the difference
between the user-observed value of a database operation and the value
that would have been returned if we were maintaining strong
consistency. By allowing replicas to diverge by some amount, the
thought goes, we sacrifice strong consistency but gain additional
flexibility in choosing how often and with which other replicas we
synchronize our data. In terms of the CAP theorem, by increasing
$\epsilon$ and thus relaxing our error bound, we trade consistency for
availability, but without abandoning all guarantees about the relative
correctness of values observed by the user. Thus, we shift from
consistency and availability as all-or-nothing conditions, as in CAP,
towards viewing them as measurable values that can be traded along a
\emph{spectrum} of possible configurations.

A quantitative definition of consistency seems specific to each
application, but ideally our consistency model can be defined and
implemented in an application-generic manner. Thus we have a few
requirements.
\begin{itemize}
  \tightlist
\item A mechanism to measure (in)consistency of data items
\item A mechanism for applications to set upper bounds on the allowed
  inconsistency of each item
\item A mechanism to efficiently enforce these inconsistency bounds
\end{itemize}

To implement a continuous consistency model that is not tied to one
application, we must first explain how inconsistency can be quantified
generically in the first place. Second, we must explain how a generic
protocols can be used to enforce.

\subsection{The conit model}
\label{ssec:conits}

We assume a fixed set $\mathcal{P} = \{P_1, P_2, \ldots P_n\}$ of
processes that coordinate to replicate a database $D$. Note that we
read ``database'' very loosely to mean any kind of data items that can
be updated in response to user requests---our ownly real requirement
is that it is possible to roll back (undo) updates if necessary. We
also make a couple simplifying assumptions about our system.
\begin{itemize}
  \tightlist
\item The database is replicated in whole at each site.
\item The group members are fixed in advance. Otherwise we would
  require a group-membership protocol to update the set of
  participants dynamically.
\end{itemize}

The application could be essentially anything. Relevant examples for
our environment could be a group chat application, a system for
requesting and dispatching resources, or a system for disseminating
information about weather and fire conditions. Clients can submit
requests to read or write (or update) values from the database at any
site. However, the application itself never updates the database
directly, but instead submits requests to a lower-level ``middleware''
that is logically situated below the application but above the network
transport layer (see Section \ref{ssec:shared-memory}). The role of
the middleware is to mediate between the application and the local
database.

When the application submits a database operation (read or write), the
middleware does not necessarily respond to the request
immediately. Instead, it may block (become unavailable) while it
coordinates with other processes to enforce the sort of consistency
guarantees defined below. During this time, the middleware can inform
other sites about new updates, or request that other sites report to
it any updates that could be relevant to the user's
request. Eventually, the middleware reads or writes from the local
copy of the database and returns a value back to the application, who
gives it to the user.

Separately from the local database itself, the middleware maintains a
\emph{write log} that stores a history of recent write requests it has
seen.

\subsection{Dimensions of consistency}
\label{measuring-consistency-on-conits}

We discuss the three consistency dimensions and how they can be
implemented. Real-time staleness and order error are both bounded by a
\emph{pull}-based approach: the originating replica of a database
operation may block while contacting other sites in order to request
information relevant to the request. Numerical error in contrast is
bounded by a \emph{push}-approach: A node may have to block during a
request in order to proactively inform other nodes about the update
before it can be applied.

\subsubsection{Real time staleness}
\label{sssec:real-time-consistency}
Take, say, an application for disseminating the most up-to-date
visualization of the location of a fire front. It may be acceptable if
this information appears 5 minutes out of date to a client, but
unacceptable if it is 30 minutes out of date. That is, we could
measure consistency with respect to \emph{time}. One should expect the
exact tolerance for \(\epsilon\) will be depend very much on the
client, among other things. For example, firefighters who are very
close to a fire have a lower tolerance for stale information than a
central client keeping only a birds-eye view of several fire fronts
simultaneously.

To enforce real time staleness, we assume that each site has loosely
synchronized physical clocks. Note that while we do not assume
physical clocks can be synchronized precisely enough for the kind of
causality tracking discussed in Section \ref{sec:background}, it may
be tenable to assume synchronization precise enough for the purposes
discussed in this section, depending on how small the allowed
real-time divergence values are. For example, we estimate that
synchronization within, say, 30 minutes is tenable using appropriate
synchronization mechanisms even in deeply challenging network
environments.

Each site maintains a vector of \emph{physical} timestamp values. The
\emph{staleness} of a conit is the physical time elapsed since the
last update not seen by this replica was submitted.

The update rule is simple. When the real time.

\newcommand{\vtphys}[2]{\mathrm{vt}_{#1}}
\begin{itemize}
\item First, check whether $t_{\mathrm{now}} - \vt{i}[j] < \delta$
  holds for each entry $j$ in the real time vector.
\item If $t_{\mathrm{now}} - \vt{i}[j] \geq \delta$, $P_i$ sends a
  request to $P_j$ to pull any updates seen by $P_j$ but not by $P_i$.
\item After receiving the updates, $P_i$ reads the conit's value and
  returns it to the user.
\end{itemize}

\subsubsection{Order consistency}
\label{order-consistency}
When the number of tentative (uncommitted) writes is high, TACT
executes a write commitment algorithm. This is a \emph{pull-based}
approach which pulls information from other processes in order to
advance \(P_i\)'s vector clock, raising the watermark and hence
allowing \(P_i\) to commit some of its writes.

\subsubsection{Numerical consistency}
\label{numerical-consistency}

We describe split-weight AE. Yu and Vahdat also describe two other
schemes for bounding numerical error. One, compound AE, bounds absolute
error trading space for communication overhead. In their simulations,
they found minimal benefits to this tradeoff in general. It is possible
that for specific applications the savings are worth it. They also
consider a scheme, Relative NE, which bounds the relative error.


\paragraph{Dynamic bounds}
Because real-time staleness and order error are bounded by pull
approach, it is straightforward to allow the user to dynamically
change the error bounds at each site. However, numerical error is
bounded by a push approach that requires every process to be aware of
all other processes's bounds and proactively cooperation to ensure
this invariant is maintained. Therefore, dynamically tuning numerical
error bounds requires a consensus mechanism that allows informing
other processes of any updates to these bounds. The application cannot
guarantee the new consistency bound will be enforced until it knows
that all other processes have seen the newly updated bounds.

\subsection{Variations and additional features}
One can imagine various ways that the conit model can be augmented
with additional capabilities.

\paragraph{Dynamic conits}
Mechanism for conits to be created. Because the application (whose
source code is of course is fixed) must specify the weight of each
update to each conit, this requires that the weight of an update can
be calculated. Donkervliet's master's thesis \citationneeded explored
dynamic conits in the context of massive multiplayer online games,
particularly Minecraft.

\paragraph{Dynamic network tuning}
We expect a rich interplay between the network protocol and a
conit-based replication protocol. We previously mentioned an example
where a UAV or a message ferry could be deployed dynamically to
provide greater throughput in a particular geographical area. Such a
resource could be dispatched if the application signals to a network
controller that it is struggling to enforce conit bounds in a timely
manner.

Network packets, or DTN bundles, could be specially marked as
containing database updates alongside any metadata (such as the weight
of an update to various conits) that could be used by the network for
quality-of-service purposes. Such usage may run contrary to the
conventional wisdom that networking protocols should be agnostic to
the actual content of a message, e.g. routers should be concerned only
with the data in IP packet headers but not the data contained in the
packet. This sort of atypical usage is potentially justified in our
setting because of a heightened requirement to optimize the user of
very scarce networking resources, even at the cost of blurring the
line between the network and application layers. We conjecture that
SDN would be particularly suitable because it is easier to modify or
customize software-defined networking protocols, so that custom
hardware is not required even for extremely specialized networking
needs.

\subsection{Old material}

The definition of \(\epsilon\) evidently requires a more or less
application-specific notion of divergence between replicas of a shared
data object.

Now suppose many disaster-response agencies coordinate with to update
and propagate information about the availability of resources. A client
may want to lookup the number of vehicles of a certain type that are
available to be dispatched within a certain geographic range. We may
stipulate that the value read by a client should always be \(4\) of the
actual number, i.e.~we could measure inconsistency with respect to some
numerical value.

In the last example, the reader may wonder we should tolerate a client
to read a value that is incorrect by 4, when clearly it is better to be
incorrect by 0. Intuitively, the practical benefit of tolerating weaker
values is to tolerate a greater level of imperfection in network
communications. For example, suppose Alice and Bob are individually
authorized to dispatch vehicles from a shared pool. In the event that
they cannot share a message.

Or, would could ask that the the value is a conservative estimate,
possibly lower but not higher than the actual amount. In these examples,
we measure inconsistency in terms of a numerical value.

As a third example,

By varying \(\epsilon\), one can imagine consistency as a continuous
spectrum. In light of the CAP theorem, we should likewise expect that
applications with weaker consistency requirements (high \(\epsilon\))
should provide higher availability, all other things being equal.

Yu and Vahdat explored the CAP tradeoff from this perspective in a
series of papers \cite{2000tact,2000tactalgorithms,10.5555/1251229.1251250,DBLP:conf/icdcs/YuV01,2002tact}
propose a theory of \emph{conits}, a logical unit of data subject to
their three metrics for measuring consistency. By controlling the
threshold of acceptable inconsistency of each conit as a continuous
quantity, applications can exercise precise control the tradeoff between
consistency and performance, trading one for the other in a gradual
fashion.

They built a prototype toolkit called TACT, which allows applications to
specify precisely their desired levels of consistency for each conit. An
interesting aspect of this work is that consistency can be tuned
\emph{dynamically}. This is desirable because one does not know a priori
how much consistency or availability is acceptable.

The biggest question one must answer is the competing goals of
generality and practicality. Generality means providing a general notion
of measuring \(\epsilon\), while practicality means enforcing
consistency in a way that can exploit weakened consistency requirements
to offer better overall performance.

\begin{itemize}
\item
  The tradeoff of CAP is a continuous spectrum between linearizability
  and high-availability. More importantly, it can be tuned in real time.
\item
  TACT captures neither CAP-consistency (i.e.~neither atomic nor
  sequential consistency) nor CAP-availability (read and write requests
  may be delayed indefinitely if the system is unable to enforce
  consistency requirements because of network issues).
\end{itemize}

\begin{comment}
\hypertarget{causal-consistency-1}{%
  \subsection{Causal consistency}\label{causal-consistency-1}}

Causal consistency is that each clients is consistent with a total order
that contains the happened-before relation. It does not put a bound on
divergence between replicas. Violations of causal consistency can
present clients with deeply counterintuitive behavior.

\begin{itemize}
  \tightlist
\item
  In a group messaing application, Alice posts a message and Bob
  replies. On Charlie's device, Bob's reply appears before Alice's
  original message.
\item
  Alice sees a deposit for \$100 made to her bank account and, because
  of this, decides to withdraw \$50. When she refreshes the page, the
  deposit is gone and her account is overdrawn by \(50\). A little while
  later, she refreshes the page and the deposit reappears, but a penalty
  has been assessed for overdrawing her account.
\end{itemize}

In these scenarios, one agent takes an action \emph{in response to} an
event, but other processes observe these causally-related events taking
place in the opposite order. In the first example, Charlie is able to
observe a response to a message he does not see, which does not make
sense to him. In the second example, Alice's observation at one instance
causes her to take an action, but at a later point the cause for her
actions appears to have occurred after her response to it. Both of these
scenarios already violate atomic and sequential consistency because
those models enforce a system-wide total order of events. Happily, they
are also ruled out by causally consistent systems. The advantage of the
causal consistency model is that it rules out this behavior without
sacrificing system availability, as shown below.

Causal consistency enforces a global total order on events that are
\emph{causally related}. Here, causal relationships are estimated very
conservatively: two events are potentially causally if there is some way
that the outcome of one could have influenced another.

\begin{figure}
  \center
  \includegraphics[scale=0.4]{images/causal1.png}
  \caption{A causally consistent, non-sequentially-consistent execution}
\end{figure}

\begin{lemma}
  Sequential consistency implies causal consistency.
\end{lemma}
\begin{proof}
  This is immediate from the definitions. Sequential consistency
  requires all processes to observe the same total order of events,
  where this total order must respect program order. Causal consistency
  only requires processes to agree on events that are potentially
  causally related. Program order is a subset of causal order, so any
  sequential executions also respects causal order.
\end{proof}

However, causal consistency is not nearly as strong as sequential
consistency, as processes do not need to agree on the order of events
with no causal relation between them. This weakness is evident in the
fact that the CAP theorem does not rule out highly available systems
that maintain causal consistency even during network partitions.

\begin{lemma}
  A causally consistent system need not be unavailabile during partitions.
\end{lemma}
\begin{proof}

  Suppose $P_1$ and $P_2$ maintain replicas of a key-value store, as
  before, and suppose they are separated by a partition. The strategy is
  simple: each process immediately handles read requests by reading from
  its local replica, and handles write requests by applying the update
  to its local replica. It is easy to see this leads to causally
  consistent histories. Intuitively, the fact that no information flows
  between the processes also means the events of each process are not
  related by causality, so causality is not violated.  \end{proof}

Note that in this scenario, a client's requests are always routed to the
same processor. If a client's requests can be routed to any node, causal
consistency cannot be maintained without losing availability. One
sometimes says that causal consistency is ``sticky available'' because
clients must stick to the same processor during partitions.

The fact that causal consistency can be maintained during partitions
suggests it is too weak. Indeed, there are no guarantees about the
difference in values for \(x\) and \(y\) across the two replicas.
\end{comment}

\subsection{TACT system model}
\label{tact-system-model}

As in Section \ref{sec:background}, we assume a distributed set of
processes collaborate to maintain local replicas of a shared data object
such as a database. Processes accept read and write requests from
clients to update items, and they communicate with each other to ensure
to ensure that all replicas remain consistent.

However, access to the data store is mediated by a middleware library,
which sits between the local copy of the replica and the client. At a
high level, TACT will allow an operation to take place if it does not
violate user-specific consistency bounds. If allowing an operation to
proceed would violate consistency constraints, the operation blocks
until TACT synchronizes with one or more other remote replicas. The
operation remains blocked until TACT ensures that executing it would
not violate consistency requirements.

\[\textrm{Consistency} = \langle \textrm{Numerical error, \textrm{Order error}, \textrm{Staleness}} \rangle.\]

Processes forward accesses to TACT, which handles commiting them to the
store. TACT may not immediately process the request---instead it may
need to coordinate with other processes to enforce consistency. When
write requests are processed (i.e.~when a response is sent to the
originating client), they are only commited in a \emph{tenative} state.
Tentative writes eventually become fully committed at some point in the
future, but when they are commited, they may be reordered. After
fullying committing, writes are in a total order known to all processes.

\begin{figure}[h]
  \center
  \includegraphics[scale=0.4]{images/TACT Logs.png}
  \caption{Snapshot of two local replicas using TACT}
  \label{fig:tact_logs}
\end{figure}

A write access \(W\) can separately quantify its \emph{numerical weight}
and \emph{order weight} on conit \(F\). Application programmers have
multiple forms of control:

Consistency is enforced by the application by setting bounds on the
consistency of read accesses. The TACT framework then enforces these
consistency levels.



\section*{Bibliography}\label{bibliography}
\addcontentsline{toc}{section}{Bibliography}

\bibliographystyle{abbrv}
\bibliography{bibliography}
\end{document}

%%% Local Variables:
%%% mode: LaTeX
%%% TeX-master: t
%%% End:


\begin{figure}[p]
  \begin{subfigure}[a]{1\textwidth} \center
    \includegraphics[scale=0.4]{images/linear1.png} \caption{A
      linearizable execution. Any choice of linearization works here.}
    \label{fig:linear_example11} \end{subfigure}
  \begin{subfigure}[b]{1\textwidth} \center
    \includegraphics[scale=0.4]{images/nonlinear0.png} \caption{A
      non-linearizable execution. The request to read $y$ returns a
      stale value. } \label{fig:linear_example12} \end{subfigure}
  \caption{A linearizable and non-linearizable execution.}
  \label{fig:linear_example1} \end{figure}

\begin{figure}[p]
  \begin{subfigure}[a]{1\textwidth}
    \center
    \includegraphics[scale=0.4]{images/linearTemplate.png}
    \caption{An execution with read responses left unspecified.}
    \label{fig:nonlinear}
  \end{subfigure}
  \begin{subfigure}[b]{1\textwidth}
    \center
    \includegraphics[scale=0.4]{images/linear3.png}
    \caption{A linearizable execution for which both reads return $1$.}
  \end{subfigure}
  \begin{subfigure}[c]{1\textwidth}
    \center
    \includegraphics[scale=0.4]{images/linear2.png}
    \caption{A linearizable execution for which both reads return $2$.}
  \end{subfigure}
  \caption{Two linearizable executions of the same underlying events that return different responses. Possible linearization points are shown in red.}
  \label{fig:linearization}
\end{figure}

\begin{figure}[p]
  \begin{subfigure}[a]{1\textwidth}
    \center
    \includegraphics[scale=0.4]{images/nonlinear1.png}
    \caption{A nonlinearizable execution with the read access returning disagreeing values. We will see later (Figure \ref{fig:sequential}) that this execution is still sequentially consistent. }
    \label{fig:nonlinear1}
  \end{subfigure}
  \begin{subfigure}[b]{1\textwidth}
    \center
    \includegraphics[scale=0.4]{images/nonlinear2.png}
    \caption{Another nonlinearizable execution with read access values swapped. This execution is not sequentially consistent.}
    \label{fig:nonlinear2}
  \end{subfigure}
  \caption{Two non-linearizable executions of the same events shown in Figure \ref{fig:linearization}.}
  \label{fig:nonlinearizable}
\end{figure}

\begin{figure}
  \begin{subfigure}[a]{1\textwidth}
    \center
    \includegraphics[scale=0.4]{images/sequential1.png}
    \caption{A non-linearizable, sequentially consistent execution.}
    \label{fig:sequential1}
  \end{subfigure}
  \begin{subfigure}[b]{1\textwidth}
    \center
    \includegraphics[scale=0.4]{images/sequential2.png}
    \caption{An equivalent interleaving of \ref{fig:sequential1}.}
    \label{fig:interleaving1}
  \end{subfigure}
  \caption{A sequentially consistent execution and a possible interleaving.}
  \label{fig:sequential}
\end{figure}

\begin{figure}
  \begin{subfigure}[a]{1\textwidth}
    \center
    \includegraphics[scale=0.4]{images/nonsequential1.png}
    \caption{A non-sequentially consistent execution.}
    \label{fig:nonsequential1}
  \end{subfigure}
  \begin{subfigure}[b]{1\textwidth}
    \center
    \includegraphics[scale=0.4]{images/nonsequential_x.png}
    \caption{The sequentially consistent history of $x$.}
    \label{fig:sequentialx}
  \end{subfigure}
  \begin{subfigure}[b]{1\textwidth}
    \center
    \includegraphics[scale=0.4]{images/nonsequential_y.png}
    \caption{The sequentially consistent history of $y$.}
    \label{fig:sequentialy}
  \end{subfigure}
  \caption{A non-sequentially consistent execution with sequentially-consistent executions at each variable.}
  \label{fig:nonsequential}
\end{figure}

%%% Local Variables:
%%% mode: LaTeX
%%% TeX-master: t
%%% End:
