% !TeX document-id = {beb7ced9-b3cd-42b2-b16a-3ed3c633a1d9}
\documentclass[]             % options: RDPonly, coveronly, nocover
{NASA}                       %   plus standard article class options
%\DeclareRobustCommand{\mmodels}{\mathrel{|}\joinrel\Relbar}

\usepackage[utf8]{inputenc}
\usepackage{setspace}
\usepackage{csquotes}
\usepackage{hyperref}
\usepackage{amsmath, amssymb, amscd, amsthm, amsfonts}
\usepackage{mathtools}
\usepackage{graphicx}
\usepackage{hyperref}
\usepackage{amsthm}
\usepackage[english]{babel}
\usepackage{stmaryrd}
\usepackage{proof}
\usepackage{tikz-cd}
\tikzcdset{scale cd/.style={every label/.append style={scale=#1},
    cells={nodes={scale=#1}}}}
% Added for subfigures
\usepackage{subcaption}
\usepackage{afterpage}
\usepackage{comment}
\usepackage{rotating}%sidewaysfigure
\usepackage{pdflscape}%alt to sidewaysfigure
\usepackage{cleveref}

\newtheorem{theorem}{Theorem}[section]
\newtheorem{corollary}[theorem]{Corollary}
\newtheorem{lemma}[theorem]{Lemma}
\theoremstyle{definition}
\newtheorem{example}[theorem]{Example}
\newtheorem{definition}[theorem]{Definition}
\include{macros.tex}

% Globally redefine pgfpicture to use \Large fonts
\let\origpgfpicture=\pgfpicture
\def\pgfpicture{\origpgfpicture\small}

% Try loading this package to prevent so much hyphenation
% as recommended by https://stackoverflow.com/questions/1609837/latex-breaking-up-too-many-words
\usepackage{microtype}

\title{Distributed Systems Challenges in Wildland Firefighting Environments}

\author{Lawrence Dunn and Alwyn E. Goodloe}

\AuthorAffiliation{Lawrence Dunn \\ Department of Computer and Information
  Science \\ University of Pennsylvania \\ Philadelphia, PA \\ Alwyn Goodloe\\                                          % for cover page
  NASA Langley Research Center, Hampton, Virginia
}
\NasaCenter{Langley Research Center\\Hampton, Virginia 23681-2199}
\Type{TM}                    % TM, TP, CR, CP, SP, TT
\SubjectCategory{64}         % two digit number
\LNumber{XXXXX}              % Langley L-number
\Number{XXXXXX}              % Report number
\Month{05}                   % two digit number
\Year{2025}                  % four digit number
\SubjectTerms{Distributed Systems, Formal Methods, Logic, }     % 4-5 comma separated words
\Pages{102}                   % all the pages from the front to back covers
\DatesCovered{}              % 10/2000--9/2002
\ContractNumber{}            % NAS1-12345
\GrantNumber{}               % NAG1-1234
\ProgramElementNumber{}
\ProjectNumber{}             % NCC1-123
\TaskNumber{}                % Task 123
\WorkUnitNumber{}            % 123-45-67-89
\SupplementaryNotes{}
\Acknowledgment{The first author conducted the work during summer internships in 2022 and 2023 at the NASA Langley Research Center in the Safety-Critical Avionics Systems Branch focusing on distributed computing issues arising in the Safety Demonstrator challenge in the NASA Aeronautics System Wide Safety (SWS) program.}

%Added for Pandoc
\providecommand{\tightlist}{%
  \setlength{\itemsep}{0pt}\setlength{\parskip}{0pt}}


\abstract{The System Wide Safety (SWS) program has been investigating
  how manned and unmanned aircraft can safely operate in shared
  airspace. Enforcing safety requirements for distributed agents
  requires situational awareness and coordination by passing messages over
  a communication network. Unfortunately, the operational environment
  will not admit reliable high-bandwidth communication between all
  agents, introducing theoretical and practical obstructions to global
  consistency that make it more difficult to maintain safety-related
  invariants. Taking disaster response scenarios, particularly
  wildfire suppression, as a motivating use case, this self-contained
  memo discusses some of the distributed systems challenges involved
  in system-wide safety through a pragmatic lens, offering many
  illustrations for clarity. We explain through figures and examples
  the essential concepts behind the continuous consistency model,
  arguing that this model has great relevance for safety-related
  distributed applications that run over adversarial and
  disruption-prone networks.}

\begin{document}
\newpage
\setcounter{tocdepth}{2}
\tableofcontents
\newpage

\section{Introduction}\label{sec:introduction}
Civil aviation has traditionally focused primarily on the efficient and safe transportation of people and goods via the airspace. Despite inherent risks, the application of sound engineering practices and conservative operating procedures has made flying the safest mode of transport today. Now, the industry's strong safety requirements make it difficult to integrate unmanned vehicles into the airspace, accommodate emerging applications, and keep pace with significant recent growth in commercial aviation. To that end, the Airspace Operations and Safety Program (AOSP) initiated the System Wide Safety (SWS) project to investigate technologies and methods that enable manned and unmanned aircraft to safely operate in shared airspace.

This memo surveys topics in computing that are relevant to maintaining system-wide safety across large, physically distributed data and communication systems. It is intended to be self-contained and accessible to a technical audience without a deep background in distributed systems. Our motivating use cases come from civil emergency response scenarios, especially wildfire suppression. This setting was chosen primarily for three reasons. First, improved technology for wildfire suppression is frequently cited as a national priority \cite{pcast2023}. First responders often stress the need for new technology to improve communications and data sharing. Second, the rules for operating in the US national airspace are typically relaxed during natural disasters and relief efforts, so this a suitable environment for testing new technologies. Finally, this setting is an excellent microcosm for the general challenges faced by other, non-emergency applications.

\subsection{Continuity and Distributed Systems}
A central theme of this document is \emph{continuity}, in the sense of continuous functions from mathematics. At a high level, a continuous function is one where small changes in the input lead to small, predictable changes in the output. A familiar example is the volume knob on a speaker: adjusting the knob slightly leads to a proportionate change in sound level, without abrupt spikes or drop-offs. Continuity underlies much of safe engineering. Many functions found in an engineering context are continuous, so small changes in a system's environment (e.g., temperature, pressure, wind speed) typically yield small changes in its behavior, at least for changes falling within a certain range. This predictability allows engineers to measure, model, and anticipate a system's performance with high confidence.

Software systems, by contrast, do not inherently exhibit continuity. For example, consider that flipping a single bit from 1 to 0 can mean the difference between a valid memory access and a segmentation fault, a positive number and a negative one, and a correct or broken authentication check. Unlike many physical systems, small changes in a program's runtime environment can produce large, discontinuous changes in its behavior, unless the system is designed to respond gracefully. For applications that model physical systems, continuity may arise naturally, but many desirable properties in a general computing context (e.g., strong consistency, defined in \Cref{sec:background}) are all-or-nothing: you either have them or you do not, without an obvious middle ground. This is challenging because, as we will show, this inflexibility often leads to situations where one desirable property must come at the expense of another, which must therefore be ``sacrificed'' by the system designer. Working in a more continuous framework can allow for a more balanced tradeoff between competing objectives, but it is not always clear what continuity means for software systems, nor how to achieve it.

The kinds of software applications under discussion here (examined in detail in \Cref{sec:disaster-response}) support emergency responders in the field. They comprise diverse computing components that exchange data across communication networks to provide what emergency workers call a \emph{common operating picture} to users of the application. In computer science terms, these are \emph{distributed systems}: systems composed of physically separated nodes that coordinate via message-passing over a network. What makes these systems ``distributed'' is that the timescale of sending messages across the network can be significant relative to other kinds of events, such as a change in environmental conditions that might threaten responders on the ground. Furthermore, the network is far from perfect, which means that delayed, out-of-order, or lost messages become central engineering concerns for application developers. Network performance may be difficult to control and predict---particularly in the emergency response environment, where systems face difficult operating conditions, such as damaged infrastructure. Naturally, all of this unreliable behavior in the message-exchange medium makes it challenging to build robust, predictable applications that rely on the network to coordinate.

In the distributed systems setting, developers must navigate delicate tradeoffs between competing objectives. One classic tradeoff, which is central to this document, stems from an inherent tension between building a system that responds to user requests quickly and one that prioritizes a strong level of global consistency between system components (the ``common'' aspect of the phrase ``common operating picture''). This tension is brought to a head in the CAP theorem, defined in \Cref{sec:background}. CAP is a fundamental result ruling out an idealized system that maintains strong consistency and guarantees system availability despite a faulty network. A na\"ive but somewhat common framing of the CAP theorem is that it forces developers to ``choose'' between consistency and responsiveness, which is exactly the sort of harsh binary choice we seek to eliminate---safe engineering implies we want systems to satisfy multiple competing objectives, rather than preferring one idealized extreme over another. Therefore, the present document culminates in a discussion of one solution proposed in the literature (the \emph{conit} model of Yu and Vahdat \cite{2002tact}) for escaping the dilemma presented by the CAP theorem. This model, one possible solution among many, offers the continuous flexibility required of a safe but efficient system that runs over an imperfect network.

%, which can be broadly understood as a choice between safety (which has a narrow technical meaning in this context, discussed in \Cref{sec:disaster-response,sec:background}) and performance.
%In the context of these kinds of discrete, yes-or-no properties, it is not always clear what continuity means, nor how to achieve it.


Ultimately, a central thesis of this document is that system-wide safety in emergency communications is not just a matter of improving radios, routers, or bandwidth. Rather, it is also a problem of computer science: ensuring that the applications built on top of this infrastructure behave reliably \emph{despite} the inherent challenges of their environments.  These systems must be engineered to make highly efficient use of their limited resources while degrading gracefully in the face of harsh conditions. In short, these systems must react to their environment continuously, so that small failures or delays do not cascade into system-wide unpredictability.


\subsection{Summaries of the sections}\label{ssec:summaries-of-the-sections}
This document does not present any novel research. Rather, our contribution is to explain in accessible terms the key technical ideas within a single document to a technical but non-specialist audience, while also explaining the specifics of the use case to readers unfamiliar with scenarios envisioned for these applications.


Section~\ref{sec:disaster-response} opens with a practical overview of disaster response and some of the computing challenges encountered in this setting. The heavily disruptive nature of the communications network in these environments raises issues fundamental to the science of distributed systems. Real-world examples from disaster response scenarios are presented that demonstrate how these challenges affect system-wide safety.

Section~\ref{sec:background} summarizes fundamental concepts and mechanisms used in distributed systems, culminating in the classic CAP theorem for both the linearizable and sequential shared memory consistency models (Theorems~\ref{thm:cap} and~\ref{thm:cap-sequential}). CAP is a ``negative'' result, meaning it proves that a distributed system cannot guarantee strong consistency and remain available to users when the communication network is disconnected. The practical implication is that agents in emergency response environments invariably have incomplete information about the global system.  While the CAP theorem is often presented as an unfortunate prohibition, this section explains that CAP merely highlights a general tradeoff. Furthermore, real-world applications often exhibit a kind of ``locality'' that mitigates some of the constraints implied by the theorem, which developers should take into account.

Section~\ref{sec:tsae} presents Golding's Timestamped Anti-Entropy (TSAE) protocol \cite{1992:golding-thesis}. TSAE provides a fault-tolerant message propagation mechanism that ensures messages are eventually delivered to all parties despite an imperfect network. This implements a ``weak'' consistency model, so it is not directly subject to the CAP theorem. By itself, TSAE does not solve the fundamental problems contemplated by this document, but it provides a strong foundation upon which to build.
% However, it has the downside that it cannot enforce bounds on how far apart any two replicas may diverge before this occurs. Therefore, users are not provided any guarantees limiting how far apart a data item observed by the user may be from its ``true'' value.

Section~\ref{sec:continuous-consistency} describes a TSAE-based data replication mechanism suitable for applications that run over networks with frequent disruptions, where the application must exercise control over the consistency of replicated data. This framework is based on the theory of \emph{conits} (short for ``consistency unit'') developed by Yu and Vahdat \cite{2002tact}, which balances the competing objectives of consistency and availability in a quantifiable way. %The idea is that applications can tolerate some level of inconsistency between replicas as long as the divergence remains less than some defined upper bound.
Using the conit framework allows applications to define units of replicated state of interest, enforce policies limiting inconsistency between their replicas, and adapt these policies dynamically in response to changing conditions. Because it provides fine-grained control without sacrificing the flexibility and resilience of weak consistency, this model is suitable when the tradeoffs implied by the CAP theorem need to be carefully calibrated to support both performance and safety.

We conclude in Section~\ref{sec:conclusion} by recapping the main themes in this document and highlighting areas for further investigation. Ultimately, building distributed systems requires design decisions tailored to the environment and application, and the specific techniques discussed in this document are suggestive examples, but not universal nor complete solutions. This leaves many opportunities to specialize the concepts discussed here to the real-world needs of users.

\section{Coordination Challenges in Disaster Response}\label{sec:disaster-response}
This section explores key aspects of disaster response, particularly
firefighting, that shape the focus of this document. We highlight how
real-world environments create fundamental challenges that require
solutions based on distributed computing principles. Even with the
best communications technologies, core issues arise when distributed
agents need to coordinate their actions across wide areas.

Disaster response settings, like wildfire suppression or hurricane
relief, are marked by systemic communications challenges. A 2023
report by the President’s Council of Advisors on Science and
Technology (PCAST) highlights the need to address ``the
vulnerabilities and shortfalls in wildland firefighter communications,
connectivity, and technology interoperability'' as its top
recommendation for wildland firefighting modernization
\cite{pcast2023}. Many of these vulnerabilities and shortfalls stem
from factors inherent to disaster response: remote locations,
difficult terrain, damaged infrastructure, harsh weather, and limited
power, to name a few.

Field agents often face high message loss, distorted signals, and unpredictable delays in communication. A cautious approach suggests preparing for the worst performance at critical times---conditions that demand urgent, reliable contact often coincide with network failures. Disasters often damage and degrade the communications infrastructure, which is accompanied by a sudden surge in user demand that can overwhelm a network completely. This was starkly evident in the immediate aftermath of the September $11^\textrm{th}$ attacks, when sudden user demand and severed trunk cables crippled New York public and private communication networks, including dedicated networks for first responders \cite{2011:Reardon}. These failures later became the impetus for the creation of FirstNet \cite{2021:firstnet, 2021:firstnet2}, a national public safety broadband network (NPSBN).

Unreliable networks make coordinating distributed agents a significant
challenge. Coherent decision-making and coordinated action require
consistency, meaning agreement on the data shared between agents. We
define consistency more precisely in Section~\ref{sec:background}, but
the concept is as follows: it is critical for everyone to agree which
firetrucks should respond to which areas, where helicopters should
land, which tasks should be prioritized, or which radio frequencies
are in use. Achieving stronger standards for consistency requires
sending more information in a shorter time frame, which places a
heavier strain on the network. When a communications link is slow,
system components may have to pause and wait before agreement can be
reached, diminishing the efficacy of the system. To avoid waiting in
such scenarios, standards for consistency may have to be relaxed,
meaning distributed agents have less agreement, which comes with its
own challenges. In summary, there is an inherent tension between
global system consistency and a system that responds quickly to user requests---consistency takes time.

\subsection{Communication and User Safety}
\label{ssec:communication-and-safety}
We turn our attention to the implications of the
consistency/responsiveness tradeoff from a user safety
perspective. Operational safety depends on agents quickly gathering
and responding to information about their environment. This
information is relayed through communication networks, so poor
communication becomes a safety problem. When communication falters,
agents face a difficult choice: either wait for more information
before acting, or act now with incomplete knowledge. Both inaction and
uninformed action carry risks. This dilemma is closely related to a
fundamental computer science principle known as the safety/liveness
tradeoff \cite{ALPERN1985181}.

\begin{figure}
  \centering
  \includegraphics[scale=0.4]{images/dc10.jpg}
  \caption{A DC-10 airtanker, rated for 9,400 gallons, drops retardant
    above Greer, Arizona. Image source: Kari Greer/US Forest Service.}\label{fig:airtanker}
\end{figure}
% TODO: How to cite picture?
% https://www.flickr.com/photos/apachesitgreavesnf/5837741382
% Also appears at https://www.nifc.gov/resources/aircraft/airtankers

\begin{figure}
  \centering
  \includegraphics[scale=0.15]{images/forestfire-videox-scaled.jpg}
  \caption{Screenshot of a firefighter using TAK, where the left
    panel shows a map and the right is a video stream from an air
    vehicle. Image source: Andreas ``AJ'' Johansson}\label{fig:atak}
\end{figure}
% TODO: How to cite picture?
%https://www.civtak.org/2020/08/04/tak-used-in-ca-firefighting-w-aircraft-video/

For example, consider the use of firefighting airtankers, particularly
Very Large Airtankers (VLATs), which can carry over 8,000 gallons of
water or fire retardant \cite{2019:airtankerops}
(Figure~\ref{fig:airtanker}). The largest VLATs can drop more than
20,000 gallons---about 170,000 pounds' worth---in a single pass. In
the U.S., these drops are typically made from just 250 feet above the
tree canopy \cite{2019:airtankerops}, and sometimes lower in
practice. This sort of maneuver can easily crush a ground vehicle
\cite{2019:stickney}. In 2018, a firefighter was killed, and three
others were injured, when an unexpectedly powerful drop from a Boeing
747-400 Supertanker knocked down an 87-foot Douglas Fir tree
\cite{2018:calfire}.

Improving firefighter communications can be expected to lead to better
safety outcomes. One such improvement is through the use of
applications like TAK, the Team Awareness Kit, developed by the
U.S. military in 2010 and later released in a civilian
version. Wildland firefighters are increasingly using TAK, extended
with aftermarket plugins, on ordinary cell phones to coordinate their
activities in the field (Figure~\ref{fig:atak}). A key application of
this tool could be tracking the real-time GPS coordinates of
firefighters for safety monitoring.

Given the risks of VLAT drops, a seemingly reasonable policy
might be to disallow drops unless a VLAT's computers have up-to-date
information about the location of ground personnel. Unfortunately,
system-wide safety is not so easily achieved, as the proposed measure
is precisely the sort of thing subject to the safety/liveness
tradeoff. Before giving an example of this tradeoff, it is important to recognize a linguistic nuance: in
the context of distributed systems, ``safety'' refers to a specific
type of system property, which is not inherently related to the safety of people. A \emph{safety} property is defined as a prohibition that stops
a system from taking an action that is considered ``bad.'' Here
is a possible safety property for the example above:
\begin{quote}
  $\Psafe$: Ground agents are known to be at least
  100 feet outside the drop zone, and this information is current to
  within 30 seconds, or airtankers will not perform a drop.
\end{quote}
In the context of emergency response, most safety properties probably affect human safety in some way, but not all properties that affect human safety are ``safety'' properties in the technical sense. We do not have to look far to find an example: the next example is not a ``safety'' property, but it has implications for human safety.

In contrast to safety properties, a \emph{liveness} property demands some kind of action
from a system, usually one that is considered ``good.'' A
characteristic of liveness properties is that they place an upper
bound on the allowable delay of something. A liveness
property for our scenario might be the following:
\begin{quote}
  $\Plive$: A VLAT on the ground will take off and
  perform a drop within 20 minutes of receiving a request from the
  incident commander.
\end{quote}
(The previous value comes from a PBS interview with the Chief of Flight Operations for Cal
    Fire, who cited 20 minutes as an upper bound on the response time for
    aerial firefighting units within designated areas of responsibility \cite{2021:aerialfirefighting}.)

Note that $\Plive$
is a liveness property, not a safety property in the narrow technical
sense, but it impacts human safety: it might be critical for VLATs to
perform drops quickly if a wildfire is threatening the safety of
ground personnel. That is why the safety/liveness tradeoff is a problem: we will show there is a tradeoff between these concepts. Because human safety requires both ``safety'' and liveness properties, we cannot simply ignore the tradeoff. Throughout the remainder of this document, ``safety'' will always refer to the narrow meaning of the word, unless it is clear from context that the everyday definition is meant.

Safety and liveness are frequently dual mandates that cannot be
guaranteed simultaneously. Such is the case in our example: though
$\Psafe$ and $\Plive$ are both desirable, certain situations will
force decision makers to prefer one over the other. Consider the fact
that the wildland firefighting environment is frequently GPS-denied.
Heavy smoke, multipath effects, and so on can easily prevent a
consumer-grade cellphone from obtaining reliable GPS
coordinates. Additionally, factors like a damaged radio tower or
environmental obstructions like a tall mountain can prevent
communications between the air and ground. Such conditions would
prevent a VLAT's computers from knowing the locations of ground
agents, which immediately presents a dilemma: should the crew proceed
without knowing the locations of ground personnel, maintaining
$\Plive$ at the cost of $\Psafe$, or should it be cautious and wait
for more information, maintaining $\Psafe$ at the cost of $\Plive$?
There is no simple answer, with either choice presenting a downside
with respect to the broader goal of system-wide safety.

Besides the safety/liveness tradeoff, the previous example exhibits
two other themes important in distributed systems, both of which will
be explored further in this document. The first is the
\emph{epistemological} nature---concerned with what information is
\emph{known} by \emph{whom}---of reasoning about distributed
systems. This aspect is reflected in wording of $\Psafe$ in VLAT
example: Ground agents are known (by the VLAT's computers) to be
outside of a dangerous area. This situation requires a deeper and more
sophisticated analysis than one simply considering what is
true. Mathematically, the logic of distributed agents is not the
ordinary propositional logic but the modal logic S5, which extends
propositional logic with additional axioms governing
knowledge. (The application of S5 to reason about distributed systems is the topic of \cite{kshemkalyani_singhal_2008}, Chapter 8.) Distributing knowledge requires communication between agents
over a period of time over the network, which is not instantaneous and
reliable, and it is from these imperfections that the safety/liveness
tradeoff arises.

The second aspect exhibited above, albeit negatively, is that of
\emph{continuity}. A continuous system can flexibly adopt to its
environment, but a discontinuous system is rigid and may exhibit
suddenly different behavior in response to only small changes in the
environment, such as a transient network failure. The properties
$\Psafe$ and $\Plive$ exhibit a stark lack of continuity because they
are inflexible, all-or-nothing propositions. Suppose that agents are
known to be $500$ feet outside the drop zone, but the information is
only current to within 31 seconds---this extra second technically
violates $\Psafe$, though it should be inferable that the ground
agents are well away from danger. In particular, this example
highlights that system-wide safety is more of a quantitative concept
than a Boolean (true-or-false) one. A distributed system in a
network-challenged environment should exhibit smoothly varying
properties in response to its inputs. Ideally one can ``tune'' the
system's properties for the particulars of its environment at any
moment. The technical aspects of this theme are the focus of Section
\ref{sec:continuous-consistency}.

\subsection{Communication Patterns in the Field}
\label{ssec:communication-patterns}
We now consider some of the communication patterns that occur in
wildland firefighting. Readers may be surprised to learn that the
state of the art is somewhat primitive, largely due to the sparse
permanent communications infrastructure that exists in this
setting. This makes wildfires an interesting and generalizable example
for other kinds of civil disaster environments where the network is
unreliable.

One important concept to draw attention to is  ``geospatial
locality of reference,'' so to speak, that system designers should consider. By
this, we mean the concomitance of two observations which, while not
guaranteed rules, are approximately true in many circumstances. The
first observation states that nearby agents have aligned interests:
\begin{quote}
  Agents with the most urgent need to coordinate their
  actions will usually be located closer together and require similar
  kinds of information.
\end{quote}
The second observation states that nearby agents have more reliable
communications:
\begin{quote}
  Agents that are located closer together generally
  enjoy more reliable communications between them than agents that are
  far apart. Conversely, information that travels long distances tends to
  be delayed or degrade in quality.
\end{quote}

These related observations are what is meant by simply the
``locality'' principle. Locality is a crucial factor to analyze
because, as presented in Section~\ref{sec:background}, there are major
theoretical and practical limits to how well agents can coordinate
\emph{globally}, meaning with all agents knowing and agreeing on
everything. To the extent the system exhibits locality, coordination
can be achieved using more efficient short-range communication than
less efficient long-range communication. Here, ``efficient'' should be
read broadly, measured with respect to things like battery life,
message delay, reliability, cost-effectiveness, equipment weight, and
so on. This raises the question of how to most efficiently utilize
network resources to achieve adequate levels of consistency. Aspects
of this question are revisited in Section
\ref{sec:continuous-consistency}, in the context of a framework for
weighing the relative importance of updates.

\subsubsection{Communication on the Ground}
\label{sssec:ground-communication}
In the field, communication between firefighters and other agents is
often facilitated by handheld (analog) land-mobile radio (LMR). These
radios are inherently limited in their battery life, bandwidth,
effective range, and ability to work around environmental factors like
foliage and smoke.

As an alternative to using a radio, it is common for wildland
firefighters in the field simply to shout commands and notifications
to nearby personnel. This exhibits the locality principle: a
substantial amount of communication occurs directly between nearby
firefighters working on related tasks that can communicate without
network infrastructure. In a future environment where agents might be
equipped with body-worn sensors and or even some form of heads-up
display (HUD), this sort of low-range local communication might be
facilitated by relatively inexpensive, low-power technologies such as
Bluetooth or mesh Wi-Fi, without the need for more sophisticated (and
heavy) equipment.

Communication over a long distance requires infrastructural support,
such as the use of cell towers and repeater stations. Typically,
disaster response environments have scarce permanent infrastructure. In a wildland fire setting, one might find a small number repeaters mounted to a
nearby watch tower, for instance, but not necessarily a cellular network. Ad-hoc infrastructure, such as Cells On Wheels
(COWs) or Cells on Light Trucks (COLTs)---i.e., portable cellular
towers---can sometimes be deployed on an as-needed basis if the
location allows for it. Similar kinds of equipment can also be mounted
to backpacks and carried into the field. A common issue is making sure
that all equipment is properly configured, for instance that radios
are listening on the correct frequencies. Configuration is especially
critical when different agencies and groups need to
interoperate---another problem highlighted during the September
$11^\textrm{th}$ attacks.

\begin{figure}[t]
  \centering
  \includegraphics[scale=0.085]{images/ironside.jpg}
  \caption{The Ironside Mountain lookout and radio repeater station,
    shown here with protective foil on August $10^\textrm{th}$, 2015
    during the 2015 River Complex fire. This particular fire burned
    77,077 acres over 77 days.}
  \label{fig:ironside}
\end{figure}
% TODO: How to cite picture?
%https://web.archive.org/web/20150923190323/http://inciweb.nwcg.gov/incident/photograph/4431/44/45122/

Use of centralized infrastructure comes with the potential for
widespread failure when the infrastructure breaks down. For example,
in California, the Ironside Mountain lookout/repeater station (seen in
Figure~\ref{fig:ironside}) was destroyed during the 2021 Monument
Fire, which burned approximately 223,124 acres over 88 days
\cite{2021:monumentfire}. The Ironside Mountain station had strategic
importance, being located on a tall ridge. According to a video blog
from a volunteer firefighter involved in the incident, its loss
prevented communication between operators on different sides of the
ridge, in networking parlance creating a \emph{partition} that lasted
until crews could ascend the ridge to deploy a temporary station:
\begin{quote}
  ``When {[}the Ironside Mountain lookout station{]} burned down the
  radio repeater went with it. And so communications were lost across
  the fire\ldots{} one side of the fire couldn't talk to the other
  side\ldots.  So it was kind of a critical job to get that road
  cleared so that the radio crews could go back up there and set up a
  temporary radio tower.'' \cite{2022:mechfire}% See also https://web.archive.org/web/20220809061927/https://www.youtube.com/watch?v=4F2dDKMgAME
\end{quote}
A scenario where communication between two groups is completely
severed is exactly the sort of thing considered by the CAP theorem in
Section~\ref{sec:background}.

\paragraph{Ground vehicles}
Large numbers of ground vehicles---sometimes on the order of 100
during a major response---are involved in wildfire
suppression. Various firetrucks, bulldozers and similar vehicles are
commonly used to control the landscape and perimeter of the fire. An
advantage of vehicles is that they can carry heavier and higher-power
communications equipment than a human. For instance, a vehicle could
be equipped with a BGAN or VSAT satellite terminal to maintain a
connection back to a central location. Additionally equipping the
vehicle with something like a Wi-Fi or cellular base station using the
satellite connection as backhaul would let the vehicle act as a bridge
between agents in the field and central coordinators such as incident
commanders or 911 dispatchers.

\subsubsection{Communication in the Air}
Wildland firefighting increasingly involves the use of helicopters and
fixed wing aircraft. Civil aviation has traditionally employed simpler
communication patterns than this use case demands. For instance,
aircraft equipped with Automatic Dependent Surveillance-Broadcast
(ADS-B) monitor their location using GPS and periodically broadcast
this information to air traffic controllers and nearby aircraft. This
sort of scheme has worked well in traditional applications, where
pilots typically only monitor the general locations of a few nearby
aircraft. The locality principle is exhibited here, too: aircraft have
the highest need to coordinate when they are physically close and
therefore in range of each other's ADS-B broadcasts.

In our setting, a large number or aircraft, easily on the order of 10 or
more, may need to operate in a small area, near complex terrain,
during adverse conditions, often at low altitude. In other words, the
demands are many and the margins for error are small. This sort of use
case calls for more sophisticated coordination schemes between
airborne and ground-based elements than solutions like ADS-B provide
by themselves.

As aircraft generally have better line-of-site to ground crews than
ground crews have to each other, firefighters sometimes relay messages
to air-based units over the radio, which in turn is relayed back down
to other ground units. The locality principle comes into play for this
sort of message relaying scheme, but in the negative direction:
relaying allows knowledge to travel farther but requires more resources and effort,
and the extended reach comes at the cost of introducing delays and
possible degradation of message quality, as in the classic game of
``telephone.'' Hence, this mode of communication has generally been reserved for
more critical information.

The Communications Program of the Civil Air Patrol (a civilian
auxiliary of the U.S. Air Force) is sometimes deployed to provide
communications for firefighters on the ground using airplane-mounted
radio repeaters. In this future, this sort of service could be
provided autonomously by portable infrastructure mounted to unmanned
aerial vehicles (UAVs), which might perform additional functions such
as tracking the fire perimeter.

In future environments, we envision resilient networks formed from
heterogeneous collections of smaller networks, incorporating various
communication technologies such as digital radios, Wi-Fi, 4G/LTE, 5G, and
satellite communications. Communications in the field may incorporate
aspects of mesh networks and mobile ad-hoc networks (MANETs). Given
the environmental challenges, we assume that two agents will often
only have intermittent end-to-end connectivity, if any. Facilitating
communication through such a dynamic and chaotic mobile network calls
for a disruption-tolerant networking (DTN) architecture, which
provides a custody transfer and store-carry-forward model that is
resilient to disruption \cite{2021:intro-dtn}. The exact form of such
a network remains a question for future investigation.

\subsection{Data Collection and Processing}
\label{ssec:data-collection}
Perhaps the most universally acknowledged expectation for future
disaster response environments is a heavy reliance on data
gathered from both humans and sensors. Besides improvements to
communications that facilitate information sharing, we expect advances
in machine intelligence to greatly influence how this data is
handled.

Agents in disaster response environments will be both producers and
consumers of data, and this data will need to processed by humans and
machines in ways that agents can readily make sense of to support
their decision-making. We list some of the possible sources and
types of pertinent data:
\begin{itemize}
\item Free-form communication, especially real-time or recorded voice messages
  broadcast to many agents at once, which may need to be processed by
  machines to extract the most pertinent information into a more
  actionable format
\item The exact or estimated location of victims, firefighters,
  vehicles, hazards, etc. displayed on applications like TAK
\item Medical information gathered from victims, perhaps stored in and
  collected from electronic triage tags \cite{2009:triagetag}
\item Data about current and predicted fire behavior gathered from
  systems like the Fire Integrated Real-time Intelligence System
  (FIRIS) or NASA's Fire Information for Resource Management System
  (FIRMS)
\item Weather data from the National Weather Service
\item Topographic information about the terrain, highlighting for
  instance the location of rivers and roads that could form a fire
  control line
\item Planned escape routes, rendezvous points, safety zones, and
  landing zones
\item Availability and dispatching of assets, e.g.~ambulances,
  airtankers, or crews on standby, such as the prototype application
  considered by Monares et al. \cite{2011:monares}
\end{itemize}
In a perfect environment, such information would be shared with all
necessary agents in whole and instantly. In reality, agents will be
presented with information that is sometimes incomplete, out of date,
or contradictory---for example, two 9-1-1 callers might give conflicting details, or two first responders may give conflicting reports about whether a structure has been evacuated already. These sorts of problems are further exacerbated by an
unreliable network, where messages can be dropped, rearranged, or delayed. A competing concern is that the information
presented will be \emph{overcomplete}, filled with petty details that
distract agents from their critical tasks.

In some ways, future systems for disaster response will bear
resemblance to future systems for war fighting, such as the conceptual
\emph{Internet of Battle Things} (IoBT) \cite{2016:iobt}. To quote
from that paper, agents ``under extreme cognitive and physical
stress'' will be subject to a highly dynamic and dangerous
environment. Various kinds of technology will assist humans by
providing data to support sensemaking, but a contraindicating concern
will be flooding agents with a ``massive, complex, confusing, and
potentially deceptive ocean of information.'' To avoid ``swimming in
sensors and drowning in data'' \cite{2010:magnuson}:
\begin{quote}
``Humans seek well-formed, reasonably-sized, essential information
  that is highly relevant to their cognitive needs, such as effective
  indications and warnings that pertain to their current situation and
  mission.'' \cite{2016:iobt}
\end{quote}

The field of Human-Computer Interaction (HCI) is concerned with
``design, evaluation and implementation of user interfaces for
computer systems that are receptive to the user's needs and habits.''
\cite{2009:hci-definition} As emergency control becomes more
data-driven, particularly in hubs like dispatch centers that aggregate
diverse streams of information, the challenge of ensuring users can
interact effectively with these systems will become increasingly
important. We propose that researchers in HCI take up the question of
how agents under stress can process and respond to the flood of
complex information they may face. Relevant topics for exploration
include structuring interfaces to avoid cognitive overload and
facilitate intuitive control. Attention should also be given to
helping agents avoid subtle but critical mistakes, such as dispatching
resources to the wrong location---for instance, \emph{S. Example Rd.}
instead of \emph{N. Example Rd}.


\subsubsection{Adversarial Behavior}
One feature of the Internet of Battle Things worth highlighting is
``the adversarial nature of the environment.'' This feature is common
also to disaster environments, whether resulting incidentally from
``fog of war'' effects or deliberately caused by malicious actors
seeking to exploit a civil disaster. Section
\ref{ssec:communication-patterns} cited a real-world example of a
critical communications station destroyed by wildfire, perhaps
comparable to an attack by enemy forces.

There is a growing trend in disaster response to rely on
``crowdsourced'' information, where public safety officials process
reports from the general public over non-traditional channels like
social media. However, a significant vulnerability of crowdsourcing
information is the potential for confusing of contradictory reports,
which can resemble intentional deception. Rumors frequently plague
disaster relief environments, which are quite susceptible to
misinformation. For instance, during Hurricane Harvey in 2017, there
were unconfirmed rumors of shots being fired at volunteer rescuers
\cite{2017:cajun-navy-rumors}. Tracing reports back to their source is
often difficult. Even fully malicious activity like
``swatting''---placing a fake 911 call to cause a large police
response---is often observed in public safety. Whether misinformation
is spread with malicious intent or through well-meaning confusion, the
proliferation of false information in this chaotic environment can
have adversarial effects. This should be anticipated as part of a
careful approach to modernizing systems in this space.

\subsubsection{Allocation of Network Resources}
\label{sssec:allocation-of-network-resource}
Communications in disaster response environments might even be less
reliable than in the battlefield (setting aside offensive behavior
like signal jamming), requiring a greater emphasis on the preservation
of scarce network resources. For instance, a group of volunteer
firefighters would have fewer resources than a tactical military unit,
relying on commercial off-the-shelf (COTS) equipment rather than best
in class hardware like sophisticated handheld satellite links. High
bandwidth channels will often be in short supply, while adverse
conditions like inclement weather or dense smoke may as well be assumed.

Given the heavy reliance on data and the scarcity of reliable
communication channels, we expect a complex interaction between the
high-level needs of distributed applications (e.g. an application for
sharing real time weather data) and low-level concerns about network
resources. This is because only the applications have enough
information to determine which data is the most important and must be
shared with whom first, which has ramifications for network-level
mechanisms designed to prioritize important messages.

There is a widely accepted wisdom in computing---the end-to-end
principle \cite{1984:end-to-end}---which suggests that
applications should not make assumptions about the network, and that
the network should be relatively agnostic to high-level application
logic. However, in natural disaster environments where resources are
scarce and reliable communication is critical, these subsystems may
need to be more tightly integrated in how they influence each other to
achieve the best performance. This approach would not contravene the
end-to-end principle, but would involve carefully considering its
application in this relatively extreme context.

Consider a centralized data fusion
application running in an edge data center.\footnote{An
  \emph{edge} data center is one located closer to a network's edge,
  nearer to users, to provide low-latency communications for
  time-sensitive applications. Edge centers support applications that
  require significant amounts of information processing---enough that
  the application must be hosted in a datacenter, where compute
  resources can be scaled dynamically, rather than colocated with
  users where resources are limited.} This application could detect
critical events like a fire crossing a control line (a phenomenon
called \emph{slopover}) and alert ground responders. It might also
warn responders who have strayed too far from an escape route or
safety zone. These are high-priority notifications, so it would be
worthwhile to allocate scarce network resources to convey them to the
relevant parties in real-time.

On the other hand, while it may be beneficial for each firefighter to
have real-time information about the location of every other
firefighter, this may not always be critical. If transmitting this
data strains the network, then perhaps only the general location of
nearby teams should be sent. If the network is extremely constrained,
communication may be restricted to only information strictly relevant
to preserving life to ensure swift, reliable delivery. Thus, network
allocation is a dynamic calculation influenced both by the criticality
of the information (which is determined by the application logic) and
the availability of network resources at a particular
location. Network services should provide mechanisms like Quality of
Service (QoS) indicators to allow prioritizing certain
communication. Such mechanisms can be incorporated into a control loop
where applications generate feedback that drives the decision-making
process in lower-level parts of the network. However, simple QoS
mechanisms may not be enough---even the routing protocol of the
network may need to be more specialized to higher-level applications
than in traditional environments.


\section{Introduction to Distributed Systems}\label{sec:background}
In this section, we distill two core topics in the theory of
distributed systems: causality and timekeeping (two closely related ideas), and shared
memory consistency.  Our discussion is primarily informed by the
manuscripts of Coulouris et al.  \cite{coulouris2005distributed} and
Kshemkalyani and Singhal \cite{kshemkalyani_singhal_2008}. We focus on
building applications relevant to the scenarios described in Section
\ref{sec:disaster-response}, aiming to highlight obstacles and
strategies for developing distributed systems that can endure the
delays and disruptions inherent to these communication-challenged
environments. Readers interested in a summary of the highlights may
skip to Section~\ref{ssec:background-summary}.

At its core, a distributed system is a network of independent entities
working together to solve problems too complex for any one part to
tackle alone. From a bird’s-eye view, the systems we envision are
intricate and complex, made up of diverse, interconnected elements:
field agents like firefighters, their handheld devices, airborne and
ground vehicles loaded with communication and computing tools, swarms
of sensors and Internet of Things (IoT) devices, and so on. These decentralized components
operate alongside more centralized hubs: data fusion centers, incident
command (IC) posts, public safety answering points (PSAPs), and
emergency operations centers (EOCs). We imagine these components being
woven together by a patchwork of communication technologies ranging
from analog and digital radios to Bluetooth, Wi-Fi, LTE, 5G, satellite
communications, and ad-hoc mesh networks like Meshtastic\footnote{The
  website of the Meshtastic project describes it as an ``open source,
  off-grid, decentralized, mesh network built to run on affordable,
  low-power devices''. See \url{https://meshtastic.org}.}, DECT-2020
NR\footnote{DECT-2020 NR is a non-cellular 5G
  standard intended for Internet of Things (IoT) operations. For a
  technical discussion see \cite{2022:dect-2020-nr}.}, and others. The
system is thus a dynamic mosaic of elements cooperating to protect
lives and property.

Given the unpredictable nature of the environment and the locality
principle outlined in Section~\ref{sec:disaster-response},
communication between edge components---such as field operators---and
centralized hubs is often inconsistent, sometimes available only
intermittently. As a result, information flow is subject to
appreciable delays compared to the timescale of critical events like a
fire shifting direction or a dangerous condition being detected. In
other words, the computing landscape is unmistakably
\emph{distributed}. Singhal and Shivaratri \cite{10.5555/562065}
define a distributed computing system as:
\begin{quote}
  ``A collection of computers that do not share common
  memory or a common physical clock, that communicate by message
  passing over a communication network, and where each computer has
  its own memory and runs its own operating system.''
\end{quote}
This stands in contrast to a centralized computing environment, where
processes can seamlessly share data through common memory, and memory
access times are considered negligible.

For our use cases, message-passing latencies are not only significant
but unpredictable and difficult to control. As a result, we can
assume that some parts of the wider system will not have
instantaneous, complete knowledge of every new piece of
information. Only a few components, if any, will be able to maintain a
global systemwide awareness. While deploying additional infrastructure
in the field, such as Cells on Wheels (COWs), can help, the inherently
distributed nature of the environment cannot be fully overcome or
abstracted away. This reality must be embedded in the design of the
software and networking architecture itself. Typically, this manifests
in a shared ``middleware'' layer to coordinate the moving parts,
ensuring they function as a unified system.

The fragmented flow of information presents several challenges for
system designers. One of the foundational difficulties is that
unpredictable latencies make it difficult for components to maintain a
common understanding about the global sequence of events. For similar
reasons, it becomes challenging for processes to synchronize and agree
on shared values, such as the current number of firetrucks available
for dispatch. The remainder of this section will delve into these
issues with more technical depth.

\subsection{Physical Synchronization}
\label{ssec:physical-synchronization}
A lot of challenges in distributed computing could be
straightforwardly overcome if we assume that all participants have
instantaneous access to a common time base, i.e.  synchronized
clocks. Let us explore why fine-grained synchronization is not a
tenable assumption for all purposes.

Physical clocks, especially consumer-grade ones, suffer from
\emph{drift}, which is to say they do not all run at the same
rate. Experienced IT administrators will testify that clocks can also
be prone to misconfiguration. An incorrect date, time, timezone, or
daylight saving time policy setting is a common source of IT issues,
typically causing time-based security mechanisms like Transport Layer Security (TLS)
authentication to misbehave. Consider also that devices may spend a
long time sitting unpowered in storage without maintaining an
always-on clock. For these sorts of reasons, we would not want to rest
the integrity of a safety-related system on the assumption that a
numerous and diverse assortment of devices have precisely synchronized
internal clocks.

Clock drift can be corrected for using, for instance, signals from GPS
satellites, but as mentioned in Section~\ref{sec:disaster-response},
civil disaster environments are frequently GPS-denied: factors like
mountainous terrain, heavy smoke, and subterranean operations can lead
to errors or block signals entirely. Protocols like the Network Time
Protocol (NTP) \cite{rfc1119} work to bring clocks into
synchronization with respect to an authoritative source. On the public
internet, NTP typically achieves synchronization to within values on the
order of tens of milliseconds \cite{rfc1128}, but it is not clear the
level of synchronization that can be expected from NTP in the sorts of use
cases we have in mind. A field device initialized without internet
access may have no idea what the time is, but it must still operate.

For distributed systems, the critical feature of time is that
\emph{the future cannot influence the past}
\cite{1989mattern}. Fortunately, this property can be
enforced using mechanisms that do not rely on measuring real
time. Below, we explain how ``logical'' clocks can be used to
measure and enforce a key relation between events, this being their
\emph{causal precedence}.


\subsection{Message Passing and Causality}
\label{ssec:message-passing}
We model a distributed system abstractly as a fixed set
$\AllProc = \{P_1, P_2, \ldots P_N\}$ of $N$ \emph{processes} which
undergo atomic (indivisible) state changes known as
\emph{events}. Events are divided into three types: internal events,
representing state changes inside a single process, and send and
receive events corresponding to \emph{messages} passed between
processes. Note that this framework is quite abstract and applies to
any kind of packet-based communication technology. To draw out the
core issues surrounding messaging, the diagrams in this section do not
depict any internal events, as they represent state changes that are
not directly viewable to the network or other processes.

Throughout the section, processes and networks are opaque blackboxes,
which concentrates our attention on the ramifications of unpredictable
network latencies. We implicitly assume the reliable asynchronous
network model: when a message is sent between processes, it certainly
arrives at some point in the future, but we cannot say anything about
when or in what order compared to other messages. At times, we
consider the possibility that a message may never arrive. The choice
depends on which networking technology (or which layer of the OSI
networking model \cite{1983:osi-reference-model}) is under
consideration.

Figure~\ref{fig:message-latencies} illustrates a series of time
diagrams for messages exchanged between three processes: $P_1$, $P_2$,
and $P_3$. The $x$-axis represents the flow of real time from left to
right, which each process represented by a worldline depicting the
events occurring within that process. Each message, $m$, originates
from a send event $\msend{}$, marking the moment the message is
dispatched across the network by its source process. The delivery of
the message corresponds to a receive event, $\mrecv{}$. For now we
assume messages have a single receiver. We write subscripts on
messages to distinguish them for clarity, but these are not inherent
to the messages themselves.

\begin{figure}[p]
  \setlength\belowcaptionskip{5ex}
  \begin{subfigure}{1\textwidth}
    \centering
    \input{images/pgf/mpEx1.pgf}
    \caption{$P_1$ has a somewhat lower-latency connection to $P_2$ than to $P_3$}
    \label{fig:message-latencies-a}
  \end{subfigure}
  \begin{subfigure}{1\textwidth}
    \centering \input{images/pgf/mpEx2.pgf}
    \caption{$P_1$ has a much lower-latency connection to $P_2$ than to $P_3$}
    \label{fig:message-latencies-b}
  \end{subfigure}
  \caption{Message-passing time diagram examples}
  \label{fig:message-latencies}
\end{figure}

In these diagrams, arrows connect corresponding send and receive
events, with their diagonal slant representing the latencies
experienced as messages traverse the network. Because messages arrive
with varying delays, they might arrive in a different order than they
were sent in. In Figure~\ref{fig:message-latencies-a}, for example,
$P_1$ sends messages $m_2$ and $m_4$ sequentially, but $m_4$ arrives
before $m_2$, which might occur if $P_1$ and $P_3$ are separated by a
high-latency communication link. In Figure
\ref{fig:message-latencies-b}, $m_1$ is the first message sent but the
last to be delivered, potentially indicating a deteriorating link
between $P_1$ and $P_3$, perhaps due to increased distance or
inclement weather.

For many applications, it is critical to maintain a natural ordering
of events known as \emph{causal precedence}, or Lamport's ``happens
before'' relation \cite{1978:lamportclocks}. To formalize this, we
first consider the intuitive way to order events within a
\emph{single} process:
\begin{definition}
  For two events $e$ and $e'$ occurring in process $P$, we
  write $e <_{P} e'$ if $e$ occurs before $e'$ in $P$'s
  worldline.
\end{definition}
The previous definition is local to one process and unambiguous, as we
assume events within a process occur at discrete, non-overlapping
points in time. To extend this to a system-wide definition of causal
precedence, we relate corresponding send and receive events, then take
the transitive closure of the relation.

\begin{definition}[Causal precedence]
  \label{def:causalprecedence}
  We define a binary relation $\to$ on the set of events as follows:
  \[e \to e' \iff
  \begin{cases}
    e <_{P} e' \textrm{ for some process $P$}
    \textbf{ or} \\
    e = \msend{} \textrm{ and } e' =\mrecv{}
    \textbf{ or} \\
    \textrm{there is some } e'' \textrm{ such that } e \to e'' \textrm{ and } e'' \to e'
  \end{cases}
  \]
  If $e \to e'$, we say $e$ has \emph{causal precedence over} $e'$ or
  \emph{happens before} $e'$.
\end{definition}
Visually, $e \to e'$ holds when one can put a finger on $e$ in the
diagram and trace a ``path of causality'' to $e'$ by following
worldlines or arrows. We use the notation $e \not \to e'$ to mean
$e \to e'$ does not hold. Note that $e \not \to e'$ does not imply
$e' \to e$.

Incidentally, ``causal precedence'' and ``happens before'' can be
misnomers, as $e \to e'$ only conveys the possibility that information
from $e$ could have influenced $e'$. The requirement to ``not let the
future affect the past'' means that if $e$ might have influenced $e'$,
then applications must avoid situations where, from the user's point
of view, it appears that $e'$ happened before $e$. For example, this
proscription means an application cannot let an ``answer'' appear
before the underlying ``question''.

\begin{example}
  Figure~\ref{fig:causal-precedence} illustrates the causal precedence
  relation corresponding to the time diagrams in
  Figure~\ref{fig:message-latencies}. For readability we suppress
  redundant transitive arrows. The visual difference between
  Figures~\ref{fig:message-latencies-b} and~\ref{fig:message-co-b}
  reflects the fact that causal order only captures a logical
  relationship between events, but does not reflect their absolute
  time or within which process they occurred.
\end{example}

Mathematically, causal precedence is an irreflexive partial order:
\emph{irreflexive} because $e \not \to e$ (an event does not precede
itself), and \emph{partial} because any two events $e$ and $e'$ may
satisfy neither $e \to e'$ nor $e' \to e$.

\begin{definition}[Logical synchronicity]
  \label{def:logically-synchronous}
  Events $e$ and $e'$ that are not related by causality are said to be
  \emph{logically synchronous}, denoted $\sync{e}{e'}$.
\end{definition}

Note that logical synchronicity is not usually transitive, meaning it
is possible to have $\sync{e}{e'}$ and $\sync{e'}{e''}$ but not
$\sync{e}{e''}$.  Relations like $\left(\sync{}{}\right)$ that are
reflexive and symmetric but not necessarily transitive are sometimes
called \emph{compatibility relations}.
\begin{example}
  \label{ex:synchronous-intransitive}
  In Figure~\ref{fig:message-co-a}, $\sync{\mrecv{1}}{\mrecv{2}}$ and
  $\sync{\mrecv{2}}{\msend{4}}$, but $\mrecv{1} \to \msend{4}$. In
  Figure~\ref{fig:message-co-b}, $\msend{1}$ is logically synchronous
  with every event except $\mrecv{1}$, but those other events are
  totally ordered by causality and not synchronous with each other.
\end{example}

\begin{figure}
  \begingroup
  \setlength\belowcaptionskip{4ex}
  \begin{subfigure}{1\textwidth}
    \centering
    \input{images/pgf/mpEx1CO.pgf}
    \caption{Causal precedence among the events in Figure~\ref{fig:message-latencies-a}}
    \label{fig:message-co-a}
  \end{subfigure}
  \endgroup
  \begin{subfigure}{1\textwidth}
    \centering
    \input{images/pgf/mpEx2CO.pgf}
    \caption{Causal precedence among the events in Figure~\ref{fig:message-latencies-b}}
    \label{fig:message-co-b}
  \end{subfigure}
  \caption{Causal precedence relations for Figure~\ref{fig:message-latencies} (transitive arrows not shown)}
  \label{fig:causal-precedence}
\end{figure}

\subsection{Virtual Clocks}
\label{ssec:timestamps}
Distributed applications systematically track causality by employing
\emph{logical} clocks, which measure the logical flow of time by
timestamping events with (possibly sets of) non-negative integers that
are advanced according to certain rules. The three major variants are
scalar, vector, and matrix clocks, which form a kind of
spectrum. Scalar clocks are simple but provide coarse-grained
information, while vector and matrix clocks track increasingly more
precise information at the cost of greater administrative overheads.

All processes timestamp their events using their local clocks. For
each event $e$, let $C(e)$ denote the timestamp attached to that
event. The fundamental property we want to satisfy is that if $e$
causally precedes $e'$, it should receive a lesser timestamp. This is
called the clock consistency condition, or simply the clock condition.

\begin{definition}
  A system of timestamps satisfies the \emph{clock consistency
  condition} if the following monotonicity property holds:
\begin{equation}
  \textrm{For all $e$ and $e'$, if $e \to e'$ then $C(e) < C(e')$} \label{eq:mp}\tag{CC}
\end{equation}
\end{definition}

This notation states that if one event causally precedes another, then
the earlier one receives a lesser timestamp. Somewhat subtly, the
clock condition does \emph{not} imply that we can decide if events are
causally related by comparing timestamps. Rather, it provides a way of
\emph{ruling out} causal precedence. This is seen by expressing
\eqref{eq:mp} in terms of the following logically equivalent
condition.
\begin{equation}
  \textrm{For all $e$ and $e'$, if $C(e') \leq C(e)$ then $e \not\to e'$} \label{eq:mp-conv}\tag{CC$'$}
\end{equation}

If \eqref{eq:mp-conv} holds, we can be sure that a particular sequence
of events $e_1, e_2, e_3\ldots$ does \emph{not} list any $e$ before an
event that might have influenced $e'$ by checking that
$C(e_{i}) \leq C(e_{i+1})$ for all $i$. We emphasize that this does
not give us a definite way to tell whether two events are in fact
causally related. If it is important to determine conclusively whether
events are causally related, one is led to consider the following
stronger requirement from a system of logical timestamps.
\begin{definition}
  An event-timestamping mechanism satisfies the \emph{strong} clock   condition if the following property holds.
  \begin{equation}
    \textrm{For all events $e$ and $e'$, } e \to e' \iff C(e) <
    C(e') \label{eq:sc}\tag{SC}
  \end{equation}
  Note that $\iff$ is notation for ``if and only if,''or logical
  equivalence.
\end{definition}
Scalar clocks, below, satisfy \eqref{eq:mp}, while vector and matrix
clocks satisfy \eqref{eq:sc}.

\subsubsection{Scalar clocks}
\label{sssec:scalar-clocks}
\begin{figure}
  \setlength\belowcaptionskip{5ex}

  \begin{subfigure}{1\textwidth}
    \centering \input{images/pgf/mpEx1Sc.pgf}
    \caption{Figure~\ref{fig:message-latencies-a} re-depicted with scalar clocks}
    \label{fig:message-latencies-scalar-a}
  \end{subfigure}

  \begin{subfigure}{1\textwidth}
    \centering \input{images/pgf/mpEx2Sc.pgf}
    \caption{Figure~\ref{fig:message-latencies-b} re-depicted with scalar clocks}
    \label{fig:message-latencies-scalar-b}
  \end{subfigure}

  \caption{Scalar clock examples}
  \label{fig:message-latencies-scalar}
\end{figure}

Lamport's scalar clocks \cite{1978:lamportclocks} require each
process $P$ to maintain a single non-negative scalar value $C$,
initialized to $0$. The clock follows two simple update rules:
\begin{enumerate}
\item[\textbf{R1}:] Before a message is sent or an internal event occurs, $P$
  increments its clock:
  \[C := C + 1.\]
  The new value serves as the event's timestamp and, for messages, is ``piggybacked''
  as part of its metadata.
\item[\textbf{R2}:] When $P$ receives a message with timestamp $C'$, it
  updates $C$ as such:
  \[C := \max(C, C') + 1.\]
  The value is the receive event's timestamp.
\end{enumerate}

\begin{example}
  Figure~\ref{fig:message-latencies-scalar} depicts the same events in
  Figure~\ref{fig:message-latencies} with scalar timestamps (shown in
  parentheses) assigned to each event. Piggybacked timestamps are
  shown as labels on the message arrows.
\end{example}

Scalar clocks satisfy the clock condition \eqref{eq:mp}. This can be
observed by tracing the path of causality between related events and
seeing that the clock is incremented at each step. However, they do
not satisfy \eqref{eq:sc}.  While $e$ having a lesser timestamp than
$e'$ rules out $e' \to e$, it does not imply $e \to e'$. For instance,
in Figure~\ref{fig:message-latencies-scalar-b}, $\msend{1}$ has a
globally minimal timestamp value of $1$, but it does not causally
precede all events with timestamps greater than $1$, or indeed any
event except $\mrecv{1}$.

\subsubsection{Vector clocks}
\label{sssec:vector-clocks}
The strong clock condition \eqref{eq:sc} cannot hold either using
scalar clocks or even synchronized physical clocks because they both
assign timestamps whose values form a total order, meaning any
non-equal timestamps $C_1, C_2$ satisfy either $C_1 < C_2$ or
$C_2 < C_1$. This leaves no way to assign timestamps to synchronous
events that satisfy neither $e \to e'$ nor $e' \to e$, except to make
their timestamps are equal. However, assigning equal timestamps to
logically synchronous events is contradictory, since an event $e$ can
be synchronous with multiple events $e', e''\ldots$ that are not
synchronous with each other (recall Example
\ref{ex:synchronous-intransitive}). The solution is to let timestamps
from a partial order, allowing clock values that are not directly
comparable.

Vector clocks store one scalar value for each process in the system,
which forms a partial order when vectors are compared
component-wise. $P$ maintains a vector $\vt{}$ of $N$ non-negative
integers, one for each process in $\AllProc$, with all values
initialized to $0$. To disambiguate $P$'s vector clock from $Q$'s, we
sometimes add superscripts, e.g. $\vt{P}$ versus $\vt{Q}$.

The $P^\textrm{th}$ component of $P$'s vector clock, denoted
$\vt{}[P]$, is called $P$'s \emph{local time}. For all other processes
$Q$, $\vt{}[Q]$ represents a lower bound of $Q$'s local time. Vector
clocks are updated according to two rules:
\begin{enumerate}
\item[\textbf{R1}:] Before an internal event occurs or a new message is sent, $P$
  increments its local time according to the rule:
  \[\vt{}[P] := \vt{}[P] + 1.\]
  The (entire) updated $\vt{}$ is the event's timestamp and is piggybacked with outgoing messages.
\item[\textbf{R2}:] When $P$ receives a message from $Q$ with timestamp
  $\vt{Q}$, $\vt{}$ is updated according to
  \[\vt{}[X] := \max(\vt{}[X], \vt{Q}[X]) \quad \textrm{for all $X$ in $\AllProc$}.\]
  That is, $\vt{}$ is set to the pointwise maximum of the two
  vectors. After this, $P$ increments its local time:
  \[ \vt{}[P] := \vt{}[P] + 1.\]
  The final vector is the timestamp of the receive event.
\end{enumerate}
These rules might be more intuitively understood by demonstration, so we provide figures to demonstrate the vector clock mechanism.

\begin{example}
  Figure~\ref{fig:message-latencies-vector} depicts the same events as
  Figure~\ref{fig:message-latencies} with vector timestamps.
\end{example}

\begin{figure}
  \setlength\belowcaptionskip{5ex}

  \begin{subfigure}{1\textwidth}
    \centering
    \input{images/pgf/mpEx1Vec.pgf}
    \caption{Figure~\ref{fig:message-latencies-a} re-depicted with vector clocks}
    \label{fig:message-latencies-vector-a}
  \end{subfigure}

  \vspace{4ex}

  \begin{subfigure}{1\textwidth}
    \centering \input{images/pgf/mpEx2Vec.pgf}
    \caption{Figure~\ref{fig:message-latencies-b} re-depicted with vector clocks}
    \label{fig:message-latencies-vector-b}
  \end{subfigure}

  \caption{Vector clock examples}
  \label{fig:message-latencies-vector}
\end{figure}
\afterpage{\clearpage}

For all other $Q$ in $\AllProc$, $\vt{P}[Q]$ represents $P$'s
conservative estimate of $Q$'s local time, or $\vt{Q}[Q]$. This
estimate is always a lower bound, since $Q$'s local time may advance
without $P$'s knowledge, but $P$ never updates $\vt{P}[Q]$ ahead of
$Q$'s actual local time. $P$ learns about updates to $Q$'s local time
through piggybacked timestamp vectors. This allows $P$ to learn about
$Q$'s time without necessarily communicating directly with $Q$.

Vector timestamps are compared component-wise. This forms a partial
order because one vector may be greater than another in some
components but less than it in others.

\begin{definition}[Vector comparison]
  Let $v, w$ be two vectors. We define the following relations:
  \begin{align*}
             v = w &\iff \forall i, v[i] = w[i] \\
  v \preccurlyeq w &\iff \forall i, v[i] \leq w[i] \\
         v \prec w &\iff v \preccurlyeq w \textrm{ and } \exists i, v[i] < w[i] \\
            \syncts{v}{w} &\iff \textrm{ neither } v \prec w \textrm{ nor } v \succ w
  \end{align*}
  That is, $v \prec w$ if all of $w$'s components are at least as
  great as $v$'s, and at least one of its components is strictly
  greater. When two non-equal vectors are compared, and neither is
  greater than the other, we write $\syncts{v}{w}$ and say the vectors
  are \emph{incomparable}.
\end{definition}

\begin{lemma}
  Vector clocks satisfy the strong clock consistency condition. That
  is, where $C(e)$ is the vector timestamp of an event, then
  \[ e \to e' \iff C(e) \prec C(e'). \]
  From this it follows that for non-equal events $e$ and $e'$ we have
  \[\sync{e}{e'} \iff {C(e) \texttt{\#}\,C(e')}. \]% This isn't typesetting right
\end{lemma}

For reasons of space we omit a proof of the preceding lemma, though
the reader may find it enlightening to formalize the details.

Note that vector clocks (and matrix clocks, defined below) both require the processes
to agree on the set of members in the group. If groups can change,
with members leaving or being added, the timekeeping data structures
would similarly have to be updated. We ignore issues of dynamic group
membership in this document.

\subsubsection{Matrix clocks}
\label{sssec:matrix-clocks}
If a vector clock stores both a local time and a lower bound estimate
of every other process's local time, then a \emph{matrix clock} stores a
local vector clock and a lower bound estimate of every other process's
vector clock. In Section~\ref{sec:disaster-response}, we mentioned the epistemic nature of
reasoning about distributed systems: a process can only make decisions
based on what it \emph{knows}, which is usually a strict subset of all
(system-wide) truths. In many cases, it is important to take into
account a kind of second-order knowledge: what we does a process know
about what other processes know? In particular, it is often of interest to compute which facts are known to \emph{all} other processes. Vector clocks can used for this purpose. In some contexts, we must take the idea one step further: what does a process know about what other processes know \emph{about other processes}? This is the purpose of matrix clocks. Sections~\ref{sec:tsae} and~\ref{sec:continuous-consistency} feature running examples of mechanisms similar to vector and matrix clocks, called version vectors and matrices. These are used in the context of database replication, where they drive decision-making about which updates need to be propagated and which updates have already been applied everywhere.

In a matrix clock, each process $P$ stores an $N\times{}N$ matrix
$\mt{}{}{}$, initialized to all zeros, with the following
interpretation. The row corresponding to $P$, $\mt{}{[P]}{}$,
stores $P$'s vector time. For all other $Q$, $\mt{}{[Q]}{}$ store $P$'s
estimate of $Q$'s vector time. Matrix timestamps are piggybacked
with messages, and the receiver uses the sender's vector clock to
update their own vector clock as usual, and takes the pointwise
maximum of all other rows.

\begin{enumerate}
\item[\textbf{R1}:] Before a new message is sent, $\mt{P}{[P]}{[P]}$ is updated according to the rule
  \[\mt{P}{[P]}{[P]} := \mt{P}{[P]}{[P]} + 1.\]
  The entire matrix $\mt{}{}{}$ is piggybacked with the message.
\item[\textbf{R2}:] When a message is received from $Q$ with a piggybacked matrix $\mt{Q}{}{}$,
  $\mt{P}{}{}$ is updated according to two cases
  \begin{enumerate}
  \item Update the row $\mt{P}{[P]}{}$ according to
    \[\mt{P}{[P]}{[X]}:= \max( \mt{P}{[P]}{[X]} ,  \mt{Q}{[Q]}{[X]}) \quad \textrm{for all $X$ in $\AllProc$}\]
  \item Update all rows for each $R \neq P$ according to
    \[\mt{P}{[R]}{[X]} := \max(\mt{P}{[R]}{[X]} ,  \mt{Q}{[R]}{[X]})) \quad \textrm{for all $X$ in $\AllProc$}\]
  \end{enumerate}
  After this, $P$ advances its own local time according to the rule
  \[ \mt{P}{[P]}{[P]} := \mt{P}{[P]}{[P]} + 1.\]
  This new matrix is the timestamp attached to the receive event.
\end{enumerate}

\begin{figure}[p]
  \begingroup
  \setlength\belowcaptionskip{4ex}
  \begin{subfigure}{1\textwidth}
    \input{images/pgf/mpEx1Mat.pgf}%
    \caption{Matrix clock timestamps for the events in Figure~\ref{fig:message-latencies-a}}
    \label{fig:message-latencies-matrix-a}
  \end{subfigure}
  \begin{subfigure}{1\textwidth}
    \input{images/pgf/mpEx2Mat.pgf}%
    \caption{Matrix clock timestamps for the events in Figure~\ref{fig:message-latencies-b}}
    \label{fig:message-latencies-matrix-b}
  \end{subfigure}
  \caption{Figure~\ref{fig:message-latencies} depicted with matrix clocks}
  \label{fig:message-latencies-matrix}
  \endgroup
\end{figure}

\begin{example}
  Figure~\ref{fig:message-latencies-matrix} depicts the same events as
  Figures~\ref{fig:message-latencies},
 ~\ref{fig:message-latencies-scalar} and
 ~\ref{fig:message-latencies-vector} using matrix timestamps. By
  comparison to Figure~\ref{fig:message-latencies-vector}, observe
  that for each process $X$, rows of the form $\mt{X}{[X]}{}$---for
  instance, the top row of matrices in $P_1$---act like ordinary vector
  clocks.
\end{example}

\subsection{Message Ordering}
\label{ssec:message-ordering}
Coulouris et al. \cite{coulouris2005distributed} summarized why
it is a problem for unpredictable network latencies to cause messages
to arrive in a different order than they were sent in.
\begin{quote}
  ``This lack of an ordering guarantee is not satisfactory for many
  applications. For example, in a nuclear power plant it may be
  important that events signifying threats to safety conditions and
  events signifying actions by control units are observed in the same
  order by all processes in the system.''
\end{quote}
In this section, we explore different paradigms for message ordering
in distributed systems. As with clocks and timestamps, the choice of
which ordering guarantee to use depends on the needs of the
application. We later generalize the discussion by admitting messages
sent to multiple recipients at once, such as in a group chat
application, where ensuring predictable message ordering is critical.

When ordering is important, applications do not show messages to the
user immediately when they come in from the network---the network can
deliver messages in unexpected and undesirable orders, after all. The
\emph{arrival} time of a message is when it is received from the
network, but instead of acting on it right away, an application may
buffer an arrived message while waiting for other messages (such as
ones with an earlier causal precedence) to ``catch up.'' When a
message is ready to be presented to the user, it is
\emph{delivered}. By waiting to deliver some messages, we can ensure
the stream of messages in order of their delivery satisfies particular
guarantees.

\subsubsection{FIFO ordering}
A modest requirement is the \emph{first-in, first-out} (FIFO)
condition, which stipulates that on any logical communication link
between two processes in the system, messages arrive in the order they
were sent. The restrictive phrase here is ``any logical communication
link''---by definition there is one link for any \emph{pair} of
processes. Hence, FIFO does not impose any conditions on messages
unless they are from the same sender and to the same recipient.

\begin{definition}[FIFO delivery]
  \label{def:fifo}
  The FIFO ordering guarantee is defined by the following condition. Let
  $P$ and $Q$ be any two processes and $m_1$ and $m_2$ be two
  messages sent from $P$ to $P$. Then
  $\msend{1} \to \msend{2} \implies \mrecv{1} \to \mrecv{2}$.
\end{definition}

The Internet Protocol (IPv4 or IPv6) by itself does not provide FIFO
semantics. In the OSI model, FIFO ordering with reliable delivery is
typically provided at the transport layer by the transmission control
protocol (TCP).\footnote{The other classic internet transport, user
  datagram protocol (UDP), does not provide any ordering or
  reliability guarantees.} Applications built on top of TCP or a
similar transport can take therefore take FIFO for granted. Providing
FIFO can be as simple as marking messages sent from $P$ to $Q$ with
consecutive integers. If message one arrives and then message three arrives, $Q$
infers that message two is lagging behind, delivering message one to the user, but
withholding delivery of message three until after message two is received and delivered.

The guarantees provided by FIFO are minimal because they only apply on
a per-link basis: every link requires its own numbering scheme, so
message numbers cannot be meaningfully compared across different
links. To compare messages globally requires something like causal
order, below.

\begin{figure}[p]
  \setlength\abovecaptionskip{0ex}
  \setlength\belowcaptionskip{4ex}
  \begin{subfigure}[t]{0.475\textwidth}
    \centering
    \input{images/pgf/ordEx1.pgf}
    \caption{A non-FIFO execution}
    \label{fig:ordex-non-fifo}
  \end{subfigure}
  \begin{subfigure}[t]{0.475\textwidth}
  \centering
  \input{images/pgf/ordEx2.pgf}
  \caption{A CO (therefore FIFO) execution}
  \label{fig:ordex-co-1}
\end{subfigure}
\begin{subfigure}[b]{0.475\textwidth}
  \centering
  \input{images/pgf/ordEx3.pgf}
  \caption{A CO execution}
  \label{fig:ordex-co-2}
\end{subfigure}
\begin{subfigure}[b]{0.475\textwidth}
  \centering
  \input{images/pgf/ordEx6.pgf}
  \caption{A CO execution}
  \label{fig:ordex-co-3}
\end{subfigure}
\begin{subfigure}[b]{0.475\textwidth}
  \centering
  \input{images/pgf/ordEx5.pgf}
  \caption{A FIFO and non-CO execution}
  \label{fig:ordex-non-co-1}
\end{subfigure}\hfill
\begin{subfigure}[b]{0.475\textwidth}
  \centering
  \input{images/pgf/ordEx4.pgf}
  \caption{A FIFO and non-CO execution}
  \label{fig:ordex-non-co-2}
\end{subfigure}
\caption{Message ordering examples}
\label{fig:message-ordering}
\end{figure}

\subsubsection{Causal ordering}
Causal order is an order guarantee consistent with causal precedence
of events. A network provides causally ordered (CO) delivery if it
satisfies the following property.
\begin{definition}[CO delivery]
  \label{def:causalorder}
  Let $P_\mathrm{dest}$ be any process and consider all messages $m$
  and $n$ sent to $P_\mathrm{dest}$ (possibly by different senders).
  CO is satisfied if $\msend{} \to n^\textrm{send}$ implies
  $\mrecv{} \to n^\textrm{recv}$. That is, each destination receives
  messages in an order consistent with causality between their send
  events.
\end{definition}
In mathematical terms, for each process $P_{\mathrm{dest}}$, the
function mapping send events to corresponding receive events at
$P_{\mathrm{dest}}$ must be monotonic with respect to causal
precedence.  Unlike FIFO, the CO condition enforces a partial order
among messages with (in general) different senders.

\begin{example}
  Figure~\ref{fig:message-ordering} demonstrates different message
  ordering conditions. We make a few observations for emphasis.

  \begin{itemize}
    \tightlist
  \item Figure~\ref{fig:ordex-non-fifo} violates FIFO because messages
    $m_1$ and $m_2$ are both sent from $P_1$ to $P_2$, but the arrive
    in the wrong order.
  \item Figure~\ref{fig:ordex-co-1} satisfies CO and therefore FIFO. Messages
    $m_1$ and $m_2$ arrive in the opposite order but they are sent to
    different destinations.
  \item Figure~\ref{fig:ordex-non-co-1} violates CO because the send event of
    $m_1$ happens before the send of $m_3$ via the chain
    $\msend{1} \to \msend{2} \to \mrecv{2} \to \msend{3},$ but
    $\mrecv{3} \to \mrecv{1}$.
  \item Figure~\ref{fig:ordex-non-co-2} violates CO because it is equivalent to~\ref{fig:ordex-non-co-1} with the roles of $P_2$ and $P_3$ swapped.
  \end{itemize}
\end{example}

\subsubsection{Multicasting and Broadcasting}
\label{sssec:multicasting}
We now extend the above definitions to the group communication setting
by allowing messages to have multiple recipients. For simplicity, we
suppose messages are broadcast to all other recipients, though the
definitions can easily generalize to ``multicast'' scenarios where
messages are sent to a subset of recipients.

One way to implement broadcasting is to sending distinct network
messages which, for present purposes, we would treat as a single
unit. Alternatively, we can lean on the network itself for assistance,
sending a single message specially marked as a broadcast, relying on
lower-level protocols in the network to distribute a copy to each
recipient. Regardless of implementation, the challenge and importance
of ensuring consistent message ordering across an entire group is a
paramount concern.

The FIFO and CO broadcast conditions are adapted from
Definitions~\ref{def:fifo} and~\ref{def:causalorder}. Additionally, we
present the notion of total ordering (TO).

\begin{definition}[FIFO broadcast]
  \label{def:fifo-bcast}
  A broadcast primitive satisfies the FIFO semantics if it satisfies
  the following condition. For any process $P$, if $P$ broadcasts
  $m_1$ before $m_2$, then all recipients receive $m_1$ before $m_2$.
\end{definition}

\begin{definition}[CO broadcast]
  \label{def:causalorder-bcast}
  A broadcast primitive satisfies CO semantics if for any broadcasts
  $m$ and $n$, if $\msend{} \to n^{\textrm{send}}$, then all
  destinations deliver $\mrecv{}$ before $n^{\textrm{recv}}$.
\end{definition}
In the above definition, the happens before relation is defined just
as in the unicast (non-broadcast) setting by following a path of
causality along worldlines and message arrows.

\begin{figure}[h]
  \centering \input{images/pgf/mpEx3.pgf}
  \caption{Broadcast example that satisfies FIFO but violates CO}
  \label{fig:broadcast-fifo-1}
\end{figure}

\begin{example}
  In Figure~\ref{fig:broadcast-fifo-1}, causal order is violated. Imagine the following conversation:
  \begin{itemize}
    \tightlist
  \item [$P_1$]: ``I need an ambulance at location A.''
  \item [$P_2$]: ``Understood, the last ambulance has been dispatched.''
  \end{itemize}
  However, $P_3$ receives $P_2$'s response before $P_1$'s request, resulting in this conflicting view:
  \begin{itemize}
    \tightlist
  \item [$P_2$]: ``Understood, the last ambulance has been dispatched.''
  \item [$P_1$]: ``I need an ambulance at location A.''
  \end{itemize}
  From $P_3$'s perspective, $P_1$ appears to be requesting resources
  that are no longer available. The sort of conflict can lead to
  confusion, with requests being duplicated or going
  unanswered. Tracking causal order is crucial to avoid such resource
  misallocation.
\end{example}

A total order broadcast ensures that all recipients receive the
messages in the same order. This order is not required to satisfy any
particular constraints except that all recipients agree on it. Such a
model is appropriate when it is more important that everyone agrees on
a common order of events but the order itself is not necessarily
critical.

\begin{definition}[TO broadcast]
  \label{def:totalorderbroadcast} For any processes $P$ and $Q$ and
  messages $m$ and $m'$ that arrive at both destinations, $m$ arrives
  before $m'$ at both processes or $m'$ arrives before $m$ at both
  processes.
\end{definition}

Total order is independent of causal order, as causality is not total
and a total order does not generally respect causality. Thus it
sensible to consider also a hybrid notion of \emph{total-causal} order
in which all messages are received in a total order respecting
causality.

\begin{figure}[p]
  \setlength\belowcaptionskip{5ex}
  \begin{subfigure}{1\textwidth}
    \centering
    \input{images/pgf/bcastEx1.pgf}
    \caption{Broadcast example that satisfies FIFO but violates CO and TO}
    \label{fig:bcast-order-examples-1}
  \end{subfigure}
  \begin{subfigure}{1\textwidth}
    \centering
    \input{images/pgf/bcastEx2.pgf}
    \caption{Broadcast example that satisfies CO but violates TO}
    \label{fig:bcast-order-examples-2}
  \end{subfigure}
  \begin{subfigure}{1\textwidth}
    \centering
    \input{images/pgf/bcastEx3.pgf}
    \caption{Broadcast example that satisfies TO but violates FIFO}
    \label{fig:bcast-order-examples-3}
  \end{subfigure}
  \caption{Multicast ordering examples}
  \label{fig:bcast-ordering-examples}
\end{figure}

\begin{example}
Figure~\ref{fig:bcast-ordering-examples} depicts examples of broadcast
message orders.
\begin{itemize}
  \tightlist
\item Figure~\ref{fig:bcast-order-examples-1} trivially satisfies FIFO
  because no process sends more than one broadcast. CO is violated
  because $\msend{1} \to \mrecv{1,4} \to \msend{2}$, while $P_2$
  receives $m_2$ before $m_1$. TO is violated because $P_2$ and $P_3$
  receive the messages in opposite orders.
\item Figure~\ref{fig:bcast-order-examples-2} violates TO for the same
  reason above, but satisfies causality because the two send events
  have no causal relation.
\item Figure~\ref{fig:bcast-order-examples-3}
  satisfies TO, but $m_2$ arrives at both processes before $m_1$ so
  FIFO is violated.
\end{itemize}
\end{example}
Section~\ref{ssec:tsae-message-ordering} describes a conventional
mechanism used to implement total order broadcast.
\paragraph{Self-delivered messages}
In some contexts one considers broadcast primitives that include the
original sender among the recipients of a message. For simplicity, the
examples in this section have not shown this sort of self-delivery,
but it is useful in many cases. Self-delivery is useful when combined
with ordering guarantees. A typical use case is that participants are
using a total order broadcast to maintain local replicas of a state
machine that can be advanced by any participating process by
announcing updates.  This usage is presented in Sections
\ref{sec:tsae} and~\ref{sec:continuous-consistency}, with the goal of
replicating shared state over a disruption-heavy network.

\subsection{Shared Memory}
\label{ssec:shared-memory}
Designing a distributed application using direct message passing can be
challenging due to the complexity of managing the low-level details
surrounding message ordering and reliability. A more abstract
approach, the \emph{distributed shared memory} (DSM) framework,
simplifies this task by allowing programmers to think in terms of
reading and writing to memory locations instead of sending messages
over a network.

The defining feature of DSM is that it allows all processes to
interact as if they had access to a single, unified proof of shared
memory---just like processes running on a single computer---despite
being spread across different, physically separated computers.  This
seamless (subject to caveats explained below) experience is
facilitated by a middleware layer inside the process called the
\emph{memory manager}, which handles all read and write requests
submitted by an application. In the background, not directly visible
to the application, the memory manager coordinates with other
instances over the network to maintain the illusion of a shared state,
or what first responders would call a ``common operating picture.''

Since there is no free lunch, the seamlessness of the DSM model is
subject to caveats, especially this one: usually, a read request
handled by the memory manager does not return the most up-to-date
value of the memory location it reads. Indeed, in the distributed
setting it is not clear a priori what it means for a returned value to
be ``up-to-date'' in the first place, in light of the fact that two
different processes can write conflicting values to the same memory
location at the same time. For developers, understanding the semantics
of the virtual memory layer is a crucial
part of building applications that function correctly while providing
reliable performance. This requires  knowing what guarantees the
virtual memory layer  makes concerning what values can be returned at which times.
 Because of the sorts of tensions discussed in
Section~\ref{sec:disaster-response}, the design space here is
generally marked by a tradeoff between stronger consistency guarantees
and faster performance.

\begin{figure}
    \centering
    \input{images/pgf/dsm_ex1_WithoutEdges.pgf}
    \caption{Time diagram for memory operations}
    \label{fig:dsm-example-1}
\end{figure}

\begin{figure}
  \centering
  \input{images/pgf/dsm_ex1_DAG.pgf}
  \caption{External order relation among operations in Figure~\ref{fig:dsm-example-1} (with edges implied by transitivity not shown)}
  \label{fig:dsm-example-1-DAG}
\end{figure}

Figure~\ref{fig:dsm-example-1} depicts an exemplary time diagram for
the shared memory abstraction, similar to those for message
passing. Two kinds of operations are shown: \emph{reads} and
\emph{writes}. A read operation, $\memread{x}$, retrieves the value
stored at (virtual) location $x$, which returns some value $v$. When
we want to indicate the value returned by the read, we write
$\memreadVal{x}{v}$. A write operation, $\memwrite{x}{v}$, indicates
writing $v$ to memory location $x$, which in code might be written as
something like $x := v$.

An operation does not happen instantly, but has a \emph{duration}. An
arbitrary read or write operation, $\Op$, spans from the moment of
time the operation is invoked by the application ($\memstart{\Op}$),
to when it finished ($\memstop{\Op}$), returning either the read value
or an acknowledgment of the write request. During this span, the
memory management layer is usually coordinating in the background with
other processes over the network, say by looking up the current value
of a memory location, but this is not shown in the diagrams. The
entire sequence of requests across all processes forms what we call a
\emph{history}. If $H$ is a history and $P$ is a process, we write
$\restrictedhistory{P}$ to mean just the sequence of operations that happen on $P$, the
so-called \emph{local history} of $P$.

Because they have a duration, memory operations on different
processes, including ones that access the same virtual memory
locations, can occur simultaneously. A fundamental relation among
operations is their \emph{external order}, the partial order that
relates non-overlapping events their physical times, but does not
assign an ordering to events whose executions overlap in physical
time.
\begin{definition}[External order]
  \label{def:external-order}
  Let $H$ be a history. An operation $\Op^1$ \emph{externally
    precedes} operation $\Op^2$ if
  $\memstop{\Op^1} < \memstart{\Op^2}$. This induces an irreflexive
  partial order on $H$ called \emph{external order}.
\end{definition}
The definition states that one operation externally precedes another
if it stops before the other is invoked. Note that we are comparing
events in terms of real, physical time: external order is the partial
order of events witnessed by an outside observer who can watch
operations executing globally in real time. Figure
\ref{fig:dsm-example-1-DAG} depicts the external order among the
operations in Figure~\ref{fig:dsm-example-1}, forming a directed
acyclic graph (DAG).

Two events not related by external order are said to be physically
concurrent.

\begin{definition}[Physical concurrency]
  \label{def:physical-concurrency}
  Consider two operations $\Op^1$ and $\Op^2$. If neither externally
  precedes the other, in another words if there is some moment in time
  during which both operations are executing, the operations are said
  to be \emph{physically concurrent}, written $\concurrent{\Op^1}{\Op^2}$.
\end{definition}

Note that we have reused notation between Definitions
\ref{def:logically-synchronous} and~\ref{def:physical-concurrency}.
Though they are similar concepts (both are reflexive and symmetric but
generally non-transitive binary relations), physically concurrent
memory operations in the DSM model should not be confused with
logically synchronous events in the message-passing model.

\subsection{Semantics and Consistency}
In a sequential application running on a single computer, it is clear
how read and write requests should be interpreted. A read request
$\memread{x}$ should return the most recent value that was written to
$x$ by a write operation $\memwrite{x}{v}$ (or return a default value
if no such write exists, but we will not consider such examples). This
is unambiguous because we assume that in a single process, memory
operations do not overlap in time, so there is always a sense of which
one happened first.

\begin{example}
  Consider the following history of operations running inside a single process.
  \[\input{images/pgf/dsm_ex_sequential.pgf}\]
  This diagram does not indicate what values are returned by the read
  operations, but since there is no ambiguity in the order of events,
  it is clear what these values \emph{should} be. Each read request
  should return the value (shown in bold below) set by the most recent
  write to that location.
  \[ \memwrite{x}{0} \to \memwrite{y}{5} \to \memreadVal{x}{\textbf{0}} \to \memwrite{x}{3} \to \memreadVal{y}{\textbf{5}} \to \memreadVal{x}{\textbf{3}}. \]
\end{example}

In a distributed system, operations on different processes can run
concurrently, so there is no obvious way to arrange events into a
total order that all processes can agree on. Consequently, the notion
of ``most recent'' operation is ambiguous, so it does not even make
sense to say that read requests always return the most recent written
value.

\begin{figure}[h]
  \input{images/pgf/dsm_ex2.pgf}
  \caption{A history with read return values left unspecified,
    featuring concurrent operations writing to and reading from the
    same location}
  \label{fig:dsm-example-2}
\end{figure}

%\begin{example}
%  \label{exmpl:concurrentupdates}
%\end{example}

Consider the history shown in Figure~\ref{fig:dsm-example-2}, which
contains three operation that write to location $x$. Two of these
operations, $\memwrite{x}{3}$ $\memwrite{x}{5}$, are executed at
overlapping moments in time, making it unclear which should be
considered ``first.'' The ambiguity is made concrete by considering
the subsequent read operations---which values should they return? Or
rather, we should ask which values are they \emph{allowed} to return,
since the possibilities are not usually deterministic.

A \emph{memory model} exists precisely to answers questions of the
form, ``Which values might be returned by read requests in which
scenarios?'' In the example above, a model would have to answer
several questions like the following ones:
\begin{enumerate}
\item Do the read operations on $P_1$ and $P_2$ have to return the same value?
\item Can the second read operation at $P_2$ return a different value
  than the first one?
\item Is it ever possible for any of the $\memread{x}$ operations to
  return the value 4?
\end{enumerate}

One can consider many different ways of answering these questions,
depending on the consistency requirements of the high-level
application. The strictest memory model is called
\emph{linearizability}. If the distributed
system whose history is shown in Figure~\ref{fig:dsm-example-2} is
linearizable, the all three read operations must return the same
value, and this must be either $3$ or $5$. This model is intuitive but
too strict for our use case, so programmers must be prepared for less
rigidly prescribed behavior from the memory manager.

Choosing to implement a particular memory model requires balancing the
needs and expectations of the application against its performance
characteristics, including its usage patterns and networking
environment. An application designed for one memory model would
generally misbehave, often in a way that is difficult to diagnose, if
executed in an environment that implements a different model. However,
on the other hand, implementing a stricter memory model may impose a
prohibitive overhead on application performance.

To resolve the ambiguity caused by overlapping memory operations, one
might attempt to assign physical timestamps to them and use this to
define an agreed-upon global total order of operations. However, using
these kinds of orders in practice requires sufficiently fine-grained
timestamps from synchronized clocks. For our environments this is
often infeasible (see Section
\ref{ssec:physical-synchronization}).

\subsection{Strong Consistency Models}
\label{ssec:strong-consistency}
This section considers the two major memory models usually said to
provide ``strong'' consistency: linearizability and sequential
consistency. Both models involve the notion of a sequential history,
or a set of operations arranged into a particular total order.

\begin{definition}[A sequential history]
  \label{def:sequential-history}
  A \emph{sequential history} is a set of memory operations in a
  particular total order. If $H$ is a history, a \emph{serialization}
  is any total order among the operations in $H$.
\end{definition}

Linearizability and sequential consistency both require that all read
operations return values consistent with some serialization of the
global history. That is, they stipulate that among all the operations
in $H$, there is some way of ordering them so that all read operations
return the values of the most recent write operations. Where the two
models differ is in how they constrain which serializations of $H$ are
allowable.

\subsubsection{Linearizability}
\label{sssec:linearizability}

\emph{Linearizability} can be concisely defined as a system that acts like
``each operation applied by concurrent processes takes effect
instantaneously at some point between its invocation and response.''
\cite{10.1145/78969.78972} The same condition is known (though
sometimes with subtle variations in meaning) by names like atomic
consistency and external consistency. It means almost the same thing
as strict serializability, except the latter terminology is used to
discuss transactional databases and implies other database-related
guarantees. Formally, a linearizable history is defined by three
features.
\begin{definition}[Linearizable history]
  \label{def:linearizable-history}
  Let $H$ be a history of memory operations. $H$ is
  \emph{linearizable} if it satisfies the following three rules.
\begin{enumerate}
  \tightlist
\item \textbf{Global Agreement on Order}: All processes behave
  (defined below) as if they are observing the same serialization of
  $H$, meaning some particular total order $\sigma$.
\item \textbf{Correct Responses}: Each read request
  \(\memreadVal{x}{a}\) returns the value of the most recent write
  request \(\memwrite{x}{a}\) as ordered by $\sigma$.
\item \textbf{Consistent with External Order}: The serialization of
  $H$ is consistent with external order: if
  $\memstop{\Op^1} < \memstart{\Op^2}$, then $\sigma$ also orders
  $\Op^1$ before $\Op^2$.
\end{enumerate}
\end{definition}

Definition~\ref{def:linearizable-history} is concerned with an
individual history of some distributed application. When the
application only ever admits linearizable histories, as permitted by
the memory manager, the entire system is said to be linearizable.

\begin{definition}[Linearizable system]
  \label{def:linearizable-system}
  A DSM application is linearizable if all possible histories of the
  application satisfy Definition~\ref{def:linearizable-history}.
\end{definition}

Consider the history Figure~\ref{fig:dsm-example-2} again. If the
application is linearizable, the read responses must agree on some
order $\sigma$ consistent with external order, implying that
$\memwrite{x}{4}$ happens before $\memwrite{x}{3}$ and
$\memwrite{x}{5}$, but the latter operations can occur in any
order. Since $P_1$ and $P_2$ have to agree on this order, all three
read responses will return the value written by whichever write is
ordered last (meaning most recent), which is either $3$ or $5$. These
possibilities are illustrated in Figure
\ref{fig:dsm-example-2-linearizations}.

Figure~\ref{fig:dsm-example-2-linearizations} also depict an
equivalent, more visually intuitive way, of approaching defining
linearizability. A linearizable history where returned values are
consistent with a choice of linearization point for each operation.
\begin{definition}
  A \emph{linearization point} $t$ for an operation $\Op$ is a time in
  the range $[\memstart{\Op}, \memstop{\Op}]$, between the operation's
  invocation and response. We forbid distinct operations from having
  an overlapping linearization point.
\end{definition}

A history is linearizable if there is some choice of linearization
point for each operation, and returned values are consistent with
operations taking effect in whole and instantaneously at their
linearization points. Figure \ref{fig:dsm-example-2-linearizations}
depicts possible choices of linearization points in yellow.

\begin{figure}
  \begin{subfigure}{1\textwidth}
    \setlength\belowcaptionskip{4ex}
    \centering
    \input{images/pgf/dsm_ex2_linear_1.pgf}
    \caption{A linearization where the read operations return 3}
    \label{fig:dsm-example-2-linearizations-1}
  \end{subfigure}
  \begin{subfigure}{1\textwidth}
    \input{images/pgf/dsm_ex2_linear_2.pgf}
        \caption{A linearization where the read operations return 5}
    \label{fig:dsm-example-2-linearizations-b}
  \end{subfigure}
  \caption{Two possible linearizations of Figure~\ref{fig:dsm-example-2} with linearization points shown in yellow}
  \label{fig:dsm-example-2-linearizations}
\end{figure}

\subsubsection{Sequential consistency}
\label{sequential-consistency}

Linearizability offers very strong guarantees related to real-time
constraints, but for many applications this requirement is a burden
for performance. A more relaxed model, sequential consistency,
provides comparably strong guarantees but does not impose the same
constraints with respect to external order. Whereas linearizability
requires operations to be consistent with a serialization respecting
external order, sequential consistency allows any serialization that
respects \emph{program order}.

\begin{definition}[Program order]
  An operation $\Op^1$ precedes another operation $\Op^2$ in
  \emph{program order} if the events occur in the same process $P$ and
  $\memstop{\Op^1} < \memstart{\Op^2}$. In this case we write
  $\Op^1 \programorder{P} \Op^2$.
\end{definition}
If two operations occur in different processes, they are not related
by program order. That is the distinction between program and external
order.

The definition of sequential consistency follows the same structure as
that for linearizability, with program order in place of external
order.

\begin{definition}[Sequentially consistent history]
  \label{def:sequentially-consistent-history}
  An history $H$ is \emph{sequentially consistent} if the following
  three rules are satisfied.
\begin{enumerate}
  \tightlist
\item \textbf{Global Agreement on Order}: All processes behave as if
  they observe the same serialization $\sigma$ of $H$.
\item \textbf{Correct Responses}: Read requests return the value of
  the most recent write request to the same location according to $\sigma$.
\item \textbf{Consistent with Program Order}: $\sigma$ is consistent
  with program order: if
  $\memstop{\Op^1} \programorder{P} \memstart{\Op^2}$ for some $P$, the serial
  history must include $\Op^1$ before $\Op^2$.
\end{enumerate}
\end{definition}

Since external order imposes more constraints than program order,
linearizable histories, like those shown in Figure
\ref{fig:dsm-example-2-linearizations}, are always sequentially
consistent.
\begin{lemma}
  \label{lem:linearsequential}
  A linearizable execution is sequentially consistent.
\end{lemma}

The converse of Lemma~\ref{lem:linearsequential} does not hold,
meaning some sequentially consistent executions are not
linearizable. As noted earlier, there are only two linearizable
histories of Figure~\ref{fig:dsm-example-2}, and they both require all
three read operations to return the same value. Examples
\ref{ex:dsm-example-2-sequential-1} and
\ref{ex:dsm-example-2-sequential-2}, below, demonstrate sequentially
consistent histories where $P_1$ and $P_2$ read non-equal values.

\begin{figure}
  \begin{subfigure}{1\textwidth}
    \setlength\belowcaptionskip{4ex}
    \centering
    \input{images/pgf/dsm_ex2_seq1.pgf}
    \caption{Sequentially consistent history where $P_1$ and $P_2$ read different values of $x$}
    \label{fig:dsm-example-2-sequential-1-sub}
  \end{subfigure}
  \begin{subfigure}{1\textwidth}
    \input{images/pgf/dsm_ex2_seq1_serial.pgf}
    \caption{A consistent serialization respecting program order}
    \label{fig:dsm-example-2-sequential-1-serial}
  \end{subfigure}
  \caption{A sequentially consistent history and its consistent serialization}
  \label{fig:dsm-example-2-sequential-1}
\end{figure}

\begin{example}
  \label{ex:dsm-example-2-sequential-1}
  Figure~\ref{fig:dsm-example-2-sequential-1-sub} depicts a sequentially
  consistent history of the operations depicted in Figure
 ~\ref{fig:dsm-example-2}. This history is non-linearizable because
  $P_1$ and $P_2$ read different values for $x$. It is sequentially
  consistent because it returns values consistent with the alternate
  history shown in Figure~\ref{fig:dsm-example-2-sequential-1-serial},
  which is sequential because has no overlapping operations. The
  latter can be obtained by ``sliding'' the operations in $P_2$ along
  their worldline so they occur after those in $P_1$.
\end{example}

\begin{figure}
  \begin{subfigure}{1\textwidth}
    \setlength\belowcaptionskip{4ex}
    \centering
    \input{images/pgf/dsm_ex2_seq2.pgf}
    \caption{Sequentially consistent history where $P_2$ reads $x$ with value $4$}
    \label{fig:dsm-example-2-sequential-2-sub}
  \end{subfigure}
  \begin{subfigure}{1\textwidth}
    \input{images/pgf/dsm_ex2_seq2_serial.pgf}
    \caption{A consistent serialization respecting program order}
    \label{fig:dsm-example-2-sequential-2-serial}
  \end{subfigure}
  \caption{A sequentially consistent history and its consistent serialization}
  \label{fig:dsm-example-2-sequential-2}
\end{figure}

\begin{example}
  \label{ex:dsm-example-2-sequential-2}
  Figure~\ref{fig:dsm-example-2-sequential-2-sub} depicts another
  sequentially consistent history of the operations in Figure
 ~\ref{fig:dsm-example-2}. In this example, $P_2$ appears to travel
  backwards in time, reading the stale value $4$ immediately after
  reading $5$. This history is consistent with the serialization
  shown in Figure~\ref{fig:dsm-example-2-sequential-2-serial}.
\end{example}

The time-traveling nature of Example
\ref{ex:dsm-example-2-sequential-2} can be explained by remembering
that the DSM model is implemented in terms of message-passing. $P_2$
may read a stale value of $4$ because of the time it takes for the
memory manager running on $P_1$ to notify $P_2$ about the
$\memwrite{x}{4}$ operation. This notification may not be received
until after $P_2$ performs the $\memreadVal{x}{5}$ operation.

Sequential consistency is an intuitive property for reasoning about
the possible behaviors of distributed programs. Note that each process
in the system issues memory operations in a particular order---these
can be thought of as individual steps in a program. Before the
application is executed on real computers, there is no guarantee about
the relative timing of program steps that run on different computers,
since different machines may run at different speeds. For instance,
before running the program and observing the series of events shown in
Figure~\ref{fig:dsm-example-2-sequential-2-sub}, we did not
necessarily know that the $\memwrite{x}{4}$ operation would precede
the $\memwrite{x}{5}$ operation in real-time---they are both the first
steps of their respective programs, with no relation to each
other. The alternate order of events shown in
\ref{fig:dsm-example-2-sequential-2-serial}, where $\memwrite{x}{5}$
precedes $\memwrite{x}{4}$, is just as likely a priori as the one that
was actually observed. Sequential consistency guarantees each program
is always consistent with one of the serializations that can be
expected a priori, before the program is executed and a real-time
external order of events is fixed.

\subsection{The CAP Theorem}
Real-world systems rarely function as a perfectly coherent, unified
system. One fundamental gap between idealized and real-world behavior
stems from a well-understood and fundamental tradeoff between
coherence and performance. The more ``coherence'' we demand from the
system, the more processes have to communicate over the network, whose
unpredictable delays impose overheads that degrade
performance. Conversely, the more we demand immediate answers from our
system, the less time a process has to communicate with other
processes, so the system as a whole does not seem as coherent and
unified to end users.

This tradeoff is made fully stark by considering the possibility that
the network suffers from a partition, which prevents some processes
from communicating with others.

\begin{definition}[Network partition] A \emph{network partition} is a
span of time where some nodes are unable to communicate with another
set of nodes on the network.
\end{definition}

In 1999, Fox and Brewer \cite{1999foxbrewer} articulated a formal
tradeoff between three desirable properties of distributed systems:
consistency, availability, and an ability to function during network
partitions. This observation was formalized and rigorously proven by
Gilbert and Lynch in 2002 \cite{2002gilbertlynchCAP}. Despite its
prominence at the heart of distributed systems, and the fact that its
proof is fairly straightforward, the CAP theorem is sometimes
misunderstood, so it is worth clarifying its key terms.

\begin{description}
\item[Consistency:] Gilbert and Lynch define consistency as
  linearizability.
\item[Availability:] A CAP-available system eventually responds to every client
  request (a read or write operation) after a finite time.
\item[Partition tolerance:] A partition-tolerant system continues to
  function in the face of arbitrary partitions in the network.
\end{description}

In the last case, the possibility is allowed that a partition never
recovers. This could happen if a critical communications cable is
permanently severed, for instance.

The CAP theorem is the simple observation that a distributed system
cannot guarantee all three properties simultaneously: a system that
operates during network partitions cannot ensure both linearizability
and availability. We give only the informal sketch here, leaving the
interested reader to consult the more formal analysis by Gilbert and
Lynch. The key assumption in the proof is that a process's behavior is
only affected by the messages it receives. During a partition, its
behavior is the same regardless of what other processes do, since it
does not communicate with them and cannot be affected by them. Below,
we term this property \emph{behavioral invariance}.

\begin{figure}
  \input{images/pgf/dsm_cap_ex1.pgf}
  \caption{A history where linearizability cannot maintained during a network partition}
  \label{fig:dsm-cap-example-1}
\end{figure}

\begin{theorem}[The CAP Theorem]
  \label{thm:cap}
  If indefinite network partitions are possible, then a distributed
  system cannot guarantee both linearizability and
  eventual availability.
\end{theorem}
\begin{proof}
  Consider the history in Figure~\ref{fig:dsm-cap-example-1}. Clearly
  there is only possible linearization of this history:
  $\memwrite{x}{1}$ executes, $\memwrite{x}{2}$ executes, and
  $\memread{x}$ reads the value $2$. Now suppose $P_1$ and $P_2$ are
  separated by a network partition, meaning $P_1$ does not receive any
  messages from $P_2$. This leaves two possibilities for how $P_1$
  might handle the $\memread{x}$ operation:
  \begin{enumerate}
  \item $P_1$ can proceed despite the network partition and return a
    value. By behavioral invariance, $P_1$ would have to return
    $\memreadVal{x}{1}$. This is value it would read (by
    linearizability) if $P_2$ did not write to $x$. Behavioral
    invariance means $P_1$'s reads the same value regardless of what
    $P_2$ does (since in either case, it receives no communication
    from $P_2$). Returning $1$ violates linearizability in the case
    above where $P_2$ \emph{does} write to $x$.
  \item $P_1$ might detect (or assume) the network suffers a partition
    and refuse to handle the $\memread{x}$ until it is able to
    communicate with $P_2$ again, whereupon it would learn the correct
    value of $x$ is $2$. However, we do not assume the partition has
    to recover, in which case $P_1$ waits forever, which violates
    availability.
  \end{enumerate}
  Thus, we cannot have both linearizable consistency and
  availability. More precisely, to ensure both of these properties, we
  would have to assume the network never suffers from partitions, but
  this is unrealistic. As discussed in Section
 ~\ref{sssec:ground-communication}, real-world examples of partitions
  in wildland firefighting environments are common.
\end{proof}

The proof above raises the question of whether the weaker notion of
sequential consistency can be used to avoid being subject to the CAP
theorem. The answer is negative: sequential consistency is also
CAP-unavailable.

\begin{figure}[p]
  \setlength\belowcaptionskip{5ex}
  \begin{subfigure}{1\textwidth}
    \centering
  \input{images/pgf/dsm_cap_ex2.pgf}
  \caption{An execution that cannot maintain sequential consistency during a network partition}
  \label{fig:dsm-cap-example-2}
  \end{subfigure}
  \begin{subfigure}{1\textwidth}
    \centering
    \input{images/pgf/dsm_cap_ex2_results.pgf}
    \caption{By behavioral invariance, if there is a network partition, the values read for $x$ and $y$ must be their initial values of $0$}
    \label{fig:dsm-cap-example-2-results}
  \end{subfigure}
  \begin{subfigure}{1\textwidth}
    \centering
    \input{images/pgf/dsm_cap_ex2_seq1.pgf}
    \caption{A serial order where $\memreadVal{y}{0}$ precedes $\memwrite{y}{1}$ forces $\memwrite{x}{1}$ to precede $\memreadVal{x}{0}$, violating sequential consistency}
    \label{fig:dsm-cap-example-2-serial1}
  \end{subfigure}
  \begin{subfigure}{1\textwidth}
    \centering
    \input{images/pgf/dsm_cap_ex2_seq2.pgf}
    \caption{A serial order where $\memreadVal{x}{0}$ precedes $\memwrite{x}{1}$ forces $\memwrite{y}{1}$ to precede $\memreadVal{y}{0}$, violating sequential consistency}
    \label{fig:dsm-cap-example-2-serial2}
  \end{subfigure}
  \caption{}
  \label{}
\end{figure}

\begin{lemma}[CAP for sequential consistency]
  \label{thm:cap-sequential}
  An eventually-available system cannot provide sequential consistency
  in the presence of network partitions.
\end{lemma}
\begin{proof}
  Consider the history in Figure~\ref{fig:dsm-cap-example-2} and
  suppose all memory locations are initialized to $0$. Following
  similar reasoning as above, behavioral invariance means that if
  $P_1$ and $P_2$ are separated by a partition and remain available,
  $P_1$ has to return $0$ to the request $\memread{y}$---that is the
  value it would return assuming $P_2$ does not write to
  $y$. Likewise, $P_2$ would read $\memreadVal{x}{0}$. However, the
  resulting history, shown in Figure
 ~\ref{fig:dsm-cap-example-2-results}, is not sequentially
  consistent. For $\memreadVal{y}{0}$ to be consistent, the sequential
  order of operations would have to arrange $\memreadVal{y}{0}$ before
  $\memwrite{y}{1}$---otherwise reading $0$ is incorrect. This results
  in the order shown in Figure~\ref{fig:dsm-cap-example-2-serial1},
  which is incorrect because $\memreadVal{x}{0}$ occurs after
  $\memwrite{x}{1}$. The situation is symmetric: to order
  $\memreadVal{x}{0}$ before $\memwrite{x}{1}$ results in an order where
  $\memwrite{y}{1}$ precedes $\memreadVal{y}{0}$ (Figure~\ref{fig:dsm-cap-example-2-serial2}).
\end{proof}

\subsubsection{Consequences of CAP}
\label{interpretation-of-the-cap-theorem}
While the CAP theorem is theoretically simple, its implications are
more nuanced than they may appear \cite{2012CAP12Years}. A common
oversimplification is that the CAP theorem is represents a ``choose 2
of 3'' scenario: a system designer can choose at most two of
consistency, availability, and partition resilience. In fact, real
systems may balance weaker forms of all three properties. The CAP
theorem only rules out the combination of all three properties when
each of them is defined in an idealized, rigid way.

In practice, applications often settle for weaker levels of
consistency than linearizability or sequential consistency. Resilience
to network partitions typically requires coping with intermittent,
rather than indefinite, communications failures. Finally, availability
is best measured in terms of actual response time as experienced by
the user, and not the mere assurance that a request will
``eventually'' be handled. Thus, each of these dimensions is actually
quantitative in nature, rather than an all-or-nothing proposition.

The locality principle is also highly relevant when considering
implications of the CAP theorem for a real system. The closer agents
are located, the more reliable their communications will be in
general, and the more applications can provide consistency and
availability for operations that only require coordinating with nearby
agents. At short time scales, operations that only require local
coordination are common.

\subsection{Causal Consistency}
\label{ssec:causal-memory}
\emph{Causal} consistency, defined by Ahamad et
al. \cite{1995:causal-memory}, is a weaker memory model than
sequential consistency. Whereas sequential consistency requires the
system as a whole to behave as if all write operations take place in
some total order (which must also respect program order), causal
consistency allows different processes to behave as if they witnessed
past write operations take effect in different orders. Only write
operations related by \emph{causal precedence} are required to take
effect in a common order across all processes: ``reads respect the
order of causally related writes.''  \cite{1995:causal-memory}

We have not defined what causal precedence means for memory
operations. The notion is similar in its motivation to causal
precedence in message-passing framework (Definition
\ref{def:causalprecedence}) and the idea of causal broadcast
(Definition~\ref{def:causalorder-bcast}) but the definition of
causally related memory operations is not as simple as that of causal
precedence among messages. In message passing, a receive event is
always associated with a unique send event, but multiple processes can
write the same value to the same memory location, and for a later
operation that reads this value, it is not clear which write
``caused'' it. For this purpose we define a \emph{writes-into} order.

\begin{definition}[Writes-into order]
  Let $H$ be a history of memory operations.\footnote{We are treating
    $H$ as a \emph{multiset}, meaning for example that separation
    operations both of the form $\memwrite{x}{v}$ are considered
    distinct.} A ``writes into'' order $\writesinto$ is a binary
  relation where each read $\memreadVal{x}{v}$ is paired with the
  write operation that determined the value that operation read. That
  is, all related pairs are of the form
  $\memwrite{x}{v} \writesinto \memreadVal{x}{v}$ and every read is
  paired with some write.
\end{definition}

  Ahamad et al. \cite{1995:causal-memory} give a slightly more complex
  definition to allow for operations that read uninitialized memory
  locations. For simplicity we assume each memory location is written
  to before it is read.

\begin{definition}[Causality order on memory operations]
  \label{def:memorycausalprecedence}
  For a given writes-into order $\writesinto$ on
  $H$, the associated \emph{causality order}
  $\causalityorder$ is the transitive closure of the union of
  $\writesinto$ and program order. That is, if $\Op \causalityorder
  \Op'$, then one of the following holds:
  \begin{itemize}
  \item $\Op \programorder{P} \Op'$ for $P$
  \item $\Op \writesinto \Op'$
  \item There is some $\Op''$ such that $\Op \causalityorder \Op''$ and $\Op'' \causalityorder \Op'$
  \end{itemize}
  By fiat, we also require that $\causalityorder$ must not be cyclic,
  meaning their are no ``causality loops'' like
  $\Op \causalityorder \Op' \causalityorder \Op$.  If
  $\Op \causalityorder \Op'$ in a causality order, we say $\Op$
  causally precedes $\Op'$.
\end{definition}

We can now define causally consistent executions of memory
operations. For a history $H$ and each process $P$, let $A|_{P}$ be
the union of $\restrictedhistory{P}$ and the set of all writes in $H$.

\begin{definition}[Causal consistency]
  \label{def:causalconsistency}
  An execution is causally consistent if each $P$ behaves as if it
  observes some serialization of $A|_{P}$ consistent with $\causalityorder$.
\end{definition}

Notably, Definition~\ref{def:causalconsistency} does not require that
all processes behave as if they are observing the \emph{same}
serialization.

\begin{example}
  \label{ex:dsm-causal-ex1}
  Figure~\ref{fig:dsm-causal-ex1} depicts a causally consistent
  execution of the operations in Figure~\ref{fig:dsm-example-2} that
  is not sequentially consistent. The writes-into order is depicted
  with dotted edges. The operations $\memwrite{x}{5}$ and
  $\memwrite{x}{3}$ are not related by $\causalityorder$ and therefore
  do not have to appear to take effect in the same order at all processes.

  Suppose this history were consistent with some serial order. By
  correctness, $\memwrite{x}{5}$ must be the last write before
  $\memreadVal{x}{5}$. By program order, $\memwrite{x}{5}$ comes
  before $\memreadVal{x}{3}$. By correctness, $\memwrite{x}{3}$ must
  come before $\memreadVal{x}{3}$, but not before
  $\memwrite{x}{5}$. But then it must be the last write before
  $\memreadVal{x}{5}$, a contradiction.
\end{example}

\begin{figure}
  \setlength\belowcaptionskip{5ex}
  \begin{subfigure}{1\textwidth}
    \centering
    \input{images/pgf/dsm_causal_ex1.pgf}
    \caption{A causally consistent history with a writes-into order
      shown with dotted edges}
    \label{fig:dsm-causal-ex1}
  \end{subfigure}
  \begin{subfigure}{1\textwidth}
    \centering
    \input{images/pgf/dsm_causal_ex1_serial1.pgf}
    \caption{A serialization consistent with the values read by $P_1$}
    \label{fig:dsm-causal-ex1-serial1}
  \end{subfigure}
  \begin{subfigure}{1\textwidth}
    \centering
    \input{images/pgf/dsm_causal_ex1_serial2.pgf}
    \caption{A serialization consistent with the values read by $P_2$}
    \label{fig:dsm-causal-ex1-serial2}
  \end{subfigure}
  \caption{A causally consistent but sequentially inconsistent history}
\end{figure}

Causal consistency is not subject to the limits of the CAP theorem.

\begin{lemma}[Causal consistency is CAP-available]
  \label{thm:cap-causal}
  A system can enforce causal consistency during network partitions.
\end{lemma}
\begin{proof}
  Consider two processes that execute read and write operations purely
  locally. That is, they never send messages to other processes, and
  they always read the most recent value they have written to a
  location, regardless of what other processes do.

  This situation is always causally consistent for the causality
  relation generated by the empty writes-into order. If the
  writes-into order is empty, each process only has to be consistent
  with some serial order of write operations, and processes do not
  have to agree on this order. In particular, each $P$ is
  consistent with a serialization where all write operations issued by
  other processes are executed \emph{after} all of $P$'s own read
  operations.
\end{proof}

The proof of the Lemma~\ref{thm:cap-causal} speaks to the weakness of
causal consistency. In the proof, different processes are allowed to
deviate arbitrarily far from consistency with each other. At any
moment in time, they may diverge wildly, which violates our goal of
maintaining a common operating picture. Causal consistency is too weak
to place an upper bound on the divergence observed by users, which
suggests it is not the most appropriate model for the kinds of
safety-related applications we have in mind. Section
\ref{sec:continuous-consistency} will consider how a continuous
consistency model can provide these sorts of bounds.

\subsection{Section Summary}
\label{ssec:background-summary}
This discussion has explored the key challenges involved in building
distributed systems that connect geographically dispersed components
over unpredictable networks. The variability in message delays,
particularly in the context of broadcasts sent to multiple recipients,
can result in messages that arrive in different orders.  This
situation can lead to chaos if a message-ordering discipline is not
imposed.

To mitigate the effects described above, distributed systems must
track the causal precedence relation between events. Because physical
clocks are not generally reliable enough for this purpose, especially
at fine time scales, logical clocks---scalar, vector, and matrix
clocks---are typically used, each with a different tradeoff in terms
of precision of the information tracked and the administrative and
messaging overhead. If groups can change dynamically, as in our use
cases, then additional group membership protocols are needed to ensure
that all processes know which other processes are participating in the
system at any moment.

Programmers may find it easier to frame distributed applications in
terms of reading and writing from a shared pool of virtual memory,
rather than sending messages, using distributed shared memory
framework. The fact that processes can access the same virtual memory
locations at the same time makes it challenging to maintain systemwide
coherence. Strong consistency models like linearizability and
sequential consistency provide the illusion of a single source of
truth, but the CAP theorem makes it virtually impossible to guarantee
these properties over connection-challenged networks. Weaker models
like causal consistency are not subject to the same limitations, but
they do not enforce limits bounding how far apart data replicas can
diverge, rendering them potentially unsuitable for safety-related
applications.

\section{Timestamped Anti-Entropy}
\label{sec:tsae}
This section presents Golding's Timestamped Anti-Entropy (TSAE)
protocol \cite{1992:golding-thesis}, a \emph{weak consistency group
  communication} mechanism that provides a form of multicasting to
applications. We picture TSAE as a key driver of communication across
a distributed system supporting first responders across a region or
state during a wide-area event, like the kind discussed in Section
\ref{sec:disaster-response}. Such a system might track firefighters'
locations, monitor a wildfire's boundaries, disseminate weather data,
and orchestrate resource deployment. In this context, TSAE would have
responsibility for ensuring that every update eventually reaches each
of its intended recipients.

Golding's thesis \cite{1992:golding-thesis} presents TSAE as one
component of a broader toolkit for developing distributed
applications. Before laying out the protocol, it is useful to explain
what role it is meant to have in the context of a larger distributed
system. We imagine a group of cooperating processes, referred to by
Golding as ``principals,'' managing shared state and communicating
through message exchange. These messages are an application-specific
construct and might contain things like instructions to update a
database. These may not map one-to-one with low-level network messages
like those discussed in Section~\ref{ssec:message-passing}, which we
think of as analogous to Internet Protocol (IP) packets. Note that an
IP packet might contain multiple application messages, and a large
application message may be split up into multiple packets during
network transit.

At a lower level, we assume the network supports point-to-point
(unicast) communication, but it does not have to guarantee FIFO
ordering and may duplicate network messages, though it does not
spontaneously create new ones. The network may not be reliable, but we
assume that persistent attempts to communicate with a distant node
will eventually succeed. The network might support native multicasting
of network-level messages, which could be used as part of an
implementation of TSAE, but the TSAE layer itself provides a form of
application-level multicasting regardless of the network
infrastructure.

A typical use case of TSAE is to maintain replicas of a shared
database at multiple sites, for which purpose its reliable eventual
delivery makes it well-suited as a fault-tolerant messaging
component. Here, ``database'' is used broadly to refer to any data
store updated according to some logical model, such as a relational
schema, a key-value store, or a document store. Processes update the
data by broadcasting update messages using TSAE. Updates are
eventually delivered to every process, at which point recipients apply
it their own replica. Of course, the semantics of updates are decided
by the application. If the underlying data model requires updates to
be applied in the same order at all replicas, TSAE can be paired with
a totally ordered delivery component; this provides a general
mechanism for replicating a state machine. Timestamped anti-entropy
with totally ordered delivery is described in Section
\ref{ssec:tsae-message-ordering} and forms the basis of the
distributed memory consistency protocol in
Section\ref{sec:continuous-consistency}.

% The resulting system provides eventual, totally-ordered delivery,
% which offers a general mechanism for implementing replicated state
% machines.

Replication is an alternative to managing state in a central location,
such as a datacenter. This provides resiliency by removing single
points of failure. It supports scalability by allowing any process
with a replica to deliver services to clients, distributing the
load. Finally, replication exploits locality (introduced in Section
\ref{ssec:communication-patterns}) because by servicing user requests
at the nearest replica, we can rely on communications links that are
generally faster and more reliable.

One highly relevant use case of globally replicating state is to
support offline usage of applications. This represents taking locality
to its limit. Responders in the field may not be able to connect to a
datacenter, but in the meantime they can interact with the application
on their device backed by a local replica of the data. This is useful
for as long as the agents can be confident that their replica has not
diverged too far from the rest of the system. A key point is that this
is an application-level matter. How quickly shared state evolves, how
to quantify divergence, and how far apart is ``too'' divergent are
determined by user intent, usage patterns, and operational
environment, among other things. Because updates are merely delivered
\emph{eventually}, TSAE does not bound the divergence of each replica
from the ``ideal'' value of the shared state at any moment. Following Yu
and Vahdat \cite{2002tact}, we show in Section
\ref{sec:continuous-consistency} how an implementation of the conit
(consistency unit) model on top of TSAE can be used to enforce,
through so-called compulsory anti-entropy sessions, quantitative
consistency requirements separately for each replica.

We now present TSAE in terms of its assumptions
(\ref{ssec:tsae-assumptions}), data structures and invariants
(\ref{ssec:tsae-message-log}--\ref{ssec:tsae-acknowledgment}),
ordering component (\ref{ssec:tsae-message-ordering}), and storage
recycling procedure (\ref{ssec:tsae-message-purging}). Finally, we
discuss how version matrices can be used instead of the loosely
synchronized physical clocks assumed below
(\ref{ssec:tsae-unsynchronized}).

\subsection{Assumptions}
\label{ssec:tsae-assumptions}
We assume each process is associated with an identifier. In practice,
this might be a Uniform Resource Identifier (URI) \cite{rfc3986}
following a structured format such as
\texttt{<agent-id>@<agency>.<state>.<country>}. For instance, the first author's father, Firefighter 116 with the Orange County Fire and Rescue Department in Florida, might be assigned this fictional identifier:
\begin{center}
  \texttt{firefighter116@ocfrd.fl.us}
\end{center}
In the text, we will not make a distinction between a process $P$ and its
identifier.

The first assumption we make for the presentation of TSAE is as follows:
\begin{quote}
  \textbf{Static process group}: The set of group members is a fixed
  set of processes $\AllProc = \{P_1, P_2, \ldots P_n\}$ where the
  identifier of each process is known to all of them.
\end{quote}
Golding's thesis describes how to connect TSAE with a dynamic group
membership management component, but we do not describe it here for
simplicity.

The second assumption we make is that processes have nearly
synchronized clocks. We write $\clock{P, t}$ for the clock value at $P$
at real time $t$.
\begin{quote}
  \textbf{Loose clock synchronization}: Processes' physical clocks are approximately
  synchronized, meaning the clocks of any two processes differ by at
  most some small constant $\delta$:
  \[ \forall t,\, \forall P, Q \in \AllProc, |\clock{P, t} - \clock{Q, t}| < \delta
  \]
  The clock resolution must be fine-grained enough for each principal
  to assign unique timestamps to all important events occurring in
  that process.
\end{quote}

Though physical clock synchronization is not a reliable assumption in
all contexts, we expect that for many useful purposes, sufficient
synchronization can be achieved with a protocol like NTP.  Section
\ref{ssec:tsae-unsynchronized} explains how synchronized physical
clocks can be replaced with version matrices at the cost of a
quadratic storage requirement. For the purpose of implementing
continuous consistency in Section~\ref{sec:continuous-consistency},
timestamps from conventional scalar logical clocks can be used in
place of physical clocks, which is how Yu and Vahdat implement TSAE as
part of their TACT framework \cite{2002tact}. The real-time
consistency metric discussed in~\ref{ssec:conit-real-time-consistency}
requires each process to keep a physical clock to measure elapsed
time, though synchronization does not appear to be strictly required
here either, assuming each clock runs at a consistent rate. We assume
synchronization here to follow Golding's presentation, highlighting
where the assumption is used.


\subsection{Message Log}
\label{ssec:tsae-message-log}
Each process $P$ manages a \emph{message log} containing all messages
sent or received by $P$. We denote $P$'s message log by $\WL{P}$. It
grows in linear order, as a stack, as new messages are sent and
received. Each message in $\WL{P}$ is tagged with the identifier of
the process that originally created it, with the subset of messages in
$\WL{P}$ that originated at $Q$ denoted by $\WLat{P}{Q}$. Thus,
$\WLat{P}{P}$ represents the set of messages created by $P$. The set
of global messages, $\W$, is defined as the (disjoint) union of
messages originating from every process, which by mild abuse of
notation we are treating as sets:
\[\W \equiv \bigcup_{X \in \AllProc} \WLat{X}{X}.\]

The application at $P$ broadcasts a message $m$ using TSAE by writing
$m$ into $\WL{P}$. We call this event the \emph{submission} of $m$ and
say that $m$ originates at $P$. At the time of submission, the message
is tagged with a pair $(P, \clock{P,t})$ containing $P$'s identifier
and current clock value. The timestamp of $m$ is denoted by
$\timestamp{m}$.

Submitted messages are not sent to other processes right away, but
propagate by a straightforward protocol. Periodically, $P$ contacts
some other process $Q$ and the pair conduct an \emph{anti-entropy
  session}. First, $P$ and $Q$ exchange summary vectors (defined
below). $P$ uses $Q$'s summary vector to quickly calculate which
messages in $\WL{P}$ are not already known to $Q$ and then transmits
these messages to $Q$. Symmetrically, $Q$ forwards messages in
$\WL{Q}$ that $P$ has not seen, resulting in $\WL{P}$ and $\WL{Q}$
containing the same messages afterwards, though typically not in the
same order.\footnote{In a multithreaded environment where $P$ and $Q$
  can engage in multiple anti-entropy sessions with different partners
  at once, the two sides may end in different states. For instance,
  $P$ may learn about new messages in an anti-entropy session with $R$
  during its session with $Q$. Later, we also consider one-sided
  anti-entropy sessions that only push or pull messages. }

TSAE provides reliable eventual delivery, meaning every message is
eventually received by every process, as long as no process fails and
no partition indefinitely separates any two nodes. In particular, if
processes stop originating new messages (so $\W$ remains fixed), if
processes remain able to communicate, then $\WL{P}$ is guaranteed to
eventually converge to $\W$. To achieve this, it is enough that each
pair of processes engage in anti-entropy periodically. This can
actually be relaxed by transitivity: it is enough that they
periodically engage in anti-entropy with a mutual partner, or with two
other processes that engage in anti-entropy with each other, and so
on. TSAE itself does not prescribe a particular policy regarding when
and with whom to engage in anti-entropy, however. Consequently, it
does not guarantee or estimate how far apart $\WL{P}$ is from
$\WL{Q}$, or from $\W$, at any moment. The framework in Section
\ref{sec:continuous-consistency} prescribes a policy for TSAE based on
conservative estimates of divergence in order to enforce these sorts
of limits.

Note that the guarantee of eventual delivery only ensures that
$\WL{P}$ converges to $\W$ as a \emph{set}. However, in general, we
think of $\WL{P}$ as a linear structure, with messages entered into
$\WL{P}$ in the order they were received by $P$. Thus, when $\WL{P}$
and $\WL{Q}$ eventually converge, it is more correct to say they will
be permutations of each other rather than equal. For applications that
require messages to be delivered in a particular order, like a total
order, an additional ordering component is used, as in
\ref{ssec:tsae-message-ordering}.

\begin{example}
  Figure~\ref{fig:message-log} shows a message log for containing six
  messages from three processes $A$, $B$, and $C$. For readability it
  is convenient to depict logs whose contents are disaggregated by
  sender (Figure~\ref{fig:message-log-b}). Disaggregation has the
  downside of obscuring the fact that message logs with the same
  contents may be arranged in different orders, as the reader should
  keep in mind.
\end{example}

\begin{figure}
  \setlength\belowcaptionskip{5ex}
  \begin{subfigure}{1\textwidth}
    \centering
    \includegraphics[width=0.6\textwidth]{images/MessageLog1.png}
    \caption{A message log with entries accumulating bottom-to-top in linear order}
    \label{fig:message-log-a}
  \end{subfigure}
  \begin{subfigure}{1\textwidth}
    \centering
    \includegraphics[width=0.6\textwidth]{images/MessageLog2.png}
    \caption{The same log shown with messages disaggregated by sender}
    \label{fig:message-log-b}
  \end{subfigure}
  \caption{A message log displayed linearly and disaggregated}
  \label{fig:message-log}
\end{figure}


\subsection{Summary Vector}
\label{ssec:tsae-summary-vectors}
Besides $\WL{P}$, the message propagation component maintains a
\emph{version vector} $\summaryVec{P}$ whose role is to quickly
communicate to other processes which messages $P$ has already
received. This structure is very similar to a vector clock (see
Section~\ref{sssec:vector-clocks}) with a few differences. First, the
version of TSAE presented here happens to store physical, rather than
logical, clock values. A more essential distinction is that while a
vector clock tracks causality between events and increments the local
clock with each event, a version vector tracks the history of updates
to replicated data. The value $\summary{P}{P}$ tracks the set of
messages sent by $P$ and is incremented when $P$ sends a new message,
but not when $P$ receives a message from another process. As with
vector clocks, $\summary{P}{Q}$ can be thought of as $P$'s lower bound
view of $\summary{Q}{Q}$.

When $P$ submits a message to its own log, $\summary{P}{P}$ is
advanced to $\clock{P, t}$ and the message is timestamped with this
value. At some point in the future, $P$ contacts some other process
$Q$ to initiate an anti-entropy session. We conceptualize this process
as happening in three phases (setup, message exchange, and conclusion):
\begin{enumerate}
\item The value $\summary{P}{P}$ is advanced to $\clock{P, t}$. Symmetrically,
  $\summary{Q}{Q}$ is advanced to $\clock{Q, t}$. The partners exchange summary vectors.
\item For each process $X \in \AllProc$, $P$ sends to $Q$ the set of
  messages in $\WLat{P}{X}$ with timestamps greater than
  $\summary{Q}{X}$, if any. Likewise for each $X$ it receives all messages
  from $\WLat{Q}{X}$ with timestamps greater than $\summary{P}{X}$ and
  adds these to $\WLat{P}{X}$. The partners exchange signals to indicate
  when they are finished sending and receiving updates.
\item Much like a vector clock, $\summaryVec{P}$ is updated to the
  pointwise maximum of its current value and the value of
  $\summaryVec{Q}$ received from $Q$. Likewise $Q$ updates
  $\summaryVec{Q}$.
\end{enumerate}
The message log satisfies an invariant, termed the coverage property,
formalizing the role of $\summaryVec{P}$ as a summary of the contents
of $P$'s message log.
\begin{quote}
  \textbf{Coverage Property}: For all $Q$, $P$ has received
  all messages originating at $Q$ whose timestamps are less than the
  $Q^\textrm{th}$ entry in $P$'s summary timestamp vector:
  \[ \{m \in \WLat{Q}{Q} \mid \timestamp{m} \leq \summary{P}{Q} \} \subseteq \WLat{P}{Q}. \]
\end{quote}
The previous subset relation is ``morally'' an equality---messages in
$\WLat{P}{Q}$ but not the subset are said to be ``early''---but only the
the subset property is required for correctness.\footnote{Section
  5.4.3 of Golding's thesis describes how a version of TSAE
  combined with an unreliable network-level multicast for optimization purposes can add
  messages to $\WLat{P}{Q}$ early.} Thus, besides forming a lower
bound of $\summary{Q}{Q}$, $\summary{P}{Q}$ can be thought of as an
\emph{upper} bound of the originating time, measured by $Q$'s clock,
of the last message $P$ received from $Q$. The coverage property
implies that $\summaryVec{P}$ provides complete information about the
(non-early) contents of $\WL{P}$.

The reader should convince themselves that the following inequalities
hold at all times for all $P$ and $Q$ (including when $P = Q$):
\[
  \max_{m \in \WLat{P}{Q}}\left({\timestamp{m}}\right) \leq \summary{P}{Q} \leq \summary{Q}{Q} \leq \clock{Q,t}.
\]

\begin{example}
  \label{ex:tsae}
  Figures~\ref{fig:tsae1}---\ref{fig:tsae6} depict the evolution of
  TSAE executing across three distributed processes $A$, $B$, and
  $C$. The figures depict the following chain of events beginning at
  $t = 3$. Note that by $t = 9$, $A$ learns of writes submitted with
  $C$ without performing direct communication with $C$. The figures
  also depict acknowledgment vectors, shown in red, and what we later
  term the commit line, shown underlined. These are explained below.

  \begin{centering}
    \begin{tabular}{rl}\\
      \textbf{Time}    & \textbf{Action} \\
      $t = 1$   & $A$ submits a write                                            \\
      $t = 2$   & $B$ and $C$ submit writes                                      \\
      $t = 3$   & $B$ submits a write                                            \\
      $t = 4$ & $A$ and $B$ begin anti-entropy and swap summary vectors \\
      $t = 5$ & $B$ submits a new write  \\
      $t = 6$ & $A$ and $B$ finish anti-entropy, $C$ submits a write \\
      $t = 7$ & $B$ and $C$ begin anti-entropy, $A$ submits a write \\
      $t = 8$ & $B$ and $C$ finish anti-entropy, $A$ and $B$ begin anti-entropy \\
      $t = 9$ & $A$ and $B$ finish anti-entropy
    \end{tabular}
  \end{centering}
\end{example}

\begin{landscape}
  \begin{figure}[h]%For some reason this empty figure adds vertical whitespace that makes the next figure positioned similarly to the ones that follow it.
  \end{figure}
  \begin{figure}[h]
    \centering
    \includegraphics[width=1.4\textwidth]{images/tsae/TSAE3.png}
    \caption{TSAE at time $t=3$. Each process has submitted a write request ($B$ has submitted two), but no process has notified any other process yet of the updates. This might be because they have not had the opportunity to exchange updates at this moment.}
    \label{fig:tsae1}
  \end{figure}
  \begin{figure}[h]
    \centering
    \includegraphics[width=1.4\textwidth]{images/tsae/TSAE4.png}
    \caption{TSAE at time $t=4$. $A$ advances $\summary{A}{A}$ to $\clock{A, t} = 4$ and likewise for $B$. After exchanging summary vectors, the participants decide to exchange the shaded messages.}
    \label{fig:tsae2}
  \end{figure}
  \begin{figure}[h]
    \centering
    \includegraphics[width=1.4\textwidth]{images/tsae/TSAE5.png}
    \caption{TSAE at time $t=5$. $B$ has submitted a message with timestamp
      $t = 5$ while $A$ and $B$ are still engaged in an anti-entropy
      session in the background.}
    \label{fig:tsae3}
  \end{figure}
  \begin{figure}[h]
    \centering
    \includegraphics[width=1.4\textwidth]{images/tsae/TSAE6.png}
    \caption{TSAE at time $t=6$. $A$ and $B$ have finished their session and updated their summary vectors. Neither $A$ nor $B$ can update their commit line past $0$ because they both contain $\summary{}{C} = 0$, indicating they have not seen any messages from $C$. $C$ submits a message with timestamp $t = 6$.}
    \label{fig:tsae4}
  \end{figure}
  \begin{figure}[h]
    \centering
    \includegraphics[width=1.4\textwidth]{images/tsae/TSAE7.png}
    \caption{TSAE at time $t=7$. $B$ and $C$ update and exchange summary vectors before deciding to exchange the shaded messages. $A$ submits a message with timestamp $t = 7$.}
    \label{fig:tsae4}
  \end{figure}
  \begin{figure}[h]
    \centering
    \includegraphics[width=1.4\textwidth]{images/tsae/TSAE8.png}
    \caption{TSAE at time $t=8$. $B$ and $C$ finish their anti-entropy session. Both sides can update their commit line to $4$, since they have seen all messages $m$ such that $\timestamp{m} \leq 4$. $A$ and $B$ begin anti-entropy, exchanging updated summary vectors and exchanging the shaded boxes.}
    \label{fig:tsae6}
  \end{figure}
  \begin{figure}[h]
    \centering
    \includegraphics[width=1.4\textwidth]{images/tsae/TSAE9.png}
    \caption{TSAE at time $t=9$. $A$ and $B$ finish their anti-entropy
      session and have both seen all messages with timestamps less than
      or equal to $t = 7$. $B$ and $C$ can remove all messages with
      timestamps less than or equal to $4$ from their logs, since they
      both have minimum entries $\ack{}{C} = 4$. $C$ has received the
      same messages as $A$ and $B$, but has not witnessed $A$
      acknowledging them.}
    \label{fig:tsae6}
  \end{figure}
\end{landscape}

\subsection{Acknowledgment Vector}
\label{ssec:tsae-acknowledgment}
$P$'s summary vector enables another process to quickly learn which
messages $P$ has seen. Additionally, $P$ must keep tabs on which
messages \emph{other} processes have seen. This information is
critical for the message ordering and log recycling components of
TSAE. Golding presents two ways to maintain this information, which
make different efficiency tradeoffs.

Arguably the simplest approach is for $P$ to maintain a local (lower
bound) copy, called $P$'s \emph{view}, of the summary vector of every
other process. During anti-entropy sessions, $P$ exchanges views with
its partner alongside its $\summaryVec{P}$, taking their pointwise
maximums afterwards. This leads to the idea of a version matrix, but
it has the downside of a per-process space requirement that is
quadratic in the size of the process group. This approach is
considered further in~\ref{ssec:tsae-unsynchronized}.

The other mechanism presented by Golding requires each process $P$
to maintain an \emph{acknowledgment vector} $\ackVec{P}$. The basic idea
is to coarsely summarize $P$'s knowledge of other processes not with
its summary vector, but the minimal element in this vector, a scalar,
which is stored in $\ack{P}{P}$. For reasons explained in
Section~\ref{sec:continuous-consistency}, this value is called $P$'s \emph{commit
  line}. Periodically, $P$'s commit line is updated to the minimal
timestamp in its summary vector,
$\min_{X \in \AllProc} \left(\summary{P}{X}\right)$.  For correctness,
the invariant required of $\ack{P}{P}$ is that it is always a lower
bound of this minimum.
\begin{quote}
  \textbf{Acknowledgment Property}: $P$'s commit line is less than or
  equal to the minimum value in $P$'s summary vector.\footnote{The
    inequality here can be thought of as morally an equality. It may
    be a strict inequality while $P$ is updating $\summaryVec{P}$
    before recomputing its minimum. Recall $P$ may be multi-threaded
    with multiple anti-entropy sessions affecting $\summaryVec{P}$ at
    the same time.}
  \begin{equation*}
    \ack{P}{P} \leq \min_{X \in \AllProc} \left(\summary{P}{X}\right)
\end{equation*}
\end{quote}

Acknowledgment vectors are updated during anti-entropy sessions much
like vector clocks and version vectors.
\begin{enumerate}
\item At the beginning of the session, $\ack{P}{P}$ is updated to
  $\min_{X \in \AllProc} \left(\summary{P}{X}\right)$. Symmetrically
  for $Q$. $P$ and $Q$ exchange acknowledgment vectors alongside
  their summary vectors.
\item At the end of the session, $P$ sets $\ackVec{P}$ and to the
  pointwise maximum of its current value and the value of $\ackVec{Q}$
  received from $Q$. $Q$ updates $\ackVec{Q}$ symmetrically.
\end{enumerate}
Note that $\ack{P}{Q} \leq \ack{Q}{Q}$ at all times for all $P$ and
$Q$.

Slightly different from Golding's presentation of the protocol, the
figures discussed in Example~\ref{ex:tsae} also demonstrate an
optimization that takes advantage of the fact that summary vectors are
updated at the end of anti-entropy sessions. After updating these
vectors to their pointwise maximum, we immediately recompute
$\ack{P}{P}$, setting it to
$\min_{X \in \AllProc} \left(\summary{P}{X}\right)$. Furthermore,
$\ack{P}{Q}$ is set to this value. Symmetrically, $Q$ updates
$\ack{Q}{Q}$ and $\ack{Q}{P}$. Note that this preserves the invariant
that $\ack{P}{Q}$ and $\ack{Q}{P}$ are lower bounds of $\ack{Q}{Q}$
and $\ack{P}{P}$, respectively, provided the implementation ensures
$P$ increments $\ack{P}{Q}$ after confirming $Q$ has received all
messages from $P$ and vice versa. This optimization advances
acknowledgment vectors (and later, version matrices) more often than
Golding's presentation, which allows the ordering and purging
mechanisms (explained below) to progress more quickly.

The following two lemmas explain the utility of $\ackVec{P}$ as a way
of estimating global state.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{lemma}
  \label{lem:commitline}
  $P$ has received all messages (from any sender) with timestamps less
  than or equal to its commit line $\ack{P}{P}$.
\end{lemma}
\begin{proof}
  Let message $m$ originate at $Q$ with timestamp
  $\timestamp{m} \leq \ack{P}{P}$. Then
  \[\timestamp{m} \leq \ack{P}{P} \leq \min_{X \in
      \AllProc}\left(\summary{P}{X}\right) \leq\summary{P}{Q}.\] The
  coverage property implies $m \in \WL{P}$.
\end{proof}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{lemma}
  \label{lem:ack-vector}
  For all messages $m$, if $\timestamp{m} \leq \ack{P}{Q}$, then $Q$
  has received $m$.
\end{lemma}
\begin{proof}
  Now $\timestamp{m} \leq \ack{P}{Q} \leq \ack{Q}{Q}$. By Lemma
 ~\ref{lem:commitline}, $Q$ has received $m$.
\end{proof}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%


When a message $m$ in the write log satisfies
$\timestamp{m} \leq \ack{P}{P}$, $P$ is said to have
\emph{acknowledged} $m$. In light of Lemma~\ref{lem:commitline}, all
acknowledged messages have been received. The converse does not hold,
since a received message will not be acknowledged until each entry in
$\summaryVec{P}$, not just the entry of its sender, is greater than
$\timestamp{m}$. We now explain how acknowledged messages can be
delivered to the application and ultimately purged from $\WL{P}$,
before considering the matrix-based alternative to acknowledgment
vectors.

\subsection{Message Ordering}
\label{ssec:tsae-message-ordering}
TSAE guarantees that messages will eventually be received by all other
processes, but ordering of these messages in different processes' logs
may vary. In some applications this is acceptable, but other
applications require more control over delivery order. Recall from
Section~\ref{ssec:message-ordering} that to enforce ordering
guarantees, a distinction is made between message receipt and
delivery. A message ordering layer buffers incoming messages upon
receipt, giving time for slower messages to catch up to faster ones,
before delivering them to the application in a predictable
order. Below, we describe a simple implementation of totally ordered
delivery for TSAE. Golding also describes straightforward mechanisms to
enforce causal and total-causal order in Section 5.5 in his
dissertation.

The message ordering component of TSAE periodically inspects $\WL{P}$
and delivers messages to $P$ when ready. To enforce total order, this
component delivers all messages whose timestamp is less than or equal
to $P$'s commit line. That is, the set of messages satisfying
\begin{equation}
  \label{eq:tsae-message-ordering-condition}
  \timestamp{m} \leq \ack{P}{P}.
\end{equation}
These messages are delivered to $P$ in order of their timestamps,
using the identifiers of their senders to resolve ties. We refer to
the combination of TSAE with total ordering as TSAE+TO. This protocol
has the following eventual convergence property.

\begin{lemma}
  TSAE+TO eventually delivers every message to every process in the
  same order.
\end{lemma}
\begin{proof}
  Assuming periodic anti-entropy sessions, the protocol in Section
 ~\ref{ssec:tsae-message-log} ensures that each message is eventually
  received by $P$ and each value of the form $\summary{P}{X}$
  eventually increases. Thus, the minimum entry in $\summaryVec{P}$,
  and thus $\ack{P}{P}$, will eventually increase beyond
  $\timestamp{m}$, so each $m$ will be delivered as long as the
  ordering component runs periodically. The fact that messages are
  delivered in the same order everywhere follows from Lemma
 ~\ref{lem:commitline}, since $P$ has seen all messages whose
  timestamp is less than $\ack{P}{P}$, and therefore the stream of
  deliverable messages does not have any ``gaps'' in the total order.
\end{proof}

The above mechanism for enforcing a total order dates back to
Lamport's introduction of scalar clocks \cite{1978:lamportclocks},
which Lamport used to implement a replicated state machine (RSM), a
conceptual device whose status is uniquely determined by a history of
transitions applied to a starting state. Two conditions ensure
replicas converge to the same state. First, the \emph{contents} of
their histories agree (they have seen all the same transitions), and
second, their \emph{orders} agree (they have applied transitions in
the same order). Using TSAE to announce transitions ensures the first
condition, since every process will eventually learn about each
transition. Combining TSAE with a TO delivery mechanism ensures the
second condition, if transitions are applied when announcements are
delivered. This provides a form of \emph{weak} consistency---it
ensures all replicas eventually reach the same state, which makes it
inherently fault-tolerant, though it does not provide guarantees about
the observed inconsistency of replicas in the meantime. We describe
using TSAE+TO for database replication in Section
\ref{sec:continuous-consistency}, incorporating the ``conit'' framework of Yu
and Vahdat \cite{2002tact} to bound observed inconsistency.

Golding's assumption of loose clock synchronization is driven by a
practical need to ensure messages are delivered (and also purged,
described below) in a timely fashion instead of just eventually. For
example, if $Q$ has an exceptionally slow clock compared to other
processes, then $\summary{P}{Q}$ will remain the minimum element in
$\summaryVec{P}$ for a long time. During this time, only messages from
$Q$ will be delivered to $P$, as all other messages would have
timestamps greater than $Q$'s clock. Section
\ref{ssec:tsae-unsynchronized} explains one way, also introduced by
Golding, that the assumption of synchronization can be partially
mitigated. The TSAE-based protocol in Section
\ref{sec:continuous-consistency} does not require synchronized clocks
except to bound real-time staleness.

\subsection{Message Purging}
\label{ssec:tsae-message-purging}
A message simply cannot be removed from the write log after being
delivered to $P$, because some of the messages in $\WL{P}$ may be
propagated to new recipients during anti-entropy in the
future.\footnote{This implies the ordering component must perform
  bookkeeping to remember which messages in the log have already been
  delivered.} However, it is untenable to let the message log grow
without limit. Thus, a separate log recycling process can be used to
remove old entries when they are no longer required.

There are two requirements for a message to be safe to delete. First,
it clearly must have been delivered to $P$ already. Additionally, it
must have been received by all other processes---otherwise it might be
one of the messages $P$ should send in a future anti-entropy
session. $P$ will know a message $m$ has been received by all
other processes when its timestamp is less than or equal to $P$'s
\emph{purge line}, defined as the minimum entry in the acknowledgment
vector:
\begin{equation}
  \label{eq:tsae-message-purging-condition}
  \timestamp{m} \leq \min_{X \in \AllProc} \left( \ack{P}{X} \right)
\end{equation}

The safety of this deletion procedure is proven by the following
lemma.
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{lemma}[Log purging]
  \label{lem:purge}
  $P$ can safely discard all messages in $\WL{P}$ with timestamps less
  than or equal to its purge line, after they have been delivered.
\end{lemma}
\begin{proof}
  Let message $m \in \WL{P}$ originate at $R$ with timestamp less than
  $P$'s purge line. Now the following inequalities hold for all $Q$:
  \[ \timestamp{m} \leq \min_{X \in \AllProc}\left(\ack{P}{X}\right)
    \leq \ack{P}{Q}.\] Therefore, by Lemma~\ref{lem:ack-vector}, $m$
  has been delivered to $Q$. Since $Q$ is arbitrary, $m$ has been
  received everywhere (where it will eventually be delivered as well)
  and can be purged from $\WL{P}$ to reclaim storage space.
\end{proof}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{comment}
For contrast, suppose $m$ has a timestamp greater than $\ack{P}{Q}$.
Then without knowing the current value of $\summary{Q}{R}$ there is no
guarantee $\timestamp{m}$ is less than this value. In this case,
deleting $m$ from $\WL{P}$ might prevent $Q$ from ever receiving $m$.
\end{comment}

Because every message is eventually delivered and acknowledged by each
process, $P$ will eventually be able to remove each message from its
log. It is still possible for $\WL{P}$ to grow without bound if the
rate of message arrival exceeds the speed at which they are
purged. This might occur during periods of heavy usage or during a
network partition, as $P$ will eventually become unable to advance
$\ack{P}{Q}$ further if $Q$ is on the other side of a partition. In this situation, further mechanisms can be incorporated (and in practice, they often are) for $P$ to decide that $Q$ is no longer a participant, and resort to some type of failure mode, with the possibility of later reincorporating $Q$ into the group. Of course, such mechanisms add to the complexity and subtlety of distributed systems protocols, and they are outside this scope of this document. In any case, the
storage requirements of the message log in a particular use case and
environment should be measured empirically as part of an application
optimization strategy.

\subsection{TSAE using Version Matrices}
\label{ssec:tsae-unsynchronized}
Using a single value,
$\min_{X \in \AllProc} \left(\summary{P}{X}\right)$, to concisely
estimate which messages $P$ has received has certain drawbacks. If
clocks are not approximately synchronized, the clock value at one
process may greatly exceed that of another. If $Q$ has a very fast
clock, this value will remain less than $\summary{P}{Q}$ for a long
time and messages from $Q$ will not be purged. If $Q$ has a slow
clock, only messages from $Q$ will be delivered and purged.

Rather than the minimum entry, the entire summary vector offers a more
precise measure of $\WL{P}$. For $P$ itself, that means tracking what
other process know about by keeping a copy of $\summaryVec{Q}$ for
each $Q$ in the system. Thus, we do away with $\ackVec{P}$ and track
what other processes know using a vector-of-vectors that we will denote $\ackMatrix{}$. Since $\summaryVec{}$ is a version
vector, then $\ackMatrix{}$ can be called a version matrix.

With this implementation strategy, $\ackMatrix{P}[P]$ stores $P$'s
summary vector, while $\ackMatrix{P}\left[Q\right]$ represents $P$'s
lower bound estimate of $Q$'s summary vector. Thus,
$\ackMatrix{P}[Q][R]$ is $P$'s lower bound estimate of the upper bound
of the timestamp of any message $Q$ has received from $R$. Matrices
are exchange during anti-entropy sessions just as before, with both
sides taking the pointwise maximum after.

We additionally apply an optimization, similar to the one for
$\ackVec{P}$, of recomputing $\ackMatrix{P}$ after confirming $Q$ has
successfully received all messages during anti-entropy. Namely,
$\ackMatrix{P}[Q]$ is advanced to the pointwise maximum of the summary
vectors $\ackMatrix{P}[P]$ and $\ackMatrix{Q}[Q]$ exchanged at the
beginning of the anti-entropy session. This increases $P$'s estimated
knowledge of $Q$ to reflect any new messages $P$ just pushed during
anti-entropy. (The previous value reflected only the messages $Q$ knew
about when the session was initiated.) $Q$ updates $\ackMatrix{Q}[P]$
symmetrically. For purposes of continuous consistency in Section
\ref{sec:continuous-consistency}, this subroutine implements the
``view advance'' mechanism used to bound numerical error.

For message ordering and log recycling, $P$ applies the following
(conservative) policies:
\begin{itemize}
\item A message with timestamp $m$ is ready to be delivered to $P$ by a total
  ordering component when the following analogue of \eqref{eq:tsae-message-ordering-condition} holds:
  \begin{equation}
    \timestamp{m} \leq \min_{X \in \AllProc} \left(\ackMatrix{P}[P][X]\right)
  \end{equation}
\item A message $m$ originating at $R$ has been
  received by $Q$ when the following condition holds:
  \begin{equation}
    \timestamp{m} \leq \ackMatrix{P}[Q][R]
  \end{equation}
\item A message $m$ originating at $R$, after being delivered to $P$,
  can be purged from the log when the following analogue of
  \eqref{eq:tsae-message-purging-condition} holds:
  \begin{equation}
    \timestamp{m} \leq \min_{X \in \AllProc}\ackMatrix{P}[X][R]
  \end{equation}
\end{itemize}
Note that the matrix-based version of TSAE does not necessarily solve
the delivery problem if clocks are unsynchronized: if physical
timestamps are used to totally order all messages in the system,
messages from a host with a slow clock will be delivered before any
other messages.

Of course, matrices require $\Theta(N^2)$ storage at each site for a
process group with $N$ members, which quickly becomes untenable for
systems where $N$ is on the order of 1,000 or greater.

\section{Continuous Consistency}
\label{sec:continuous-consistency}
We now turn our attention back to the topic of distributed memory
consistency, first introduced in Section~\ref{ssec:shared-memory}. We
will unite the main themes in this document by explaining the ideas
behind \emph{continuous} consistency. We particularly focus on the
conit (short for ``consistency unit'') model proposed by Yu and Vahdat
in a series of papers~\cite{2000tact,2000tactalgorithms,10.5555/1251229.1251250,DBLP:conf/icdcs/YuV01,2002tact}.
Accompanying their work is a prototype implementation called TACT
(Tunable Availability and Consistency Toolkit), a Java-powered
middleware that uses timestamped anti-entropy to maintain a
configurable level of consistency between replicas of a shared
database.\footnote{The source code to the TACT prototype, built in the
  early 2000's, was evidently not made publicly available.}

The conit approach to consistency is motivated by the observation that
many real-world applications can tolerate a certain amount of
divergence among replicas in exchange for greater application
performance. However, they cannot tolerate too much inconsistency: if
the divergence exceeds a certain threshold, the data becomes too
unreliable for its intended use. For these kinds of applications,
rather than viewing consistency as a yes-or-no condition, as with
linearizability and sequential consistency, it is desirable to have a
consistency model that numerically quantifies levels of inconsistency
and provides controls to ``tune'' the application by tightening or
relaxing the allowed amount of divergence between replicas. This makes
the consistency/availability tradeoff into not merely an abstract
concept but a tangible one, allowing applications to choose where they
are located on a spectrum between total consistency
(i.e. linearizability) and total availability (i.e. never blocking to
enforce consistency requirements).

Mechanisms to exchange consistency for availability, or vice versa,
provide advantages for distributed shared memory frameworks deployed
across disruption-prone networks. In these contexts, message-passing
latencies virtually guarantee that some amount of global inconsistency
is inevitable. However, the safety-related nature of the applications
we have in mind makes this inconsistency important to measure
quantitatively and then limit. Of course, imposing tighter limits on
inconsistency eventually comes at the cost of system performance. The
advantage of the conit model is that the precise tradeoff can
configured according to policies set by the application, rather than
being determined directly by the consistency model. Indeed, it is
possible to adjust these policies at runtime, perhaps in response to
factors like application workload and network capacity, which might
provide the precise sort of behavioral continuity foreshadowed in
Section \ref{ssec:communication-and-safety}.

%We describe the framework now in terms of its system model
%(\ref{ssec:conit-system-model}),
%its three dimensions of consistency
%(\ref{ssec:conit-numerical-consistency}--\ref{ssec:conit-real-time-consistency}),
%correctness (\ref{ssec:conit-correctness}) and possible extensions
%(\ref{ssec:conit-extensions}).

\subsection{System Model}
\label{ssec:conit-system-model}
The system consists of processes in a group $\AllProc$ that replicate
a shared database or, more generally, any kind of replicated state
machine. We shall assume that every process maintains a complete
replica of the database. For simplicity, we assume that the set of
participating processes is fixed and known to each member, though one
can imagine extending the framework to support dynamic group
membership following Golding \cite{1992:golding-thesis}.


Each process begins with their replica in the same initial starting
state, denoted $\Dinit$. For each participating process
$P \in \AllProc$, we denote the current state of $P$'s replica with
$\Dstate{P}$. $\Dstate{P}$ changes as $P$ learns about updates to the data, which
can come from two sources: a request submitted to $P$ by a client of
the application, or a notification about a request submitted to some
other process by one of its clients. For a request submitted to $P$
directly by a client, $P$ is said to be the \emph{originating
  replica}. For all other requests, $P$ is said to be a \emph{remote
  replica}.

As in Section~\ref{ssec:shared-memory}, we imagine requests divided
into two types: read requests and write requests. We call either type
of request a data \emph{access}. Unlike in
Section~\ref{ssec:shared-memory}, we allow for write accesses that are
more complex than simple instructions that set the value of a logical
memory location. Instead, here we are viewing a write as more like an
entire \emph{database transaction}---a potentially complex set of
steps that can read several data items, modify them, and might also
return a value to the user. In fact, read accesses should be thought
of as merely special cases of write accesses that do not modify any
data. Using terminology we will introduce later, a read access is
effectively one that applies zero numerical and order error to every
conit, so it does not need to be entered into $\WL{P}$ or participate
in write propagation.

It is important to note that a write access can encode
application-level logic. For example, it may read a value in the
database and make a business decision whether to increment it. The
resulting state after applying write action $w$ to a database in state
$D$ is denoted $D + w$. Because reads are just accesses that happen
not to modify the underlying database, we have the equation
$D + r = D$ if $r$ is a read. In many real-world data models, writes
are not commutative, meaning in general we have the following
inequality:
\begin{equation}
  D + w + w' \neq D + w' + w \label{eq:conit-non-commutative}
\end{equation}
For such applications, consistency requires writes to be applied in
the same order everywhere. Therefore the conit framework ensures that
processes can enforce a global total order among writes. We shall
explain later how it also provides a mechanism for individual replicas
to optimistically deviate from the total order within controllable
bounds, which can improve application performance.

Recall that a \emph{history} is an ordered sequence of read and write
accesses. If $H$ is any history, for each access $a \in H$ in the
history, the \emph{prefix} history of $a$, denoted
$\PH{\left(a\right)}$, is the sequence of accesses in $H$ that precede
$a$. The \emph{local history} of a process $P$, denoted
$\localhistory{P}$, is the sequence of accesses $P$ has applied to the
initial state $\Dinit$ since the start of the application. Let $D + H$
denote the result of applying each of the accesses in $H$ to $D$ in
history order. Thus, the database state at process $P$ at any moment,
written $\Dstate{P}$, is governed by the following equation:
\begin{equation}
  \Dstate{P} = \Dinit + \localhistory{P}. \label{eq:conit-D-obs}
\end{equation}


The effect of executing a read or write access $a$ against the replica
at $P$ is entirely determined by the local history of $P$ at the time
$a$ is submitted. Because, in general, accesses can encode arbitrarily
complex application-level logic, the state of $\Dstate{P}$ observed by $a$
can strongly influence how $a$ is executed and what value it returns
to the user.

\begin{definition}
  The \emph{observed prefix history} $\PHobs{\left(a\right)}$ of an
  access $a$ originating at $P$ is the value of $\localhistory{P}$
  immediately before $a$ is applied to $\Dstate{P}$. The
  \emph{observed state}, denoted $\Dobs\left(a\right)$, is the state of
  $\Dstate{P}$ at the time $a$ is applied, which gives the equation
  \begin{gather}
    \Dobs\left(a\right) = \Dinit + \PHobs{\left(a\right)} \label{eq:conit-D-obs-at}
  \end{gather}
\end{definition}


Intuitively, the goal of the conit framework is ensure that each
access observes a value of $\Dstate{P}$ whose divergence from its correct or
``ideal'' value is limited by an upper bound. The ideal value of $\Dstate{P}$
is the state it would be in if it has received all updates and applied
them locally in the correct order. In the conit framework, there are
two sources of error that can cause a replica to diverge from its
ideal value:
\begin{description}
\item[Unseen updates] State transitions originating at other processes
  that have not been applied to $\Dstate{P}$ because $P$ has not
  been notified of them yet
\item[Our of order updates] State transitions $P$ has applied locally
  in the wrong order, leading it down an ``errant path'' beginning
  with first update that disagrees with the global order
\end{description}

Unseen updates occur when a write access is submitted by a client of
some other process $Q$ and $P$ is not notified right away, making
$P$'s replica stale. The conit framework presents two metrics with
respect to which we can limit unseen updates. The first, numerical
error, limits the total ``weight'' of unseen updates, where weight is
a conceptual measure of how significant an update is with respect to
the data model. Numerical error is the subject of
Section~\ref{ssec:conit-numerical-consistency}. The second, real-time
staleness, limits the maximum amount of time that may pass before a
process is made aware of a new update. Real-time staleness is the
subject of Section~\ref{ssec:conit-real-time-consistency}.

Out of order updates can occur because when $P$ receives an update (or
a batch of updates), whether submitted by a client locally or
forwarded to $P$ by another process, $P$ generally applies the update
to its own replica immediately, \emph{bypassing} the total-order
delivery mechanism. This may improve performance because the
application might otherwise have to block while the ordering mechanism
determines its place in the total order. This is an I/O-bound
operation, as described in Section~\ref{ssec:conit-order-consistency},
since it generally requires pulling information from other processes
over the network to advance $P$'s commit line.

Recent updates that have been applied without running the total-order
delivery mechanism are said to be \emph{tentative}, while the set of
updates known to have been applied in the correct order (always a
prefix of $\localhistory{P}$) are \emph{committed}. Some time later,
the total-order delivery mechanism may determine that a subset (always
a suffix) of the tentative updates were applied in the wrong
order. The framework provides a mechanism to rollback these incorrect
updates and reapply them in the correct order. ``Out-of-order'' error
sets a limit on the weight of tentative updates before the total-order
mechanism must be invoked. The ``order weight'' of an update is
separate from the numerical weight, and may be thought of as the
potential cost associated with rolling back an update later discovered to
have been applied in the wrong order. Out-of-order error and the
commitment process are the subject of Section
\ref{ssec:conit-order-consistency}.

Consistency is measured at the granularity of conits, or consistency
units, which are defined by the programmer. They are implemented
simply by specifying the numerical and order weight of each update on
a per-conit basis. A particular update may be deemed to change one
conit significantly and another only slightly without affecting a
third conit at all. Likewise, each process specifies its tolerable
error, broken down by numerical error, order error, and real-time
staleness, for each conit. The middleware is responsible for ensuring
that each process' error bounds are enforced for each conit for each
metric. If the error bounds are very tight, the system will spend more
time blocking and less time responding to users. If the error bounds
are very loose, users will observe a more responsive system, with
relatively less assurance of the consistency of what they observe.

\subsection{Write Propagation}
\label{ssec:conit-write-propagation}
We imagine process in $\AllProc$ communicate over a disruption-prone
network, perhaps a tactical mesh network deployed in the field. The
details of this network are not salient to the discussion, except to
emphasize that such a scenario does not lend itself to centralized
solutions where a single replica is maintained that all processes
access through a designated server.

The first requirement to implement the conit framework is a mechanism
for reliable eventual totally-ordered delivery to propagate write
accesses between the processes in $\AllProc$---this is a general
method for replicating a state machine. The implementation we describe
is the one proposed by Yu and Vahdat, which is based on TSAE+TO, or
timestamped anti-entropy with a totally ordered delivery component,
defined in Section~\ref{ssec:tsae-message-ordering}. Each process $P$
maintains a write log $\WL{P}$ that functions as the message log in
TSAE. $P$ also maintains the other data structures required for TSAE,
whether in the form of summary and acknowledgment vectors (Sections
\ref{ssec:tsae-summary-vectors} and~\ref{ssec:tsae-acknowledgment}) or
a summary matrix (Section~\ref{ssec:tsae-unsynchronized}).

Writes originating at $P$ are tagged with $P$'s identifier and clock
value (whether physical or logical) and entered into $\WL{P}$ when
they are applied to $\Dstate{P}$. Remote write accesses added to $\WL{P}$
during anti-entropy are applied to $\Dstate{P}$ in the order they are
received.  Thus, at all times $\WL{P}$ contains the history of all
updates applied to $\Dstate{P}$ and we have the following equation:
\begin{equation}
  \Dstate{P} = \Dinit + \WL{P} \label{eq:conit-DP}
\end{equation}
This follows from Equation \eqref{eq:conit-D-obs} and the observation
that $D + r = D$ if $r$ represents a read access. Reads are handled
locally by $P$ without notifying remotes or entering the access into
$\WL{P}$.

% The distinction between $\localhistory{P}$ and $\WL{P}$ is that the
% former is an abstract concept, includes read accesses, and mostly
% serves to define correctness of the protocol. $\WL{P}$ is a physical
% data structure required for write propagation.

Using TSAE, $P$ uses the summary vectors of remote replicas to
determine which writes it may need to send them, and likewise sends
its summary vector to others to receive updates from them. Messages
are only ever sent in batches determined by comparing summary vectors,
and properties like the coverage property (Section
\ref{ssec:tsae-summary-vectors}) are maintained as invariants.

One feature of the version of TSAE presented here is that we allow
anti-entropy to be one-sided, where only one side learns about new
updates and advances its summary vector. We describe one-sided
sessions as push-based or pull-based depending on whether the sending
or receiving side initiates the session:
\begin{description}
\item[Push based] $P$ initiates a session by requesting the summary
  vector of $Q$. $P$ uses this information to decide which writes $P$
  is aware of that $Q$ has not been informed about, pushing these
  updates to $Q$.
\item[Pull based] $P$ initiates a session by sending its summary
  vector to a remote replica $Q$. $Q$ uses this information to
  determine which writes to send to $P$.
\end{description}

Additionally, unlike in ``pure'' TSAE, the implementation we describe
introduces a notion of compulsory anti-entropy sessions. Recall that
the progress guarantee provided by TSAE is only that messages are
delivered eventually, and so it does not place any requirement on how
often anti-entropy sessions are scheduled except that they happen
periodically. To bound the divergence between replicas at all times,
the conit framework requires processes to become unavailable and
engage in one-way anti-entropy sessions to increase consistency
whenever responding to a user's request immediately would violate
consistency requirements.

\subsection{Ideal States}
\label{ssec:conit-ideal-history}
To define the correctness of the conit framework, we need a history to
serve as a common reference point with respect to which each local
history is measured. Intuitively, this history should represent one
that might be observed if the middleware submitted all requests to a
central database instead of maintaining separate replicas. This
history should be ``global'' in the sense that it contains every
access, which is equivalent to taking the union
$\bigcup_{X \in \AllProc} \localhistory{X}$ of all local histories
(more precisely, the union of their underlying sets---this notation is
implicitly ignoring their ordered structure). Note that accesses are
uniquely determined by the tag containing their name of their
originating process, paired with the timestamp of that process at the
time it was submitted.

Recall from Definition~\ref{def:external-order} that an access $a$
externally precedes $a'$ if $a$ has returned to the caller before $a'$
is invoked. Yu and Vahdat also define a notion of causality:
\begin{definition}[Causal precedence of accesses]
  \label{def:conit-causal-precedence}
  Access $a$ \emph{causally precedes} $a'$ if $a$ was already in the local
  history of the originating replica when $a'$ was submitted (and so
  could have influenced how $a'$ executed).
\end{definition}

The necessity of Definition \ref{def:conit-causal-precedence} is seen
by imagining that $a$ and $a'$ represent long-running isolated
database transactions executed concurrently. In this case, one
operation will logically take effect (and be entered into the write
log) before the other, which is a causal relation, but the operations
have no external order relation.

With the preceding definitions, we can define an idealized global
history to serve as a reference point for measuring divergence.
\begin{definition}
  A \emph{ECG} (externally consistent, causally consistent, global)
  history contains every access in the system, arranged in some total
  order, $<$, that is consistent with both external and causal order
  among accesses.
  \begin{equation}
    \Hglobal = \langle \bigcup_{X \in \AllProc} \localhistory{X}, < \rangle
  \end{equation}
\end{definition}
We will refer to an ECG history as simply a ``global'' history---the
fact this history must respect external and causal order is
implicit. A global history provides a notion of an ideal database
state against which to measure each replica.
\begin{definition}
  Relative to a global history $\Hglobal$, the ideal database image is
  the state it would be in after applying all the updates in the
  global history in order.  If $\Hglobal$ is given as a global
  history, the ideal database image is defined as follows:
  \begin{gather}
    \Dideal = \Dinit + \Hglobal \label{eq:conit-D-ideal}
  \end{gather}
\end{definition}
Note that a global history is not uniquely determined by the set of
local histories, because external and causal order do not uniquely
determine a global total order. The correctness condition of the conit
framework states that at all times, some global history exists such
that each replica is within some error margin of the ideal database
state for this history. For now we assume some global history
$\Hglobal$ has been given. This is needed to define the metrics used
to measure a replica's divergence from its ideal value.

\begin{definition}
  The \emph{ideal prefix history} $\PHideal{\left(a\right)}$ of an
  access $a$ is defined as the prefix of $a$ as it occurs in the
  global history $\Hglobal$. Similarly, the \emph{ideal state} of an
  access is defined as the state of the database at the time $a$ is
  applied in the ideal history:
\begin{gather}
  \Dideal\left(a\right) = \Dinit + \PHideal{\left(a\right)} \label{eq:conit-D-ideal-at}
\end{gather}
\end{definition}

The conit framework seeks to ensure that each local history remains
within some distance of the global history, with the difference
consisting of a limited number of unseen or out-of-order
updates. Roughly, the statement of correctness has the following form:

\begin{quote}
  ``At any moment, there exists some ECG history $\Hglobal$ such that
  each access submitted to any process $P$ observes a level of
  consistency within some margin $\epsilon$ of what it would observe
  in the idealized ECG history.''
\end{quote}
\noindent The preceding is roughly translated into the following informal
equation for all accesses $a$:
\begin{equation}
  | \Dobs\left(a\right) - \Dideal\left(a\right) | < \epsilon
\end{equation}

To interpret this equation, we would need a way to quantify the
difference between two replicas of a database. We now turn our
attention to this topic.

\subsection{Measuring Divergence}
\label{sssec:conit-divergence}
At any moment, it is likely that no local replica perfectly matches
the ideal database state. Intuitively, clients of process $P$ can
usefully operate with the application as long as the difference is
bounded above by some application-defined margin of error. Thus, we
must provide a framework to measure this margin of error.

\subsubsection{Units of Consistency}
\label{sssec:conit-units-consistency}
A complicating factor of defining a general framework is that
applications have unique data models. Note that we have not made any
assumptions about the format of the backing data store. In the
simplest case, the data may be a key-value store, such as a simple
model that associates names like $x, y, z\ldots$ with numerical
values. This sort of simple memory model was used in Section
\ref{ssec:strong-consistency}. In real-world applications, the
database may be something like a relational database, a database
optimized for use in Geographic Information Systems (GIS), or a
bespoke data model uniquely designed for the application. It is not
clear a priori how to design a general framework to measure divergence
without making detailed assumptions about the nature of the data.

Indeed, it is not even clear what the fundamental \emph{unit} of
consistency is---it may be the case that two replicas totally agree on
some parts of the data, but disagree on other parts. This intuition
leads one to consider a more granular model of consistency than one
that measures divergence at the level of whole replicas.

The conit framework strikes a balance between being general enough to
work in applications with different data models and practical enough
to efficiently enforce consistency with simple protocols. The question
of what constitutes a unit of enforceable consistency is handled
simply: the decision is entirely delegated to the programmer. In terms
of how they are implemented, a ``conit'' is nothing but an
identifier invented by the programmer. Somewhat arbitrarily, we refer
to conits with names like $F$, $F_1$, $F_2$, and so on.

Rather than attempting to provide a general theory by which the
middleware can define and measure the significance of an update to the
database, the framework inverts responsibility: the application
programmer is entirely responsible for informing the middleware how
much change each update applies to each conit. These values are not
enforced by the middleware, but simply accepted as ground truths as
used as inputs for further decision-making.



\subsubsection{Dimensions of Consistency}
\label{ssec:conit-bounding-divergence}
Each process $P$ specifies its consistency requirements for conit $F$
with a tuple of three values:
\begin{equation*}
  \langle \NE \left(P, F\right), \OErr(P, F), \RTE(P, F)\rangle
\end{equation*}
These stand for Numerical Error, Order Error, and Real Time Error,
respectively. Recall that the disagreement between $\Dstate{P}$ and
its ideal value comes from two sources: messages that have not been
seen, and tentative writes applied in an order differing from the final
global order. Numerical error and real-time error (used interchangeably
with staleness) are both forms of unseen error, and out of order
error, naturally, bounds the number of messages applied out of
order. We describe each error metric below, starting with numerical error.

Each write is associated a well-defined numerical weight defined for
each conit, though this may be $0$ for conits that the write does not
modify. The numerical error of a replica is always measured at the
level of weight applied to individual conits.

\begin{definition}
  The \emph{numerical weight} of a write $w$ on a conit $F$ is a real
  number $\NumWeight(w, F)$ supplied by the programmer when $w$ is
  submitted to the replication middleware.
\end{definition}
\noindent Intuitively, $\NumWeight(w, F)$ measures the change that $w$ has on
the data item(s) represented by $F$. Since the middleware cannot
calculate this value itself, the programmer must make the decision,
although in some cases there is an ``obvious'' choice.

\begin{example}
  If the database is a key-value store of numerical values, then the
  programmer might define a conit, say $F_x$, for a key named $x$. A
  write update that increments $x$ by $1$ should be declared with
  $\NumWeight(w, F_x) = 1$. More complicated conit definitions are
  possible as well. The programmer might define a conit
  $F_{\mathsf{sum}}$ to correspond to the sum of keys $x$ and $y$. In
  this case, a write that increments $x$ by 3 and subtracts $1$ from
  $y$ should be specified with $\NumWeight(w, F_{\mathsf{sum}}) = 2$.
\end{example}

$\NE\left(P, F\right)$ sets a bound on the total numerical weight
applied to $F$ of writes that $P$ is unaware of. Setting this value to
$0$ means $P$ will be notified of every write access that affects $F$
originating at any process before that write request is finished
executing and returns to the client who submitted it. This process
will be described in Section~\ref{ssec:conit-numerical-consistency}.

Separately from numerical weight, each write is associated with an
order weight for each conit.
\begin{definition}
  The \emph{order weight} of a write $w$ on a conit $F$ is a
  non-negative real number $\OrderWeight(w, F)$ supplied by the
  programmer when $w$ is submitted to the replication middleware.
\end{definition}
\noindent The order weight of $w$ on conit $F$ is best thought of as a
measure of liability, namely the penalty the application (or users of
the application) must pay if $w$ is applied out of order and has to be
rolled back later. The precise definition and utility of measuring
order error will be given in Section
\ref{ssec:conit-order-consistency}.

$\OErr(P, F)$ bounds the maximum weight of of
updates that affect $F$ that $P$ might apply out of order---setting
this value to $0$ means all writes that affect $F$ will be applied
locally by $P$ in their correct order relative to each other, where
``correct'' is defined with respect to some global history $\Hglobal$
whose existence is guaranteed by the conit framework.

How the middleware associates a write $w$ with numerical and order
weights is an implementation detail. The approach described by Yu and
Vahdat \cite{2002tact} has the programmer invoke function calls of the
form $\mathsf{AffectConit}(F, x, y)$ inside in the body of functions
that modify the backing data store. Here, $F$ is the conit, $x$ is
$\NumWeight(w, F)$, and $y$ is $\OrderWeight(w, F)$.

The third metric used to measure consistency is real-time staleness,
which bounds the real time that is allowed to elapse between when a
write is originated and when some other process is notified of
it. Because it is measured in terms of physical time, the programmer
cannot specify the ``real time weight'' of a write on a conit.

$\RTE(P, F)$ bounds the real time staleness of $P$ with respect to any
write that affects $F$. Setting this value to $5$ seconds, say,
implies that $P$ will always be aware of any write affecting $F$ that
finished executing more than $5$ seconds ago. Setting either of
$\RTE(P, F)$ or $\NE(P, F)$ to $0$ would make the other effectively
$0$ as well, though the metrics are enforced with different mechanisms
and would exhibit different behavior (both being correct in the sense
of preserving the correctness properties, but with different
application performance). Real-time staleness is described in
Section \ref{ssec:conit-real-time-consistency}.

\subsubsection{Enforcing Error Bounds}
\label{sssec:conit-tuning-bounds}
Each read or write access submitted to $P$ is responsible for
informing the middleware about which conits the access depends
on. These are the conits that logically represent data in $\Dstate{P}$ that
might influence how the access is executed and what value it returns
to the user; these are the ones whose consistency will be enforced
before handling the access. We adopt a convention of denoting a set of
conits with a script $\Conits$. The middleware is responsible for
ensuring that each of $\NE \left(P, F\right)$, $\OErr(P, F)$, and
$\RTE(P, F)$ is enforced for each conit $F \in \Conits$ that an access
depends on.

The three measures of consistency are enforced with different
mechanisms. Both order error and real-time error are bounded purely
locally---that is, $P$ can enforce these error bounds without
proactive cooperation from other processes. Numerical error is bounded
by a proactive protocol that requires every process to know $P$'s
error bounds and actively cooperate to ensure they are enforced.
Roughly speaking, when a data access is submitted to $P$ by a client,
$P$ executes the following steps:
\begin{enumerate}
\item \textbf{Enforce $\OErr$ and $\RTE$:} For each depended-on conit
  $F$, the values $\OErr(P, F)$ and $\RTE(P, F)$ are enforced using
  compulsory pull-based anti-entropy sessions to pull updates from
  remote replicas, if necessary.
\item \textbf{Apply the access locally:} The access is applied to the
  local replica, which in general will yield some return value.
\item \textbf{Add writes to the log:} If the access is a write access,
  it is tagged with the pair $(P, \clock{P,t})$ and pushed onto $\WL{P}$ so
  that it may participate in write propagation.
\item \textbf{Enforce $\NE$ for remotes:} If the access is a write
  $w$, for each conit $F$ affected by $w$, the system decides for each
  remote $Q$ whether it is required to initiate compulsory push-based
  anti-entropy with $Q$ to cooperatively bound $\NE(Q, F)$.
\item \textbf{Return to the user:} The request returns control back to
  the user, yielding the return value of the access if there was one.
\end{enumerate}

Because $\OErr\left(P, F\right)$ and $\RTE(P, F)$ are enforced
locally, these values can be changed on a per-access basis, with each
access specifying its preferred consistency levels. However, changing
$\NE\left(P, F\right)$ requires notifying every other process about
the update so they can proactively enforce it, so may be costly to
change this value frequently.

\subsection{Numerical Consistency}
\label{ssec:conit-numerical-consistency}
We assume each conit $F$ is associated with a valuation function,
\[
  \Val^F\colon \mathsf{Database\ Image} \to \mathbb{R}
\]
that maps a database state to some real number representing the value
of that conit. Yu and Vahdat actually \emph{define} a conit as what we
have called a valuation function. We adopt a slightly more abstract
terminology and say that a conit is just an identifier such that each
write is associated with a well-defined numerical weight for each
conit. Intuitively, the value $\NumWeight(w, F)$ codifies the effect
on $F$ of applying $w$ to the database in the sense that it should be
defined by the following equation:
\begin{equation}
  \NumWeight\left(w, F\right) \equiv \Val^F(D + w) - \Val^F(D).
\end{equation}
To make sense of this equation, we must assume the value on the
right-hand side is independent of the current state $D$ of the
database. This is sensible because we think of writes as containing
logic to modify the database, such as incrementing or decrementing a
value. This contrasts with writes that directly set the value of each
data item, in which case the difference would directly depend on the
item's previous value.  If the change applied to $F$ by $w$ could
depend on the state of the replica, then $\NumWeight\left(w, F\right)$
might be given as an upper bound of the above expression quantified
over possible states of $D$ instead, but have not come across a use
case where this would be required.

Let $\Vinit{F} \equiv V^F(\Dinit)$ denote the value of $F$
in the initial database state. Let $V^F_P \equiv V^F(\Dstate{P})$
denote the current value of $F$ at $P$'s replica. Let
$\Videal{F} \equiv V^F(\Dideal)$ represent the value of $F$ at
$\Dideal$.  Now $F$ distributes over $+$ in the sense that the
following holds:
\begin{equation}
  \Val^F(D + w) = \Val^F(D) + \NumWeight(w, F).
\end{equation}
Combining this with Equations \eqref{eq:conit-D-obs} and
\eqref{eq:conit-D-ideal} gives
\begin{gather}
  \conitAt{F}{P} = \Vinit{F} + \sum \{\NumWeight(w, F) \mid w \in \localhistory{P}\} \\
  \Videal{F} = \Vinit{F} + \sum \{\NumWeight(w, F) \mid w \in \Hglobal\}
\end{gather}

The correctness condition required of numerical error is that the
difference between these values is bounded at all times according to
the following inequality:
\begin{equation}
  | \Videal{F} - \conitAt{F}{P} | < \NE\left(P, F \right)
\end{equation}
Enforcing this condition requires bounding the combined weight of set
of writes that $P$ has not seen, specifically the ones that affect
conit $F$:
\[
  \{ w \in \Hglobal \mid \NumWeight(w, F) \neq 0 \} \setminus \WL{P}
\]
This is accomplished by requiring all \emph{other} process to maintain
approximate knowledge of the contents $\WL{P}$. Each process $Q$
uses its estimate of $\WL{P}$ to bound its own ``contribution''
towards the writes in $\Hglobal$ that are not in $\WL{P}$, namely the
writes originating at $Q$ that $P$ has not been notified of yet.

\subsubsection{Assumptions}
\label{sssec:conit-numerical-assumptions}

Bounding numerical error requires a cooperation between all
processes. For this, we make an assumption that each process knows
every other process's numerical error bounds for each conit.
\begin{quote}
  \textbf{Global knowledge of error bounds}: Every process knows
  $\NE\left(P, F \right)$ for each conit $F$ and each process $P$.
\end{quote}
If $P$ wishes to dynamically update its numerical error bounds for a
conit $F$, it must invoke some mechanism to inform all other processes
of this change.

In order to bound $P$'s numerical error, each remote process $Q$ needs
to know which writes $P$ has not seen. Specifically, $Q$ must keep
track of at least its \emph{own} writes $P$ has not seen. Recall that
$\WLat{P}{Q}$ contains the writes $P$ has received that originated at
$Q$. Therefore, the set of writes originating at $Q$ unseen by $P$ is
defined by the following set difference:
\begin{equation}
  \Unseen^{Q}{\left(P\right)} \equiv \WLat{Q}{Q} \setminus \WLat{P}{Q}
\end{equation}
$Q$ cannot compute this set exactly because $\WLat{P}{Q}$ is a data
structure maintained by $P$, not $Q$. For this reason, we require $Q$
to maintain a conservative estimate, called its \emph{view}, of this
value. $Q$'s view of $P$ is denoted $\View{Q}{P}$.
\begin{quote}
  \textbf{Approximate knowledge of remote knowledge}: Each process $Q$
  can compute a set $\View{Q}{P}$ subject to the following invariant:
  \begin{equation}
    \View{Q}{P} \subseteq \WLat{P}{Q}  \label{eqn:conit-approximate-view}
  \end{equation}
  $Q$ must also implement a mechanism to advance its view by pushing
  updates to $P$, at which point $\View{Q}{P} =
  \WLat{P}{Q}$. Section~\ref{sssec:conit-views} describes two ways to
  implement views.
\end{quote}
The subset relation above states that $Q$ maintains a lower bound
estimate of this set. It is a lower bound because $P$ might have
learned about writes originating at $Q$ through anti-entropy with some
intermediary process $R$, and $Q$ may not know about this. The lower
bound corresponds to an upper bound estimate of the updates
originating at $Q$ that $P$ has \emph{not} received yet, defined by the
following equation:
\begin{equation}
  \EstUnseen^{Q}{\left(P\right)} \equiv \WLat{Q}{Q} \setminus \View{Q}{P}
\end{equation}
\noindent Finally, condition \eqref{eqn:conit-approximate-view} implies the
following subset relation:
\begin{equation}
  \Unseen^{Q}{\left(P\right)} \subseteq \EstUnseen^{Q}{\left(P\right)}
\end{equation}

To bound numerical error, $Q$ never allows the combined weight of
writes in $\EstUnseen^{Q}{\left(P\right)}$ to exceed a certain
threshold on a per-conit basis. As long as every process collaborates
in this manner, the weight of writes unseen by $P$ will remain within
$P$'s numerical error
bounds. Section~\ref{sssec:conit-split-weight-ae} describes a simple
mechanism for achieving this.

\subsubsection{Implementations of Views}\label{sssec:conit-views}
We describe two ways to implement views for two implementations of
TSAE described in Section \ref{sec:tsae}.

\paragraph{Acknowledgment Vectors}
If TSAE is implemented using acknowledgment vectors, $Q$ maintains an
additional vector $\lastVec{Q}$ where $\last{Q}{P}$ stores the value
of $\clock{Q,t}$ at the time of the last push to $P$. $Q$
conservatively estimates that $P$ has not received any messages from
$Q$ (via a third party) since $\last{Q}{P}$:
\begin{equation}
  \View{Q}{P} \equiv \{ m \in \WLat{Q}{Q} \mid \timestamp{m} \leq
  \last{Q}{P} \}
\end{equation}
While handling a write with timestamp $\clock{Q, t}$, after pushing
messages to $P$, $\last{Q}{P}$ is advanced to $\clock{Q, t}$.

Note that $\ack{P}{Q}$ itself provides a conservative view of
$\WL{Q}$, but it is too coarse: there is no guarantee it will advance
after pushing updates to $Q$, since it is a lower bound of the minimum
value of $\summary{Q}{X}$ for \emph{any} $X$.

\paragraph{Matrices}
If TSAE is implemented with summary matrices, $Q$ estimates that $P$
has not seen any messages from $Q$ with timestamp newer than
$\ackMatrix{Q}[P][Q]$:
\begin{equation}
  \View{Q}{P} \equiv \{ m \in \WLat{Q}{Q} \mid \timestamp{m} \leq
  \ackMatrix{Q}[P][Q] \}
\end{equation}

The advantage of using $\ackMatrix{}$ over $\lastVec{}$ is that it
allows $Q$ to learn from other processes which messages originating at
$Q$ $P$ has received, since all processes will track this
information. Entries in $\lastVec{Q}$ can only be updated by $Q$
itself, making it a coarser estimate of $Q$'s write log, potentially
causing $P$ to push updates more often.

\subsubsection{Split Weight Absolute Error}\label{sssec:conit-split-weight-ae}
We describe the \emph{split-weight AE} (absolute error) algorithm,
which Yu and Vahdat explicate most at length in a 2000
paper~\cite{2000tactalgorithms}. For reasons explained below, we
consider writes with positive and negative weights
separately.
\begin{gather}
  \EstUnseenPos{Q}{F}{P} \equiv \{ w \in \EstUnseen^{Q}{\left(P\right)} \mid \NumWeight\left(w, F\right) > 0 \} \\
  \EstUnseenNeg{Q}{F}{P} \equiv \{ w \in \EstUnseen^{Q}{\left(P\right)} \mid \NumWeight\left(w, F\right) < 0 \}
\end{gather}
For each $F$, define the following values totaling the positive and
negative weights to conit $F$ of writes originating at $Q$ thought to
be unseen by $P$.
\begin{gather}
  \twp{Q}{F}{P} \equiv \sum \{ \NumWeight\left(w, F\right) \mid w \in \EstUnseenPos{Q}{F}{P} \} \\
  \twn{Q}{F}{P} \equiv \sum \{ \NumWeight\left(w, F\right) \mid w \in \EstUnseenNeg{Q}{F}{P} \}
\end{gather}
To bound $\NE\left(P, F\right)$, the intuition is that $Q$'s estimate
of numerical weight on $F$ unseen by $P$ must not exceed an allotted
``share'' of $\NE\left(P, F\right)$. There are $|\AllProc|$ total
processes, of which $|\AllProc| - 1$ can originate writes
without $P$ immediately seeing them. Therefore, the total weight of
unseen messages accepted by these processes must not exceed
$\NE\left(P, F \right) / \left(|\AllProc| - 1\right)$.  When $P$
submits a new write, $P$ first checks whether the following
conditions hold:
\begin{align*}
  \twp{Q}{F}{P} + \NumWeight(w, F) &< \phantom{-}  \frac{\NE\left(P, F\right)}{|\AllProc| - 1} & \textrm{if $\NumWeight(w, F) > 0$} \\
  \twn{Q}{F}{P} + \NumWeight(w, F) &> - \frac{\NE\left(P, F\right)}{|\AllProc| - 1} & \textrm{if $\NumWeight(w, F) < 0$}
\end{align*}
If either condition is violated, then $Q$ updates its view of $P$,
requesting the latest value of $P$'s summary vector and sending any
unseen writes (including those not necessarily originating at $Q$)
following a one-sided version of the usual TSAE protocol. Before the write
access at $Q$ returns to the user, $\WL{P}$ will reflect all updates
originating at $Q$ before and including the one being handled, and
$\twp{Q}{F}{P}$ and $\twn{Q}{F}{P}$ will be zero.

\begin{lemma}[Numerical weight correctness]
  When following the above protocol, then each value of each conit at process will satisfy
  \[ | \Videal{F} - \conitAt{F}{P} | < \NE{(P, F)}. \]
\end{lemma}
\begin{proof}
  The difference between the ideal value of conit $F$ and the actual
  value of $F$ at $P$ is the sum of all weights applied to $F$ by
  writes that are not in $P$'s write log:
  \begin{equation*}
    % \Videal{F} - \conitAt{F}{P} =  \sum_{Q \in \AllProc \setminus \{P\}} \{ \NumWeight\left(w, F\right) | w \in \WLat{Q}{Q} \setminus \WLat{P}{Q}\}
    \Videal{F} - \conitAt{F}{P} =  \sum_{Q \in \AllProc \setminus \{P\}} \{ \NumWeight\left(w, F\right) \mid w \in \Unseen^Q\left(P\right) \}
  \end{equation*}
  Because actual unseen writes are a subset of estimated unseen writes, we have the following equation:
  \begin{align*}
    & \sum \{ \NumWeight\left(w, F\right) \mid w \in \Unseen^Q\left(P\right) \} \\
    < & \sum \{ \NumWeight\left(w, F\right) \mid w \in \EstUnseenPos{Q}{F}{P} \}\\
    \equiv & \ \twp{Q}{F}{P}
  \end{align*}
  Likewise we have the following:
  \begin{align*}
    &  \twn{Q}{F}{P} \\
    \equiv & \sum \{ \NumWeight\left(w, F\right) \mid w \in \EstUnseenNeg{Q}{F}{P} \}\\
    < & \sum \{ \NumWeight\left(w, F\right) \mid w \in \Unseen^Q\left(P\right) \}
  \end{align*}
  Now as long as the invariants
  \begin{equation*}
    -\frac{\NE(P, F)}{|\AllProc|-1} < \twn{Q}{F}{P} \textrm{\quad{}and\quad}
    \twp{Q}{F}{P} < \frac{\NE(Q, F)}{|\AllProc|-1}
  \end{equation*} are maintained for each choice of $Q$, then the following inequality holds:
  \begin{equation*}
    - \NE{(P, F)} < \Videal{F} - \conitAt{F}{P} < \NE{(P, F)}
  \end{equation*}
\end{proof}

The motivation for tracking positive and negative weights separately
stems from the fact that $P$'s view is conservative, and letting
writes with positive weight ``cancel out'' writes with negative weight
can lead to incorrect behavior. For example, suppose $Q$ has
originated writes with positive and negative weights that exactly
cancel out, and suppose $P$ has actually seen, unbeknownst to $Q$, all
of the writes with negative weight. If $Q$ totaled all estimated
unseen weights together, it would wrongly estimate that the weight of
writes unseen by $P$ is $0$, when the actual value would be some
positive value that may exceed $\NE{(P, F)}$.

\begin{figure}
  \centering
  \includegraphics[width=0.6\textwidth]{images/conit/Numerical1.png}
  \caption{Write log $\WL{A}$ for Example~\ref{ex:conit-numerical}, where
    messages with a grid background represent $A$'s view of $\WL{C}$.}
  \label{fig:conit-numerical}
\end{figure}

\begin{example}
  \label{ex:conit-numerical}
  Figure~\ref{fig:conit-numerical} depicts the role of numerical
  weight for a process $A$.  Messages with a grid background represent
  $A$'s view of $\WL{C}$. We are assuming here that summary matrices
  are used to implement TSAE, so $A$ also has a view of $\WLat{C}{B}$,
  though this does not play a role. $A$ only works to bound the weight
  of its own writes unseen by $C$.

  $A$ estimates there are two messages (with timestamps $(A, 6)$ and
  $(A, 9)$) in $\WLat{A}{A}$ that are not in $\WLat{C}{A}$. We assume
  both of these updates apply positive weight to a conit $F$. While
  handling access $(A, 9)$, before returning to the user, the combined
  weight of the updates must be less than
  \mbox{$\NE\left(C, F \right)/ 2$}. If this limit is exceeded, $A$
  would become unavailable and engage in compulsory anti-entropy with
  $C$. Note that if $A$ is multithreaded and can handle multiple
  accesses at once, then $A$ only has to be unavailable for further
  accesses involving the same underlying conit.
\end{example}

\subsubsection{Distributed Locking}
\label{sssec:conit-distributed-locking}
A subtle but important implementation detail we have not described
concerns the finer details of write propagation. Yu and Vahdat
describe two possible implementations of what happens when, following
the protocol in Section~\ref{sssec:conit-split-weight-ae}, $Q$ decides
to push updates to $P$. The difference concerns whether ensures that
no concurrent writes are possible while $Q$ handles the client's
request.

\paragraph{Single Round Push} With this implementation, $Q$ applies
the write update to its own replica immediately, then engages in
anti-entropy with $P$ (and any other required processes) to push the
new update, awaits acknowledgment from all destinations, then returns
to the user.

\paragraph{Two Round Push} With this implementation, $Q$ first
acquires locks (i.e. exclusive rights to modify) covering any of the
data items affected by the write on $P$ and any other required
processes. After acquiring all locks, the write is executed against
$\Dstate{Q}$ and pushed to all destinations. Locks are released and
the request returns to the user after receiving all acknowledgments.

The two-round protocol, a simple form of distributed two-phase
locking, is required for correctness if numerical error bounds are
enforced for the observed state seen write accesses $w$ submitted to
$Q$. Acquiring locks prevents any of the destinations from initiating
their own updates while $w$ is executed against
$\Dstate{Q}$. Otherwise, destinations may update the data while $Q$ is
handling $w$, and those updates may be found to precede $w$ in the
global history, making them unseen updates for $w$.

The single-phase protocol is appropriate when observed numerical error
bounds do not have to be enforced for write updates.  According to the
authors, applications where writes are interchangeable may benefit
from the one-round protocol.

\subsubsection{Variations}
Yu and Vahdat also describe two other schemes
for bounding numerical error. \emph{Compound-weight absolute error} is
similar to split-weight AE, but allows positive and negative weights
to cancel out. This method represents a potential tradeoff between
storage space and communication, but they did not find the savings
particularly compelling in their performance analysis. They also
consider a scheme, \emph{inductive relative error}, which bounds the
relative error $|1 - V^F_P / \Videal{F} |$. It is somewhat notable
that this algorithm relies only on each process' local knowledge,
because it is not obvious how to efficiently bound relative error
without knowing $\Videal{F}$.


\subsection{Order Consistency}
\label{ssec:conit-order-consistency}
The write log $\WL{P}$ is a linearly ordered structure, and the local
replica state $\Dstate{P} = \Dinit + \WL{P}$ reflects this
order. Generally, writes are added to $\WL{P}$ and applied to
$\Dstate{P}$ in the order they are received, instead of waiting for
the totally-ordered delivery component of TSAE+TO to determine their
correct order. Consequently, writes might be applied in the wrong
order. This section provides a way to enforce an upper bound on the
``weight'' of out-of-order writes at any moment.

Periodically, following the protocol described in this section, the
total-order component learns more information about the final (global)
order of writes; at this time, it may discover that some of the recent
updates have been applied in the wrong order. Such writes then have to
be un-applied from $\Dstate{P}$, as it were, and then reapplied in their
correct order. How this rollback-and-reapply mechanism is implemented
is determined by the application and its data model. The mechanism
described in this section only determines when this process is
necessary to avoid violating the application's consistency
requirements.

Writes accepted in $\localhistory{P}$ whose final order has been
confirmed are said to be committed. Other writes are said to be
tentative. This distinction divides the local history into two
contiguous segments:
\begin{equation}
  \localhistory{P} = \Committed{P} + \Uncommitted{P} \label{eqn:conit-history-segments}
\end{equation}

The out-of-order error $\OErr(P, F)$ is enforced as an upper bound on
the weight of the tentative segment, relative to the conit $F$. Before
defining this value formally, we describe a running example, adapted
from an application described by Yu and Vahdat \cite{2002tact}, which
we will use to demonstrate out-of-order error and write
commitment.

\begin{comment}
so at any moment it
is possible that $P$'s state machine has diverged from its ideal
value, beginning at the first access $P$ that was not applied in the
final order. The allowable order error bounds how far $P$'s replicated
state machine may tread down an errant path of transitions, before
winding back transitions and reapplying them in the correct order.
\end{comment}
\begin{example}
  \label{ex:conit-booking}
  Suppose $P$ and $Q$ are two web servers independently processing
  client requests to reserve seats on a flight. To improve performance,
  they do not maintain strong consistency. Now suppose both process
  separate reservations for seat $A1$ at the same time, denoted $w_P$
  and $w_Q$. This results in inconsistent states, $\Dinit + w_P$ and
  $\Dinit + w_Q$, respectively.

  Eventually, $P$ and $Q$ learn about each other's updates through
  anti-entropy and commit them in an agreed order. Assume $P$'s update
  is ordered first. In this case, $P$ transitions to
  $\Dinit + w_P + w_Q$, while $Q$ rolls back its state and reapplies
  its write as follows:
  \begin{equation*}
    \Dinit + w_Q \xmapsto{\textrm{rollback}} \Dinit \xmapsto{\textrm{reapply}} \Dinit + w_P +
    w_Q
  \end{equation*}

  Recall that $w_P$ and $w_Q$ represent transactions that may include
  business logic. The final state $\Dinit + w_P + w_Q$ might be
  interpreted as, ``Seat $A1$ is reserved for $P$'s client, while
  $Q$'s client experiences a double-booking error.''  The rollback
  process may trigger notifications to $Q$'s client about the
  cancellation, along with issuing a refund (and possibly a
  compensation fee).
\end{example}


The order weight $\OrderWeight\left(w, F\right)$ of a write $w$
defines the relative cost of rolling back a tentative update, which
can be thought of as a liability. In Example~\ref{ex:conit-booking},
accepting $w_Q$ in a tentative state represented a liability for the
airline. One way to bound this liability is by defining a single
conit, say $F_{\textrm{flight}}$, to represent the seats on the
flight. Then, a natural policy would be to define each reservation on
the flight to apply $\NumWeight\left(w,F_{\textrm{flight}}\right) = 1$
(or whatever number of seats the reservation is for) and set
$\OrderWeight\left(w,F_{\textrm{flight}}\right)$ to the airline's cost
to cancel the reservation and refund the reservation holder. We will
now walk through how such an application would execute depending on
how the bounds are set.

Suppose the airline wishes to avoid double-booking. Setting
$\OErr(Q, F_{\textrm{flight}}) = 0$ would suffice to ensure that $Q$
never accepts a reservation without knowing its final order in the
global history, meaning $Q$ never incorrectly tells a client that
their reservation has been successful. On the other hand, suppose the
airline is willing to risk double-booking seats to support application
performance (perhaps $P$ and $Q$ are located on opposite sides of the
world). In this case, $\OErr(Q, F_{\textrm{flight}})$ would be set to
the maximum potential cost of issuing refunds the airline is willing
to tolerate from server $Q$. Effectively, $Q$ would be free to issue
some reservations without immediately checking for seat conflicts, so
long as an allowable dollar amount of potential refunds is not
exceeded.

An indirect way to bound this sort of liability would be for $Q$ to
enforce $\NE(Q, F_{\textrm{flight}}) = 0$. Indeed, if the two-phase
locking policy is used (see
Section~\ref{sssec:conit-distributed-locking}), $Q$ would not accept a
reservation without being aware of a conflicting reservation at
$P$. However, this would be enforced with a push-based protocol where
$P$ immediately notifies $Q$ of every new reservation, which may be
inefficient. Furthermore, this metric does not provide a natural way
of allowing $Q$ to issue a controlled number of tentative
reservations. The protocol to bound order error, described below, is
pull-based and would only require communication with $P$ when the cost
of $Q$'s tentative reservations exceeds its allowable bounds. One or
the other strategy may be substantially more efficient depending on
the application characteristics.

\subsubsection{Out-of-Order Error}

We now define out-of-order error rigorously.

\begin{definition}
  Given two histories $H$ and $H'$, let their \emph{intersection} or
  \emph{greatest common prefix}, $H \cap H'$, be the set of all
  accesses they agree on since their beginning
\end{definition}

\begin{definition}
  The \emph{errant history} of an access $a$ submitted to $P$ is defined
  as all of the writes at the tail end of $\PHobs(a)$, beginning at the
  first write where $\PHobs(a)$ does not agree with $\PHideal(a)$:
  \begin{equation*} \PHobs(a) - \left(\PHobs(a) \cap \PHideal(a)\right)
  \end{equation*}
\end{definition}

As an exercise, the reader may which to check that the following
relation holds, where $H \subseteq H'$ means $H$ is a prefix of $H'$:
\begin{equation}\label{eqn:conit-committed-subset-ideal}
  \Committed{P} \subseteq \PHobs(a) \cap \PHideal(a)
\end{equation}
This follows because the committed segment of $\localhistory{P}$ is
always a prefix of both the ideal history $\Hglobal$ and the observed
history $\PHobs(a)$. Equation \eqref{eqn:conit-committed-subset-ideal}
implies that the errant history is a suffix of the tentative
writes. These facts are demonstrated in the next example.

\begin{figure}
  \begin{subfigure}{0.5\textwidth}
    \centering
    \includegraphics[width=0.5\textwidth]{images/conit/Order1.png}
    \caption{$\WL{A}$ shown with $5$ uncommitted writes}
    \label{fig:conit-order-a}
  \end{subfigure}%
  \begin{subfigure}{0.5\textwidth}
    \centering
    \includegraphics[width=0.5\textwidth]{images/conit/Order2.png}
    \caption{$\WL{A}$ shown at a later time}
    \label{fig:conit-order-b}
  \end{subfigure}
  \caption{Logs for Example~\ref{ex:conit-order} where committed writes are drawn with a dotted background}
  \label{fig:conit-order}
\end{figure}

\begin{example}
  \label{ex:conit-order}
  Figure~\ref{fig:conit-order} depicts two write logs where committed
  writes are shown with a dotted grid pattern. In Figure
 ~\ref{fig:conit-order-a}, five writes are uncommitted. No write with
  timestamp greater than or equal to $3$ can be committed, since the
  minimum timestamp in the summary vector is only $2$. The final order
  of these accesses is shown in Figure~\ref{fig:conit-order-b}. For
  the next access submitted to $A$, with tag $(A, 11)$, the errant history
  consists of all accesses after and including $(A, 6)$, the point at
  which the write log deviates from the ideal history.
  \begin{align*}
    &\PHobs \cap \PHideal &&= \{ (B, 1) \ldots (A, 3) \} \\
    &\PHobs - \left(\PHobs \cap \PHideal\right) &&= \{ (A, 6), (B, 4), (B, 5), (A, 9) \}
  \end{align*}
\end{example}

Let $r$ be a read access submitted to $P$ with a dependency on conit
set $\mathcal{F}$.  Let $\Uncommitted{P}$ represent the uncommitted
messages in $\WL{P}$. As a set, the errant history is a subset
(actually a suffix) of the tentative writes.
\begin{equation}
  \PHobs(a) - \left(\PHobs(a) \cap \PHideal(a)\right) \subseteq \Uncommitted{P}
\end{equation}
Therefore, the tentative writes can be used as an upper bound estimate
of which writes may be out of order.

For a read access that depends on conits in a set $\Conits$, the
relative order of updates applied to $\Dstate{P}$ only matters if they
affect (i.e. apply non-zero order weight to) one or more of the conits
in $\Conits$. (This can be considered an axiomatic constraint on how
applications should define conits and order weight.) This means the
errant history actually overstates the difference between $\PHobs$ and
$\PHideal$. For instance, if they only differ in the relative order of
updates applied to conits that do not affect $\Conits$, then a read
depending on $\Conits$ should be considered to observe $0$ order
error.

\begin{definition}[Write-order projection]
  Let $H|_\Conits$ denote the restriction of $H$ to $\Conits$,
  consisting of just the writes $w$ such that
  $\OrderWeight(w, F) \neq 0$ for at least one $F$ in $\Conits$.
\end{definition}

\begin{definition}
  For an access $a$ depending on a set of conits $\Conits$, the set of
  observed \emph{out-of-order} accesses to $\Conits$,
  $\mathsf{OOO}\left(a, \Conits\right)$ is the set of all writes
  affecting any conit in $\Conits$ that have been applied in an order
  deviating from their final order relative to each other:
\begin{equation}
  \mathsf{OOO}\left(a, \Conits\right)  = \PHobs(a)|_\Conits - \left(\PHobs(a)|_\Conits \cap \PHideal(a)|_\Conits \right)
\end{equation}
\end{definition}

The reader may want to verify with an example that computing the
errant history and then restricting to writes that affect $\Conits$, yielding the sequence
\begin{equation*}
  \left(\PHobs(a) - \left(\PHobs(a) \cap \PHideal(a)\right)\right)|_\Conits
\end{equation*}
overcounts the number of out-of-order updates if only the relative
order of writes affecting $\Conits$ is considered important.

The order error for conit $F$ of an access $a$ depending on conits
in $\Conits$ is the total order weight of out of order writes.
\begin{definition}[Order error]
  Let $a$ be an access depending on a conit set $\mathcal{F}$. The
  \emph{order error} relative to the conit $F$ is the sum of
  $\OrderWeight\left(a, F\right)$ for all writes $w$ that are in the
  out-of-order set for $\mathcal{F}$.
  \begin{equation}
    \OrderError\left(a, F\right) \equiv \sum \{ \OrderWeight\left(w, F\right) \mid w \in \mathsf{OOO}\left(a, \Conits\right) \}
  \end{equation}
\end{definition}

The out-of-order set is always a subset of the uncommitted writes. So, $P$
can estimate the order error of an access by totaling the order weight
of accesses to $\Conits$ that have not been committed, yielding the
following value:
\begin{equation}
  \EstOrderError\left(a, F \right) \equiv \sum \{ \OrderWeight\left(w, F\right) \mid w \in \Uncommitted{P}|_\Conits \}
\end{equation}
Now
$\mathsf{OOO}\left(a, \Conits\right) \subseteq
\Uncommitted{P}|_\Conits$ implies
$\OrderError\left(a, F\right) \leq \EstOrderError\left(a,
  F\right)$. Therefore it suffices for $P$ to bound the estimated
order error of each access.


\subsubsection{Implementation}
To bound out-of-order error, we assume that processes, when required,
can invoke a write commitment mechanism to learn the final order of
their tentatively accepted updates.
\begin{quote}
  \textbf{Ability to commit writes}: While handling an access, each
  process has a mechanism to determine the final order of any
  uncommitted writes in its write log.
\end{quote}

For the TSAE+TO implementation, commitment is implemented with a
pull-based approach. Recall that $P$ can commit writes by pulling
messages through anti-entropy to advance its commit line
($\min_{X \in \AllProc} \left(\summary{P}{X}\right)$) far enough for
the total ordering component to decide the final value of all writes
in its log, meaning the commit line must be greater than the maximum
timestamp of a write in the log. When $P$ pulls enough messages from
remotes to decide the final order of its tentative updates, any errant
updates can be rolled back and reapplied in their final order.

Let $t$ be the greatest timestamp of any message in $P$'s write
log. To guarantee that $P$ can advance its commit line enough to
commit the write, it is enough to ensure that $\summary{P}{Q}$ is
greater than $t$ after engaging in anti-entropy with each $Q$. This is
true of physically synchronized clocks, since $\summary{P}{Q}$ will
reflect the time at which $P$ initiated contact with $Q$. This is also
true if processes maintain simple scalar logical clocks, since
$\summary{P}{Q}$ would be set to the value of $Q$'s scalar clock after
being contacted by $P$, which will be greater than $P$'s clock, itself
an upper bound of the timestamp of any message in the log.

Let $P$ accept an access $a$ from a client with a dependency on the
conits in $\Conits$. The correctness condition of this metric is that
the following inequality holds:
\begin{equation}
  \OrderError\left(a,F\right) < \OErr(P, F)
\end{equation}
While handling $a$, for each conit $F$ that $a$ depends on, if
$\EstOrderError(a, F)$ exceeds $\OErr(P, F)$, $P$ engages the write
commitment procedure to commit enough of its tentative updates to make
the inequality hold. This process is repeated for each conit $F$ that
$a$ depends on.

Note that because $P$ does not require proactive cooperation from
other processes in $\AllProc$, the value of $\OErr(P, F)$ can be set
uniquely for each access submitted to $P$. This allows controlling the
risk of an out-of-order access on a per-access basis. For example, a
preferred client of $P$ may enforce $0$ order error for any conits it
depends on, ensuring that client never risks an canceled reservation.

\begin{example}
  Suppose in Figure~\ref{fig:conit-order-a} that an access submitted
  to $A$ at time $t = 11$ is timestamped $(A, 11)$. Suppose all writes
  apply unit order weight to a conit $F$. If $(A, 11)$ depends on $F$
  with an allowable order error of less than $5$, the number of
  uncommitted writes, then the update will be executed until $A$ pulls
  writes from $B$ and $C$ so that all messages up to $(A, 9)$ can be
  committed. These anti-entropy sessions increase $\summary{A}{B}$ and
  $\summary{A}{C}$ to $11$.  Figure~\ref{fig:conit-order-b} shows a
  possible state at a later time $t = 13$, after accepting another
  write with timestamp $(A, 12)$
\end{example}


\subsection{Real Time Staleness}
\label{ssec:conit-real-time-consistency}
The \emph{real time staleness} metric allows each process $P$ to bound
the maximum amount of time between an access affecting a conit being
issued and $P$ seeing that access. Here we rely on the assumption that
$\summaryVec{P}$ stores physical timestamps from loosely synchronized
physical clocks, though this assumption can be weakened.

\begin{definition}
  The \emph{real-time staleness} of an access $a$ relative to conit
  $F$ is the value
  \begin{equation*}
    \memstart{a} - \min \left\{\memstop{w} \quad \big|\quad
      \begin{aligned}&w \in \PHideal-\PHobs \\
                     \textrm{and } &\NumWeight\left(w, F\right) \neq 0 \\
                     \textrm{and } &\textrm{$w$ externally precedes $a$}
    \end{aligned}\quad \right\}
  \end{equation*}
\end{definition}

The correctness condition for real-time staleness is that the above
value is less than $\RTE\left(P, F\right)$ for any access originating
at $P$ with a read dependency on $F$.

\subsubsection{Implementation}
While handling an access with a read dependency on $F$, submitted at
real time $t$, $P$ checks for each $X \in \AllProc$ whether
$|\clock{P, t} - \summary{P}{X}| < \RTE\left(P, F\right)$ is true for
each $X$. If it is not true, then $P$ engages in a pull-based
anti-entropy session with $X$, at which point $\summary{P}{X}$ has
value $\clock{X, t'}$ for some $t' \approx t$. Note that the assumption of
loose synchronization implies $\clock{X, t'} \approx \clock{P, t}$.

This protocol ensures that the original access, timestamped with value
$\clock{P,t}$, will observe the effect of all writes affecting $F$
with timestamps less than $\clock{P, t} - \RTE(P, F)$. The assumption
of external precedence owes to the corner case scenario where
processing the access takes a long time, during which time some other
process, whose writes were already pulled by $P$, originates a new
write that finishes before $P$'s write by more than
$\RTE\left(P, F\right)$. Such a write has no external precedence over
$P$'s write, although it may be ordered before it in the global order.

A pull-based protocol may seem wasteful because $P$ may poll remotes
for updates even if when they do not have any new writes. However, an
approach where remotes push updates to $P$ cannot bound real-time
staleness without an upper bound on the time it takes to push messages
across the network to $P$. The pull-based approach does not suffer the
same problem---high network latencies will cause $P$ to block for a
long time, but will preserve the intended correctness property.

If clocks are not loosely synchronized, an alternative implementation
strategy is for $P$ to maintain a vector $\vtphys{P}{}$ where
$\vtphys{P}[X]$ stores the value $\clock{P,t}$ of the last time $P$
was on the receiving end of an anti-entropy session directly with
$X$. Then $P$ enforces consistency by using $\vtphys{P}$ in place of
$\summary{P}{X}$ above. This approach only compares values from $P$'s
clock; synchronization is not required assuming $\clock{P}$ runs at a
constant rate. However, this approach has the downside that, unlike
$\summary{P}{Q}$, the value of $\vtphys{P}[Q]$ is not updated based on
information indirectly learned during anti-entropy with a third party.

\subsection{Correctness Properties}
\label{ssec:conit-correctness}
Section \ref{sssec:conit-distributed-locking} described two
implementations of write propagation that differ in their
guarantees. The stronger but less efficient method involves a
two-phase locking procedure where, during write propagation, remote
locks covering all of the affected data items are first acquired from
all hosts where one intends to send write updates. Once all locks have
been acquired, all necessary writes are sent. While locks are held,
reads from affected conits are blocked on those remotes. When the
writes are propagated, locks are released. This two-phase locking
mechanism, which is also a conventional method to implement
linearizability, ensures that the propagated write operations appear
to take effect at all destinations at the same time. When writes are
propagated this way, the numerical and order weights of all accesses
are properly bounded with respect to their ideal values in a strongly
consistent history.
\begin{theorem}[Yu and Vahdat]
  \label{thm:conit-correct}
  Assuming the two-phase locking policy is used during compulsory
  write propagation, there is an ECG history such that the observed
  numerical, order, and real-time error of every access is correctly
  bounded with respect to its ideal return value in the ECG history.
\end{theorem}

The following result is Theorem 4.1 from \cite{2002tact}. Note that
``strict serializability'' here is essentially synonymous
linearizability in the context of replicated databases. (The condition
also implies serializable isolation of transactions, which is a
concept specific to the database context.)
\begin{theorem}
  \label{thm:conit-correct-linearizability}
  If a conit is defined for each data item, and an access depends on
  each conit it reads or writes, if the allowable numerical error and
  order error on all conits is $0$, and all writes have unit numerical
  and order weight on all affected conits, then the system provides
  strict serializability.
\end{theorem}
\begin{comment}
On the other hand, allowing unbounded numerical error provides
one-copy serializability (1SR) \cite{1984:1sr}. The condition of 1SR
roughly states that the history is consistent with some totally
ordered history, but the history does not have to respect real-time
order. Thus, one-copy serializability is something of an analogue of
sequential consistency for replicated databases, where the unit of
operation is a database transaction.
\begin{theorem}
    \label{thm:conit-correct-1sr}
    If the above conditions are enforced except numerical weight is
    unbounded, the system provides one-copy serializability.
\end{theorem}
\end{comment}

If the one-round protocol is used where remote locks are not acquired
before pushing writes, then some replicas appear to see new writes
before others. That is, this policy does not enforce atomic visibility
---updates at different replicas, appear to occur at different
physical times instead of all at once. This is a weaker consistency
model but may be valuable for certain kinds of information,
particularly for applications where accepting new updates is
always valuable, even if this update has not propagated to others
yet. Otherwise, the two-round protocol would require all replicas to
be notified before the new information can affect future read
requests.

\subsection{Extensions}
\label{ssec:conit-extensions}
One can imagine various ways that the conit model can be augmented
with additional capabilities. These topics are outside the scope of
this memo but offered for future consideration.

\paragraph{Dynamic bounds}
We imagine dynamically changing error bounds automatically in response
to operational factors. For example, if the network is badly
congested, the application may temporarily relax its error
bounds. Returning to the VLAT example in
Section~\ref{ssec:communication-and-safety}, heavy smoke may cause an
application to relax the real-time staleness bounds for information
about firefighters' locations on the ground. Correspondingly, the
application may enforce a wider margin for authorizing VLAT drops,
requiring the location estimates to be an even greater distance
outside the drop zone to compensate for the increased
uncertainty. This can resolve the discontinuity highlighted in that
section, where poor network performance might require grounding VLATs
to enforce an overly rigid safety policy that cannot be adjusted for
ground conditions.

Because real-time staleness and order error are bounded by pull-based
anti-entropy, the user can dynamically change the error bounds for
each access. However, numerical error is bounded by a push-based
approach that requires every process to track all other processes'
error bounds. One might follow Golding's approach
\cite{1992:golding-thesis} to extend the model with dynamic group
membership and provide a consensus mechanism for adjusting numerical
error bounds.

\paragraph{Dynamic conits}
The framework we have described above assumes the set of conits is
fixed in advance. Besides tuning bounds dynamically, we can imagine
situations where new conits need to be created on-the-fly. For
instance, data related to a new wildfire that has emerged may require
forming new conits to set consistency bounds.

Donkervliet's master's thesis \cite{dyconits} explored the subject of
dynamic conit creation in the context of massive multiplayer online
games, particularly Minecraft. In that work, new conits may be
associated with newly encountered objects in an area, and their
consistency bounds tuned as the user approaches them, exploiting a
form of locality to allocate network resources for information the
where inconsistency would most readily be perceived by the
player. Adapting their \emph{dyconits} (dynamic conits) framework to
the wide-area tactical environment may be worthwhile. It is notable
that games like Minecraft, where players navigate three-dimensional
environments and communicate over a network with sometimes perceptible
delays, some similarities with real-world environments, such as the
fact nearby users are likely to share an interest in the same conits.

\paragraph{Interaction with the Network}
We mentioned in Section~\ref{sssec:allocation-of-network-resource} our
expectation of a tighter, more complex interaction between the network
and application layers in this environment because of the need to
optimize scarce network resources. Because conits allow quantifying
divergence, and therefore the relative importance of an update, one
way this might be realized is by making the network
conit-aware. Network packets, or DTN bundles \cite{2021:intro-dtn},
could be specially marked as containing database updates alongside any
metadata such as the weight of the update to various conits. This
information could then be used by the network for quality-of-service
purposes.

Such usage may run contrary to a general wisdom that networking
protocols should be agnostic to the content of a message---routers for
example should only inspect IP packet headers but not the data
payload. This sort of usage may be justified in our setting because of
a heightened requirement to optimize network resources, potentially
at the cost of blurring the line between the network and application
layers.

Modifying a network protocol to optimize a particular middleware or
application is not a lightweight task, particularly since network
drivers are often embedded into an operating system kernel or into
hardware. Software-defined networking \cite{2016:sdn-battlefield}, a
trend that broadly raises network protocols to the level of ordinary
software development, is likely to be highly useful for this kind of
experimentation. Using a language such as P4 \cite{2014:p4} to
implement a conit-aware extension of delay-tolerant networking
protocols, for instance building on work by Ta et
al. \cite{2023:towards-sdn-dtn}, would offer the ability to prototype
designs without needing to design special-purpose hardware or replace
low-level drivers.

\section{Conclusion}
\label{sec:conclusion}
The increasing severity of wildfires and other natural disasters has
underscored the need for more advanced and reliable communication
systems for first responders. Modern tools like the Team Awareness Kit
(TAK) for situational awareness at the edge, as well as more
data-intensive centralized processes like NASA's Fire Information for
Resource Management System (FIRMS), have demonstrated the need and the
utility of large-scale complex systems for collecting, processing, and
distributing data among agents operating in adverse environments.
Traditional communication models, designed for more stable
environments, cannot necessarily meet the demands of such dynamic and
critical scenarios.

At a low level, the challenges of these environments can be addressed
through innovations in hardware such as mesh radios operating with
protocols optimized for mobile ad-hoc and disruption-heavy
networks. However, these non-traditional network architectures and
extreme operational conditions raise higher-level questions about how
to design distributed applications that communicate over these
networks. We explored how applications that rely on strong memory
consistency models, such as linearizability or sequential consistency,
are not a good fit for this sort of use case. This implication
stems largely from the locality principle in Section
\ref{ssec:communication-patterns}, which suggests that the quality of
communication between distributed agents---whether measured by message
latency, packet loss, or some other metric---is strongly influenced by
the geographical distance between them.

Strong consistency models are well-suited to scenarios where a
centralized database can be accessed through a small number of
dedicated servers, but locality suggests that agents at the tactical
edge will face difficulty maintaining communication with central
servers. Alternatively, for resilience and efficiency, multiple
replicas of a shared database can be maintained and deployed at
strategic locations in the network. However, the high coordination
overhead required to keep these replicas consistent with respect to
strong memory models is prohibitive for the networks under
consideration. We concluded that weaker consistency models are called
for in these settings.

Brewer's CAP theorem, a cornerstone result in distributed systems
theory, seemingly poses a major challenge when strong consistency is
unattainable. A simplistic interpretation of the theorem suggests that
when strong consistency is sacrificed in favor of system performance,
system designers are left with little control over the relative
consistency between different replicas of common data. This presents
an uncomfortable dilemma, because the appreciable safety concerns in
disaster response environments demand control over the consistency of
shared information. This is because a common operating picture is a
prerequisite to effective coordination between agents. The CAP theorem
seems to suggest that the application designer is stuck between a rock
and a hard place.

Fortunately, the CAP theorem is not as prohibitive as it may seem. The
continuous consistency framework presented in Section
\ref{sec:continuous-consistency}---though it guarantees neither the
`C' nor the `A' in the CAP theorem---presents a way through this
impasse. By formally quantifying the divergence between replicas with
respect to units of consistency, and then providing efficient
mechanisms for estimating this divergence using only local
information, applications can track the relative consistency of
distributed replicas with respect to different metrics and react
intelligently to these values. The framework we presented is dynamic,
providing ways for applications to adjust their position along the
spectrum between entirely favoring consistency and entirely favoring
system availability. How best to exploit these mechanisms, such as
designing policies that automatically tune the application based on
observed system performance, remains an exciting and largely
unexplored topic that will benefit from future work along theoretical
and applied fronts.

In conclusion, we have given a broad overview of the key challenges in
distributed systems in the context of natural disaster environments,
with a particular focus on memory consistency in contexts where the
network is unreliable and message-passing is subject to significant
delays. This content provides a foundation for building resilient,
high-performance systems tailored to the needs of disaster response in
the $21^\textrm{st}$ century.

\section*{Bibliography}\label{bibliography}
\addcontentsline{toc}{section}{Bibliography}

\bibliographystyle{abbrv}
\bibliography{bibliography}
\end{document}

%%% Local Variables:
%%% mode: LaTeX
%%% TeX-master: t
%%% End:

% LocalWords:  th Wi Fi hoc et IoBT al Kshemkalyani Singhal DECT pgf
% LocalWords:  Shivaratri Lamport's mpEx recv Ahamad RSM AE Minecraft
% LocalWords:  Donkervliet's dyconits
