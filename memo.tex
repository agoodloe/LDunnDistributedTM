% !TeX document-id = {beb7ced9-b3cd-42b2-b16a-3ed3c633a1d9}
\documentclass[]             % options: RDPonly, coveronly, nocover
{NASA}                       %   plus standard article class options
%\DeclareRobustCommand{\mmodels}{\mathrel{|}\joinrel\Relbar}

\usepackage[utf8]{inputenc}
\usepackage{setspace}
\usepackage{csquotes}
\usepackage{hyperref}
\usepackage{amsmath, amssymb, amscd, amsthm, amsfonts}
\usepackage{mathtools}
\usepackage{graphicx}
\usepackage{hyperref}
\usepackage{amsthm}
\usepackage[english]{babel}
\usepackage{stmaryrd}
\usepackage{proof}
\usepackage{tikz-cd}
\tikzcdset{scale cd/.style={every label/.append style={scale=#1},
    cells={nodes={scale=#1}}}}
% Added for subfigures
\usepackage{caption}
\usepackage{subcaption}
\usepackage{afterpage}
\usepackage{comment}
\usepackage{rotating}%sidewaysfigure
\usepackage{pdflscape}%alt to sidewaysfigure

\newtheorem{theorem}{Theorem}[section]
\newtheorem{corollary}[theorem]{Corollary}
\newtheorem{lemma}[theorem]{Lemma}
\theoremstyle{definition}
\newtheorem{example}[theorem]{Example}
\newtheorem{definition}[theorem]{Definition}
\include{macros.tex}

% Globally redefine pgfpicture to use \Large fonts
\let\origpgfpicture=\pgfpicture
\def\pgfpicture{\origpgfpicture\small}

% Try loading this package to prevent so much hyphenation
% as recommended by https://stackoverflow.com/questions/1609837/latex-breaking-up-too-many-words
\usepackage{microtype}

\title{Distributed Systems Challenges in Wildland Firefighting Environments}

\author{Lawrence Dunn and Alwyn E. Goodloe}

\AuthorAffiliation{Lawrence Dunn \\ Department of Computer and Information
  Science \\ University of Pennsylvania \\ Philadelphia, PA \\ Alwyn Goodloe\\                                          % for cover page
  NASA Langley Research Center, Hampton, Virginia
}
\NasaCenter{Langley Research Center\\Hampton, Virginia 23681-2199}
\Type{TM}                    % TM, TP, CR, CP, SP, TT
\SubjectCategory{64}         % two digit number
\LNumber{XXXXX}              % Langley L-number
\Number{XXXXXX}              % Report number
\Month{12}                   % two digit number
\Year{2022}                  % four digit number
\SubjectTerms{Distributed Systems, Formal Methods, Logic, }     % 4-5 comma separated words
\Pages{46}                   % all the pages from the front to back covers
\DatesCovered{}              % 10/2000--9/2002
\ContractNumber{}            % NAS1-12345
\GrantNumber{}               % NAG1-1234
\ProgramElementNumber{}
\ProjectNumber{}             % NCC1-123
\TaskNumber{}                % Task 123
\WorkUnitNumber{}            % 123-45-67-89
\SupplementaryNotes{}
\Acknowledgment{The work was conducted during a summer internship at the NASA Langley Research Center in the Safety-Critical Avionics Systems Branch focusing on distributed computing  issues arising in the Safety Demonstrator challenge in the NASA Aeronautics System Wide Safety (SWS) program.}

%Added for Pandoc
\providecommand{\tightlist}{%
  \setlength{\itemsep}{0pt}\setlength{\parskip}{0pt}}


\abstract{The System Wide Safety (SWS) program has been investigating
  how crewed and uncrewed aircraft can safely operate in shared
   airspace. Enforcing safety requirements for distributed agents
  requires coordination by passing messages over a communication
  network. Unfortunately, the operational environment will not admit
  reliable high-bandwidth communication between all agents,
  introducing theoretical and practical obstructions to global
  consistency that make it more difficult to maintain safety-related
  invariants. Taking disaster response scenarios, particularly
  wildfire suppression, as a motivating use case, this self-contained
  memo discusses some of the distributed systems challenges involved
  in system-wide safety through a pragmatic lens. We survey topics
  ranging from consistency models and network architectures to data
  replication and data fusion, in each case focusing on the practical
  relevance of topics in the literature to the sorts of scenarios and
  challenges we expect from our use case.  }

\begin{document}
\newpage
\setcounter{tocdepth}{2}
\tableofcontents
\newpage

\section{Introduction}
\label{sec:introduction}
Civil aviation has traditionally focused primarily on the efficient
and safe transportation of people and goods via the airspace. Despite
inherent risks, the application of sound engineering practices and
conservative operating procedures has made flying the safest mode of
transport today. Now, the industry's strong requirements for safety
make it difficult to integrate unmanned vehicles into the airspace,
accomodate emerging applications, and keep pace with significant
recent growth in commercial aviation. To that end, the NASA
Aeronautics' Airspace Operations and Safety Program (AOSP) has
initiated the System Wide Safety (SWS) project to investigate
technologies and methods to enable crewed and uncrewed aircraft to
safely operate in shared airspace.

This memo surveys topics in computing that are relevant to maintaining
system-wide safety across large, physically distributed data and
communication systems. It is intended to be self-contained and
accessible to a technical audience without a deep background in
distributed systems. Our primary motivating use cases come from civil
emergency response scenarios, especially wildfire suppression and
hurricane relief. These were chosen primarily for three
reasons. First, improved technology for wildfire suppression,
especially related to communications and data sharing, is frequently
cited as a national priority \cite{pcast2023}.  Second, the rules for
operating in the US national airspace are typically relaxed during
natural disasters and relief efforts, so this is a suitable setting
for testing new technologies. Finally, this setting is an excellent
microcosm for the sorts of general challenges faced by other,
non-emergency applications.

One theme visited throughout this document is \emph{continuity} in the
sense considered by topology.\footnote{For an introductory textbook
  see \cite{mendelson2012introduction}.}  The systems we examine must
function under harsh operating conditions that limit their
performance. For example, wireless communication is less reliable
during severe weather. To design a system whose behavior and
performance is predictable---this is clearly a prerequisite for
safety---it must flexible enough to perform reliably under a wide
range of adverse conditions. In other words, the behavior of a safe
system should in some sense be a \emph{continuous} function of its
inputs and environment. Achieving this sort of robust design is
challenging because distributed systems designers must navigate
delicate tradeoffs between competing objectives. At a high level,
these tradeoffs stem from an inherent tension between designing a
system that handles user requests quickly and one that prioritizes
maintaining a strong level of global consistency between system
components.

The key insight the reader should take away from this document is that
achieving system-wide safety is not solely a matter of improving
communications hardware and physical infrastructure. It is also in
large part a computer science and software problem concerned with the
high-level applications that execute on top of the communications
infrastructure. These software systems must be engineered to maintain
a common operating picture between distributed users while making
efficient use of networking and compute resources in a dynamic and
even adversarial environment.

\subsection{Summaries of the sections}
\label{ssec:summaries-of-the-sections}
Section \ref{sec:disaster-response} opens with a practical overview of
disaster response and some of the computing challenges encountered in
this setting. Real-world examples from disaster response scenarios are
presented that demonstrate the role of distributed systems principles
in achieving system-wide safety.

Section \ref{sec:background} summarizes fundamental concepts and
mechanisms used in distributed systems, culminating in the classic
``CAP'' theorem for both the linearizable and sequential consistency
models (Theorems \ref{thm:cap} and \ref{thm:cap-sequential}). CAP is
considered a ``negative'' result, as it proves that a distributed
system cannot guarantee strong consistency and remain available to
users when the communication network is disconnected. The practical
implication of the theorem is that agents in emergency response
environments will always operate with incomplete information about the
global system.  While the CAP theorem is often presented as a kind of
unfortunate prohibition, it merely highlights a general kind of
tradeoff. Furthermore, real-world systems often exhibit a kind of
``locality'' that mitigates some of the constraints implied by the CAP
theorem.

Motivated by the CAP theorem, Section \ref{sec:continuous-consistency}
describes a hypothetical application suitable for networks with
frequent disruptions: a data replication service built on the theory
of \emph{conits} (short for ``consistency unit'') developed by Yu and
Vahdat \cite{2002tact}. This framework provides a \emph{continuous}
consistency model that balances the competing objects of consistency
and availability in a quantifiable and controllable way. The idea is
that applications can tolerate some level of inconsistency between
replicas of a data item, as long as it the divergence remains less
than some defined upper bound. A conit-based system allows
applications to define units of replicated state of interest, enforce
policies limiting inconsistency between their replicas, and adapt
these policies dynamically. This sort of approach can meet the strict
requirements of safety-related systems while tolerating the adverse
environments and real-world limitations of the environment.

We conclude in Section \ref{sec:conclusion} by recapping some of the
main themes in this document and highlighting areas for further
investigation. Ultimately, building distributed systems requires
design decisions tailored to the environment and application. We
expect that many of these decisions will involve a combination of
simulation and real-world testing.

\section{Coordination Challenges in Disaster Response}
\label{sec:disaster-response}
This section explores key aspects of disaster response, particularly
firefighting, that shape the focus of this document. We highlight how
real-world environments create fundamental challenges that require
solutions based on distributed computing principles. Even with the
best communications technologies, core issues arise when distributed
agents need to coordinate their actions across wide areas.

Disaster response settings, like wildfire suppression or hurricane
relief, are marked by systemic communications challenges. A 2023
report by the President’s Council of Advisors on Science and
Technology (PCAST) highlights the need to address ``the
vulnerabilities and shortfalls in wildland firefighter communications,
connectivity, and technology interoperability'' as its top
recommendation for wildland firefighting modernization
\cite{pcast2023}. Many of these vulnerabilities and shortfalls stem
from factors inherent to disaster response: remote locations,
difficult terrain, damaged infrastructure, harsh weather, and limited
power, to name a few.

Field agents often face high message loss, distorted signals, and
unpredictable delays in communication. A cautious approach suggests
preparing for the worst performance at critical times---network
failures often coincide with the sorts of conditions that demand
urgent, reliable contact. Disasters often damage and degrade the
communications infrastructure, which is accompanied by a sudden surge
in user demand that can overwhelm a network completely. This was
starkly evident in the immediate aftermath of the September
$11^\textrm{th}$ attacks, when sudden user demand and severed trunk
cables crippled New York public and private communication networks,
including dedicated networks for first responders
\cite{2011:Reardon}. These failures later became the impetus for the
creation of FirstNet \cite{2021:firstnet, 2021:firstnet2}, a national
public safety broadband network (NPSBN).

Unreliable networks make coordinating distributed agents a significant
challenge. Coherent decision-making and coordinated action require
consistency, meaning agreement on the data shared between agents. We
define consistency more precisely in Section \ref{sec:background}, but
the idea is clear: it is critical for everyone to agree which
firetrucks should respond to which areas, where helicopters should
land, which tasks should be prioritized, or which radio frequencies
are in use. Achieving stronger standards for consistency requires
sending more information in a shorter time frame, which places a
heavier strain on the network. When a communications link is slow,
system components may have to pause and wait before agreement can be
reached, diminishing the efficacy of the system. To avoid waiting in
such scenarios, standards for consistency may have to be relaxed,
meaning distributed agents have less agreement, which comes with its
own challenges. In sum, there is an inherent tension between
consistency and latency (delay) of action.

\subsection{Communication and User Safety}
\label{ssec:communication-and-safety}
We turn our attention to the implications of the consistency/latency
tradeoff from a user safety perspective. Operational safety depends on
agents quickly gathering and responding to information about their
environment. This information is relayed through communication
networks, so poor communication becomes a safety problem. When
communication falters, agents face a difficult choice: either wait for
more information before acting, or act now with incomplete
knowledge. Both inaction and uninformed action carry risks. This
dilemma is closely related to a fundamental computer science principle
known as the safety/liveness tradeoff.

\begin{figure}
  \centering
  \includegraphics[scale=0.4]{images/dc10.jpg}
  \caption{A DC-10 airtanker, rated for 9,400 gallons, drops retardant
    above Greer, Arizona. Image source: Kari Greer/US Forest Service.}\label{fig:airtanker}
\end{figure}
% TODO: How to cite picture?
% https://www.flickr.com/photos/apachesitgreavesnf/5837741382
% Also appears at https://www.nifc.gov/resources/aircraft/airtankers

\begin{figure}
  \centering
  \includegraphics[scale=0.15]{images/forestfire-videox-scaled.jpg}
  \caption{Screenshot of a firefighter using ATAK, where the left
    panel shows a map and the right is a video stream from an air
    vehicle. Image source: Andreas ``AJ'' Johansson}\label{fig:atak}
\end{figure}
% TODO: How to cite picture?
%https://www.civtak.org/2020/08/04/tak-used-in-ca-firefighting-w-aircraft-video/

For example, consider the use of firefighting airtankers, particularly
Very Large Airtankers (VLATs), which can carry over 8,000 gallons of
water or fire retardant \cite{2019:airtankerops}
(Figure \ref{fig:airtanker}). The largest VLATs can drop more than
20,000 gallons---about 170,000 pounds' worth---in a single pass. In
the U.S., these drops are typically made from just 250 feet above the
tree canopy \cite{2019:airtankerops}, and sometimes lower in
practice. This sort of maneuver can easily crush a ground vehicle
\cite{2019:stickney}. In 2018, a firefighter was killed, and three
others were injured, when an unexpectedly powerful drop from a Boeing
747-400 Supertanker knocked down an 87-foot Douglas Fir tree
\cite{2018:calfire}.

Improving firefighter communications can be expected to lead to better
safety outcomes. One such improvement is the through the use of
applications like ATAK---the Android Team Awareness Kit, developed by
the U.S. military in 2010 and later released in a civilian
version. Wildland firefighters are increasingly using ATAK, extended
with aftermarket plugins, on ordinary cell phones to coordinate their
activities in the field (Figure \ref{fig:atak}). A key application of
this tool could be tracking the real-time GPS coordinates of
firefighters for safety monitoring.

Given the risks of VLAT drops, a seemingly reasonable safety measure
might be to disallow drops unless a VLAT's computers have up-to-date
information about the location of ground personnel. Unfortunately,
system-wide safety is not so easily achieved, as the proposed measure
is precisely the sort of thing subject to the safety/liveness
tradeoff. Here, it is important to recognize a linguistic nuance: in
the context of distributed systems, ``safety'' refers to a specific
type of system property; the concept in not inherently related to the
safety of people. A \emph{safety} property is a prohibition that stops
a system from taking an action that might be ``bad'' in some way. Here
is an exemplary safety property for the example above:
\begin{quote}
  $\Psafe$: Ground agents are known to be at least
  100 feet outside the drop zone, and this information is current to
  within 30 seconds, or airtankers will not perform a drop.
\end{quote}
By contrast, a \emph{liveness} property demands some kind of action
from a system, usually one that is ``good'' in some way. A
characteristic of liveness properties is that they place an upper
bound on the allowable delay of something. An exemplary liveness
property for our scenario might be the following:
\begin{quote}
  $\Plive$: A VLAT on the ground will take off and
  perform a drop within 20 minutes of receiving a request from an
  incident commander. \footnote{The Chief of Flight Operations for Cal
    Fire cited 20 minutes as an upper bound on the response time for
    aerial firefighting units within designated responsibility areas
    in an interview with PBS \cite{2021:aerialfirefighting}.}
\end{quote} Note that $\Plive$
is a liveness property, not a safety property in the narrow technical
sense, but it impacts human safety: it might be critical for VLATs to
perform drops quickly if a wildfire is threatening the safety of
ground personnel.

Safety and liveness are frequently dual mandates that cannot be
guaranteed simultaneously. Such is the case in our example: though
$\Psafe$ and $\Plive$ are both
desirable, certain situations will force policymakers to prefer one
over the other. Consider the fact that the wildland firefighting
environment is frequently GPS-denied: heavy smoke, multipath effects,
and so on can easily prevent a consumer-grade cellphone from obtaining
reliable GPS coordinates. Additionally, factors like a damaged radio
tower or environmental obstructions like a tall mountain can prevent
communications between the air and ground. Such conditions would
prevent a VLAT's computers from knowing the locations of ground
agents, which immediately presents a dilemma: should the crew proceed
without knowing the locations of ground personnel, maintaining
$\Plive$ at the cost of $\Psafe$,
or should it be cautious and wait for more information, maintaining
$\Psafe$ at the cost of $\Plive$?
There is no simple answer, with either choice presenting a downside
with respect to the broader goal of system-wide safety.

Besides the safety/liveness tradeoff, the previous example exhibits
two other themes important in distributed systems, both of which will
be explored further in this document. The first is the
\emph{epistomological} nature---concerned with what information is
\emph{known} by \emph{whom}---of reasoning about distributed
systems. This aspect is reflected in wording of
$\Psafe$ in VLAT example: Ground agents are known
(by the VLAT's computers) to be outside of a dangerous area. This
situation requires a deeper and more sophisticated analysis than one
simply considering what is true, but not necessarily
known. Mathematically, the logic of distributed agents is not the
ordinary propositional logic but the modal logic S5, which extends
propositional logic with additional axioms governing
knowledge.\footnote{The application of S5 to reason about distributed
  systems is the topic of \cite{kshemkalyani_singhal_2008}, Chapter
  8.} Distributing knowledge requires communication between agents
over a period of time over the network, which is not instantaneous and
reliable, and it is from these imperfections that the safety/liveness
tradeoff arises.

The second aspect exhibited above, albeit negatively, is that of
\emph{continuity}. A continuous system can flexibly adopt to its
environment, but a discontinuous system is rigid and may exhibit
suddenly different behavior in response to only small changes in the
environment. The properties $\Psafe$ and
$\Plive$ exhibit a stark lack of continuity because
they are inflexible, all-or-nothing propositions. Suppose that agents
are known to be $500$ feet outside the drop zone, but the information
is only current to within 31 seconds---this extra second technically
violates $\Psafe$, though it should be inferrable
that the ground agents are well away from danger. In particular, this
example highlights that system-wide safety is more of a quantitative
concept than a Boolean (true-or-false) one. A distributed system in a
network-challenged environment should exhibit smoothly varying
properties in response to its inputs, and ideally allow ``tuning'' the
system's properties for the particulars of its environment at any
moment. The technical aspects of this theme are the focus of Section
\ref{sec:continuous-consistency}.

\subsection{Communication Patterns in the Field}
\label{ssec:communication-patterns}
We now consider some of the communication patterns that occur in
wildland firefighting. Readers may be surprised to learn that the
state of the art is somewhat primitive, largely due to the sparse
permanent communications infrastructure that exists in this
setting. This makes wildfires an interesting and generalizable example
for other kinds of civil disaster environments where the network is
unreliable.

One important concept to draw attention to is a kind of ``geospatial
locality of reference'' that system designers should consider. By
this, we mean the concomitance of two observations which, while not
guaranteed rules, are approximately true in many circumstances. The
first observation states that nearby agents have aligned interests:
\begin{quote}
  $\textbf{O}_1$: Agents with the most urgent need to coordinate their
  actions will usually be located closer together and require similar
  kinds of information.
\end{quote}
The second observation states that nearby agents have more reliable
communications:
\begin{quote}
  $\textbf{O}_2$: Agents that are located closer together generally
  enjoy more reliable communications between them than agents that are
  far apart. Conversely, information that travels long distances tends to
  be delayed or degrade in quality.
\end{quote}

These related observations are what is meant by simply the
``locality'' principle. Locality is a crucial factor to analyze
because, as presented in Section \ref{sec:background}, there are major
theoretical and practical limits to how well agents can coordinate
\emph{globally}, meaning with all agents knowing and agreeing on
everything. To the extent the system exhibits locality, coordination
can be achieved using more efficient short-range communication than
less efficient long-range communication. Here, ``efficient'' should be
read broadly, measured with respect to things like battery life,
message delay, reliability, cost-effectiveness, equipment weight, and
so on. This raises the question of how to most efficiently utilize
network resources to achieve adequate levels of consistency. This
question is revisited in Section \ref{sec:continuous-consistency}.

\subsubsection{Communication on the Ground}
\label{sssec:ground-communication}
In the field, communication between firefighters and other agents is
often facilitated by handheld (analog) land-mobile radio (LMR). These
radios are inherently limited in their battery life, bandwidth,
effective range, and ability to work around environmental factors like
foliage and smoke.

As an alternative to using a radio, it is common for wildland
firefighters in the field simply to shout commands and notifications
to nearby personnel. This exhibits the locality principle: a
substantial amount of communication occurs directly between nearby
firefighters working on closely related tasks that can communicate
without network infrastructure. In a future environment where agents
might be equipped with body-worn sensors and or even some form of
heads-up display (HUD), this sort of low-range local communication
might be facilitated by relatively inexpensive, low-power technologies
such as Bluetooth, without the need for more sophisticated (and heavy)
equipment.

Communication over a long distance requires infrastructural support,
such as the use of cell towers and repeater stations. Typically,
disaster response environments have scarce permanent infrastructure:
in a wildland fire setting, perhaps a few repeaters mounted to a
nearby watch tower. Ad-hoc infrastructure, such as Cells On Wheels
(COWs) or Cells on Light Trucks (COLTs)---i.e. portable cellular
towers---can sometimes be deployed on an as-needed basis if the
location allows for it. Similar kinds of equipment can also be mounted
to backpacks and carried into the field by specially-trained users. A
common issue is making sure that all equipment is properly configured,
for instance that radios are listening on the correct
frequencies. Configuration is especially critical when different
agencies and groups need to interoperate---another problem highlighted
during the September $11^\textrm{th}$ attacks.

\begin{figure}[t]
  \centering
  \includegraphics[scale=0.085]{images/ironside.jpg}
  \caption{The Ironside Mountain lookout and radio repeater station,
    shown here with protective foil on August $10^\textrm{th}$, 2015
    during the 2015 River Complex fire. This particular fire burned
    77,077 acres over 77 days.}
  \label{fig:ironside}
\end{figure}
% TODO: How to cite picture?
%https://web.archive.org/web/20150923190323/http://inciweb.nwcg.gov/incident/photograph/4431/44/45122/

Use of centralized infrastructure comes with the potential for
widespread failure when the infrastructure breaks down. For example,
in California, the Ironside Mountain lookout/repeater station (seen in
Figure \ref{fig:ironside}) was destroyed during the 2021 Monument
Fire, which burned approximately 223,124 acres over 88 days
\cite{2021:monumentfire}. The Ironside Mountain station had strategic
importance, being located on a tall ridge. According to a video blog
from a volunteer firefighter involved in the incident, its loss
prevented communication between operators on different sides of the
ridge, in networking parlance creating a \emph{partition} that lasted
until crews could ascend the ridge to deploy a temporary station:
\begin{quote}
  ``When {[}the Ironside Mountain lookout station{]} burned down the
  radio repeater went with it. And so communications were lost across
  the fire\ldots{} one side of the fire couldn't talk to the other
  side\ldots.  So it was kind of a critical job to get that road
  cleared so that the radio crews could go back up there and set up a
  temporary radio tower.'' \cite{2022:mechfire}% See also https://web.archive.org/web/20220809061927/https://www.youtube.com/watch?v=4F2dDKMgAME
\end{quote}
A scenario where communication between two groups is completely
severed is exactly the sort of thing considered by the CAP theorem in
Section \ref{sec:background}.

\paragraph{Ground vehicles}
Large numbers of ground vehicles---sometimes on the order of 100
during a major response---are involved in wildfire
suppression. Besides various types of firetrucks, bulldozers and
similar vehicles are commonly used to control the landscape and
perimeter of the fire. An advantage of vehicles is that they can carry
heavier and higher-power communications equipment than a human. For
instance, a vehicle could be equipped with a BGAN or VSAT satellite
terminal to maintain a high-bandwidth connection back to a central
location. Additionally equipping the vehicle with something like a
Wi-Fi or cellular base station using the satellite connection as
backhaul would let the vehicle act as a bridge between agents in the
field and central coordinators such as incident commanders or 911
dispatchers.

\subsubsection{Communication in the Air}
Wildland firefighting increasingly involves the use of helicopters and
fixed wing aircraft. Civil aviation has traditionally employed simpler
communication patterns than this use case demands. For instance,
aircraft equipped with Automatic Dependent Surveillance-Broadcast
(ADS-B) monitor their location using GPS and periodically broadcast
this information to air traffic controllers and nearby aircraft. This
sort of scheme has worked well in traditional applications, where
pilots typically only monitor the general locations of a few nearby
aircraft. The locality principle is exhibited here, too: aircraft have
the highest need to coordinate when they are physically close and
therefore in range of each other's ADS-B broadcasts.

In our setting, a large number or aircraft, easily on the order of 10 or
more, may need to operate in a small area, near complex terrain,
during adverse conditions, often at low altitude. In other words, the
demands are many and the margins for error are small. This sort of use
case calls for more sophisticated coordination schemes between
airborne and ground-based elements than solutions like ADS-B provide
by themselves.

As aircraft generally have better line-of-site to ground crews than
ground crews have to each other, firefighters sometimes relay messages
to air-based units over the radio, which in turn is relayed back down
to other ground units. The locality principle comes into play for this
sort of message relaying scheme, but in the negative direction:
relaying allows knowledge to travel farther but requires more resources and effort,
and the extended reach comes at the cost of introducing delays and
possible degradation of message quality, as in the classic game of
``telephone.'' Hence, this mode of communication has generally been reserved for
more critical information.

The Communications Program of the Civil Air Patrol (a civilian
auxiliary of the U.S. Air Force) is sometimes deployed to provide
communications for firefighters on the ground using airplane-mounted
radio repeaters. Air-based repeaters are better than the ``telephone''
scheme in the previous paragraph as they do not require as much human
intervention to receive and re-transmit information. That is, this
form of relaying is more \emph{transparent}. In this future, this sort
of service could be provided autonomously by portable infrastructure
futuremounted to unmanned aerial vehicles (UAVs), which might perform
additional functions such as tracking the fire perimeter.

In future environments, we envision resilient networks formed from
heterogeneous collections of smaller networks, incorporating various
communication technologies such as digital radios, Wi-Fi, 4G/LTE, and
satellite communications. Communications in the field may incorporate
aspects of mesh networks and mobile ad-hoc networks (MANETs). The
infrastructure will be comprised of both permanent infrastructure and
temporary equipment carried into the field by responders, vehicles on
the ground or in the air. Given the environmental challenges, we
assume that two agents will often only have intermittent end-to-end
connectivity, if any. Facilitating communication through such a
dynamic and chaotic mobile network calls for a disruption-tolerant
networking (DTN) architecture, which provides a custody transfer and
store-carry-forward model that is resilient to disruption
\cite{2021:intro-dtn}. The exact form of such a network remains an
open question for future investigation.

\subsection{Data Collection and Processing}
\label{ssec:data-collection}
Perhaps the most universally acknowledged expectation for future
disaster response environments is a heavy reliance on data
gathered from both humans and sensors. Besides improvements to
communications that facilitate information sharing, we expect advances
in machine intelligence to greatly influence how this data is
handled.

Agents in disaster response environments will be both producers and
consumers of data, and this data will need to processed by humans and
machines in ways that agents can readily make sense of to support
their decision-making. Just some of the possible sources and types of
pertinent data are as follows:
\begin{itemize}
\item Free-form communication, especially real-time or recorded voice messages
  broadcast to many agents at once, which may need to be processed by
  machines to extract the most pertinent information into a more
  actionable format
\item The exact or estimated location of victims, firefighters,
  vehicles, hazards, and so on displayed on applications like ATAK
\item Medical information gathered from victims, perhaps stored in and
  collected from electronic triage tags \cite{2009:triagetag}
\item Data about current and predicted fire behavior gathered from
  systems like the Fire Integrated Real-time Intelligence System
  (FIRIS) or NASA's Fire Information for Resource Management System
  (FIRMS)
\item Weather data from the National Weather Service
\item Topographic information about the terrain, highlighting for
  instance the location of rivers and roads that could form a fire
  control line
\item Planned escape routes, rendezvous points, safety zones, and
  landing zones
\item Availability and dispatching of assets, e.g.~ambulances,
  airtankers, or crews on standby, such as the prototype application
  considered by Monares et al. \cite{2011:monares}
\end{itemize}
In a perfect environment, such information would be shared with all
necessary agents in whole and instantly. In reality, agents will be
presented with information that is sometimes incomplete, out of date,
or contradictory---all problems that are further exacerbated by an
unreliable network. A competing concern is that the information
presented will be \emph{overcomplete}, filled with petty details that
distract agents from their important tasks.

In some ways, future systems for disaster response will bear
resemblence to future systems for warfighting, such as the conceptual
\emph{Internet of Battle Things} (IoBT) \cite{2016:iobt}. To quote
from that paper, agents ``under extreme cognitive and physical
stress'' will be subject to a highly dynamic and dangerous
environment. Various kinds of technology will assist humans by
providing data to support sensemaking, but a contraindicating concern
will be flooding agents with a ``massive, complex, confusing, and
potentially deceptive ocean of information.'' To avoid ``swimming in
sensors and drowning in data'' \cite{2010:magnuson}:
\begin{quote}
``Humans seek well-formed, reasonably-sized, essential information
  that is highly relevant to their cognitive needs, such as effective
  indications and warnings that pertain to their current situation and
  mission.'' \cite{2016:iobt}
\end{quote}

We propose that researchers in field of Human-Computer Interaction
(HCI) should take up the question of how public safety agents under
stress can process and respond to the flood of information they may
face as public safety systems become more complex. HCI has been
defined as follows:
\begin{quote}
  ``A subfield within computer science concerned with the study of the
  interaction between people (users) and computers and the design,
  evaluation and implementation of user interfaces for computer
  systems that are receptive to the user's needs and habits.'' \cite{2009:hci-definition}
\end{quote}
HCI research offers insights into how interfaces should be structured
to avoid cognitive overload and facilitate intuitive control without
distracting users. As emergency control becomes increasingly
data-driven, particularly in centralized hubs like dispatch centers
that aggregate diverse streams of information, the challenge of
ensuring that users can interact effectively with these systems will
become increasingly important.

\subsubsection{Adversarial Behavior}
One feature of the Internet of Battle Things worth highlighting is
``the adversarial nature of the environment.'' This feature is common
also to disaster environments, whether resulting incidentally from
``fog of war'' effects or deliberately caused by malicious actors
seeking to exploit a civil disaster. Section
\ref{ssec:communication-patterns} cited a real-world example of a
critical communications station destroyed by wildfire, perhaps
comparable to an attack by enemy forces.

There is a growing trend in disaster response to rely on
``crowdsourced'' information, where public safety officials process
reports from the general public over non-traditional channels like
social media. However, a significant vulnerability of crowdsourcing
information is the potential for confusing of contradictory reports,
which can resemble intentional deception. Rumors frequently plague
disaster relief environments, which are quite susceptible to
misinformation. For instance, during Hurricane Harvey in 2017, there
were unconfirmed rumors of shots being fired at volunteer rescuers
\cite{2017:cajun-navy-rumors}. Tracing reports back to their source is
often difficult. Even fully malicious activity like
``swatting''---placing a fake 911 call to cause a large police
response---is often observed in public safety. Whether misinformation
is spread with malicious intent or through well-meaning confusion, the
proliferation of false information in this chaotic environment can
have adversarial effects. This should be anticipated as part of a
careful approach to modernizing systems in this space.

\subsubsection{Allocation of Network Resources}
\label{sssec:allocation-of-network-resource}
Communications in disaster response environments might even be less
reliable than in the battlefield (setting aside offensive behavior
like signal jamming), requiring a greater emphasis on the preservation
of scarce network resources. For instance, a group of volunteer
firefighters would have fewer resources than a tactical military unit,
relying on commercial off-the-shelf (COTS) equipment rather than best
in class hardware like sophisticated handheld satellite links. High
bandwidth channels will often be in short supply, while adverse
conditions like inclement weather are assumed.

Given the heavy reliance on data and the scarcity of reliable
communication channels, we expect a complex interaction between the
high-level needs of distributed applications (e.g. an application for
sharing real time weather data) and low-level concerns about network
resources. This is because only the applications have enough
information to determine which data is the most important and must be
shared with whom first, while only the network-level protocols have
enough information and control to make prudent use of scarce network
availability.

There is a widely accepted wisdom in computing---the end-to-end
principle \cite{1984:end-to-end}---which suggests roughly that
applications should not make assumptions about the network, and that
the network should be relatively agnostic to high-level application
logic. However, in natural disaster environments where resources are
scarce and reliable communication is critical, these subsystems may
need to be more tightly integrated in how they influence each other to
achieve the best performance. This approach would not contravene the
end-to-end principle, but would involve carefully considering its
application in this relatively extreme context.

Consider, say 5 to 10 years in the future, a centralized data fusion
application that running in an edge data center.\footnote{An
  \emph{edge} data center is one located closer to a network's edge,
  nearer to users, to provide low-latency communications for
  time-sensitive applications. Edge centers support applications that
  require significant amounts of information processing---enough that
  the application must be hosted in a datacenter, where compute
  resources can be scaled dynamically, rather than colocated with
  users where resources are limited.} This application could detect
critical events like a fire crossing a control line (a phenomenon
called \emph{slopover}) and alert ground responders. It might also
warn responders who have strayed too far from an escape route or
safety zone. These are high-priority notifications, so it would be
worthwhile to allocate scarce network resources to convey them to the
relevant parties in real-time.

On the other hand, while it may be beneficial for each firefighter to
have real-time information about the location of every other
firefighter, this may not always be critical. If transmitting this
data strains the network, then perhaps only the general location of
other crews or nearby teams should be sent. If the network is
extremely constrained, communication may be restricted to only
information strictly relevant to preserving life to ensure this is
delivered swiftly and reliably. Thus, network allocation is a dynamic
calculation influenced both by the criticality of the information
(which is determined by the application logic) and the availability of
network resources at a particular location. Advanced systems should
provide mechanisms like Quality of Service (QoS) values to allow
prioritizing certain communication. Such mechanisms can be
incorporated into a control loop where applications generate feedback
that drives the decision-making process in lower-level parts of the
network. However, traditional QoS mechanisms may not be enough---even
the routing protocol of the network may need to be more specialized to
higher-level applications than in traditional environments.


\section{Introduction to Distributed Systems}
\label{sec:background}
In this section, we distill two core topics in the theory of
distributed systems: causality and timekeeping, along with shared
memory consistency.  Our discussion is primarily informed by the
manuscripts of Coulouris et al.  \cite{coulouris2005distributed} and
Kshemkalyani and Singhal \cite{kshemkalyani_singhal_2008}. We focus on
building applications relevant to the scenarios described in Section
\ref{sec:disaster-response}, aiming to highlight obstacles and
strategies for developing distributed systems that can endure the
delays and disruptions inherent to these communication-challenged
environments. Readers wishing for a condensed summary of the main
highlights may skip to Section \label{ssec:background-summary}.

At its core, a distributed system is a network of independent entities
working together to solve problems too complex for any one part to
tackle alone. From a bird’s-eye view, the systems we envision are
intricate and complex, made up of diverse, interconnected elements:
field agents like firefighters, their handheld devices, airborne and
ground vehicles loaded with communication and computing tools, swarms
of sensors and IoT devices, and so on. These decentralized components
operate alongside more centralized hubs: data fusion centers, incident
commanders, public safety answering points (PSAPs), and emergency
operations centers (EOCs). We imagine these components being woven
together by a patchwork of communication technologies ranging from
analog and digital radios to Bluetooth, Wi-Fi, LTE, 5G, satellite
communications, and ad-hoc mesh networks like
Meshtastic\footnote{The website of the
  Meshtastic project describes it as an ``open source, off-grid,
  decentralized, mesh network built to run on affordable, low-power
  devices''. See \url{https://meshtastic.org} or
  \url{https://github.com/meshtastic}.}, DECT-2020
NR\footnote{DECT-2020 NR, also called NR$^{+}$, is a non-cellular 5G
  standard intended for Internetof Things (IoT) operations. For a
  technical discussion see \cite{2022:dect-2020-nr}.}, and
others. Together, the systems form a dynamic mosaic of elements
cooperating to save lives and protect proprty.

Given the unpredictable nature of the environment and the locality
principle outlined in Section \ref{sec:disaster-response},
communication between edge components---such as field operators---and
centralized hubs is often inconsistent, sometimes available only
intermittently. As a result, information flow is subject to
appreciable delays compared to the timescale of critical events like a
fire shifting direction or a dangerous condition being detected. In
other words, the computing landscape is unmistakably
\emph{distributed}. Singhal and Shivaratri \cite{10.5555/562065}
define a distributed computing system as:
\begin{quote}
  ``A collection of computers that do not share common
  memory or a common physical clock, that communicate by message
  passing over a communication network, and where each computer has
  its own memory and runs its own operating system.''
\end{quote}
This stands in contrast to a centralized computing environment, where
processes can seamlessly share data through common memory, and memory
access times are considered negligible.

For our use cases, message-passing latencies are not only significant
but unpredictable and difficult to control. As a result, we can safely
assume that some parts of the wider system will not have
instantaneous, complete knowledge of every new piece of
information. Only a few components, if any, will be able to maintain a
global systemwide awareness. While deploying additional network
resources in the field—such as COWs (Cells on Wheels) and COLTs (Cells
on Light Trucks)—can help, the inherently distributed nature of the
environment cannot be fully overcome or abstracted away. This reality
must be embedded in the design of the software and networking
architecture itself. Typically, this manifests in a shared
``middleware'' layer to coordinate the numerous moving parts, ensuring
they function as a unified system.

The fragmented flow of information presents several challenges for
system designers. Foundationally, one of the primary computer science
problems is that unpredictable latencies make it difficult for
components to maintain a common understanding about the global
sequence of events. For similar reasons, it becomes challenging for
processes to synchronize and agree on shared values, such as the
current number of firetrucks available for dispatch. The remainder of
this section will delve into these issues with more technical depth,
while later sections will examine how some of these challenges can be
reflected in the middleware design.

\subsection{Physical Synchrony}
\label{ssec:physical-synchrony}
A lot of challenges in distributed computing could be
straightforwardly overcome if we assume that all participants have
instantaneous access to a common time base, i.e.  synchronized
clocks. Let us explore why fine-grained synchronization is not a
tenable assumption, at least not for all purposes.

Physical clocks, especially consumer-grade ones, suffer from
\emph{drift}, which is to say they do not all run at the same
rate. Experienced IT administrators will testify that clocks can also
be prone to misconfiguration. An incorrect date, time, timezone, or
daylight saving time policy setting is a common source of IT issues,
typically causing time-based security mechanisms like TLS
authentication to misbehave. Consider also that devices may spend a
long time sitting unpowered in storage without maintaining an
always-on clock. For these sorts of reasons, we would not want to rest
the integrity of a safety-related system on the assumption that a
numerous and diverse assortment of devices have precisely synchronized
internal clocks.

Clock drift can be corrected for using, for instance, signals from GPS
satellites, but as mentioned in Section \ref{sec:disaster-response},
civil disaster environments are frequently GPS-denied: factors like
mountainous terrain, heavy smoke, and subterranean operations can lead
to errors or block signals entirely. Protocols like the Network Time
Protocol (NTP) \cite{rfc1119} work to bring clocks into
synchronization with respect to an authoritative source. On the public
internet, NTP typically achieves synchrony to within values on the
order of tens of milliseconds \cite{rfc1128}, but it is not clear the
level of synchrony that can be expected from NTP in the sorts of use
cases we have in mind. A field device initialized without internet
access may have no idea what the time is, but it must still operate.

For our use case, what seems most important about time is that
\emph{the future cannot influence the past}
\cite{1989mattern}. Fortunately, this sort of invariant can be
enforced with mechanisms that do not rely on measuring real
time. Below, we explain how so-called logical clocks can be used to
measure and enforce a key relation between events, this being their
\emph{causal precedence}.


\subsection{Message Passing and Causality}
\label{ssec:message-passing}
We model a distributed system abstractly as a fixed set
$\mathcal{P} = \{P_1, P_2, \ldots P_n\}$ of \emph{processes} which
undergo atomic (indivisible) state changes known as
\emph{events}. Events are divided into three types: internal events,
representing state changes inside a single process, and send and
receive events corresponding to \emph{messages} passed between
processes. Note that this framework is quite abstract and applies to
any kind of packet-based communication technology. To draw out the
core issues surrounding messaging, the diagrams in this section do not
depict any internal events, as they represent state changes that are
not directly viewable to the network or other processes.

Throughout the section, processes and networks are opaque blackboxes,
which concentrates our attention on the ramifications of unpredictable
network latencies. We implicitly assume the reliable asynchronous
network model: when a message is sent between processes, it certainly
arrives at some point in the future, but we cannot say anything about
when or in what order compared to other messages. At times, we
consider the possibility that a message may never arrive. The choice
depends on which networking technology (or which layer of the OSI
networking model \cite{1983:osi-reference-model}) is under
consideration.

Figure \ref{fig:message-latencies} illustrates a series of time
diagrams for messages exchanged between three processes: $P_1$, $P_2$,
and $P_3$. The $x$-axis represents the flow of real time from left to
right, which each process represented by a worldline depicting the
events occurring within that process. Each message, $m$, originates
from a send event $\msend{}$, marking the moment the message is
dispatched across the network by its source process. The delivery of
the message corresponds to a receive event, $\mrecv{}$. For now we
assume messages have a single receiver. We write subscripts on
messages to distinguish them for clarity, but these are not inherent
to the messages themselves.

\begin{figure}[p]
  \setlength\belowcaptionskip{5ex}
  \begin{subfigure}{1\textwidth}
    \centering
    \input{images/pgf/mpEx1.pgf}
    \caption{$P_1$ has a somewhat lower-latency connection to $P_2$ than to $P_3$}
    \label{fig:message-latencies-a}
  \end{subfigure}
  \begin{subfigure}{1\textwidth}
    \centering \input{images/pgf/mpEx2.pgf}
    \caption{$P_1$ has a much lower-latency connection to $P_2$ than to $P_3$}
    \label{fig:message-latencies-b}
  \end{subfigure}
  \caption{Message-passing time diagram examples}
  \label{fig:message-latencies}
\end{figure}

In these diagrams, arrows connect corresponding send and receive
events, with their diagonal slant representing the latencies
experienced as messages traverse the network. Because messages arrive
with varying delays, they might arrive in a different order than they
were sent in. In Figure \ref{fig:message-latencies-a}, for example,
$P_1$ sends messages $m_2$ and $m_4$ sequentially, but $m_4$ arrives
before $m_2$, which might occur if $P_1$ and $P_3$ are separated by a
high-latency communication link. In Figure
\ref{fig:message-latencies-b}, $m_1$ is the first message sent but the
last to be delivered, potentially indicating a deteriorating link
between $P_1$ and $P_3$, perhaps due to increased distance or
inclement weather.

For many applications, it is critical to maintain a natural ordering
of events known as \emph{causal precedence}, or Lamport's ``happens
before'' relation \cite{1978:lamportclocks}. To formalize this, we
first consider the intuitive way to order events within a
\emph{single} process:
\begin{definition}
  For two events $e$ and $e'$ occurring in process $P_i$, we
  write $e <_{P_i} e'$ if $e$ occurs before $e'$ in $P_i$'s
  worldline.
\end{definition}
The previous definition is local to one process and unambiguous, as we
assume events within a process occur at discrete, non-overlapping
points in time. To extend this to a system-wide definition of causal
precedence, we relate corresponding send and receive events, then take
the transitive closure of the relation.

\begin{definition}[Causal precedence]
  \label{def:causalprecedence}
  We define a binary relation $\to$ on the set of events as follows:
  \[e \to e' \iff
  \begin{cases}
    e <_{P_i} e' \textrm{ for some process $P_i$}
    \textbf{ or} \\
    e = \msend{} \textrm{ and } e' =\mrecv{}
    \textbf{ or} \\
    \textrm{there is some } e'' \textrm{ such that } e \to e'' \textrm{ and } e'' \to e'
  \end{cases}
  \]
  If $e \to e'$, we say $e$ has \emph{causal precedence over} $e'$ or
  \emph{happens before} $e'$.
\end{definition}
Visually, $e \to e'$ holds when one can put a finger on $e$ in the
diagram and trace a ``path of causality'' to $e'$ by following
worldlines or arrows. We use the notation $e \not \to e'$ to mean
$e \to e'$ does not hold. Note that $e \not \to e'$ does not imply
$e' \to e$.

Incidentally, ``causal precedence'' and ``happens before'' can be
misnomers, as $e \to e'$ only conveys the possibility that information
from $e$ could have influenced $e'$. If information from event $e$
might have influenced $e'$, then it is crucial that applications avoid
situations where, from the user's point of view, it appears that $e'$
happened before $e$. For example, this proscription means an
application cannot let an ``answer'' appear before the underlying
``question''. This is what is meant by not letting the future affect
the past.

\begin{example}
  Figure \ref{fig:causal-precedence} illustrates the causal precedence
  relation corresponding to the time diagrams in Figure
  \ref{fig:message-latencies}. For readability we suppress redundant
  transitive arrows. The visual difference between Figures
  \ref{fig:message-latencies-b} and \ref{fig:message-co-b} reflects
  the fact that causal order only captures a logical relationship
  between events, but does not reflect their absolute time or within
  which process they occurred.
\end{example}

Mathematically, causal precedence is an irreflexive partial order:
\emph{irreflexive} because $e \not \to e$ (an event does not precede
itself), and \emph{partial} because any two events $e$ and $e'$ may
satisfy neither $e \to e'$ nor $e' \to e$.

\begin{definition}[Logical synchronicity]
  \label{def:logically-synchronous}
  Events $e$ and $e'$ that are not related by causality are said to be
  \emph{logically synchronous}, denoted $\sync{e}{e'}$.
\end{definition}

Note that
logical synchronicity is not usually transitive, meaning it is
possible to have $\sync{e}{e'}$ and $\sync{e'}{e''}$ but not
$\sync{e}{e''}$. For example,
\begin{itemize}
\item In Figure \ref{fig:message-co-a}, $\sync{\mrecv{1}}{\mrecv{2}}$
  and $\sync{\mrecv{2}}{\msend{4}}$, but $\mrecv{1} \to \msend{4}$.
\item In Figure \ref{fig:message-co-b}, $\msend{1}$ is logically synchronous
with every event except $\mrecv{1}$, but those other events are
totally ordered by causality and not synchronous with each
other.
\end{itemize}

Relations like $\sync{}{}$ that are reflexive and symmetric but not
necessarily transitive are sometimes called \emph{compatibility
  relations}.

\begin{figure}
  \begingroup
  \setlength\belowcaptionskip{4ex}
  \begin{subfigure}{1\textwidth}
    \centering
    \input{images/pgf/mpEx1CO.pgf}
    \caption{Causal precedence among the events in Figure \ref{fig:message-latencies-a}}
    \label{fig:message-co-a}
  \end{subfigure}
  \endgroup
  \begin{subfigure}{1\textwidth}
    \centering
    \input{images/pgf/mpEx2CO.pgf}
    \caption{Causal precedence among the events in Figure \ref{fig:message-latencies-b}}
    \label{fig:message-co-b}
  \end{subfigure}
  \caption{Causal precedence relations for Figure \ref{fig:message-latencies} (transitive arrows not shown)}
  \label{fig:causal-precedence}
\end{figure}

\subsection{Virtual Clocks}
\label{ssec:timestamps}
Distributed applications systematically track causality by employing
\emph{logical} clocks, which measure the logical flow of time by
timestamping events with (possibly sets of) non-negative integers that
are advanced according to certain rules. The three major variants are
scalar, vector, and matrix clocks, which form a kind of
spectrum. Scalar clocks are simple but provide coarse-grained
information, while vector and matrix clocks track increasingly more
precise information at the cost of greater administrative overheads.

All processes timestamp their events using their local clocks. For
each event $e$, let $C(e)$ denote the timestamp attached to that
event. The fundamental property we want to satisfy is that if $e$
causally precedes $e'$, it should receive a lesser timestamp. This is
called the clock consistency condition, commonly just called the clock condition.

\begin{definition}
  A system of timestamps satisfies the \emph{clock consistency
  condition} if the following monotonicity property holds:
  \[ \textrm{For all events $e$ and $e'$, } e \to e' \implies C(e) < C(e') \label{eq:mp}\tag{CC} \]
\end{definition}

This notation states that if one event causally precedes another, then
the earlier one receives a lesser timestamp. Somewhat subtly, the
clock condition does \emph{not} imply that we can decide if events are
causally related by comparing timestamps. It may be helpful to express
\eqref{eq:mp} in terms of the following logically equivalent
condition.
\[ \textrm{For all events $e$ and $e'$, }C(e) \leq C(e') \implies e'
  \not\to e \label{eq:mp-conv}\tag{CC$'$} \]

If this condition is true, we can be sure that a particular sequence
of events $e_1, e_2, e_3\ldots$ does \emph{not} violate causal
precedence (i.e., does not list any event $e$ before another event
that could have influenced $e$) by checking that
$C(e_{i}) \leq C(e_{i+1})$ for all $i$. We emphasize that this does
not give us a definite way to tell whether two events are in fact
causally related.

For some applications it is important to determine conclusively
whether events are causally related. In this case, one is led to
consider the following stronger requirement from a system of logical
timestamps.
\begin{definition}
  An event-timestamping mechanism satisfies the \emph{strong} clock   condition if the following property holds.
  \[ \textrm{For all events $e$ and $e'$, } e \to e' \iff C(e) < C(e') \label{eq:sc}\tag{SC} \]
  Note that $\iff$ is notation for ``if and only if,'' i.e. logical equivalence.
\end{definition}
Below we see one logical clock protocol that satisfies the weaker
clock condition, and two that satisfy the stronger condition.

\subsubsection{Scalar clocks}
\label{sssec:scalar-clocks}
\begin{figure}
  \setlength\belowcaptionskip{5ex}

  \begin{subfigure}{1\textwidth}
    \centering \input{images/pgf/mpEx1Sc.pgf}
    \caption{Figure \ref{fig:message-latencies-a} redepicted with scalar clocks}
    \label{fig:message-latencies-scalar-a}
  \end{subfigure}

  \begin{subfigure}{1\textwidth}
    \centering \input{images/pgf/mpEx2Sc.pgf}
    \caption{Figure \ref{fig:message-latencies-b} redepicted with scalar clocks}
    \label{fig:message-latencies-scalar-b}
  \end{subfigure}

  \caption{Scalar clock examples}
  \label{fig:message-latencies-scalar}
\end{figure}

Lamport's scalar clocks \cite{1978:lamportclocks} require each
process $P_i$ to maintain a single non-negative scalar value $C_i$,
initialized to $0$. The clock follows two simple update rules:
\begin{enumerate}
\item[\textbf{R1}:] Before a message is sent or an internal event occurs, $P_i$
  increments its clock:
  \[C_i := C_i + 1.\]
  The new value serves as the event's timestamp and, for messages, is ``piggybacked''
  as part of its metadata.
\item[\textbf{R2}:] When $P_i$ receives a message with timestamp $C$, it
  updates $C_i$ as such:
  \[C_i := \max(C, C_i) + 1.\]
  The value is the receive event's timestamp.
\end{enumerate}

\begin{example}
  Figure \ref{fig:message-latencies-scalar} depicts the same events in
  Figure \ref{fig:message-latencies} with scalar timestamps (shown in
  parentheses) assigned to each event. Piggybacked timestamps are
  shown as labels on the message arrows.
\end{example}

Scalar clocks satisfy the clock condition \eqref{eq:mp}. This can be
observed by tracing the path of causality between related events and
seeing that the clock is incremented at each step. However, they do
not satisfy \eqref{eq:sc}.  While $e$ having a lesser timestamp than
$e'$ rules out $e' \to e$, it does not imply $e \to e'$. For instance,
in Figure \ref{fig:message-latencies-scalar-b}, $\msend{1}$ has a
globally minimal timestamp value of $1$, but it does not causally
precede all events with timestamps greater than $1$, or indeed any
event except $\mrecv{1}$.

\subsubsection{Vector clocks}
\label{sssec:vector-clocks}
The strong clock condition \eqref{eq:sc} cannot hold either using
scalar clocks or even synchronized physical clocks. This is because
both mechanisms assign timestamps whose values form a total order---meaning any
two distinct timestamps $C_1, C_2$ satisfy either $C_1 < C_2$ or $C_2 < C_1$.

A clock protocol that uses a total order cannot enforce the strong
clock condition. For logically synchronous events $\sync{e}{e'}$,
neither $e \to e'$ nor $e' \to e$ holds, so strong consistency and the
total order property would require $C(e) = C(e')$. This is an
impossible requirement because logical concurrency is not
transitive. For instance, recall that in Figure
\ref{fig:message-latencies-b}, $\msend{1}$ is logically synchronous
with every event except $\mrecv{1}$. This would require assigning them
all the same timestamp, which contradicts the fact they are not
synchronous with each other. The solution is to let timestamps from a
partial order, where distinct timestamps $C_1$ and $C_2$ do not have
to satisfy either $C_1 < C_2$ or $C_1 > C_2$.

\begin{figure}
  \setlength\belowcaptionskip{5ex}

  \begin{subfigure}{1\textwidth}
    \centering
    \input{images/pgf/mpEx1Vec.pgf}
    \caption{Figure \ref{fig:message-latencies-a} redepicted with vector clocks}
    \label{fig:message-latencies-vector-a}
  \end{subfigure}

  \vspace{4ex}

  \begin{subfigure}{1\textwidth}
    \centering \input{images/pgf/mpEx2Vec.pgf}
    \caption{Figure \ref{fig:message-latencies-b} redepicted with vector clocks}
    \label{fig:message-latencies-vector-b}
  \end{subfigure}

  \caption{Vector clock examples}
  \label{fig:message-latencies-vector}
\end{figure}
\afterpage{\clearpage}

Vector clocks store one scalar value for each process in the system,
which forms a partial order when vectors are compared
component-wise. If the system is comprised of $N$ processes, $P_i$
maintains a vector $\vt_i[1 \ldots N]$ of non-negative integers, with
all values initialized to $0$. The $i^\textrm{th}$ component, or
$\vt_i[i]$, is called $P_i$'s local time, while the remaining
components are used to estimate other processes' local times. Vector
clocks have two update rules:
\begin{enumerate}
\item[\textbf{R1}:] Before an internal event occurs or a new message is sent, $P_i$
  increments its local time according to the rule:
  \[\vt_i[i] := \vt_i[i] + 1.\]
  The (entire) updated $\vt_i$ is the event's timestamp and is piggybacked with outgoing messages.
\item[\textbf{R2}:] When $P_i$ receives a message with timestamp
  $\vt$, $\vt_i$ is updated according to
  \[\vt_i[x] := \max(\vt[x], \vt_i[x]) \quad \textrm{for all $x = 1\ldots N$}.\]
  After this, $P_i$ increments its local time:
  \[ \vt_i[i] := \vt_i[i] + 1.\]
  The final vector is the timestamp of the receive event.
\end{enumerate}
These rules are more intuitively understood by demonstration.

\begin{example}
  Figure \ref{fig:message-latencies-vector} depicts the same events as
  Figure \ref{fig:message-latencies-scalar} with vector timestamps.
\end{example}

For all $j \neq i$, $\vt_i[j]$ represents $P_i$'s \emph{estimate} of
$P_j$'s local time, or $\vt_j[j]$. This estimate is always a lower
bound, since $P_j$'s local time may advance without $P_i$'s knowledge,
but $P_i$ never updates $\vt_i[j]$ ahead of $P_j$'s actual local
time. $P_i$ learns about updates to $P_j$'s local time through
piggybacked timestamp vectors, which allow $P_i$ to learn about
$P_j$'s time without communicating directly with $P_j$.

Vector timestamps are compared component-wise. This forms a partial
order because one vector may be greater than another in some
components but less than it in others.

\begin{definition}[Vector comparison]
  Let $v, w$ be two vector clocks. We define the following relations:
  \begin{align*}
             v = w &\iff \forall i, v[i] = w[i] \\
  v \preccurlyeq w &\iff \forall i, v[i] \leq w[i] \\
         v \prec w &\iff v \preccurlyeq w \textrm{ and } \exists i, v[i] < w[i] \\
            \syncts{v}{w} &\iff \textrm{ neither } v \prec w \textrm{ nor } v \succ w
  \end{align*}
  That is, $v \prec w$ if all of $w$'s components are at least as
  great as $v$'s, and at least one of its components is strictly
  greater. When two non-equal vectors are compared, and neither is
  greater than the other, we write $\syncts{v}{w}$ and say the vectors
  are \emph{incomparable}.
\end{definition}

 is justified by the fact that vector
clocks satisfy \ref{eq:sc}, so these otherwise distinct notions will
coincide.

\begin{lemma}
  Vector clocks satisfy the strong clock consistency condition. That
  is, where $C(e)$ is the vector timestamp of an event, then
  \[ e \to e' \iff C(e) \prec C(e'). \]
  From this it follows that for non-equal events $e$ and $e'$ we have
  \[\sync{e}{e'} \iff {C(e) \texttt{\#}\,C(e')}. \]% This isn't typesetting right
\end{lemma}

For reasons of space we omit a proof of the preceding lemma, though
the reader may find it enlighting to formalize the details.

\subsubsection{Matrix clocks}
\label{sssec:matrix-clocks}
If a vector clock stores both a local time and a lower bound estimate
of every other process's local time, then a matrix clock stores a
local vector clock and a lower bound estimate of every other process's
vector clock. Each process $P_i$ stores an $N\times{}N$ matrix
$\vt_i$, initialized to all zeros, with the following
interpretation. The $i^{\textrm{th}}$ row from the top, $\vt_i[i, -]$,
stores $P_i$'s vector time. All other rows $\vt_i[j,-]$ store $P_i$'s
estimate of $P_j$'s vector time. Matrix timestamps are piggybacked
with messages, and the receiver uses the sender's vector clock to
update their own vector clock as usual, and takes the pointwise
maximum of all other rows.

\begin{enumerate}
\item[\textbf{R1}:] Before a new message is sent, $\vt_i[i]$ is updated according to the rule
  \[\vt_i[i,i] := \vt_i[i,i] + 1.\]
  The entire updated matrix $\vt_i$ is piggybacked with the message.
\item[\textbf{R2}:] When a message is received from $P_j$ with a piggybacked timestamp $\vt$,
  $\vt_i$ is updated according to two cases
  \begin{enumerate}
  \item Update the row $\vt_i[i, -]$ according to
    \[\vt_i[i, k] := \max(\vt_i[i,k], \vt[j, k]) \quad \textrm{for all $k = 1\ldots N$}.\]
  \item Update all other rows $\vt_i[j', -]$ according to
    \[\vt_i[j', k] := \max(\vt_i[j',k], \vt[j', k]) \quad \textrm{for all $k = 1\ldots N$}.\]
  \end{enumerate}
  After this, $P_i$ advances its own local time according to the rule
  \[ \vt_i[i,i] := \vt_i[i,i] + 1.\]
  This new matrix is the timestamp attached to the receive event.
\end{enumerate}

\begin{figure}[p]
  \begingroup
  \setlength\belowcaptionskip{4ex}
  \begin{subfigure}{1\textwidth}
    \input{images/pgf/mpEx1Mat.pgf}%
    \caption{Matrix clock timestamps for the events in Figure \ref{fig:message-latencies-a}}
    \label{fig:message-latencies-matrix-a}
  \end{subfigure}
  \begin{subfigure}{1\textwidth}
    \input{images/pgf/mpEx2Mat.pgf}%
    \caption{Matrix clock timestamps for the events in Figure \ref{fig:message-latencies-b}}
    \label{fig:message-latencies-matrix-b}
  \end{subfigure}
  \caption{Figure \ref{fig:message-latencies} depicted with matrix clocks}
  \label{fig:message-latencies-matrix}
  \endgroup
\end{figure}

\begin{example}
  Figure \ref{fig:message-latencies-matrix} depicts the same events as
  Figures \ref{fig:message-latencies-scalar} and
  \ref{fig:message-latencies-vector} with matrix timestamps. By
  comparison to Figure \ref{fig:message-latencies-vector}, observe
  that that rows of the form $\vt_i[i,-]$ act like ordinary vector
  clocks.
\end{example}

In Section \ref{sec:background}, we mentioned the epistemic nature of
reasoning about distributed systems: a process can only make decisions
based on what it \emph{knows}, which is usually a strict subset of all
(system-wide) truths. In many cases, it is important to take into
account a kind of second-order knowledge: what does a process know
about what other processes know? One major utility of vector and
matrix clocks is that they can be be used to track which facts known
to one process are also known to another processes. When this is of
interest, it is often because a process wants to compute which facts
are known to \emph{all} other processes. In Section
\ref{sec:continuous-consistency}, particularly Section
\ref{sssec:tsae-unsynchronized}, we will see an example of how a
vector and matrix clocks (or rather, very similar mechanisms called
version vectors and matrices) can be used in the context of
replicating a database over a disruption-heavy network.

\subsection{Message Ordering}
\label{ssec:message-ordering}
Coulouris et al. \cite{coulouris2005distributed} aptly summarized why
it is a problem for unpredictable network latencies to cause messages
to arrive in a different order than they were sent in.
\begin{quote}
  ``This lack of an ordering guarantee is not satisfactory for many
  applications. For example, in a nuclear power plant it may be
  important that events signifying threats to safety conditions and
  events signifying actions by control units are observed in the same
  order by all processes in the system.''
\end{quote}
In this section, we explore different paradigms for message ordering
in distributed systems. As with clocks and timestamps, the choice of
which ordering guarantee to use depends on the needs of the
application. We later generalize the discussion by admitting messages
sent to multiple recipients at once, such as in a group chat
application, where ensuring predictable message ordering is critical.

When ordering is important, applications do not show messages to the
user immediately when they come in from the network---the network can
deliver messages in unexpected and undesirable orders, after all. The
\emph{arrival} time of a message is when it is received from the
network, but instead of acting on it right away, an application may
buffer an arrived message while waiting for other messages (such as
ones with an earlier causal precedence) to ``catch up.'' When a
message is ready to be presented to the user, it is
\emph{delivered}. By waiting to deliver some messages, we can ensure
the stream of messages in order of their delivery satisfies particular
guarantees.

\subsubsection{FIFO ordering}
A modest requirement is the \emph{first-in, first-out} (FIFO)
condition, which stipulates that on any logical communication link
between two processes in the system, messages arrive in the order they
were sent. The restrictive phrase here is ``any logical communication
link''---by definition there is one link for any \emph{pair} of
processes. Hence, FIFO does not impose any conditions on messages
unless they are from the same sender and to the same recipient.

\begin{definition}[FIFO delivery]
  \label{def:fifo}
  The FIFO ordering guarantee is defined by the following condition. Let
  $P_i$ and $P_j$ be any two processes and $m_1$ and $m_2$ be two
  messages sent from $P_i$ to $P_j$. Then
  $\msend{1} \to \msend{2} \implies \mrecv{1} \to \mrecv{2}$.
\end{definition}

The Internet Protocol (IPv4 or IPv6) by itself does not provide FIFO
semantics. In the OSI model, FIFO ordering with reliable delivery is
typically provided at the transport layer by the transmission control
protocol (TCP).\footnote{The other classic internet transport, user
  datagram protocol (UDP), does not provide any ordering or
  reliability guarantees.} Applications built on top of TCP or a
similar transport can take therefore take FIFO for granted. Providing
FIFO can be as simple as marking messages sent from $P$ to $Q$ with
consecutive integers. If message $1$ arrives and then $3$ arrives, $Q$
infers that $2$ is lagging behind, delivering $1$ to the user but
withholding delivery of $3$ until after $2$ is received and delivered.

The guarantees provided by FIFO are minimal because they only apply on
a per-link basis: every link requires its own numbering scheme, so
message numbers cannot be meaningfully compared across different
links. To compare messages globally requires something like causal
order, below.

\begin{figure}[p]
  \setlength\abovecaptionskip{0ex}
  \setlength\belowcaptionskip{4ex}
  \begin{subfigure}[t]{0.475\textwidth}
    \centering
    \input{images/pgf/ordEx1.pgf}
    \caption{A non-FIFO execution}
    \label{fig:ordex-non-fifo}
  \end{subfigure}
  \begin{subfigure}[t]{0.475\textwidth}
  \centering
  \input{images/pgf/ordEx2.pgf}
  \caption{A CO (therefore FIFO) execution}
  \label{fig:ordex-co-1}
\end{subfigure}
\begin{subfigure}[b]{0.475\textwidth}
  \centering
  \input{images/pgf/ordEx3.pgf}
  \caption{A CO execution}
  \label{fig:ordex-co-2}
\end{subfigure}
\begin{subfigure}[b]{0.475\textwidth}
  \centering
  \input{images/pgf/ordEx6.pgf}
  \caption{A CO execution}
  \label{fig:ordex-co-3}
\end{subfigure}
\begin{subfigure}[b]{0.475\textwidth}
  \centering
  \input{images/pgf/ordEx5.pgf}
  \caption{A FIFO and non-CO execution}
  \label{fig:ordex-non-co-1}
\end{subfigure}\hfill
\begin{subfigure}[b]{0.475\textwidth}
  \centering
  \input{images/pgf/ordEx4.pgf}
  \caption{A FIFO and non-CO execution}
  \label{fig:ordex-non-co-2}
\end{subfigure}
\caption{Message ordering examples}
\label{fig:message-ordering}
\end{figure}

\subsubsection{Causal ordering}
Causal order is an order guarantee consistent with causal precedence
of events. A network provides causally ordered (CO) delivery if it
satisfies the following property.
\begin{definition}[CO delivery]
  \label{def:causalorder}
  For any process $P_\mathrm{dest}$ in the system, if we consider all
  messages $m$ and $n$ sent to $P_\mathrm{dest}$ (possibly by
  different senders), if $\msend{} \to n^\textrm{send}$ then
  $\mrecv{} \to n^\textrm{recv}$. That is, each destination receives
  messages in an order consistent with causality between their send
  events.
\end{definition}
Unlike FIFO, the CO condition enforces a partial order among messages
with (in general) different senders. In mathematical terms, if we for
each process $P_{\mathrm{dest}}$, the function mapping send events to
corresponding receive events at $P_{\mathrm{dest}}$ must be monotonic
with respect to causal precedence.

\begin{example}
  Figure \ref{fig:message-ordering} demonstrates different message
  ordering conditions. We make a few observations for emphasis.

  \begin{itemize}
    \tightlist
  \item \ref{fig:ordex-non-fifo} violates FIFO because messages $m_1$
    and $m_2$ are both sent from $P_1$ to $P_2$, but the arrive in the wrong order.
  \item \ref{fig:ordex-co-1} satisfies CO and therefore FIFO. Messages
    $m_1$ and $m_2$ arrive in the opposite order but they are sent to
    different destinations.
  \item \ref{fig:ordex-non-co-1} violates CO because the send event of
    $m_1$ happens before that of $m_3$ via the chain
    $\msend{1} \to \msend{2} \to \mrecv{2} \to \msend{3}$ but
    $\mrecv{3} \to \mrecv{1}$.
  \item \ref{fig:ordex-non-co-2} violates CO because it is equivalent to
    \ref{fig:ordex-non-co-1} with the roles of $P_2$ and $P_3$ swapped.
  \end{itemize}
\end{example}

\subsubsection{Multicasting and Broadcasting}
\label{sssec:multicasting}
We now extend the above definitions to the group communication setting
by allowing messages to have multiple recipients. For simplicity, we
suppose messages are broadcast to all other recipients, though the
definitions can easily generalize to ``multicast'' scenarios where
messages are sent to a subset of recipients.

One way to implement broadcasting is to sending distinct network
messages which, for present purposes, we would treat as a single
unit. Alternatively, we can lean on the network itself for assistance,
sending a single message specially marked as a broadcast, relying on
lower-level protocols in the network to distribute a copy to each
recipient. Regardless of implementation, the challenge and importance
of ensuring consistent message ordering across an entire group is a
paramount concern.

The FIFO and CO broadcast conditions are adapted from Definitions
\ref{def:fifo} and \ref{def:causalorder}. Additionally, we introduce
the notion of total ordering (TO) below.

\begin{definition}[FIFO broadcast]
  \label{def:fifo-bcast}
  A broadcast primitive satisfies the FIFO semantics if it satisfies
  the following condition. For any process $P_i$, if $P_i$ broadcasts
  $m_1$ before $m_2$, then all recipients receive $m_1$ before $m_2$.
\end{definition}

\begin{definition}[CO broadcast]
  \label{def:causalorder-bcast}
  A broadcast primitive satisfies CO semantics if for any broadcasts
  $m$ and $n$, if $\msend{} \to n^{\textrm{send}}$, then all
  destinations deliver $\mrecv{}$ before $n^{\textrm{recv}}$.
\end{definition}
In the above definition, the happens before relation is defined just
as in the unicast (non-broadcast) setting by following a path of
causality along worldlines and message arrows.

\begin{figure}[h]
  \centering \input{images/pgf/mpEx3.pgf}
  \caption{Broadcast example that satisfies FIFO but violates CO}
  \label{fig:broadcast-fifo-1}
\end{figure}

\begin{example}
  In Figure \ref{fig:broadcast-fifo-1}, causal order is violated. Imagine the following conversation:
  \begin{itemize}
    \tightlist
  \item [$P_1$]: ``I need an ambulance at location A.''
  \item [$P_2$]: ``Understood, the last ambulance has been dispatched.''
  \end{itemize}
  However, $P_3$ receives $P_2$'s response before $P_1$'s request, resulting in this conflicting view:
  \begin{itemize}
    \tightlist
  \item [$P_2$]: ``Understood, the last ambulance has been dispatched.''
  \item [$P_1$]: ``I need an ambulance at location A.''
  \end{itemize}
  From $P_3$'s perspective, $P_1$ appears to be requesting resources
  that are no longer available. The sort of conflict can lead to
  confusion, with requests being duplicated or going
  unanswered. Tracking causal order is crucial to avoid such resource
  misallocations.
\end{example}

A total order broadcast ensures that all recipients receive the
messages in the same order. This order is not required to satisfy any
particular constraints except that all recipients agree on it. Such a
model is appropriate when it is more important that everyone agrees on
a common order of events but the order itself is not necessarily
critical.

\begin{definition}[TO broadcast]
  \label{def:totalorderbroadcast} For any processes $P$ and $Q$ and
  messages $m$ and $m'$ that arrive at \emph{both} destinations, $m$
  arrives before $m'$ at both processes or $m'$ arrives before $m$ at
  both processes.
\end{definition}

Total order is independent of causal order, as causality is not total
and a total order does not generally respect causality. Thus it
sensible to consider also a hybrid notion of \emph{total-causal} order
in which all messages are received in a total order respecting
causality.

\begin{figure}[p]
  \setlength\belowcaptionskip{5ex}
  \begin{subfigure}{1\textwidth}
    \centering
    \input{images/pgf/bcastEx1.pgf}
    \caption{Broadcast example that satisfies FIFO but violates CO and TO}
    \label{fig:bcast-order-examples-1}
  \end{subfigure}
  \begin{subfigure}{1\textwidth}
    \centering
    \input{images/pgf/bcastEx2.pgf}
    \caption{Broadcast example that satisfies CO but violates TO}
    \label{fig:bcast-order-examples-2}
  \end{subfigure}
  \begin{subfigure}{1\textwidth}
    \centering
    \input{images/pgf/bcastEx3.pgf}
    \caption{Broadcast example that satisfies TO but violates FIFO}
    \label{fig:bcast-order-examples-3}
  \end{subfigure}
  \caption{Multicast ordering examples}
  \label{fig:bcast-ordering-examples}
\end{figure}

\begin{example}
Figure \ref{fig:bcast-ordering-examples} depicts examples of broadcast
message orders.
\begin{itemize}
  \tightlist
\item Figure \ref{fig:bcast-order-examples-1} trivially satisfies FIFO
  because no process sends more than one multicast, but causality is
  violated because $\msend{1} \to \mrecv{1,4} \to \msend{2}$, but
  $P_2$ receives $m_2$ before $m_1$. Total order is also violated
  because $P_2$ and $P_3$ receive the messages in opposite orders.
\item Figure \ref{fig:bcast-order-examples-2} violates TO for the same
  reason above, but satisfies causality because the two send events
  have no causal relation.
\item Figure \ref{fig:bcast-order-examples-3}
  satisfies TO, but $m_2$ arrives at both processes before $m_1$ so
  FIFO is violated.
\end{itemize}
\end{example}
Section \ref{sssec:tsae-message-ordering} describes a particular
mechanism to implement total order broadcast.
\paragraph{Self-delivered messages}
In some contexts one considers broadcast primitives that include the
original sender among the recipients of a message. For simplicity, the
examples in this section have not shown this sort of self-delivery,
but it is useful in many cases. A typical use case is that
participants are using a total order broadcast to maintain local
replicas of a state machine that can be advanced by any participating
process by announcing updates. An example of this usage is presented
in Section \ref{sec:continuous-consistency}, where the goal is to
maintain distributed replicas of a database over a disruption-heavy
network, which can improve the performance of system applications.

%When a site wishes to update the shared data, it
%announces its intention using a totally ordered (say) broadcast that
%includes the sender in the list of recipients. To ensure consistency,
%we only actually modify our replica of the database when we hear about
%updates, including our own, over the totally ordered broadcast
%channel. In this manner, we can ensure all sites participating in the
%database replication reflect all updates in the same order, thus
%maintaining consistency.


\subsection{Shared Memory}
\label{ssec:shared-memory}
Desiging a distributed application using direct message passing can be
challenging due to the complexity of managing the low-level details
surrounding message ordering and reliability. A more abstract
approach, the \emph{distributed shared memory} (DSM) framework,
simplifies this task by allowing programmers to think in terms of
reading and writing to memory locations instead of sending messages
over a network.

The defining feature of DSM is that it allows all processes to
interact as if they had access to a single, unified proof of shared
memory---just like processes running on a single computer---despite
being spread across different, physically separated computers.  This
seamless (subject to caveats explained below) experience is
facilitated by a middleware layer inside the process called the
\emph{memory manager}, which handles all read and write requests
submitted by an application. In the background, not directly visible
to the application, the memory manager coordinates with other
instances over the network to maintain the illusion of a shared state,
or what first responders would call a ``common operating picture.''

Since there is no free lunch, the seamlessness of the DSM model is
subject to caveats, especially this one: usually, a read request
handled by the memory manager does not return the most up-to-date
value of the memory location it reads. Indeed, in the distributed
setting it is not clear a priori what it means for a returned value to
be ``up-to-date'' in the first place, in light of the fact that two
different processes can write conflicting values to the same memory
location at the same time. For developers, understanding the semantics
of the virtual memory layer, meaning knowing what guarantees it makes
concerning what values can be returned at which times, is a crucial
part of building applications that function correctly while providing
reliable performance. Because of the sorts of tensions discussed in
Section \ref{sec:disaster-response}, the design space here is
generally marked by a tradeoff between stronger consistency guarantees
and faster performance.

\begin{figure}
    \centering
    \input{images/pgf/dsm_ex1_WithoutEdges.pgf}
    \caption{Time diagram for memory operations}
    \label{fig:dsm-example-1}
\end{figure}

\begin{figure}
  \centering
  \input{images/pgf/dsm_ex1_DAG.pgf}
  \caption{External order relation among operations in Figure \ref{fig:dsm-example-1} (with edges implied by transitivity not shown)}
  \label{fig:dsm-example-1-DAG}
\end{figure}

Figure \ref{fig:dsm-example-1} depicts an exemplary time diagram for
the shared memory abstraction, similar to those for message
passing. Two kinds of operations are shown: \emph{reads} and
\emph{writes}. A read operation, $\memread{x}$, retrieves the value
stored at (virtual) location $x$, which returns some value $v$. When
we want to indicate the value returned by the read, we write
$\memreadVal{x}{v}$. A write operation, $\memwrite{x}{v}$, indicates
writing $v$ to memory location $x$, which in code might be written as
something like $x := v$.

An operation does not happen instantly, but has a \emph{duration}. An
arbitrary read or write operation, $\Op$, spans from the moment of
time the operation is invoked by the application ($\memstart{\Op}$),
to when it finished ($\memstop{\Op}$), returning either the read value
or an acknowledgment of the write request. During this span, the
memory management layer is usually coordinating in the background with
other processes over the network, say by looking up the current value
of a memory location, but this is not shown in the diagrams. The
entire sequence of requests across all processes forms what we call a
\emph{history}. If $H$ is a history and $P$ is a process, we write
$H|_P$ to mean just the sequence of operations that happen on $P$, the
so-called \emph{local history} of $P$.

Because they have a duration, memory operations on different
processes, including ones that access the same virtual memory
locations, can occur simultaneously. A fundamental relation among
operations is their \emph{external order}, the partial order that
relates non-overlapping events their physical times, but does not
assign an ordering to events whose executions overlap in physical
time.
\begin{definition}[External order]
  \label{def:external-order}
  Let $H$ be a history. An operation $\Op^1$ \emph{externally
    precedes} operation $\Op^2$ if
  $\memstop{\Op^1} < \memstart{\Op^2}$. This induces an irreflexive
  partial order on $H$ called \emph{external order}.
\end{definition}
The definition states that one operation externally precedes another
if it stops before the other is invoked. Note that we are comparing
events in terms of real, physical time: external order is the partial
order of events witnessed by an outside observer who can watch
operations executing globally in real time. Figure
\ref{fig:dsm-example-1-DAG} depicts the external order among the
operations in Figure \ref{fig:dsm-example-1}, forming a directed
acyclic graph (DAG).

Two events not related by external order are said to be physically
concurrent.

\begin{definition}[Physical concurrency]
  \label{def:physical-concurrency}
  Consider two operations $\Op^1$ and $\Op^2$. If neither externally
  precedes the other, in another words if there is some moment in time
  during which both operations are executing, the operations are said
  to be \emph{physically concurrent}, written $\concurrent{\Op^1}{\Op^2}$.
\end{definition}

Note that we have reused notation between Definitions
\ref{def:logically-synchronous} and \ref{def:physical-concurrency}.
Though they are similar concepts (both are reflexive and symmetric but
generally non-transitive binary relations), physically concurrent
memory operations in the DSM model should not be confused with
logically synchronous events in the events and message-passing model.

\subsection{Semantics and Consistency}
In a sequential application running on a single computer, it is clear
how read and write requests should be interpreted. A read request
$\memread{x}$ should return the most recent value that was written to
$x$ by a write operation $\memwrite{x}{v}$ (or return a default value
if no such write exists, but we will not consider such examples). This
is unambiguous because we assume that in a single process, memory
operations do not overlap in time, so there is always a sense of which
one happened first. %In a transactional database, this property can be
% achieved using standard \emph{serialization} mechanisms.

\begin{example}
  Consider the following history of operations running inside a single process.
  \[\input{images/pgf/dsm_ex_sequential.pgf}\]
  This diagram does not indicate what values are returned by the read
  operations, but since there is no ambiguity in the order of events,
  it is clear what these values \emph{should} be. Each read request
  should return the value (shown in bold below) set by the most recent
  write to that location.
  \[ \memwrite{x}{0} \to \memwrite{y}{5} \to \memreadVal{x}{\textbf{0}} \to \memwrite{x}{3} \to \memreadVal{y}{\textbf{5}} \to \memreadVal{x}{\textbf{3}}. \]
\end{example}

In a distributed system, operations on different processes can run
concurrently, so there is no obvious way to arrange events into a
total order that all processes can agree on. Consequently, the notion
of ``most recent'' operation is ambiguous, so it does not even make
sense to say that read requests always return the most recent written
value.

\begin{figure}[h]
  \input{images/pgf/dsm_ex2.pgf}
  \caption{A history with read return values left unspecified,
    featuring concurrent operations writing to and reading from the
    same location}
  \label{fig:dsm-example-2}
\end{figure}

%\begin{example}
%  \label{exmpl:concurrentupdates}
%\end{example}

Consider the history shown in Figure \ref{fig:dsm-example-2}, which
contains three operation that write to location $x$. Two of these
operations, $\memwrite{x}{3}$ $\memwrite{x}{5}$, are executed at
overlapping moments in time, making it unclear which should be
considered ``first.'' The ambiguity is made concrete by considering
the subsequent read operations---which values should they return? Or
rather, we should ask which values are they \emph{allowed} to return,
since there is not always a deterministic answer.

A \emph{memory model} exists precisely to answers questions of the
form, ``Which values might be returned by read requests in which
scenarios?'' In the example above, a model would have to answer
several questions like the following ones:
\begin{enumerate}
\item Do the read operations on $P_1$ and $P_2$ have to return the same value?
\item Can the second read operation at $P_2$ return a different value
  than the first one?
\item Is it ever possible for any of the $\memread{x}$ operations to
  return the value 4?
\end{enumerate}

One can consider many different ways of answering these questions,
depending on the consistency requirements of the high-level
application. The strictest memory model, called
\emph{linearizability}, is a sort of gold standard. If the distributed
system whose history is shown in Figure \ref{fig:dsm-example-2} is
linearizable, the all three read operations must return the same
value, and this must be either $3$ or $5$. This model is intuitive but
too strict for our use case, so programmers must be prepared for less
rigidly prescribed behavior from the memory manager.

Choosing to implement a particular memory model requires balancing the
needs and expectations of the application against its performance
characteristics, including its usage patterns and networking
environment. An application designed for one memory model would
generally misbehave, often in a way that is difficult to diagnose, if
executed in an environment that implements a different model. However,
on the other hand, implementing a stricter memory model may impose a
prohibitive overhead on application performance.

To resolve the ambiguity caused by overlapping memory operations, one
might attempt to assign timestamps to them and use this to define an
agreed-upon global total order of operations (recall that external
order is only a partial order, since it does not relate overlapping
events). For instance, one might globally order operations by their
start time or stop time. However, using these kinds of orders in
practice would require sufficiently fine-grained timestamps from
synchronized clocks, but synchronization is usually an infeasible
assumption (see Section
\ref{ssec:physical-synchrony}). %In that section, we were lead
% to define a global partial order, causal precedence, partly in
% reaction to the fact that we cannot use physical timestamps to
% arrange all systemwide events into a total order.

\subsection{Strong Consistency Models}
\label{ssec:strong-consistency}
This section considers the two major memory models usually said to
provide ``strong'' consistency: linearizability and sequential
consistency. Both models involve the notion of a sequential history,
or a set of operations arranged into a particular total order.

\begin{definition}[A sequential history]
  \label{def:sequential-history}
  A \emph{sequential history} if a set of memory operations in a
  particular total order. If $H$ is a history, a \emph{serialization}
  $H$, called $\sigma$, is any total order among the operations in
  $H$.
\end{definition}

Linearizability and sequential consistency both require that all read
operations return values consistent with some serialization of the
global history. That is, they stipulate that among all the operations
in $H$, there is some way of ordering them so that all read operations
return the values of the most recent write operations. Where the two
models differ is in how they constrain which serializations of $H$ are
allowable.

\subsubsection{Linearizability}
\label{sssec:linearizability}

\emph{Linearizability}, a sort of gold standard for memory
consistency, can be concisely defined as a system that acts like
``each operation applied by concurrent processes takes effect
instantaneously at some point between its invocation and response.''
\cite{10.1145/78969.78972} The same condition is known by other names
like atomic consistency, strict consistency, and external
consistency. It means almost the same thing as strict serializability,
except the latter terminology is used to discuss transactional
databases and implies other database-related guarantees. Formally, a
linearizable history is defined by three features.
\begin{definition}[Linearizable history]
  \label{def:linearizable-history}
  Let $H$ be a history of memory operations, where all read operations
  include their return values. $H$ is \emph{linearizable} if it
  satisfies the following three rules.
\begin{enumerate}
  \tightlist
\item \textbf{Global Agreement on Order}: All processes behave
  (defined below) as if they are observing the same serialization of
  $H$, meaning some particular total order $\sigma$.
\item \textbf{Correct Responses}: Each read request
  \(\memreadVal{x}{a}\) returns the value of the most recent write
  request \(\memwrite{x}{a}\) as ordered by $\sigma$.
\item \textbf{Consistent with External Order}: The serialization of
  $H$ is consistent with external order: if
  $\memstop{\Op^1} < \memstart{\Op^2}$, then $\sigma$ also orders
  $\Op^1$ before $\Op^2$.
\end{enumerate}
\end{definition}

Note that some authors define a serialization of $H$ as a total order
that is consistent with external order, but we consider these ideas
separately.

Definition \ref{def:linearizable-history} is concerned with an individual
history of some distributed application. When the application only
ever has linearizable histories, as permitted by the memory manager,
the entire system is said to be linearizable.

\begin{definition}[Linearizable system]
  \label{def:linearizable-system}
  A DSM application is linearizable if all possible histories of the
  application satisfy Definition \ref{def:linearizable-history}.
\end{definition}

Consider the history Figure \ref{fig:dsm-example-2} again. If the
application is linearizable, the read responses must agree on some
order $\sigma$ consistent with external order, implying that
$\memwrite{x}{4}$ happens before $\memwrite{x}{3}$ and
$\memwrite{x}{5}$, but the latter operations can occur in any
order. Since $P_1$ and $P_2$ have to agree on this order, all three
read responses will return the value written by whichever write is
ordered last (meaning most recent), which is either $3$ or $5$. These
possibilities are illustrated in Figure
\ref{fig:dsm-example-2-linearizations}.

Figure \ref{fig:dsm-example-2-linearizations} also depict an
equivalent, more visually intuitive way, of approaching defining
linearizability. A linearizable history where returned values are
consistent with a choice of linearization point for each operation.
\begin{definition}
  A \emph{linearization point} $t$ for an operation $\Op$ is a time in
  the range $[\memstart{\Op}, \memstop{\Op}]$, between the operations
  invocation and response. We forbid distinct operations from having
  an overlapping linearization point.
\end{definition}

A history is linearizable if there is some consistent choice of
linearization points for each operation, and all returned values are
consistent assuming each operation takes effect in whole and
instantaneously at its linearization point. The subfigures in
\ref{fig:dsm-example-2-linearizations} depict possible choices of
linearization points in yellow.

\begin{figure}
  \begin{subfigure}{1\textwidth}
    \setlength\belowcaptionskip{4ex}
    \centering
    \input{images/pgf/dsm_ex2_linear_1.pgf}
    \caption{A linearization where the read operations return 3}
    \label{fig:dsm-example-2-linearizations-1}
  \end{subfigure}
  \begin{subfigure}{1\textwidth}
    \input{images/pgf/dsm_ex2_linear_2.pgf}
        \caption{A linearization where the read operations return 5}
    \label{fig:dsm-example-2-linearizations-b}
  \end{subfigure}
  \caption{Two possible linearizations of Figure \ref{fig:dsm-example-2} with linearization points shown in yellow}
  \label{fig:dsm-example-2-linearizations}
\end{figure}

\subsubsection{Sequential consistency}
\label{sequential-consistency}

Linearizability offers very strong guarantees related to real-time
constraints, but for many applications this requirement is a burden
for performance. A more relaxed model, sequential consistency,
provides comparably strong guarantees but does not impose the same
constraints with respect to external order. Whereas linearizability
requires operations to be consistent with a serialization respecting
external order, sequential consistency allows any serialization that
respects \emph{program order}.

\begin{definition}[Program order]
  An operation $\Op^1$ precedes another operation $\Op^2$ in
  \emph{program order} if the events occur in the same process and
  $\memstop{\Op^1} < \memstart{\Op^2}$. In this case we write $\Op^1 \programorder{i} \Op^2$.
\end{definition}
If two operations occur in different processes, they are not related
by program order. That is the distinction between program and external
order, as the latter would relate the operations as long as they do
not overlap in time.

The definition of sequential consistency follows the same structure as
that for linearizability, with program order in place of external
order.

\begin{definition}[Sequentially consistent history]
  \label{def:sequentially-consistent-history}
  An history $H$ is \emph{sequentially consistent} if the following
  three rules are satisfied.
\begin{enumerate}
  \tightlist
\item \textbf{Global Agreement on Order}: All processes behave as if
  they observe the same serialization $\sigma$ of $H$.
\item \textbf{Correct Responses}: Read requests return the value of
  the most recent write request to the same location according to $\sigma$.
\item \textbf{Consistent with Program Order}: $\sigma$ is consistent
  with program order: if
  $\memstop{\Op^1} \programorder{i} \memstart{\Op^2}$, the serial
  history must include $\Op^1$ before $\Op^2$.
\end{enumerate}
\end{definition}

Since external order imposes more constraints than program order,
linearizable histories, like those shown in Figure
\ref{fig:dsm-example-2-linearizations}, are always sequentially
consistent.
\begin{lemma}
  \label{lem:linearsequential}
  A linearizable execution is sequentially consistent.
\end{lemma}

The converse of Lemma \ref{lem:linearsequential} does not hold,
meaning some sequentially consistent executions are not
linearizable. As noted earlier, there are only two linearizable
histories of Figure \ref{fig:dsm-example-2}, and they both require all
three read operations to return the same value. Examples
\ref{ex:dsm-example-2-sequential-1} and
\ref{ex:dsm-example-2-sequential-2}, below, demonstrate sequentially
consistent histories where $P_1$ and $P_2$ read non-equal values.

Visually, we can think of sequential consistency as organizing
operations like beads on a string. The worldline of each process is
like its own ``string,'' while the operations occurring in that
process are like ``beads''. Beads on the same string can move forward
or backward in time, but they cannot overtake each other; this
corresponds to respecting the program order of operations. However,
beads on different strings---representing operations from different
processes---are free to slide past each other.  A serialization that
respects program order is any non-overlapping arrangement of
operations that can be obtained in this manner.

\begin{figure}
  \begin{subfigure}{1\textwidth}
    \setlength\belowcaptionskip{4ex}
    \centering
    \input{images/pgf/dsm_ex2_seq1.pgf}
    \caption{Sequentially consistent history where $P_1$ and $P_2$ read different values of $x$}
    \label{fig:dsm-example-2-sequential-1-sub}
  \end{subfigure}
  \begin{subfigure}{1\textwidth}
    \input{images/pgf/dsm_ex2_seq1_serial.pgf}
    \caption{A consistent serialization respecting program order}
    \label{fig:dsm-example-2-sequential-1-serial}
  \end{subfigure}
  \caption{A sequentially consistent history and its consistent serialization}
  \label{fig:dsm-example-2-sequential-1}
\end{figure}

\begin{example}
  \label{ex:dsm-example-2-sequential-1}
  Figure \ref{fig:dsm-example-2-sequential-1} depicts a sequentially
  consistent history of the operations depicted in Figure
  \ref{fig:dsm-example-2}. This history is non-linearizable because
  $P_1$ and $P_2$ read different values for $x$. It is sequentially
  consistent because it returns values consistent with the alternate
  history shown in Figure \ref{fig:dsm-example-2-sequential-1-serial},
  which is sequential because has no overlapping operations. The
  latter can be obtained by ``sliding'' the operations in $P_2$ along
  their worldline so they occur after those in $P_1$.
\end{example}

\begin{figure}
  \begin{subfigure}{1\textwidth}
    \setlength\belowcaptionskip{4ex}
    \centering
    \input{images/pgf/dsm_ex2_seq2.pgf}
    \caption{Sequentially consistent history where $P_2$ reads $x$ with value $4$}
    \label{fig:dsm-example-2-sequential-2-sub}
  \end{subfigure}
  \begin{subfigure}{1\textwidth}
    \input{images/pgf/dsm_ex2_seq2_serial.pgf}
    \caption{A consistent serialization respecting program order}
    \label{fig:dsm-example-2-sequential-2-serial}
  \end{subfigure}
  \caption{A sequentially consistent history and its consistent serialization}
  \label{fig:dsm-example-2-sequential-2}
\end{figure}

\begin{example}
  \label{ex:dsm-example-2-sequential-2}
  Figure \ref{fig:dsm-example-2-sequential-2} depicts another
  sequentially consistent history of the operations in Figure
  \ref{fig:dsm-example-2}. In this example, $P_2$ appears to travel
  backwards in time, reading the stale value $4$ immediately after
  reading $5$. This history is consistent with the sequential history
  shown in Figure \ref{fig:dsm-example-2-sequential-2-sub}.
\end{example}

The time-traveling nature of Example
\ref{ex:dsm-example-2-sequential-2} can be explained by remembering
that the DSM model is implemented in terms of message-passing. $P_2$
may read a stale value of $4$ because of the time it takes for the
memory manager running on $P_1$ to notify $P_2$ about the
$\memwrite{x}{4}$ operation. This notification may not be received
until after $P_2$ performs the $\memreadVal{x}{5}$ operation.

Sequential consistency is an intuitive property for reasoning about
the possible behaviors of distributed programs. Note that each process
in the system issues memory operations in a particular order---these
can be thought of as individual steps in a program. Before the
application is executed on real computers, there is no guarantee about
the relative timing of program steps that run on different computers,
since different machines may run at different speeds. For instance,
before running the program and observing the series of events shown in
Figure \ref{fig:dsm-example-2-sequential-2-sub}, we did not
necessarily know that the $\memwrite{x}{4}$ operation would precede
the $\memwrite{x}{5}$ operation in real-time---they are both the first
steps of their respective programs, with no relation to each
other. The alternate order of events shown in
\ref{fig:dsm-example-2-sequential-2-serial}, where $\memwrite{x}{5}$
precedes $\memwrite{x}{4}$, is just as likely a priori as the one that
was actually observed. Sequential consistency guarantees each program
is always consistent with one of the serializations that can be
expected a priori, before the program is executed and a real-time
external order of events is fixed.

\subsection{The CAP Theorem}
Real-world systems rarely function as a perfectly coherent,
integrated, cohesive system. The gap between idealized system behavior
and real-world behavior stems from a well-understood and fundamental
tradeoff between coherence and performance. The more ``coherence'' we
demand from the system, the more processes have to communicate over
the network, whose unpredictable delays impose overheads that degrade
performance. Conversely, the more we demand immediate answers from our
system, the less time a process has to communicate with other
processes, so the system as a whole does not seem as coherent and
unified to end users.

This tradeoff is made fully stark by considering the possibility that
the network suffers from a partition, which prevents some processes
from communicating with others.

\begin{definition}[Network partition] A \emph{network partition} is a
span of time where some nodes are unable to communicate with another
set of nodes on the network.
\end{definition}

In 1999, Fox and Brewer \cite{1999foxbrewer} articulated a formal
tradeoff between three desirable properties of distributed systems:
consistency, availability, and an ability to function during network
partitions. This observation was formalized and rigorously proven by
Gilbert and Lynch \cite{2002gilbertlynchCAP} in 2002. Despite its
prominence at the heart of distributed systems, and the fact that its
proof is fairly straightforward, the CAP theorem is sometimes
misunderstood, so it is worth clarifying its key terms.

\begin{description}
\item[Consistency] Gilbert and Lynch define consistency as
  linearizability.
\item[Availability] A CAP-available system responds to every client
  request (a read or write operation) in a finite time.
\item[Partition tolerance] A partition-tolerant system continues to
  function in the face of arbitrary partitions inthe network.
\end{description}

In the last case, the possibility is allowed that a partition never
recovers. This could happen if a critical communications cable is
permanently severed, for instance.

The CAP theorem is the simple observation that a distributed system
cannot guarantee all three properties simultaneously: a system that
operates during network partitions cannot ensure both linearizability
and availability. We give only the informal sketch here, leaving the
interested reader to consult the more formal analysis by Gilbert and
Lynch. The key assumption in the proof is that a process's behavior is
only affected by the messages it receives. During a partition, its
behavior is the same regardless of what other processes do, since it
does not communicate with them and cannot be affected by them. Below,
we term this property \emph{behavioral invariance}.

\begin{figure}
  \input{images/pgf/dsm_cap_ex1.pgf}
  \caption{An history where linearizability cannot maintained during a network partition}
  \label{fig:dsm-cap-example-1}
\end{figure}

\begin{theorem}[The CAP Theorem]
  \label{thm:cap}
  If indefinite network partitions are possible, then a distributed
  system cannot guarantee both linearizability and
  eventual availability.
\end{theorem}
\begin{proof}
  Consider the history in Figure \ref{fig:dsm-cap-example-1}. Clearly
  there is only possible linearization of this history:
  $\memwrite{x}{1}$ executes, $\memwrite{x}{2}$ executes, and
  $\memread{x}$ reads the value $2$. Now suppose $P_1$ and $P_2$ are
  separated by a network partition, meaning in particular that $P_1$
  does not receive any messages from $P_2$. This leaves two
  possibilities for how $P_1$ might handle the $\memread{x}$
  operation:
  \begin{enumerate}
  \item $P_1$ can proceed despite the network partition and return a
    value. By behavioral invariance, $P_1$ would have to return
    $\memreadVal{x}{1}$. This is value it would return (by
    linearizability) if there was a network partition and $P_2$ did
    \emph{not} write to $x$, but $P_1$'s is the same regardless of the
    of this operation. Returning $1$ violates linearizability in the
    case above where $P_2$ \emph{does} write to $x$.
  \item $P_1$ might detect (or assume) the network suffers a partition
    and refuse to handle the $\memread{x}$ until it is able to
    communicate with $P_2$ again, whereupon it would learn the correct
    value of $x$ is $2$. However, we do not assume the partition has
    to recover, in which case $P_1$ waits forever, which violates
    availability.
  \end{enumerate}
  Thus, we cannot have both linearizable consistency and
  availability. More precisely, to ensure both of these properties, we
  would have to assume the network never suffers from partitions, but
  this is unrealistic. As discussed in Section
  \ref{sssec:ground-communication}, real-world examples of partitions
  in wildland firefighting environments are common.
\end{proof}

The proof above raises the question of whether the weaker notion of
sequential consistency can be used to avoid being subject to the CAP
theorem. The answer is negative: sequential consistency is also
CAP-unavailabile.

\begin{figure}[p]
  \setlength\belowcaptionskip{5ex}
  \begin{subfigure}{1\textwidth}
    \centering
  \input{images/pgf/dsm_cap_ex2.pgf}
  \caption{An execution that cannot maintain sequential consistency during a network partition}
  \label{fig:dsm-cap-example-2}
  \end{subfigure}
  \begin{subfigure}{1\textwidth}
    \centering
    \input{images/pgf/dsm_cap_ex2_results.pgf}
    \caption{By behavioral invariance, if there is a network partition, the values read for $x$ and $y$ must be their initial values of $0$}
    \label{fig:dsm-cap-example-2-results}
  \end{subfigure}
  \begin{subfigure}{1\textwidth}
    \centering
    \input{images/pgf/dsm_cap_ex2_seq1.pgf}
    \caption{A serial order where $\memreadVal{y}{0}$ precedes $\memwrite{y}{1}$ forces $\memwrite{x}{1}$ to precede $\memreadVal{x}{0}$, violating sequential consistency}
    \label{fig:dsm-cap-example-2-serial1}
  \end{subfigure}
  \begin{subfigure}{1\textwidth}
    \centering
    \input{images/pgf/dsm_cap_ex2_seq2.pgf}
    \caption{A serial order where $\memreadVal{x}{0}$ precedes $\memwrite{x}{1}$ forces $\memwrite{y}{1}$ to precede $\memreadVal{y}{0}$, violating sequential consistency}
    \label{fig:dsm-cap-example-2-serial2}
  \end{subfigure}
  \caption{}
  \label{}
\end{figure}

\begin{lemma}[CAP for sequential consistency]
  \label{thm:cap-sequential}
  An eventually-available system cannot provide sequential consistency
  in the presense of network partitions.
\end{lemma}
\begin{proof}
  Consider the history in Figure \ref{fig:dsm-cap-example-2} and
  suppose all memory locations are initialized to $0$. Following
  similar reasoning as above, behavioral invariance means that if
  $P_1$ and $P_2$ are separated by a partition and remain available,
  $P_1$ has to return $0$ to the request $\memread{y}$---that is the
  value it would return assuming $P_2$ does not write to
  $y$. Likewise, $P_2$ would read $\memreadVal{x}{0}$. However, the
  resulting history, shown in Figure
  \ref{fig:dsm-cap-example-2-results}, is not sequentially
  consistent. For $\memreadVal{y}{0}$ to be consistent, the sequential
  order of operations would have to arrange $\memreadVal{y}{0}$ before
  $\memwrite{y}{1}$---otherwise reading $0$ is incorrect. This results
  in the order shown in Figure \ref{fig:dsm-cap-example-2-serial1},
  which is incorrect because $\memread{x}{0}$ occurs after
  $\memwrite{x}{1}$. The situation is symmetric: to order
  $\memreadVal{x}{0}$ before $\memwrite{x}{1}$ results in an order where
  $\memwrite{y}{1}$ precedes $\memreadVal{y}{0}$ (Figure \ref{fig:dsm-cap-example-2-serial2}).
\end{proof}

\subsubsection{Consequences of CAP}
\label{interpretation-of-the-cap-theorem}
While the CAP theorem is theoretically simple, its implications are
more nuanced than they may appear \cite{2012CAP12Years}. A common
oversimplification is that the CAP theorem is represents a ``choose 2
of 3'' scenario: a system designer can choose at most two of
consistency, availability, and partition resilience. In fact, real
systems may balance weaker forms of all three properties. The CAP
theorem only rules out the combination of all three properties when
each of them is defined in an idealized, rigid way.

In practice, applications often settle for weaker levels of
consistency than linearizability or sequential consistency. We shall
see an example in the next section. Resilience to network partitions
typically requires coping with intermittent, rather than indefinite,
communications failures. Finally, availability is best measured in
terms of actual response time as experienced by the user, and not the
mere assurance that a request will ``eventually'' be handled. Thus,
each of these dimensions is actually quantitative in nature, rather
than an all-or-nothing proposition.

The locality principle is also highly relevant when considering
implications of the CAP theorem for a real system: the closer agents
are located, the more reliable their communications will be in
general, and the more applications can provide consistency and
availability for operations that only require coordinating with nearby
agents. At short time scales, operations that only require local
coordination are common.

\subsection{Causal Consistency}
\label{ssec:causal-memory}
\emph{Causal} consistency, defined by Ahamad et
al. \cite{1995:causal-memory}, is a weaker memory model than
sequential consistency. Whereas sequential consistency requires the
system as a whole to behave as if all write operations take place in
some total order (which must also respect program order), causal
consistency allows different processes to behave as if they witnessed
past write operations take effect in different orders. Only write
operations related by \emph{causal precedence} are required to take
effect in a common order across all processes: ``reads respect the
order of causally related writes.''  \cite{1995:causal-memory}

We have not defined what causal precedence means for memory
operations. The notion is similar in its motivation to causal
precedence in message-passing framework (Definition
\ref{def:causalprecedence}) and the idea of causal broadcast
(Definition \ref{def:causalorder-bcast}) but the definition of
causally related memory operations is not as simple as that of causal
precedence among messages. In message passing, a receive event is
always associated with a unique send event, but multiple processes can
write the same value to the same memory location, and for a later
operation that reads this value, it is not clear which write
``caused'' it. For this purpose we define a \emph{writes-into} order.

\begin{definition}[Writes-into order]
  Let $H$ be a history of memory operations.\footnote{We are treating $H$ as a
  \emph{multiset}, meaning for example that two operations both of the
  form $\memwrite{x}{v}$ are considered distinct.} A ``writes into''
  order $\writesinto$ is any binary relation among the operations in
  $H$ that satisfies the following conditions:
  \begin{itemize}
  \item All pairs of operations related by $\writesinto$ are of
    the form $\memwrite{x}{v} \writesinto \memreadVal{x}{v}$ for
    memory some location $x$ and value $v$.
  \item For each operation of the form $\memreadVal{x}{v}$, there is
    exactly one write operation in $H$ that
    $\memwrite{x}{v} \writesinto \memreadVal{x}{v}$
  \end{itemize}
\end{definition}
Ahamad et al. \cite{1995:causal-memory} give a slightly more complex
definition accomodate operations that read uninitialized memory
locations. For simplicity we assume each memory location is written to
before it is read.

\begin{definition}[Causality order on memory operations]
  \label{def:memorycausalprecedence}
  For a given writes-into order $\writesinto$ on
  $H$, the associated \emph{causality order}
  $\causalityorder$ is the transitive closure of the union of
  $\writesinto$ and program order. That is, if $\Op \causalityorder
  \Op'$, then one of the following holds:
  \begin{itemize}
  \item $\Op \programorder{i} \Op'$ for $P_i$
  \item $\Op \writesinto \Op'$
  \item There is some $\Op''$ such that $\Op \causalityorder \Op''$ and $\Op'' \causalityorder \Op'$
  \end{itemize}
  By fiat, we also require that $\causalityorder$ must not be cyclic,
  meaning their are no ``causality loops'' like
  $\Op \causalityorder \Op' \causalityorder \Op$.  If
  $\Op \causalityorder \Op'$ in a causality order, we say $\Op$
  causally precedes $\Op'$.
\end{definition}

We can now define causally consistent executions of memory
operations. For a history $H$ and each process $P_i$, let $A_i$ be
union of $H|_P$ and the set of all writes in $H$. In other words,
$A_i$ is the local history of $P_i$ plus any write operation on any
other process.

%\begin{figure}[p]
%  \begin{subfigure}{1\textwidth}
%    \centering
%    \input{images/pgf/smEx4S3.pgf}
%    \caption{}
%    \label{fig:smEx4L2}
%  \end{subfigure}
%  \begin{subfigure}{1\textwidth}
%    \input{images/pgf/smEx4S4.pgf}
%    \caption{}
%    \label{fig:smEx4S2}
%  \end{subfigure}
%  \caption{Two non-sequentially-consistent executions of Figure \ref{fig:dsm-example-2}}
%  \label{fig:smEx4-alt}
%\end{figure}

\begin{definition}[Causal consistency]
  \label{def:causalconsistency}
  An execution is causally consistent if each $P_i$ behaves as if it
  observes some serialization of $A_i$ consistent with $\causalityorder$.
\end{definition}

Notably, Definition \ref{def:causalconsistency} does not require that
all processes behave as if they are observing the \emph{same}
serialization.

\begin{example}
  \label{ex:dsm-causal-ex1}
  Figure \ref{fig:dsm-causal-ex1} depicts a causally consistent
  history of the operations in Figure \ref{fig:dsm-example-2}. The
  writes-into order is depicted with dotted edges. This example is not
  sequentially consistent: if it were, then $\memwrite{x}{5}$ must be
  ordered after $\memwrite{x}{3}$ and before $\memreadVal{x}{5}$
  (otherwise the latter return value is incorrect). However, both
  $\memread{x}{3}$ operations must be ordered after $\memwrite{x}{5}$
  (by program order), and therefore $3$ is not the most recent value
  of $x$ and these operations return incorrect values.
\end{example}

\begin{figure}
  \setlength\belowcaptionskip{5ex}
  \begin{subfigure}{1\textwidth}
    \centering
    \input{images/pgf/dsm_causal_ex1.pgf}
    \caption{A causally consistent history\ref{fig:dsm-example-2} with a writes-into order shown with dotted edges}
    \label{fig:dsm-causal-ex1}
  \end{subfigure}
  \begin{subfigure}{1\textwidth}
    \centering
    \input{images/pgf/dsm_causal_ex1_serial1.pgf}
    \caption{A serialization consistent with the values read by $P_1$}
    \label{fig:dsm-causal-ex1-serial1}
  \end{subfigure}
  \begin{subfigure}{1\textwidth}
    \centering
    \input{images/pgf/dsm_causal_ex1_serial2.pgf}
    \caption{A serialization consistent with the values read by $P_2$}
    \label{fig:dsm-causal-ex1-serial2}
  \end{subfigure}
  \caption{A causally consistent but sequentially inconsistent history}
\end{figure}

Causal consistency not subject to the limits of the CAP theorem.

\begin{lemma}[Causal consistency is CAP-available]
  \label{thm:cap-causal}
  Causal consistency can be enforced during network partitions. That
  is, causal consistency is not subject to the CAP thereom.
\end{lemma}
\begin{proof}
  Consider two processes that execute read and write operations purely
  locally. That is, they never send messages to other processes, and
  they always read the most recent value they have written to a
  location, regardless of what other processes do.

  This situation is always causally consistent for the causality
  relation generated by the empty writes-into order. If the
  writes-into order is empty, each process only has to be consistent
  with some serial order of write operations, and processes do not
  have to agree on this order. In particular, each $P$ is
  consistent with a serialization where all write operations issued by
  other processes are executed \emph{after} all of $P$'s own read
  operations.
\end{proof}

The proof of the Lemma \ref{thm:cap-causal} speaks mostly to the
weakness of causal consistency. In the proof, different processes are
allowed to deviate arbitrary far from consistency with each other, in
the sense that no processes need to agree on anything about the order
of write operations---at any moment in time, they may read wildly
different values for the same logical memory location, instead of
maintaining a common operating picture. As a result, causal
consistency is too weak to place any kind of bound on the divergence
of two processes, which suggests it is not strong enough for the kinds
of safetly-related applications we have in mind. This issue will be
addressed in Section \ref{sec:continuous-consistency}.

\subsection{Section Summary}
\label{ssec:background-summary}
This discussion has explored the key challenges involved in building
distributed systems that connect geographically dispersed components
over unpredictable networks. The variability in message delays,
particularly in the context of broadcasts sent to multiple recipients,
can result in messages that arrive in different orders.  This
situation can lead to chaos if a message-ordering discipline is not
imposed.

To mitigate the effects described above, distributed systems must
track the causal precedence relation between events. Because physical
clocks are not generally reliable enough for this purpose, especially
at fine time scales, logical clocks---scalar, vector, and matrix
clocks---are typically used, each with a different tradeoff in terms
of precision of the information tracked and the administrative and
messaging overhead. If groups can change dynamically, as in our use
cases, then additional group membership protocols are needed to ensure
that all processes know which other processes are participating in the
system at any moment.

Programmers may find it easier to frame distributed applications in
terms of reading and writing from a shared pool of virtual memory,
rather than sending messages, by employing the distributed shared
memory or DSM abstraction. However, the fact that many processes can
access the same virtual memory locations at the same time makes it
challenging to maintain systemwide coherence. Strong consistency
models like linearizability and sequential consistency provide the
illusion of a single, unified source of truth, but the CAP theorem
makes it virtually impossible to guarantee these properties over
chaotic, disruption-prone networks. Weaker models like causal
consistency are not subject to the same limitations, but they do not
enforce any limits bounding how far apart data replicas can
diverge. This renders weaker models potentially unsuitable for
safety-critical applications like we aim to build.

In summary, there is no free lunch in distributed systems. Designing
resilient distributed systems for emergency response scenarios
requires a careful balancing act between competing properties that is
carefully calibrated to the use case and the operational environment.

\section{Continuous Consistency}
\label{sec:continuous-consistency}
In this section, we present a \emph{continuous} consistency model
developed by Yu and Vahdat \cite{2002tact} that we argue is
well-suited for distributed shared memory across a wide area connected
by disruption-prone networks. Rather than viewing consistency as an
all-or-nothing proposition, continuous consistency makes the
consistency/availability tradeoff first class by providing conceptual
knobs and dials to ``tune'' the strength of the model based on the
application and the capacity of the network.

Before we present the memory model, we present a key mechanism that
can be used to implement it: Golding's Timestamped Anti-Entropy (TSAE)
protocol \cite{1992:golding-thesis}. TSAE is a \emph{weak consistency
  group communication} mechanism that provides a form of multicasting
to applications. We picture TSAE as a key driver of communication
across a distributed system supporting first responders across a
region or state during a wide-area event, like the kind discussed in
Section \ref{sec:disaster-response}. Such a system might track
firefighters' locations, monitor a wildfire's boundaries, disseminate
weather data, and orchestrate resource deployment. In this context,
TSAE would have responsibility for ensuring that every multicast
update eventually reaches each of its intended recipients.

TSAE provides reliable eventual delivery, which makes it useful as a
fault-tolerant messaging component in an implementation of distributed
shared memory. Because updates are merely propagated
\emph{eventually}, TSAE used this way does not bound the divergence of
each replica from the ``ideal'' value of the shared state (the value
it would have if strong consistency were maintained). However,
following Yu and Vahdat \cite{2002tact}, we show how an implementation
of the conit (consistency unit) model on top of TSAE can be used to
enforce, through so-called compulsory anti-entropy sessions,
consistency requirements on this message propagation component.

\subsection{Timestamped Anti-Entropy}
\label{ssec:tsae}
Golding's thesis \cite{1992:golding-thesis} presents TSAE as one
component of a broader toolkit for developing distributed
applications. Before laying out the algorithm itself, it is useful to
consider what services it provides from the perspective of an
application developer. We imagine a group of cooperating processes,
referred to by Golding as ``principals,'' managing shared state and
communicating through message exchange. These messages are an
application-specific construct and might contain things like
instructions to update a database. These may not map one-to-one with
low-level network messages like those discussed in Section
\ref{ssec:message-passing}, which we think of as analogous to Internet
Protocol (IP) packets. Note that an IP packet might contain multiple
application messages, and a large application message may be split up
into multiple packets.

At a lower level, we assume the network supports point-to-point
(unicast) communication, but it does not have to guarantee FIFO
ordering and may duplicate network messages, though it does not
spontaneously create new ones. The network may not be reliable, but we
assume that persistent attempts to communicate with a distant node
will eventually succeed. The network might support native multicasting
of network-level msharedessages, which could be used as part of an
implementation of TSAE, but the TSAE layer itself provides a form of
application-level multicasting regardless of the network
infrastructure.

A typical use case of TSAE is to maintain replicas of a shared
database at multiple sites throughout the system. This database is
updated according to some logical data model, such as a relational
schema, a key-value store, or a document store. For simplicity, we
will assume that every process maintains a complete replica of the
data. Each process may submit an update by sending a message (at the
application level, using TSAE) announcing it. TSAE ensures that this
message is eventually delivered to every process; when this happens,
the recipient applies the update to its own replica. Of course, the
semantic meaning of updates is entirely decided by the
application. If, for instance, the underlying data model required
updates to be applied in the same order at all sites to ensure they
reach the same final state, then the application would combine TSAE
with a total ordering component to ensure that messages are received
in the same order everywhere, as we do in
\ref{sssec:tsae-message-ordering}.

Replication is an alternative to managing state in a central location,
such as a datacenter. This provides resiliency by removing single
points of failure. It supports scalability by allowing any process
with a replia to deliver services to clients, distributing the
load. Finally, replication exploits locality (introduced in Section
\ref{ssec:communication-patterns}) because by servicing user requests
at the nearest replica, we can rely on communications links that are
generally faster and more reliable.

One highly relevant use case of globally replicating state is to
support offline usage of applications. This represents taking locality
to its limit. Agents in the field may not be able to connect to a
datacenter, but in the meantime they can interact with the application
on their device backed by a local replica of the data. This is useful
for as long as the agents can be confident that their replica has not
diverged too far from the rest of the system. A key point is that this
is an application-level matter. How quickly shared state evolves, how
to quantify divergence, and how far apart is ``too'' divergent are
determined by user intent, usage patterns, and operational
environment, among other things. The advantage of the framework
presented in this section is that the middleware provides the
application with flexible methods for tuning consistency guarantees,
allowing these decisions to be encoded into the application logic on a
per-process basis.

We now present TSAE in terms of its assumptions
(\ref{sssec:tsae-assumptions}), data structures and invariants
(\ref{sssec:tsae-message-log}--\ref{sssec:tsae-acknowledgement})
ordering component (\ref{sssec:tsae-message-ordering}), and storage
recycling procedure (\ref{sssec:tsae-message-purging}). Finally, we
discuss how version matrices can be used instead of the loosely
synchronized physical clocks assumed below
(\ref{sssec:tsae-unsynchronized}).

\subsubsection{Assumptions}
\label{sssec:tsae-assumptions}
We assume each process is associated with an identifier. In practice,
these might be Uniform Resource Identifiers (URIs) \cite{rfc3986}
following a structured format like
\texttt{firefighter116@<agency>.<state>.us}. However, in the text we
will not make a distinction between a process $P$ and its
identifier. The first assumption we make is as follows:
\begin{quote}
  \textbf{Static process group}: The set of group members is a fixed
  set of processes $\mathcal{P} = \{P_1, P_2, \ldots P_n\}$ where the
  identifier of each process is known to all of them.
\end{quote}
Golding's thesis describes how to connect TSAE with a dynamic group
membership management component, but we do not describe it here for
simplicity.

The second assumption we make is that processes have nearly
sychronized clocks. We write $\clock{P, t}$ for the clock value at $P$
at real time $t$.
\begin{quote}
  \textbf{Loose clock sychronization}: Processes' physical clocks are approximately
  synchronized, meaning the clocks of any two processes differ by at
  most some small constant $\delta$:
  \[ \forall t,\, \forall P, Q \in \mathcal{P}, |\clock{P, t} - \clock{Q, t}| < \delta
  \]
  The clock resolution must be fine-grained enough for each principal
  to assign unique timestamps to all important events occurring in
  that process.
\end{quote}

Though physical clock synchronization is not a reliable assumption in
all contexts, we expect that for many useful purposes, sufficient
synchronization can be achieved with a protocol like NTP.  Section
\ref{sssec:tsae-unsynchronized} explains how synchronized physical
clocks can be replaced with version matrices at the cost of quadratic
storage requirement. Our sense is that for our purpose of implementing
continuous consistency in Section \ref{ssec:consistency-units},
conventional scalar logical clocks can be used in place of physical
clocks below.\footnote{Golding's requirement for synchronized clocks
  stems from a need to ensure that messages are delivered in a
  reasonable time, since messages originating at a process with a fast
  clock may never be delivered (from a database point of view,
  tentatively applied writes may never become committed). However, the
  conit framework below bounds the number of uncommitted writes by
  pull-based compulsory anti-entropy, so it is enough that these
  sessions ensure progress.} Indeed, this seems to be how Yu and
Vahdat \cite{2000tact} implement TSAE as part of their TACT
framework. The real-time consistency metric discussed in
\ref{sssec:conit-real-time-consistency} requires each process to keep
a physical clock to measure elapsed time, though synchronization does
not appear to be strictly required here either, assuming each clock
runs at a consistent rate. We assume synchronization here to follow
Golding's presentation, highlighting where the assumption is used.


\subsubsection{Message Log}
\label{sssec:tsae-message-log}
Each process $P$ manages a \emph{message log} containing all messages
sent or received by $P$.\footnote{Some implementations of TSAE may not
  require a message log and can operate directly on the shared state
  to achieve the same effect, but we describe TSAE in the most general
  case here.} We denote $P$'s message log by $\WL{P}$. Each message in
$\WL{P}$ is tagged with the identifier of the process that originally
created it. The subset of messages in $\WL{P}$ that originated at $Q$
is denoted by $\WLat{P}{Q}$. Thus, $\WLat{P}{P}$ represents the set of
messages created by $P$. The set of global messages, $\W$, is defined
as the (disjoint) union of messages originating from every process:
\[\W \equiv \bigcup_{X \in \AllProc} \WLat{X}{X}.\]

The application at $P$ broadcasts a message $m$ using TSAE by writing
$m$ into $\WL{P}$. We call this event the \emph{submission} of $m$ and
say that $m$ originates at $P$. At the time of submission, the message
is tagged with a pair $(P, \clock{P,t})$ containing $P$'s identifier
and current clock value. The timestamp of $m$ is denoted by
$\timestamp{m}$.

Submitted messages are not sent to other processes right away, but
propagate by a fairly straightforward protocol. Periodically, $P$
contacts some other process $Q$ and the pair conduct an
\emph{anti-entropy session}. First, $P$ and $Q$ exchange summary
vectors, defined below. $P$ uses $Q$'s summary vector to quickly
calculate which messages in $\WL{P}$ are not already known to $Q$ and
then transmits these messages to $Q$. Symmetrically, $Q$ forwards
messages in $\WL{Q}$ that $P$ has not seen, leaving the two sides in
synchronization afterwards.\footnote{In a multithreaded environment
  where $P$ and $Q$ can engage in multiple anti-entropy sessions with
  different partners at once, the two sides may end in different
  states. For instance, $P$ may learn about new messages in an
  anti-entropy session with $R$ during its session with $Q$. Later, we
  also consider one-sided anti-entropy sessions that only push or pull
  messages. }

TSAE provides reliable eventual delivery, meaning every message is
eventually received by every process, as long as no process fails and
no partition indefinitely separates any two nodes. In particular, if
processes stop originating new messages so $\W$ remains fixed, if
processes remain able to communicate, then $\WL{P}$ is guaranteed to
eventually converge to $\W$. To achieve this, it is enough that each
pair of processes engage in anti-entropy periodically. This can
actually be relaxed by transitivity: it is enough that they
periodically engage in anti-entropy with a mutual partner, or with two
other processes that engage in anti-entropy with each other, and so
on. TSAE itself does not prescribe a particular policy regarding when
and with whom to engage in anti-entropy, however. Consequently, it
does not guarantee or estimate how far apart $\WL{P}$ is from
$\WL{Q}$, or from $\W$. The framework in Section
\ref{ssec:consistency-units} prescribes a policy for TSAE based on
conservative estimates of divergence in order to enforce these sorts
of limits.

Note that the guarantee of eventual delivery only ensures that
$\WL{P}$ converges to $\W$ as a \emph{set}. However, in general, we
think of $\WL{P}$ as a linear structure, with messages entered into
$\WL{P}$ in the order they were received by $P$. Thus, when $\WL{P}$
and $\WL{Q}$ eventually converge, it is more correct to say they will
be permutations of each other rather than equal. For applications that
require messages to be delivered in a particular order, like a total
order, an ordering component is used, as in
\ref{sssec:tsae-message-ordering}.

Figure \ref{fig:message-log} shows a message log for containing six
messages from three processes $A$, $B$, and $C$. Note that the log is
linearly ordered. For readability it is convenient to depict logs
whose contents are disaggregated by sender (Figure
\ref{fig:message-log-b}). Disaggregation has the downside of obscuring
the fact that message logs with the same contents may be arranged in
different orders, as the reader should keep in mind.

\begin{figure}
  \setlength\belowcaptionskip{5ex}
  \begin{subfigure}{1\textwidth}
    \centering
    \includegraphics[width=0.6\textwidth]{images/MessageLog1.png}
    \caption{A message log with entries accumulating linearly}
    \label{fig:message-log-a}
  \end{subfigure}
  \begin{subfigure}{1\textwidth}
    \centering
    \includegraphics[width=0.6\textwidth]{images/MessageLog2.png}
    \caption{The same message log shown with messages from different senders disaggregated}
    \label{fig:message-log-b}
  \end{subfigure}
  \caption{A message log displayed linearly and disaggregated}
  \label{fig:message-log}
\end{figure}


\subsubsection{The Summary Vector and Its Invariant}
\label{sssec:tsae-summary-vectors}
Besides the message log, the delivery component a \emph{version
  vector} $\summaryVec{P}$ whose role is to quickly communicate to
other processes which messages $P$ has already received. This
structure is very similar to a vector clock, except for one minor and
one more fundamental difference. First, the version of TSAE presented
here stores physical rather than logical clock values, although this
is a non-essential difference and we relax this assumption later. A
more fundamental distinction is that while a vector clock tracks
causality between events and increments the local clock with each
event, here the value $\summary{P}{P}$ tracks the set of messages sent
by $P$ and follows a slightly different update procedure than the ones
described in \ref{sssec:vector-clocks}. Unlike a vector clock,
$\summary{P}{P}$ not incremented when $P$ receives a message from
another process. At all times, $\summary{P}{P}$ is an upper bound on
the timestamp $\clock{P,t}$ of $P$'s most recent message. As with
vector clocks, $\summary{P}{Q}$ can be thought of as $P$'s lower bound
view of $\summary{Q}{Q}$.

When $P$ submits a message to its own log, $\summary{P}{P}$ is
advanced to $\clock{P, t}$ and the message is timestamped with this
value. At some point in the future, $P$ contacts some other process
$Q$ to initiate an anti-entropy session. We conceptualize this process
as happening in three phases (setup, message exchange, and conclusion):
\begin{enumerate}
\item $\summary{P}{P}$ is advanced to $\clock{P, t}$. Symmetrically,
  $\summary{Q}{Q}$ is advanced to $\clock{Q, t}$. The parters exchange summary vectors.
\item For each process $X \in \AllProc$, $P$ sends to $Q$ the set of
  messages in $\WLat{P}{X}$ with timestamps greater than
  $\summary{Q}{X}$. Likewise for each $X$ it receives all messages
  from $\WLat{Q}{X}$ with timestamps greater than $\summary{P}{X}$ and
  adds these to $\WL{P}$. The partners exchange signals when
  they are finished sending new messages.
\item Much like a vector clock, $\summaryVec{P}$ is set to the pointwise maximum of its
  current value and the value of $\summaryVec{Q}$ received from $Q$. Likewise
  $Q$ updates $\summaryVec{Q}$.
\end{enumerate}
There is additionally bookkeeping related to another structure, the
acknowledgement vector, but we summarize its role later.

The message log satisfies an invariant, termed the coverage property,
formalizing the role of $\summaryVec{P}$ as a summary of the contents
of $P$'s message log.
\begin{quote}
  \textbf{Coverage Property}: $P$ has received all messages
  originating at $Q$ whose timestamps are less than the
  $Q^\textrm{th}$ entry in $P$'s summary timestamp vector.
  \[ \{m \in \WLat{Q}{Q} | \timestamp{m} \leq \summary{P}{Q} \} \subseteq \WLat{P}{Q} \]
\end{quote}
The previous subset relation is usually an equality and can be thought
as an equality ``morally.'' When equality holds, then besides forming
a lower bound of $\summary{Q}{Q}$, $\summary{P}{Q}$ can be thought of
as an \emph{upper} bound of the originating time, measured by $Q$'s
clock, of the last message $P$ received from $Q$. In this case,
$\summary{P}{Q}$ provides complete information about the contents of
$\WL{P}$. However, technically, only the subset property is required
for correctness. This observation is relevant to avoid subtle race
conditions: implementations can safely add messages to $\WL{P}$ before
$\summaryVec{P}$ is updated but not vice versa. Section 5.4.3 of
Golding's thesis also describes a situation where an optimized version
of TSAE that is combined with an unreliable network-level multicast
can lead to situations where some messages are added to $\WL{P}$
``early,'' in which case the above property is a strict subset
relation.

The reader should convince themselves that the following inequalities
hold at all times for all $P$ and $Q$ (including when $P = Q$):
\[
  \max_{m \in \WLat{P}{Q}}\left({\timestamp{m}}\right) \leq \summary{P}{Q} \leq \summary{Q}{Q} \leq \clock{Q,t}.
\]

\begin{example}
  \label{example:tsae}
  Figures \ref{fig:tsae1}---\ref{fig:tsae6} depict the evolution of
  TSAE executing across three distributed processes $P$, $Q$, and
  $R$. The figures depict the following chain of events beginning at
  $t = 3$. Note that by $t = 9$, $A$ learns of writes submitted with
  $C$ without performing direct communication with $C$. The figures
  also depict acknowledgment vectors, shown in red, and what we later
  term the commit line, shown underlined. These are explained below.

  \begin{centering}
    \begin{tabular}{rl}\\
      \textbf{Time}    & \textbf{Action} \\
      $t = 1$   & $A$ submits a write                                            \\
      $t = 2$   & $B$ and $C$ submit writes                                      \\
      $t = 3$   & $B$ submits a write                                            \\
      $t = 4$ & $A$ and $B$ begin anti-entropy and swap summary vectors \\
      $t = 5$ & $B$ submits a new write  \\
      $t = 6$ & $A$ and $B$ finish anti-entropy, $C$ submits a write \\
      $t = 7$ & $B$ and $C$ begin anti-entropy, $A$ submits a write \\
      $t = 8$ & $B$ and $C$ finish anti-entropy, $A$ and $B$ begin anti-entropy \\
      $t = 9$ & $A$ and $C$ finish anti-entropy
    \end{tabular}
  \end{centering}
\end{example}

\begin{landscape}
  \begin{figure}%For some reason this empty figure adds vertical whitespace that makes the next figure positioned similarly to the ones that follow it.
  \end{figure}
  \begin{figure}[h]
    \centering
    \includegraphics[width=1.4\textwidth]{images/tsaenew/TSAE3.png}
    \caption{TSAE at time $t=3$.}
    \label{fig:tsae1}
  \end{figure}
  \begin{figure}[h]
    \centering
    \includegraphics[width=1.4\textwidth]{images/tsaenew/TSAE4.png}
    \caption{TSAE at time $t=4$. $A$ advances $\summary{A}{A}$ to $\clock{A, t} = 4$ and likewise for $B$. After exchanging summary vectors, the participants decide to exchange the shaded messages.}
    \label{fig:tsae2}
  \end{figure}
  \begin{figure}[h]
    \centering
    \includegraphics[width=1.4\textwidth]{images/tsaenew/TSAE5.png}
    \caption{TSAE at time $t=5$. $B$ has submitted a message with timestamp
      $t = 5$ while $A$ and $B$ are still engaged in an anti-entropy
      session in the background.}
    \label{fig:tsae3}
  \end{figure}
  \begin{figure}[h]
    \centering
    \includegraphics[width=1.4\textwidth]{images/tsaenew/TSAE6.png}
    \caption{TSAE at time $t=6$. $A$ and $B$ have finished their session and updated their summary vectors. Neither $A$ nor $B$ can update their commit line past $0$ because they both contain $\summary{}{C} = 0$, indicating they have not seen any messages from $C$. $C$ submits a message with timestamp $t = 6$.}
    \label{fig:tsae4}
  \end{figure}
  \begin{figure}[h]
    \centering
    \includegraphics[width=1.4\textwidth]{images/tsaenew/TSAE7.png}
    \caption{TSAE at time $t=7$. $B$ and $C$ update and exchange summary vectors before decided to exchange the shaded messages. $A$ submits a message with timestamp $t = 7$.}
    \label{fig:tsae4}
  \end{figure}
  \begin{figure}[h]
    \centering
    \includegraphics[width=1.4\textwidth]{images/tsaenew/TSAE8.png}
    \caption{TSAE at time $t=8$. $B$ and $C$ finish their anti-entropy session. Both sides can update their commit line to $4$, since they have seen all messages $m$ such that $\timestamp{m} \leq 4$. $A$ and $B$ begin anti-entropy, exchanging updated summary vectors and exchanging the shaded boxes.}
    \label{fig:tsae6}
  \end{figure}
  \begin{figure}[h]
    \centering
    \includegraphics[width=1.4\textwidth]{images/tsaenew/TSAE9.png}
    \caption{TSAE at time $t=9$. $A$ and $B$ finish their anti-entropy
      session and have both seen all messages with timestampsless than
      or equal to $t = 7$. $B$ and $C$ can remove all messages with
      timestamps less than or equal to $4$ from their logs, since they
      both have minimum entries $\ack{}{C} = 4$. $C$ has received the
      same messages as $A$ and $B$, but has not witnessed $A$
      acknowledging them.}
    \label{fig:tsae6}
  \end{figure}
\end{landscape}

\subsubsection{The Acknowledgement Vector}
\label{sssec:tsae-acknowledgement}
$P$'s summary vector enables another process to quickly learn which
messages $P$ has seen. Additionally, $P$ must keep tabs on which
messages \emph{other} processes have seen. This information is
critical for the message ordering and log recycling components of
TSAE. Golding presents two ways to maintain this information, which
make different efficiency tradeoffs.

Arguably the simplest approach is for $P$ to maintain a local copy,
called $P$'s \emph{view}, of the summary vector of every other
process. During anti-entropy sessions, $P$ exchanges and updates its
view of each process, effectively tracking a lower bound estimate of
their current state. This leads to the idea of a version matrix, but
it has the downside of a per-process space requirement quadratic in
the size of the process group. This approach is considered further in
\ref{sssec:tsae-unsynchronized}.

The other mechanism presented requires each process $P$ maintain an
\emph{acknowledgement vector} $\ackVec{P}$. The basic idea is to
coarsely estimate $P$'s knowledge of other processes not with its
summary vector, but the minimal element in this vector, a scalar,
which is stored in $\ack{P}{P}$. For reasons explained in
\ref{ssec:consistency-units}, this value is called $P$'s \emph{commit
  line}. Periodically, $P$'s commit line is updated to the minimal
timestamp in its summary vector,
$\min_{X \in \AllProc} \left(\summary{P}{X}\right)$.  For correctness,
the invariant required of $\ack{P}{P}$ is that it is always a lower
bound.
\begin{quote}
  \textbf{Acknowledgement Property}: $P$'s commit line is less than or
  equal to the minimum value in $P$'s summary vector.\footnote{The
    inequality here can be thought of as morally an equality. It may
    be a strict inequality while $P$ is updating $\summaryVec{P}$
    before recomputing its minimum. Recall $P$ may be multi-threaded
    with multiple anti-entropy sessions affecting $\summaryVec{P}$ at
    the same time.}
\[ \ack{P}{P} \leq \min_{X \in \AllProc} \left(\summary{P}{X}\right)\]
\end{quote}

Acknowledgment vectors are updated during anti-entropy sessions much
like vector clocks and version vectors.
\begin{enumerate}
\item At the beginning of the session, $\ack{P}{P}$ is advanced to
  $\min_{X \in \AllProc} \left(\summary{P}{X}\right)$. Symmetrically
  for $Q$. $P$ and $Q$ exchange acknowledgement vectors alongside
  their summary vectors.
\item At the end of the session, $P$ sets $\ackVec{P}$ and to the
  pointwise maximum of its current value and the value of $\ackVec{Q}$
  received from $Q$. $Q$ updates $\ackVec{Q}$ symmetrically.
\end{enumerate}
Note that $\ack{P}{Q} \leq \ack{Q}{Q}$ at all times for all $P$ and
$Q$. The following two lemmas explain the utility of $\ackVec{P}$ as a
way of estimating global state.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{lemma}
  \label{lem:commitline}
  $P$ has received all messages (from any sender) with timestamps less
  than or equal to its commit line $\ack{P}{P}$.
\end{lemma}
\begin{proof}
  Let message $m$ originate at $Q$ with timestamp
  $\timestamp{m} \leq \ack{P}{P}$. Then
  \[\timestamp{m} \leq \ack{P}{P} \leq \min_{X \in
      \AllProc}\left(\summary{P}{X}\right) \leq\summary{P}{Q}.\] The
  coverage property implies $m \in \WL{P}$.
\end{proof}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{lemma}
  \label{lem:ack-vector}
  For all messages $m$, if $\timestamp{m} \leq \ack{P}{Q}$, then $Q$
  has received $m$.
\end{lemma}
\begin{proof}
  Now $\timestamp{m} \leq \ack{P}{Q} \leq \ack{Q}{Q}$. By Lemma
  \ref{lem:commitline}, $Q$ has received $m$.
\end{proof}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%


When a message $m$ in the write log satisfies
$\timestamp{m} \leq \ack{P}{P}$, $P$ is said to have
\emph{acknowledged} $m$. In light of Lemma \ref{lem:commitline}, all
acknowledged messages have been received. The converse does not hold,
since a received message will not be acknowledged until each entry in
$\summaryVec{P}$, not just the entry of its sender, is greater than
$\timestamp{m}$. We now explain how acknowledged messages can be
delivered and ultimately purged from $\WL{P}$, before considering the
matrix-based alternative to acknowledgement vectors.

\subsubsection{Message Ordering}
\label{sssec:tsae-message-ordering}
TSAE guarantees that messages will eventually be received by all other
processes, but ordering of these messages in different processes' logs
may vary. In some applications this is acceptable, but other
applications require more control over delivery order. Recall from
Section \ref{ssec:message-ordering} that to enforce ordering
guarantees, a distinction is made between message receipt and
delivery. A message ordering layer buffers incoming messages upon
receipt, giving time for slower messages to catch up to faster ones,
before delivering them to the application in a predictable order.

The message ordering component of TSAE periodically inspects $\WL{P}$
and delivers messages to $P$ when ready. To enforce total order, this
component delivers all messages whose timestamp is less than or equal
to $P$'s commit line. That is, the set of messages satisfying
\begin{equation}
  \label{eq:tsae-message-ordering-condition}
  \timestamp{m} \leq \ack{P}{P}
\end{equation}
These messages are delivered to $P$ order of their timestamps, using
the identifiers of their senders to resolve ties. The correctness of
this approach follows from Lemma \ref{lem:commitline}, since $P$ has
seen all messages whose timestamp is less than $\ack{P}{P}$, and
therefore the stream of delivered messages will not have any ``gaps.''
This mechanism for enforcing a total order dates back to the
introduction of scalar clocks \cite{1978:lamportclocks}. Golding also
describes straightfoward mechanisms to enforce causal and total-causal
order in Section 5.5 in his dissertation. The ordering component
guarantees messages will eventually be delivered:
\begin{lemma}
  Every message will eventually be delivered to $P$ by TSAE.
\end{lemma}
\begin{proof}
  Assuming periodic anti-entropy sessions, the process in
  \ref{sssec:tsae-message-log} ensures each message is eventually
  received by $P$ and each value of the form $\summary{P}{Q}$
  eventually increases. Thus, the minimum entry in $\summaryVec{P}$
  will eventually increase beyond $\timestamp{m}$, so each $m$ will be
  delivered as long as the ordering component runs periodically.
\end{proof}

Golding's assumption of loose clock synchronization is driven by a
practical need to ensure messages are delivered in a timely fashion
instead of just eventually. For example, if $Q$ has an exceptionally
slow clock compared to other processes, then $\summary{P}{Q}$ will
remain the minimum element in $\summaryVec{P}$ for a long time. During
this time, only messages from $Q$ will be delivered to $P$, as all
other messages would have timestamps greater than $Q$'s clock.

A message simply cannot be removed from the write log after being
delivered to $P$, because some of the messages in $\WL{P}$ may still
need to be propagated to new recipients during anti-entropy in the
future. Consequently, the ordering component must perform bookkeeping
to remember which messages in the log have already been delivered.

\subsubsection{Message Purging}
\label{sssec:tsae-message-purging}
As presented, the message log at each host grows without limit, so it
requires an unbounded amount of storage. Thus, a separate log
recycling process can be used to remove old entries when they are no
longer required.

There are two requirements for a message to be safe to delete. First,
it clearly must have been delivered to $P$ already. Additionally, it
must have been received by all other processes---otherwise it might be
one of the messages $P$ should send in a future anti-entropy
session. $P$ will know a message $m$ has been acknowledged by all
other processes when its timestamp is less than or equal to $P$'s
\emph{purge line}, defined as the minimum entry in the acknowledgment
vector:
\begin{equation}
  \label{eq:tsae-message-purging-condition}
  \timestamp{m} \leq \min_{X \in \AllProc} \left( \ack{P}{X} \right)
\end{equation}

The safety of this deletion procedure is proven by the following
lemma.
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{lemma}[Log purging]
  \label{lem:purge}
  $P$ can safely discard all messages in $\WL{P}$ with timestamps less
  than or equal to its purge line, after they have been delivered.
\end{lemma}
\begin{proof}
  Let message $m \in \WL{P}$ originate at $R$ with timestamp less than
  $P$'s purge line. Now the following inequalities hold for all $Q$:
  \[ \timestamp{m} \leq \min_{X \in \AllProc}\left(\ack{P}{X}\right)
    \leq \ack{P}{Q}.\] Therefore, by Lemma \ref{lem:ack-vector}, $m$
  has been delivered to $Q$. Since $Q$ is arbitrary, $m$ has been
  received everywhere (where it will eventually be delivered as well)
  and can be purged from $\WL{P}$ to reclaim storage space.
\end{proof}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
On the other hand, if $m$ has a timestamp greater than $\ack{P}{Q}$,
then without knowing the current value of $\summaryVec{Q}$, there is
no guarantee $\timestamp{m} < \summary{Q}{X}$, where $X$ is the
originator of $m$. In this case, deleting $m$ from $\WL{P}$ might
prevent $Q$ from ever receiving $m$.

Because every message is eventually delivered and acknowledged by each
process, $P$ will eventually be able to remove each message from its
log. It is still possible for $\WL{P}$ to grow without bound if the
rate of message arrival exceeds the speed at which they are
purged. This might occur during periods of heavy usage or during a
network partition, as $P$ will eventually become unable to advance
$\ack{P}{Q}$ further if $Q$ is on the other side of a partition. The
storage requirements of the message log in a particular use case and
environment should be measured empirically as part of an application
optimization strategy.

\subsubsection{TSAE using Version Matrices}
\label{sssec:tsae-unsynchronized}
If clocks are not approximately synchronized, the clock value at one
process may greatly exceed that of another. Because the minimal entry
in $\summaryVec{P}$ is used to concisely summarize which messages $P$
has seen, if $Q$ has a very fast clock, messages $P$ receives from $Q$
may not ever be acknowledged, since the minimal entry will remain less
than $\summary{P}{Q}$ for a long time.

Rather than concisely summarizing which messages $P$ has seen using
the minimum entry in $\summaryVec{P}$, the entire vector offers a more
precise measure. For $P$ itself, that means tracking what other
process know about by keeping a copy of $\summaryVec{Q}$ for each $Q$
in the system. Thus, we do away with $\ackVec{P}$ and track what other
processes know using a vector-of-vectors, to say a matrix, that we
call $\ackMatrix{}$. Since $\summaryVec{}$ is a version vector, then
$\ackMatrix{}$ can be called a version matrix.

With this implementation strategy, $\ackMatrix{P}[P]$ stores $P$'s
summary vector. $\ackMatrix{P}\left[Q\right]$ represents $P$'s lower
bound estimate of $Q$'s summary vector, with $\ackMatrix{P}[Q][R]$
providing a lower bound estimate of the greatest timestamp of any
message $Q$ has received from $R$. Matrices are exchange during
anti-entropy sessions just as before, with both sides taking the
pointwise maximum after.

Altogether, $P$ applies the following (conservative) policies:
\begin{itemize}

\item A message with timestamp $m$ is ready to be delivered to $P$ by a total
  ordering component when the following analogue of \eqref{eq:tsae-message-ordering-condition} holds:
  \[\timestamp{m} \leq \min_{X \in \AllProc} \left(\ackMatrix{P}[P][X]\right)\]
\item A message $m$ originating at $R$ has been
  received by $Q$ when the following condition holds:
  \[ \timestamp{m} \leq \ackMatrix{P}[Q][R] \]
\item A message $m$ originating at $R$, after being delivered to $P$,
  can be purged from the log when the following analogue of
  \eqref{eq:tsae-message-purging-condition} holds:
  \[ \timestamp{m} \leq \min_{X \in \AllProc}\ackMatrix{P}[X][R]\]
\end{itemize}

Of course, matrices require $\Theta(n^2)$ storage at each site for a
process group with $n$ members, which quickly becomes untenable for
systems where $n$ is on the order of 1,000 or greater.

\subsection{Consistency Unit Framework}
\label{ssec:consistency-units}

Using periodic timestamped anti-entropy sessions to synchronize
replicas only provides a progress guarantee: all messages will
eventually be received, acknowledged, delivered, and purged from the
log of all processes, assuming the devices do not fail and network
partitions do not last forever. This implements a \emph{weak
  consistency} model: using TSAE to replicate state allows replicas to
diverge, but ensures they will eventually converge to an agreement if
allowed to communicate, at least if new updates do not outpace the
rate of convergence. Unfortunately, this property does not say
anything about how far apart replicas might diverge in the meantime.

This section summarizes the key ideas behind \emph{continuous}
consistency, with a particular focus on the conit (``consistency
unit'') model proposed by Yu and Vahdat
\cite{2000tact,2000tactalgorithms,10.5555/1251229.1251250,DBLP:conf/icdcs/YuV01,2002tact}. Continuous
consistency is motivated by the observation that real-world
applications can generally tolerate some level of divergence of
replicated data, especially in exchange for greater performance and
availability. Intuitively, applications can operate with replicas that
deviate from their ``ideal'' value by some margin of error
$\epsilon \geq 0$. However, applications have unique data models and
measure this error in different ways, so building a general framework
to enforce quantitative error bounds on replicas without making
specific assumptions about the nature of the data is challenging.

The conit framework strikes a desirable balance between being general
enough to work in applications with very different data models, and
practical enough to efficiently enforce error bounds with
straightforward protocols. We describe it now in terms of its system
model (\ref{sssec:conit-system-model}), its three dimensions of
consistency
(\ref{sssec:conit-numerical-consistency}---\ref{sssec:conit-real-time-consistency}),
and possible extensions (\ref{sssec:conit-extensions}).


\subsubsection{System Model}
\label{sssec:conit-system-model}
The system consists of processes in $\AllProc$ that replicate a shared
database (more generally, any kind of replicated state
machine). Processes perform two types actions, read or write requests,
as in Section \ref{ssec:shared-memory}. We call actions of both types
\emph{accesses}. Accesses potentially contain multiple instructions,
such as in a relational database transaction. Recall that a history is
an ordered sequence of read and write accesses. The \emph{local
  history} of a process $P$ is the sequence of accesses $P$ has
applied to $\Dinit$ since the start of the application. A read access
submitted to $P$ by a user is always handled locally by $P$ without
involving other processes, but all writes submitted to $P$ are
eventually propagated to all replicas using TSAE as the messaging
framework.

To define quantify deviation from strong consistency, we must give a
few definitions. Recall the notion of external order (Definition
\ref{def:external-order}): an access $A$ externally precedes $A'$ if
$A$ has returned to the caller before $A'$ is invoked. Yu and Vahdat
also define a notion of causality:
\begin{definition}[Causal precedence of accesses]
  \label{def:conit-causal-precedence}
  $A$ \emph{causally precedes} $A'$ if $A$ was already in the local
  history of the originating replica when $A'$ was submitted, and so
  could have influenced how $A'$ executed.\footnote{At face value it
    may seem that if $A$ is in a replica's write log before $A'$, then
    it must have completed before $A'$ started and thus already
    precedes $A'$ externally. However, if these represent long-running
    database transactions, it is possible that $A$ logically takes
    effect before $A'$ at some replia, though the two transactions may
    be physically concurrently.}
\end{definition}

With these definitions, we can define a strongly consistent execution
as a reference point for measuring deviation.

\begin{definition}[Ideal image]
  An ECG (externally consistent, causally consistent, global) history
  is the set of accesses across the system arranged in some total
  order that respects both external and causal order as defined above.
\end{definition}
Definitions below are given with respect to some ECG
history. Intuitively, the condition expected from the conit framework
is that at any moment in time, there is some ECG history such that all
replicas diverge from the ECG history by at most some error bound.

The initial database state at each replica is $\Dinit$.  Write
accesses encode an action to be performed against a database image
(rather than the final value the data after performing that
action). The result of applying write action $w$ to a database state
$D$ is denoted $D + w$. Let $D + H$ denote the result of applying each
of the writes in $H$ to $D$ in order.  Each process $P$ maintains a
write log, $\WL{P}$, containing the history of all writes applied to
its local database image in the order they were applied (making
$\WL{P}$ equivalent to the local history of $P$ restricted to write
requests). Note that the current state of $P$ is uniquely determined
by a combination of the starting state ($\Dinit$) and $\WL{P}$. In the
above notation, the current value $D_P$ of $P$'s replia is
$\Dinit + \WL{P}$. When a read request is submitted to $P$, the
requested value is read immediately from $D_P$ and returned to the
caller. When a write request $w$ is submitted, the action is performed
against the local replica and $w$ is added to $\WL{P}$. With either
type of access, $P$ is said to be the \emph{originating replica}, and
all other processes are \emph{remote}. The value of $D_P$ is said to
be the \emph{observed state} of the access.  We assume some ECG
history as a reference point. The \emph{ideal result} of an access $a$
is the value $\Dinit + \PH_\textrm{a}$.  The following equations hold.
\begin{gather}
  D_P = \Dinit + \WL{P} \label{eq:conit-DP} \\
  \Dideal = \Dinit + \WL{\textrm{ideal}} \label{eq:conit-Dideal}
\end{gather}


Timestamped anti-entropy is used to propagate writes to remote
replicas, with $\WL{P}$ acting as the message log. When a remote
replica $Q$ receives new writes, they are added to $\WL{Q}$ and
applied to $Q$'s local image as well. Now, replicated state machines
will reach the same final state on two conditions. First, all replicas
learn about each write, and second, all replicas execute writes in the
same order. TSAE by itself ensures the first condition, since every
process will eventually learn about every write. However, we know that
TSAE alone does not provide ordering guarantees. Thus, the data model
should provide a mechanism for rolling back (undoing) writes that have
been applied to $D$. When a write is first accepted, it is said to be \emph{uncommitted}
and applied \emph{tentatively} to the local replica. Uncommitted
writes are subject to being rolled back and reapplied in a different
order later, possibly with different results. Eventually, the write
becomes \emph{committed}, after which it is never rolled
back. Committed writes are applied in the same order at all
replicas. Taking the place of the message ordering component, a write
committment component is responsible for ultimately committing writes
accesses. Commitment is an adaptation of the total ordering mechanism
in \ref{sssec:tsae-message-ordering}.

\subsubsection{Conits}
The intention of the conit framework is this: at any moment in time,
there exists some ECG history of system accesses such that no
individual replica deviates from too far this history. To define what
it means to deviate, we now define conceptual units of data whose
relative (in)consistency can be quantified.

A read request depends on a set of conits $\mathcal{F}$. That is to
say, it assumed that the read will return the same value for any two
database images $D$ and $D'$ such that $F(D) - F(D') = 0$ for each
conit $F$ in $\mathcal{F}$. This access will be associated with a
consistency requirement for each conit in $\mathcal{F}$.

We write $\WL{P}|_\mathcal{F}$ to indicate the history of $P$
restricted to just the messages with non-zero weight on any of the
conits in the set $\mathcal{F}$.

The application can specify the consistency requirements for each
conit along a three-dimensional axis:
\[\textrm{Consistency} = \langle \textrm{Numerical error,
    \textrm{Order error}, \textrm{Staleness}} \rangle.\]

Anti-entropy can be push- or pull-based. To push updates from $P$ to
$Q$, $P$ obtains $Q$'s summary vector $\summaryVec{Q}$ and pushes all
unseen messages in $\WL{P}$ to $Q$. To pull updates, $P$ sends its
version vector and requests any messages in $\WL{Q}$ that $P$ has not
seen.

Numerical error bounded by a \emph{push}-approach: $P$ may have to
block during a request in order to proactively inform $Q$ about the
update before it can be applied. This consists of $P$ obtaining $Q$'s
current summary vector and then forwarding messages in $P$'s write log
that $Q$ hasn't seen.

Take, say, an application for disseminating the most up-to-date
visualization of the location of a fire front. A client may find this
it acceptable for this information to appears 30 seconds out of date
to a client, but unacceptable if it is 30 minutes out of date. For
example, firefighters who are very close to a fire have a lower
tolerance for stale information than a central client keeping only a
birds-eye view of several fire fronts simultaneously. The \emph{real
  time staleness} metric allows each process $P$ to bound the maximum
amount of time between an access affecting a conit being issued and
$P$ seeing that access.

Real-time staleness and order error are both bounded by a
\emph{pull}-based approach: $P$ may have to block during an operation
while contacting other sites in order to request information from
them.

\subsubsection{Numerical consistency}
\label{sssec:conit-numerical-consistency}
We imagine that a conit $F$ is associated with a valuation function,
\[
  \Val^F\colon \mathsf{Database\ Image} \to \mathbb{R}
\]
that maps a database state to some real value. Then,
$\Val^F(D)$ is thought of as the value of conit $F$ for a
database state $D$. Let $V_P$ denote the current value of $F$ at $P$'s
replica $D_P$. Let $\Videal$ represents the value of $F$ at $\Dideal$.

Each write update $w$ is associated with a value, $\NumWeight^F(w)$,
for each conit $F$, codifying the effect of $F$ of applying $w$ to a
database. That is, $w$ represents the value
\[ \NumWeight\left(w, F\right) = \Val^F(D + w) - \Val^F(D), \] which
we assume is independent of $D$ itself. Note that $F$ distributes over
$+$ in the sense that $F(D + w) = F(D) + \NumWeight(w, F)$. Combining
this with Equations \eqref{eq:conit-DP} and \eqref{eq:conit-Dideal}
gives
\begin{gather}
  V_P = V_{\textrm{init}} + \sum \{\NumWeight(w, F) | w \in \WL{P}\} \\
  \Videal = V_{\textrm{init}} + \sum \{\NumWeight(w, F) | w \in \WL{\textrm{ideal}}\}
  %\sum \{\NumWeight(w) | w \in \WL{P}\} = \left(\mathsf{SeenPosWeight}_F^P\left(X\right) + \mathsf{SeenNegWeight}_F^P\left(X\right)\right) \\
\end{gather*}

We assume each process $P$ maintains a conservative estimate, called
its \emph{view}, of which writes originating at $P$ have been received
by each other process. $P$'s view of $Q$ is denoted by
$\View{P}{Q}$. This estimate must be safe, meaning $P$ will not assume
$Q$ has received a message that it has not.
\begin{quote}
  \textbf{Approximate local knowledge of remote knowledge}: For each $Q$,
  $P$ can compute a set $\View{P}{Q}$ subject to the following
  invariant:
  \begin{equation*}
    \View{P}{Q} \subseteq \WL{Q}(P)
  \end{equation*}
  $P$ must also implement a mechanism to advance its view by
  synchronizing with $Q$.
\end{quote}
Its view also provides $P$ with an estimate of the messages it has
originated that $Q$ has not received yet, namely
$\WLat{P}{P} \setminus \View{P}{Q}$. Yu and Vahdat do not prescribe a
particular mechanism for a process to maintain its view. However, the
following policies seem to be implicit.
\begin{itemize}
\item If TSAE is implemented with matrices, the implementation of
  views is trivial. $P$ estimates that $Q$ has not seen any
  messages from $P$ with timestamp newer than $\ackMatrix{P}[Q][P]$:
  \begin{equation*}
    \View{P}{Q} \equiv \{ m \in \WLat{P}{P} | \timestamp{m} \leq
    \ackMatrix{P}[Q][P] \}
  \end{equation*}
  After push-based anti-entropy at time $t$, $P$'s view is advanced
  because $\ackMatrix{P}[Q][P]$ will have value $\clock{P, t}$.
\item If TSAE is implemented with $\ackVec{P}{}$, then $P$ must
  maintain an additional vector $\lastVec{P}$ where
  $\last{P}{Q}$ stores the value of $\clock{P,t}$ at the time
  of the last push to $Q$. $P$ estimates $Q$ has not received any
  messages from $P$ (via a third party) since this time:
  \begin{equation*}
    \View{P}{Q} \equiv \{ m \in \WLat{P}{P} | \timestamp{m} \leq
    \last{P}{Q} \}
  \end{equation*}
  After anti-entropy, $\last{P}{Q}$ is advanced to
  $\clock{P, t}$.  It may seem that $\ackVec{P}$ can be used instead
  of $\lastVec{P}$, but the acknowledgment vector is too coarse to
  track information for present purposes, because after pushing
  updates to $Q$, there is no guarantee that $\ack{P}{Q}$ will
  advance.
\end{itemize}
The advantage of version matrices for this use case is that, for
example, $P$ could learn through some process $R$ that $Q$ has
received (via a third party $S$) messages that originated at
$P$. Entries in $\lastVec{P}$ can only be updated by $P$ itself,
so this mechanism provides a coarser view, which does not affect
correctness but may affect performance.

We also need to make an assumption that processes are able and willing
to cooperate to maintain each other's numerical consistency
requirements.  We need every process to know every processes' bounds.
\begin{quote}
  \textbf{Global knowledge of error bounds}: Every process knows, for
  each conit $F$, the numerical consistency bounds of each other
  process for each conit. The numerical error bound for $P$ on $F$ is
  denoted $\epsilon^P_F$.
\end{quote}
If $P$ wishes to dynamically update its consistency bounds for a conit
$F$, it must invoke some mechanism to inform all other processes of
this change. For this reason, though theoretically possible,
individual accesses at $P$ cannot easily specify their own tailored
numerical consistency requirements for each access. Instead, $P$
maintains a requirement per conit (not per accesses).

\paragraph{Split weight absolute error}
We describe \emph{split-weight AE} (absolute error) algorithm, which
Yu and Vahdat explicate most at length in a 2000 paper
\cite{2000tactalgorithms}. For each other process $Q$, $P$ maintains
two values $\mathsf{PosWeight}^{P}(Q)$ and
$\mathsf{NegWeight}^{P}(Q)$. When $P$ submits a new write (in response
to a client's request), $P$ first checks for each $Q$ whether
$\mathsf{tnw}_{P}(Q)$\ldots

When $P$ accepts a write $w \in \WLat{P}{P}$, $P$ checks whether the following two conditions hold:
\begin{gather*}
  \mathsf{pos} + \mathsf{NumWeight} \leq \frac{\epsilon_Q}{|\AllProc| - 1} \\
  \mathsf{neg} + \mathsf{NumWeight} \geq \frac{\epsilon_Q}{|\AllProc| - 1}
\end{gather*}

If either of these conditions are violated, then $P$ updates its view
of $Q$, which might involve pushing new updates that $Q$ has not seen.

\begin{lemma}[Numerical weight correctness]
  When following the above protocol, then each value of each conit at process will satisfy
  \[ | \Videal - V_{P} | \leq \epsilon_{P}. \]
\end{lemma}


\paragraph{Variations} Yu and Vahdat also describe two other schemes
for bounding numerical error. \emph{Compound-weight absolute error} is
similar to split-weight AE, but saves space at the cost of extra
communication overhead. They also consider a scheme, \emph{inductive
  relative error}, which bounds the relative error
$|1 - \frac{V_i}{V_{\textrm{final}}}|$. Notably, this algorithm only
relies on $P$'s local knowledge; how to do bound relative error
efficiently without knowing the ideal value $V_{\textrm{final}}$ is
non-obvious.

\begin{figure}
  \centering
  \includegraphics[width=0.6\textwidth]{images/conit/Numerical1.png}
  \caption{Figure for Example \ref{ex:conit-numerical} where shaded
    messages represent this process' view of $\WL{C}$.}
  \label{fig:conit-numerical}
\end{figure}

\begin{example}
  \label{ex:conit-numerical}
  Figure \ref{fig:conit-numerical} depicts the role of numerical
  weight. We assume all writes apply unit weight to a single conit. If
  the lightly shaded messages represent this process' view of
  $\WL{C}$, the combined weight of the four writes estimated to be
  unseen must not exceed
  \mbox{$\epsilon^C_\textrm{num} / \left(3 - 1\right)$}.
\end{example}

\subsubsection{Order consistency}
\label{sssec:conit-order-consistency}
Recall that that the write log $\WL{P}$ is a linearly ordered
structure. Messages are initially received and applied tentatively to
$D_P$ in an uncommitted state. Eventually they will become committed
in a common global order, but the relative position of each tentative
write in the final order is not fixed. Writes applied in the wrong
order will have to be rolled back. The rolling back process may
involve application-specified logic and be associated with a cost, so
tentative writes represent a liability. The goal of ordered
consistency to is to bound this liability.

For instance, suppose an airline reservation application is used to
book individual seats for a flight. Suppose $P$ and $Q$ are two web
servers used to provide this service, and suppose both servers
independently process requests from clients to reserve a ticket for
seat \#1 at the same time. For efficiency, $P$ and $Q$ do not maintain
strict consistency, so they may both issue tickets and double-book the
seat. On the level of TSAE, the processes issue writes $w_P$ and $w_Q$
with timestamps $(P, t)$ and $(Q, t)$, respectively, and update their
local replicas to $\Dinit + w_P$ and $\Dinit + w_Q$. Eventually, $P$
and $Q$ synchronize, where the issue is discovered---the final
database state \mbox{$\Dinit + w_P + w_Q$} attempts to reserve seat
\#1 twice.\footnote{Semantically, the reader should think of the
  expression $\Dinit + w_P + w_Q$ as meaning something like, ``Reserve
  seat \#1 to $P$'s client, then issue a refund to $Q$'s client.''}
The business may decide that $P$'s ticket is valid, but the customer
who reserved a ticket from $Q$ may lose their ticket and be issued a
refund, plus a compensation fee. Thus, at the time of accepting $w_Q$
in a tentative state, the fact that $w_Q$ could be rolled back
represented a liability, and clearly one that applications may want to
bound. This is the purpose of controlling order error.

Let $\Uncommitted{P}$ represent the uncommitted messages in $\WL{P}$,
with $\Uncommitted{P}|_{\mathcal{F}}$ denoting the writes that affect
any of the conits in a set $\mathcal{F}$. Each write is $w$ is
associated with an \emph{order weight}, intended to capture the cost
of having to apply $w$ in a different order than the one it was first
applied. Let $r$ be a read access submitted to $P$ with a dependency
on conit set $\mathcal{F}$. Let $\PH_{\textrm{obs}}$ be the observed
prefix history. Now $\PH_{\textrm{obs}} \cap \PH_{\textrm{ideal}}$,
the common prefix of the observed and ideal history, represents the
longest part of $\PH_{\textrm{obs}}$ that is correct (i.e. agrees with
the ideal history). Therefore,
$\PH_{\textrm{obs}} \setminus \left(\PH_{\textrm{obs}} \cap
  \PH_{\textrm{ideal}}\right)$ represents all of the accesses that
have been applied to $P$'s local replica that will have to be rolled
back during the eventual write committment process. For purposes of
order error, we are only interested in measuring writes that affect
the conits. The order error is the combined order weight of these
writes:
\begin{definition}[Order error]
  The \emph{order error} of an access depending on a conit set
  $\mathcal{F}$ is the following sum (where $-$ denotes set difference):
  \[
    \mathsf{OrderError}\left(r, \mathcal{F}\right) \equiv \sum_{F \in \mathcal{F}} \left\{\OrderWeight\left(w, F\right) | w \in \PH_{\textrm{obs}}|_\Conits - \left(\PH_{\textrm{obs}}|_\Conits \cap
  \PH_{\textrm{ideal}}|_\Conits \right) \right\}
\]
\end{definition}

Since committed writes are globally totally ordered, the set of writes
in
$\PH_{\textrm{obs}} \setminus \left(\PH_{\textrm{obs}} \cap
  \PH_{\textrm{ideal}}\right)$ is a subset of the uncommitted
writes. Thus, we can bound the uncommitted order weight on a conit
$F$ is defined as the sum
\[ \sum_{F \in \mathcal{F}} \{\mathsf{OrdWeight}\left(w, F\right) | w \in \Uncommitted{P}|_{\mathcal{F}}\}
\]

Let $\epoe$ be the allowable upper bound of
$\OrderError\left(r,\mathcal{F}\right)$. To bound order error, it is
enough to bound the estimated value shown above. Whenever $P$ accepts
an access that, if added to $\WL{P}$, would cause the estimated order
weight to exceed $\epoe$, then $P$ must execute a write commitment
protocol to reduce the size of $\Uncommitted{P}$. This is implemented
with a \emph{pull-based} approach, as $P$ must advance its commit line
($\min_{X \in \AllProc} \left(\summary{P}{X}\right)$) far enough for
the write commitment protocol to decide the final order of enough
writes until the order error is within bounds.

\begin{figure}
  \begin{subfigure}{0.5\textwidth}
    \centering
    \includegraphics[width=0.5\textwidth]{images/conit/Order1.png}
    \caption{$\WL{A}$ shown with $5$ uncommitted writes}
    \label{fig:conit-order-a}
  \end{subfigure}%
  \begin{subfigure}{0.5\textwidth}
    \centering
    \includegraphics[width=0.5\textwidth]{images/conit/Order2.png}
    \caption{$\WL{A}$ shown at a later time}
    \label{fig:conit-order-b}
  \end{subfigure}
  \caption{Logs for Example \ref{ex:conit-order} where dotted messages represent committed writes}
  \label{fig:conit-order}
\end{figure}

\begin{example}
  \label{ex:conit-order}
  Figure \ref{fig:conit-order} depicts the role of order weight. We
  assume all writes apply unit weight to a single conit. Lightly
  dotted messages represent this process' committed writes. In Figure
  \ref{fig:conit-order-a}, five writes are uncommitted. In particular,
  no write with timestamp greater than or equal to $3$ can be
  committed, since the minimum entry in the log, $\WL{A}{C}$, is only
  $2$.

  The next access added to $\WL{A}$ will observe an incorrect prefix
  history,
  \[\PH_{\textrm{obs}} - \left(\PH_{\textrm{obs}} \cap
      \PH_{\textrm{ideal}}\right),\] consisting of all writes after
  and including $(A, 6)$, the point at which the write log deviates
  from the ideal history (seen in Figure
  \ref{fig:conit-order-b}). This corresponds to an order error of
  $4$. Note that the message $(A, 3)$ happens to be in its ideal
  position and does not count towards the actual error, but it does
  contribute to the estimated order error of $5$, the combined weight
  of all uncommitted writes. If $5$ exceeds the allowable order error
  of the next access, the process will invoke the write commitment
  protocol, pulling updates from $B$ and $C$ to advance $A$'s summary
  vector before handling any new operation.
\end{example}

\subsubsection{Real time staleness}
\label{sssec:conit-real-time-consistency}
The \emph{real time staleness} metric allows each process $P$ to bound
the maximum amount of time between an access affecting a conit being
issued and $P$ seeing that access. Here we rely on the assumption that
$\summaryVec{P}$ stores physical timestamps from loosely synchronized
physical clocks, though this assumption can be weakened. Let $P$ have
an upper bound of $\eprt \geq 0$ on the real-time staleness of a conit
$F$. Here, $\eprt$ should be greater than the time it takes for $P$ to
engage in a typical anti-entropy session. The rule for enforcing
real-time bounds is very simple.

While handling an access with a read dependency on $F$, submitted at
time $t$, $P$ checks for each $X \in \AllProc$ whether
$|\clock{P, t} - \summary{P}{X}| < \eprt$ is true. If it is not true,
then $P$ engages in a pull-based anti-entropy session with $X$, at
which point $\summary{P}{X}$ has value $\clock{X, t'}$ for some
$t' > t$. Note that the assumption of loose synchronization implies
$\clock{X, t'} \approx \clock{P, t}$ if $t \approx t'$. This protocol
ensures that the original access, timestamped with value
$\clock{P,t}$, will observe the effect of all writes affecting $F$
with timestamps less than $\clock{P,t} - \eprt$.

A pull-based protocol may seem wasteful because $P$ may poll $X$ for
updates even if $X$ does not have any new writes. However, an approach
where $X$ pushes updates to $P$ cannot bound real-time staleness
without an upper bound on the time it takes to push messages across
the network to $P$.

If clocks are not loosely synchronized, an alternative implementation
strategy is for $P$ to maintain a vector $\vtphys{P}{}$ where
$\vtphys{P}[X]$ stores the value $\clock{P,t}$ of $P$'s clock at the
last time $P$ was on the receiving end of an anti-entropy session
directly with $X$. Then $P$ enforces consistency by ensuring that
$|\clock{P, t} - \vtphys{P}{[X]}| < \eprt$ is true before handling an
access submitted at time $t$. Since this approach only compares values
from $P$'s clock, synchronization is not required assuming $\clock{P}$
runs at a constant rate. However, this approach has the downside that,
unlike $\summary{P}{Q}$, $\vtphys{P}[Q]$ cannot be updated based on
information indirectly learned during anti-entropy with a third
party.

\subsubsection{Conit Variations and Extensions}
\label{sssec:conit-extensions}
One can imagine various ways that the conit model can be augmented
with additional capabilities. These topics are outside the scope of
this memo but offered for future consideration.

\paragraph{Dynamic bounds}
Because real-time staleness and order error are bounded by pull-based
anti-entropy sessions, it is straightforward to allow the user to
dynamically change the error bounds at each site. However, numerical
error is bounded by a push-based approach that requires every process
to be track all other processes' error bounds and cooperate to enforce
it. Therefore, dynamically tuning numerical $P$'s numerical error
bounds requires a consensus mechanism so that $P$ can inform other
processes any changes to its error bounds. However, $P$ cannot be sure
its new bounds will be respected until every process has acknowledged
the update.

Yu and Vahdat do not propose a particular mechanism for consensus. One
possible approach may be to reuse the existing message-propagating
mechanism to announce changes to error bounds, similar to Golding's
approach for handling dynamic group membership.

\paragraph{Dynamic conits}
The framework we have described above assumes the set of conits is
fixed in advance. Besides tuning bounds dynamically, we can imagine
situations where new conits need to be created on-the-fly. For
instance, data related to a new wildfire that has emerged may require
forming new conits to set consistency bounds.

Donkervliet's master's thesis \cite{dyconits} explored the subject of
dynamic conit creation in the context of massive multiplayer online
games, particularly Minecraft. In that work, new conits may be
associated with newly encountered objects in an area, and their
consistency bounds tuned as the user approaches them, exploiting a
form of locality to allocate network resources for information the
where inconsistency would most readily be perceived by the
player. Adapting their \emph{dyconits} (dynamic conits) framework to
the wide-area tactical environment may be worthwhile.

\paragraph{Interaction with the Network}
We mentioned in Section \ref{sssec:allocation-of-network-resource} our
expectation of a tighter, more complex interaction between the network
and application layers in this environment because of the need to
optimize scarce network resources for the most important
information. Because conits can quantify divergence, and therefore
indirectly the relative importance of an update, one way this might be
realized is by making the network conit-aware.

Network packets, or DTN bundles, could be specially marked as
containing database updates alongside any metadata (such as the weight
of an update to various conits) that could be used by the network for
quality-of-service purposes. Such usage may run contrary to the
conventional wisdom that networking protocols should be agnostic to
the actual content of a message, e.g. routers should be concerned only
with the data in IP packet headers but not the data contained in the
packet. This sort of atypical usage is potentially justified in our
setting because of a heightened requirement to optimize the user of
very scarce networking resources, even at the cost of blurring the
line between the network and application layers.

Modifying a network protocol to optimize a particular middleware or
application is not a lightweight task, particularly since network
drivers are often embedded into an operating system kernel or into
hardware---this makes their modification difficult or at least
fraught. We conjecture that SDN would be particularly suitable because
it is easier to modify or customize software-defined networking
protocols, so that custom hardware is not required even for extremely
specialized networking needs. The ability to design network protocols
at the level of conventional application software, rather than baking
them into hardware, might offer the flexibility to experiment with
variations of protocols.

We previously mentioned an example where a UAV or a message ferry
could be deployed dynamically to provide greater throughput in a
particular geographical area. Such a resource could be dispatched if
the application signals to a network controller that it is struggling
to enforce conit bounds in a timely manner.

Yu and Vahdat discuss quality of service as one of the features that
might itself use conits.



\section{Conclusion and Summary}
\label{sec:conclusion}

\section*{Bibliography}\label{bibliography}
\addcontentsline{toc}{section}{Bibliography}

\bibliographystyle{abbrv}
\bibliography{bibliography}
\end{document}

%%% Local Variables:
%%% mode: LaTeX
%%% TeX-master: t
%%% End:
