% !TeX document-id = {beb7ced9-b3cd-42b2-b16a-3ed3c633a1d9}
\documentclass[]             % options: RDPonly, coveronly, nocover
{NASA}                       %   plus standard article class options
%\DeclareRobustCommand{\mmodels}{\mathrel{|}\joinrel\Relbar}

\usepackage[utf8]{inputenc}
\usepackage{setspace}
\usepackage{csquotes}
\usepackage{hyperref}
\usepackage{amsmath, amssymb, amscd, amsthm, amsfonts}
\usepackage{mathtools}
\usepackage{graphicx}
\usepackage{hyperref}
\usepackage{amsthm}
\usepackage[english]{babel}
\usepackage{stmaryrd}
\usepackage{proof}
\usepackage{tikz-cd}
\tikzcdset{scale cd/.style={every label/.append style={scale=#1},
    cells={nodes={scale=#1}}}}
% Added for subfigures
\usepackage{caption}
\usepackage{subcaption}
\usepackage{afterpage}
\usepackage{comment}
\usepackage{rotating}%sidewaysfigure
\usepackage{pdflscape}%alt to sidewaysfigure

\newtheorem{theorem}{Theorem}[section]
\newtheorem{corollary}[theorem]{Corollary}
\newtheorem{lemma}[theorem]{Lemma}
\theoremstyle{definition}
\newtheorem{example}[theorem]{Example}
\newtheorem{definition}[theorem]{Definition}
\include{macros.tex}

% Globally redefine pgfpicture to use \Large fonts
\let\origpgfpicture=\pgfpicture
\def\pgfpicture{\origpgfpicture\small}

% Try loading this package to prevent so much hyphenation
% as recommended by https://stackoverflow.com/questions/1609837/latex-breaking-up-too-many-words
\usepackage{microtype}

\title{Distributed Systems Challenges in Wildland Firefighting Environments}

\author{Lawrence Dunn and Alwyn E. Goodloe}

\AuthorAffiliation{Lawrence Dunn \\ Department of Computer and Information
  Science \\ University of Pennsylvania \\ Philadelphia, PA \\ Alwyn Goodloe\\                                          % for cover page
  NASA Langley Research Center, Hampton, Virginia
}
\NasaCenter{Langley Research Center\\Hampton, Virginia 23681-2199}
\Type{TM}                    % TM, TP, CR, CP, SP, TT
\SubjectCategory{64}         % two digit number
\LNumber{XXXXX}              % Langley L-number
\Number{XXXXXX}              % Report number
\Month{12}                   % two digit number
\Year{2022}                  % four digit number
\SubjectTerms{Distributed Systems, Formal Methods, Logic, }     % 4-5 comma separated words
\Pages{46}                   % all the pages from the front to back covers
\DatesCovered{}              % 10/2000--9/2002
\ContractNumber{}            % NAS1-12345
\GrantNumber{}               % NAG1-1234
\ProgramElementNumber{}
\ProjectNumber{}             % NCC1-123
\TaskNumber{}                % Task 123
\WorkUnitNumber{}            % 123-45-67-89
\SupplementaryNotes{}
\Acknowledgment{The work was conducted during a summer internship at the NASA Langley Research Center in the Safety-Critical Avionics Systems Branch focusing on distributed computing  issues arising in the Safety Demonstrator challenge in the NASA Aeronautics System Wide Safety (SWS) program.}

%Added for Pandoc
\providecommand{\tightlist}{%
  \setlength{\itemsep}{0pt}\setlength{\parskip}{0pt}}


\abstract{The System Wide Safety (SWS) program has been investigating
  how crewed and uncrewed aircraft can safely operate in shared
   airspace. Enforcing safety requirements for distributed agents
  requires coordination by passing messages over a communication
  network. Unfortunately, the operational environment will not admit
  reliable high-bandwidth communication between all agents,
  introducing theoretical and practical obstructions to global
  consistency that make it more difficult to maintain safety-related
  invariants. Taking disaster response scenarios, particularly
  wildfire suppression, as a motivating use case, this self-contained
  memo discusses some of the distributed systems challenges involved
  in system-wide safety through a pragmatic lens. We survey topics
  ranging from consistency models and network architectures to data
  replication and data fusion, in each case focusing on the practical
  relevance of topics in the literature to the sorts of scenarios and
  challenges we expect from our use case.  }

\begin{document}
\newpage
\setcounter{tocdepth}{2}
\tableofcontents
\newpage

\section{Introduction}
\label{sec:introduction}
Civil aviation has traditionally focused primarily on the efficient
and safe transportation of people and goods via the airspace. Despite
inherent risks, the application of sound engineering practices and
conservative operating procedures has made flying the safest mode of
transport today. Now, the industry's strong requirements for safety
make it difficult to integrate unmanned vehicles into the airspace,
accomodate emerging applications, and keep pace with significant
recent growth in commercial aviation. To that end, the NASA
Aeronautics' Airspace Operations and Safety Program (AOSP) has
initiated the System Wide Safety (SWS) project to investigate
technologies and methods to enable crewed and uncrewed aircraft to
safely operate in shared airspace.

This memo surveys topics in computing that are relevant to maintaining
system-wide safety across large, physically distributed data and
communication systems. It is intended to be self-contained and
accessible to a technical audience without a deep background in
distributed systems. Our primary motivating use cases come from civil
emergency response scenarios, especially wildfire suppression and
hurricane relief. These were chosen primarily for three
reasons. First, improved technology for wildfire suppression,
especially related to communications and data sharing, is frequently
cited as a national priority \cite{pcast2023}.  Second, the rules for
operating in the US national airspace are typically relaxed during
natural disasters and relief efforts, so this is a suitable setting
for testing new technologies. Finally, this setting is an excellent
microcosm for the sorts of general challenges faced by other,
non-emergency applications.

One theme visited throughout this document is \emph{continuity} in the
sense considered by topology.\footnote{For an introductory textbook
  see \cite{mendelson2012introduction}.}  The systems we examine must
function under harsh operating conditions that limit their
performance. For example, wireless communication is less reliable
during severe weather. To design a system whose behavior and
performance is predictable---this is clearly a prerequisite for
safety---it must flexible enough to perform reliably under a wide
range of adverse conditions. In other words, the behavior of a safe
system should in some sense be a \emph{continuous} function of its
inputs and environment. Achieving this sort of robust design is
challenging because distributed systems designers must navigate
delicate tradeoffs between competing objectives. At a high level,
these tradeoffs stem from an inherent tension between designing a
system that handles user requests quickly and one that prioritizes a
strong level of global consistency between system components.

The key insight the reader should take away from this document is that
achieving system-wide safety is not solely a matter of improving
communications hardware and physical infrastructure. It is also in
large part a computer science and software problem concerned with the
high-level applications that execute on top of the communications
infrastructure. These software systems must be engineered to maintain
a common operating picture between distributed users while making
efficient use of networking and compute resources in a dynamic and
even adversarial environment.

\subsection{Summaries of the sections}
\label{ssec:summaries-of-the-sections}
Section \ref{sec:disaster-response} opens with a practical overview of
disaster response and some of the computing challenges encountered in
this setting. The heavily disruptive nature of the communications
network in these environments invariably raises issues fundamental to
the science of distributed systems. Real-world examples from disaster
response scenarios are presented that demonstrate how these challenges
affect system-wide safety.

Section \ref{sec:background} summarizes fundamental concepts and
mechanisms used in distributed systems, culminating in the classic
``CAP'' theorem for both the linearizable and sequential consistency
models (Theorems \ref{thm:cap} and \ref{thm:cap-sequential}). CAP is
considered a ``negative'' result, as it proves that a distributed
system cannot guarantee strong consistency and remain available to
users when the communication network is disconnected. The practical
implication of the theorem is that agents in emergency response
environments will always operate with incomplete information about the
global system.  While the CAP theorem is often presented as a kind of
unfortunate prohibition, it merely highlights a general kind of
tradeoff. Furthermore, real-world systems often exhibit a kind of
``locality'' that mitigates some of the constraints implied by the
theorem.

Section \ref{sec:tsae} presents Golding's Timestamped Anti-Entropy
(TSAE) protocol. TSAE provides a fault-tolerant message propagation
mechanism that ensures messages are eventually delivered to all
parties. This implements a weak (eventual) consistency model,
representing an optimistic approach to consistency where replicas of
shared state are allowed to diverge temporarily and have their
differences reconciled periodically. However, it has the downside that
it cannot enforce bounds on how far apart any two replicas may diverge
before this occurs. Therefore, users are not provided any guarantees
limiting how far apart a data item observed by the user may be from
its ``true'' value.

Section \ref{sec:continuous-consistency} describes a TSAE-based
replication mechanism suitable for networks with frequent disruptions,
but where it is also important to measure and control how far apart
replicas may diverge at any moment. This uses the theory of
\emph{conits} (short for ``consistency unit'') developed by Yu and
Vahdat \cite{2002tact}, which provides a \emph{continuous} consistency
model that balances the competing objectives of consistency and
availability in a quantifiable way. The idea is that applications can
tolerate some level of inconsistency between replicas of a data item,
as long as the divergence remains less than some defined upper
bound. Using the conit framework allows applications to define units
of replicated state of interest, enforce policies limiting
inconsistency between their replicas, and adapt these policies
dynamically in response to the environment. By combining the enforced
guarantees of strong consistency models with the flexbility and
resilience of weak consistency, this model is suitable where the
tradeoffs implied by the CAP theorem may need to be carefully
calibrated to support both performance and safety.


\begin{comment}
We conclude in Section \ref{sec:conclusion} by recapping some of the
main themes in this document and highlighting areas for further
investigation. Ultimately, building distributed systems requires
design decisions tailored to the environment and application. We
expect that many of these decisions will involve a combination of
simulation and real-world testing.
\end{comment}

\section{Coordination Challenges in Disaster Response}
\label{sec:disaster-response}
This section explores key aspects of disaster response, particularly
firefighting, that shape the focus of this document. We highlight how
real-world environments create fundamental challenges that require
solutions based on distributed computing principles. Even with the
best communications technologies, core issues arise when distributed
agents need to coordinate their actions across wide areas.

Disaster response settings, like wildfire suppression or hurricane
relief, are marked by systemic communications challenges. A 2023
report by the President’s Council of Advisors on Science and
Technology (PCAST) highlights the need to address ``the
vulnerabilities and shortfalls in wildland firefighter communications,
connectivity, and technology interoperability'' as its top
recommendation for wildland firefighting modernization
\cite{pcast2023}. Many of these vulnerabilities and shortfalls stem
from factors inherent to disaster response: remote locations,
difficult terrain, damaged infrastructure, harsh weather, and limited
power, to name a few.

Field agents often face high message loss, distorted signals, and
unpredictable delays in communication. A cautious approach suggests
preparing for the worst performance at critical times---network
failures often coincide with the sorts of conditions that demand
urgent, reliable contact. Disasters often damage and degrade the
communications infrastructure, which is accompanied by a sudden surge
in user demand that can overwhelm a network completely. This was
starkly evident in the immediate aftermath of the September
$11^\textrm{th}$ attacks, when sudden user demand and severed trunk
cables crippled New York public and private communication networks,
including dedicated networks for first responders
\cite{2011:Reardon}. These failures later became the impetus for the
creation of FirstNet \cite{2021:firstnet, 2021:firstnet2}, a national
public safety broadband network (NPSBN).

Unreliable networks make coordinating distributed agents a significant
challenge. Coherent decision-making and coordinated action require
consistency, meaning agreement on the data shared between agents. We
define consistency more precisely in Section \ref{sec:background}, but
the idea is clear: it is critical for everyone to agree which
firetrucks should respond to which areas, where helicopters should
land, which tasks should be prioritized, or which radio frequencies
are in use. Achieving stronger standards for consistency requires
sending more information in a shorter time frame, which places a
heavier strain on the network. When a communications link is slow,
system components may have to pause and wait before agreement can be
reached, diminishing the efficacy of the system. To avoid waiting in
such scenarios, standards for consistency may have to be relaxed,
meaning distributed agents have less agreement, which comes with its
own challenges. In sum, there is an inherent tension between
consistency and responsiveness.

\subsection{Communication and User Safety}
\label{ssec:communication-and-safety}
We turn our attention to the implications of the
consistency/responsiveness tradeoff from a user safety
perspective. Operational safety depends on agents quickly gathering
and responding to information about their environment. This
information is relayed through communication networks, so poor
communication becomes a safety problem. When communication falters,
agents face a difficult choice: either wait for more information
before acting, or act now with incomplete knowledge. Both inaction and
uninformed action carry risks. This dilemma is closely related to a
fundamental computer science principle known as the safety/liveness
tradeoff.

\begin{figure}
  \centering
  \includegraphics[scale=0.4]{images/dc10.jpg}
  \caption{A DC-10 airtanker, rated for 9,400 gallons, drops retardant
    above Greer, Arizona. Image source: Kari Greer/US Forest Service.}\label{fig:airtanker}
\end{figure}
% TODO: How to cite picture?
% https://www.flickr.com/photos/apachesitgreavesnf/5837741382
% Also appears at https://www.nifc.gov/resources/aircraft/airtankers

\begin{figure}
  \centering
  \includegraphics[scale=0.15]{images/forestfire-videox-scaled.jpg}
  \caption{Screenshot of a firefighter using TAK, where the left
    panel shows a map and the right is a video stream from an air
    vehicle. Image source: Andreas ``AJ'' Johansson}\label{fig:atak}
\end{figure}
% TODO: How to cite picture?
%https://www.civtak.org/2020/08/04/tak-used-in-ca-firefighting-w-aircraft-video/

For example, consider the use of firefighting airtankers, particularly
Very Large Airtankers (VLATs), which can carry over 8,000 gallons of
water or fire retardant \cite{2019:airtankerops}
(Figure \ref{fig:airtanker}). The largest VLATs can drop more than
20,000 gallons---about 170,000 pounds' worth---in a single pass. In
the U.S., these drops are typically made from just 250 feet above the
tree canopy \cite{2019:airtankerops}, and sometimes lower in
practice. This sort of maneuver can easily crush a ground vehicle
\cite{2019:stickney}. In 2018, a firefighter was killed, and three
others were injured, when an unexpectedly powerful drop from a Boeing
747-400 Supertanker knocked down an 87-foot Douglas Fir tree
\cite{2018:calfire}.

Improving firefighter communications can be expected to lead to better
safety outcomes. One such improvement is the through the use of
applications like TAK, the Team Awareness Kit, developed by the
U.S. military in 2010 and later released in a civilian
version. Wildland firefighters are increasingly using TAK, extended
with aftermarket plugins, on ordinary cell phones to coordinate their
activities in the field (Figure \ref{fig:atak}). A key application of
this tool could be tracking the real-time GPS coordinates of
firefighters for safety monitoring.

Given the risks of VLAT drops, a seemingly reasonable safety measure
might be to disallow drops unless a VLAT's computers have up-to-date
information about the location of ground personnel. Unfortunately,
system-wide safety is not so easily achieved, as the proposed measure
is precisely the sort of thing subject to the safety/liveness
tradeoff. Here, it is important to recognize a linguistic nuance: in
the context of distributed systems, ``safety'' refers to a specific
type of system property. The concept is not inherently related to the
safety of people. A \emph{safety} property is a prohibition that stops
a system from taking an action that might be ``bad'' in some way. Here
is an exemplary safety property for the example above:
\begin{quote}
  $\Psafe$: Ground agents are known to be at least
  100 feet outside the drop zone, and this information is current to
  within 30 seconds, or airtankers will not perform a drop.
\end{quote}
By contrast, a \emph{liveness} property demands some kind of action
from a system, usually one that is ``good'' in some way. A
characteristic of liveness properties is that they place an upper
bound on the allowable delay of something. An exemplary liveness
property for our scenario might be the following:
\begin{quote}
  $\Plive$: A VLAT on the ground will take off and
  perform a drop within 20 minutes of receiving a request from an
  incident commander. \footnote{The Chief of Flight Operations for Cal
    Fire cited 20 minutes as an upper bound on the response time for
    aerial firefighting units within designated responsibility areas
    in an interview with PBS \cite{2021:aerialfirefighting}.}
\end{quote} Note that $\Plive$
is a liveness property, not a safety property in the narrow technical
sense, but it impacts human safety: it might be critical for VLATs to
perform drops quickly if a wildfire is threatening the safety of
ground personnel.

Safety and liveness are frequently dual mandates that cannot be
guaranteed simultaneously. Such is the case in our example: though
$\Psafe$ and $\Plive$ are both desirable, certain situations will
force decision makers to prefer one over the other. Consider the fact
that the wildland firefighting environment is frequently GPS-denied.
Heavy smoke, multipath effects, and so on can easily prevent a
consumer-grade cellphone from obtaining reliable GPS
coordinates. Additionally, factors like a damaged radio tower or
environmental obstructions like a tall mountain can prevent
communications between the air and ground. Such conditions would
prevent a VLAT's computers from knowing the locations of ground
agents, which immediately presents a dilemma: should the crew proceed
without knowing the locations of ground personnel, maintaining
$\Plive$ at the cost of $\Psafe$, or should it be cautious and wait
for more information, maintaining $\Psafe$ at the cost of $\Plive$?
There is no simple answer, with either choice presenting a downside
with respect to the broader goal of system-wide safety.

Besides the safety/liveness tradeoff, the previous example exhibits
two other themes important in distributed systems, both of which will
be explored further in this document. The first is the
\emph{epistomological} nature---concerned with what information is
\emph{known} by \emph{whom}---of reasoning about distributed
systems. This aspect is reflected in wording of $\Psafe$ in VLAT
example: Ground agents are known (by the VLAT's computers) to be
outside of a dangerous area. This situation requires a deeper and more
sophisticated analysis than one simply considering what is
true. Mathematically, the logic of distributed agents is not the
ordinary propositional logic but the modal logic S5, which extends
propositional logic with additional axioms governing
knowledge.\footnote{The application of S5 to reason about distributed
  systems is the topic of \cite{kshemkalyani_singhal_2008}, Chapter
  8.} Distributing knowledge requires communication between agents
over a period of time over the network, which is not instantaneous and
reliable, and it is from these imperfections that the safety/liveness
tradeoff arises.

The second aspect exhibited above, albeit negatively, is that of
\emph{continuity}. A continuous system can flexibly adopt to its
environment, but a discontinuous system is rigid and may exhibit
suddenly different behavior in response to only small changes in the
environment, such as a transient network failure. The properties
$\Psafe$ and $\Plive$ exhibit a stark lack of continuity because they
are inflexible, all-or-nothing propositions. Suppose that agents are
known to be $500$ feet outside the drop zone, but the information is
only current to within 31 seconds---this extra second technically
violates $\Psafe$, though it should be inferrable that the ground
agents are well away from danger. In particular, this example
highlights that system-wide safety is more of a quantitative concept
than a Boolean (true-or-false) one. A distributed system in a
network-challenged environment should exhibit smoothly varying
properties in response to its inputs. Ideally one can ``tune'' the
system's properties for the particulars of its environment at any
moment. The technical aspects of this theme are the focus of Section
\ref{sec:continuous-consistency}.

\subsection{Communication Patterns in the Field}
\label{ssec:communication-patterns}
We now consider some of the communication patterns that occur in
wildland firefighting. Readers may be surprised to learn that the
state of the art is somewhat primitive, largely due to the sparse
permanent communications infrastructure that exists in this
setting. This makes wildfires an interesting and generalizable example
for other kinds of civil disaster environments where the network is
unreliable.

One important concept to draw attention to is a kind of ``geospatial
locality of reference'' that system designers should consider. By
this, we mean the concomitance of two observations which, while not
guaranteed rules, are approximately true in many circumstances. The
first observation states that nearby agents have aligned interests:
\begin{quote}
  $\textbf{O}_1$: Agents with the most urgent need to coordinate their
  actions will usually be located closer together and require similar
  kinds of information.
\end{quote}
The second observation states that nearby agents have more reliable
communications:
\begin{quote}
  $\textbf{O}_2$: Agents that are located closer together generally
  enjoy more reliable communications between them than agents that are
  far apart. Conversely, information that travels long distances tends to
  be delayed or degrade in quality.
\end{quote}

These related observations are what is meant by simply the
``locality'' principle. Locality is a crucial factor to analyze
because, as presented in Section \ref{sec:background}, there are major
theoretical and practical limits to how well agents can coordinate
\emph{globally}, meaning with all agents knowing and agreeing on
everything. To the extent the system exhibits locality, coordination
can be achieved using more efficient short-range communication than
less efficient long-range communication. Here, ``efficient'' should be
read broadly, measured with respect to things like battery life,
message delay, reliability, cost-effectiveness, equipment weight, and
so on. This raises the question of how to most efficiently utilize
network resources to achieve adequate levels of consistency. Aspects
of this question are revisited in Section
\ref{sec:continuous-consistency}, in the context of a framework for
weighing the relative importance of updates.

\subsubsection{Communication on the Ground}
\label{sssec:ground-communication}
In the field, communication between firefighters and other agents is
often facilitated by handheld (analog) land-mobile radio (LMR). These
radios are inherently limited in their battery life, bandwidth,
effective range, and ability to work around environmental factors like
foliage and smoke.

As an alternative to using a radio, it is common for wildland
firefighters in the field simply to shout commands and notifications
to nearby personnel. This exhibits the locality principle: a
substantial amount of communication occurs directly between nearby
firefighters working on related tasks that can communicate without
network infrastructure. In a future environment where agents might be
equipped with body-worn sensors and or even some form of heads-up
display (HUD), this sort of low-range local communication might be
facilitated by relatively inexpensive, low-power technologies such as
Bluetooth or mesh Wi-Fi, without the need for more sophisticated (and
heavy) equipment.

Communication over a long distance requires infrastructural support,
such as the use of cell towers and repeater stations. Typically,
disaster response environments have scarce permanent infrastructure:
in a wildland fire setting, perhaps a few repeaters mounted to a
nearby watch tower. Ad-hoc infrastructure, such as Cells On Wheels
(COWs) or Cells on Light Trucks (COLTs)---i.e. portable cellular
towers---can sometimes be deployed on an as-needed basis if the
location allows for it. Similar kinds of equipment can also be mounted
to backpacks and carried into the field. A common issue is making sure
that all equipment is properly configured, for instance that radios
are listening on the correct frequencies. Configuration is especially
critical when different agencies and groups need to
interoperate---another problem highlighted during the September
$11^\textrm{th}$ attacks.

\begin{figure}[t]
  \centering
  \includegraphics[scale=0.085]{images/ironside.jpg}
  \caption{The Ironside Mountain lookout and radio repeater station,
    shown here with protective foil on August $10^\textrm{th}$, 2015
    during the 2015 River Complex fire. This particular fire burned
    77,077 acres over 77 days.}
  \label{fig:ironside}
\end{figure}
% TODO: How to cite picture?
%https://web.archive.org/web/20150923190323/http://inciweb.nwcg.gov/incident/photograph/4431/44/45122/

Use of centralized infrastructure comes with the potential for
widespread failure when the infrastructure breaks down. For example,
in California, the Ironside Mountain lookout/repeater station (seen in
Figure \ref{fig:ironside}) was destroyed during the 2021 Monument
Fire, which burned approximately 223,124 acres over 88 days
\cite{2021:monumentfire}. The Ironside Mountain station had strategic
importance, being located on a tall ridge. According to a video blog
from a volunteer firefighter involved in the incident, its loss
prevented communication between operators on different sides of the
ridge, in networking parlance creating a \emph{partition} that lasted
until crews could ascend the ridge to deploy a temporary station:
\begin{quote}
  ``When {[}the Ironside Mountain lookout station{]} burned down the
  radio repeater went with it. And so communications were lost across
  the fire\ldots{} one side of the fire couldn't talk to the other
  side\ldots.  So it was kind of a critical job to get that road
  cleared so that the radio crews could go back up there and set up a
  temporary radio tower.'' \cite{2022:mechfire}% See also https://web.archive.org/web/20220809061927/https://www.youtube.com/watch?v=4F2dDKMgAME
\end{quote}
A scenario where communication between two groups is completely
severed is exactly the sort of thing considered by the CAP theorem in
Section \ref{sec:background}.

\paragraph{Ground vehicles}
Large numbers of ground vehicles---sometimes on the order of 100
during a major response---are involved in wildfire
suppression. Various firetrucks, bulldozers and similar vehicles are
commonly used to control the landscape and perimeter of the fire. An
advantage of vehicles is that they can carry heavier and higher-power
communications equipment than a human. For instance, a vehicle could
be equipped with a BGAN or VSAT satellite terminal to maintain a
connection back to a central location. Additionally equipping the
vehicle with something like a Wi-Fi or cellular base station using the
satellite connection as backhaul would let the vehicle act as a bridge
between agents in the field and central coordinators such as incident
commanders or 911 dispatchers.

\subsubsection{Communication in the Air}
Wildland firefighting increasingly involves the use of helicopters and
fixed wing aircraft. Civil aviation has traditionally employed simpler
communication patterns than this use case demands. For instance,
aircraft equipped with Automatic Dependent Surveillance-Broadcast
(ADS-B) monitor their location using GPS and periodically broadcast
this information to air traffic controllers and nearby aircraft. This
sort of scheme has worked well in traditional applications, where
pilots typically only monitor the general locations of a few nearby
aircraft. The locality principle is exhibited here, too: aircraft have
the highest need to coordinate when they are physically close and
therefore in range of each other's ADS-B broadcasts.

In our setting, a large number or aircraft, easily on the order of 10 or
more, may need to operate in a small area, near complex terrain,
during adverse conditions, often at low altitude. In other words, the
demands are many and the margins for error are small. This sort of use
case calls for more sophisticated coordination schemes between
airborne and ground-based elements than solutions like ADS-B provide
by themselves.

As aircraft generally have better line-of-site to ground crews than
ground crews have to each other, firefighters sometimes relay messages
to air-based units over the radio, which in turn is relayed back down
to other ground units. The locality principle comes into play for this
sort of message relaying scheme, but in the negative direction:
relaying allows knowledge to travel farther but requires more resources and effort,
and the extended reach comes at the cost of introducing delays and
possible degradation of message quality, as in the classic game of
``telephone.'' Hence, this mode of communication has generally been reserved for
more critical information.

The Communications Program of the Civil Air Patrol (a civilian
auxiliary of the U.S. Air Force) is sometimes deployed to provide
communications for firefighters on the ground using airplane-mounted
radio repeaters. In this future, this sort of service could be
provided autonomously by portable infrastructure mounted to unmanned
aerial vehicles (UAVs), which might perform additional functions such
as tracking the fire perimeter.

In future environments, we envision resilient networks formed from
heterogeneous collections of smaller networks, incorporating various
communication technologies such as digital radios, Wi-Fi, 4G/LTE, and
satellite communications. Communications in the field may incorporate
aspects of mesh networks and mobile ad-hoc networks (MANETs). Given
the environmental challenges, we assume that two agents will often
only have intermittent end-to-end connectivity, if any. Facilitating
communication through such a dynamic and chaotic mobile network calls
for a disruption-tolerant networking (DTN) architecture, which
provides a custody transfer and store-carry-forward model that is
resilient to disruption \cite{2021:intro-dtn}. The exact form of such
a network remains a question for future investigation.

\subsection{Data Collection and Processing}
\label{ssec:data-collection}
Perhaps the most universally acknowledged expectation for future
disaster response environments is a heavy reliance on data
gathered from both humans and sensors. Besides improvements to
communications that facilitate information sharing, we expect advances
in machine intelligence to greatly influence how this data is
handled.

Agents in disaster response environments will be both producers and
consumers of data, and this data will need to processed by humans and
machines in ways that agents can readily make sense of to support
their decision-making. We list just some of the possible sources and
types of pertinent data:
\begin{itemize}
\item Free-form communication, especially real-time or recorded voice messages
  broadcast to many agents at once, which may need to be processed by
  machines to extract the most pertinent information into a more
  actionable format
\item The exact or estimated location of victims, firefighters,
  vehicles, hazards, and so on displayed on applications like TAK
\item Medical information gathered from victims, perhaps stored in and
  collected from electronic triage tags \cite{2009:triagetag}
\item Data about current and predicted fire behavior gathered from
  systems like the Fire Integrated Real-time Intelligence System
  (FIRIS) or NASA's Fire Information for Resource Management System
  (FIRMS)
\item Weather data from the National Weather Service
\item Topographic information about the terrain, highlighting for
  instance the location of rivers and roads that could form a fire
  control line
\item Planned escape routes, rendezvous points, safety zones, and
  landing zones
\item Availability and dispatching of assets, e.g.~ambulances,
  airtankers, or crews on standby, such as the prototype application
  considered by Monares et al. \cite{2011:monares}
\end{itemize}
In a perfect environment, such information would be shared with all
necessary agents in whole and instantly. In reality, agents will be
presented with information that is sometimes incomplete, out of date,
or contradictory---all problems that are further exacerbated by an
unreliable network. A competing concern is that the information
presented will be \emph{overcomplete}, filled with petty details that
distract agents from their important tasks.

In some ways, future systems for disaster response will bear
resemblence to future systems for warfighting, such as the conceptual
\emph{Internet of Battle Things} (IoBT) \cite{2016:iobt}. To quote
from that paper, agents ``under extreme cognitive and physical
stress'' will be subject to a highly dynamic and dangerous
environment. Various kinds of technology will assist humans by
providing data to support sensemaking, but a contraindicating concern
will be flooding agents with a ``massive, complex, confusing, and
potentially deceptive ocean of information.'' To avoid ``swimming in
sensors and drowning in data'' \cite{2010:magnuson}:
\begin{quote}
``Humans seek well-formed, reasonably-sized, essential information
  that is highly relevant to their cognitive needs, such as effective
  indications and warnings that pertain to their current situation and
  mission.'' \cite{2016:iobt}
\end{quote}

The field of Human-Computer Interaction (HCI) is concerned with
``design, evaluation and implementation of user interfaces for
computer systems that are receptive to the user's needs and habits.''
\cite{2009:hci-definition} As emergency control becomes more
data-driven, particularly in hubs like dispatch centers that aggregate
diverse streams of information, the challenge of ensuring users can
interact effectively with these systems will become increasingly
important. We propose that researchers in HCI take up the question of
how agents under stress can process and respond to the flood of
complex information they may face. Relevant topics for exploration
include structuring interfaces to avoid cognitive overload and
facilitate intuitive control. Attention should also be given to
helping agents avoid subtle but critical mistakes, such as dispatching
resources to the wrong location---for instance, \emph{S. Example Rd.}
instead of \emph{N. Example Rd}.


\subsubsection{Adversarial Behavior}
One feature of the Internet of Battle Things worth highlighting is
``the adversarial nature of the environment.'' This feature is common
also to disaster environments, whether resulting incidentally from
``fog of war'' effects or deliberately caused by malicious actors
seeking to exploit a civil disaster. Section
\ref{ssec:communication-patterns} cited a real-world example of a
critical communications station destroyed by wildfire, perhaps
comparable to an attack by enemy forces.

There is a growing trend in disaster response to rely on
``crowdsourced'' information, where public safety officials process
reports from the general public over non-traditional channels like
social media. However, a significant vulnerability of crowdsourcing
information is the potential for confusing of contradictory reports,
which can resemble intentional deception. Rumors frequently plague
disaster relief environments, which are quite susceptible to
misinformation. For instance, during Hurricane Harvey in 2017, there
were unconfirmed rumors of shots being fired at volunteer rescuers
\cite{2017:cajun-navy-rumors}. Tracing reports back to their source is
often difficult. Even fully malicious activity like
``swatting''---placing a fake 911 call to cause a large police
response---is often observed in public safety. Whether misinformation
is spread with malicious intent or through well-meaning confusion, the
proliferation of false information in this chaotic environment can
have adversarial effects. This should be anticipated as part of a
careful approach to modernizing systems in this space.

\subsubsection{Allocation of Network Resources}
\label{sssec:allocation-of-network-resource}
Communications in disaster response environments might even be less
reliable than in the battlefield (setting aside offensive behavior
like signal jamming), requiring a greater emphasis on the preservation
of scarce network resources. For instance, a group of volunteer
firefighters would have fewer resources than a tactical military unit,
relying on commercial off-the-shelf (COTS) equipment rather than best
in class hardware like sophisticated handheld satellite links. High
bandwidth channels will often be in short supply, while adverse
conditions like inclement weather are assumed.

Given the heavy reliance on data and the scarcity of reliable
communication channels, we expect a complex interaction between the
high-level needs of distributed applications (e.g. an application for
sharing real time weather data) and low-level concerns about network
resources. This is because only the applications have enough
information to determine which data is the most important and must be
shared with whom first, which has ramifications for network-level
mechanisms designed to prioritize important messages.

There is a widely accepted wisdom in computing---the end-to-end
principle \cite{1984:end-to-end}---which suggests roughly that
applications should not make assumptions about the network, and that
the network should be relatively agnostic to high-level application
logic. However, in natural disaster environments where resources are
scarce and reliable communication is critical, these subsystems may
need to be more tightly integrated in how they influence each other to
achieve the best performance. This approach would not contravene the
end-to-end principle, but would involve carefully considering its
application in this relatively extreme context.

Consider, say 5 to 10 years in the future, a centralized data fusion
application that running in an edge data center.\footnote{An
  \emph{edge} data center is one located closer to a network's edge,
  nearer to users, to provide low-latency communications for
  time-sensitive applications. Edge centers support applications that
  require significant amounts of information processing---enough that
  the application must be hosted in a datacenter, where compute
  resources can be scaled dynamically, rather than colocated with
  users where resources are limited.} This application could detect
critical events like a fire crossing a control line (a phenomenon
called \emph{slopover}) and alert ground responders. It might also
warn responders who have strayed too far from an escape route or
safety zone. These are high-priority notifications, so it would be
worthwhile to allocate scarce network resources to convey them to the
relevant parties in real-time.

On the other hand, while it may be beneficial for each firefighter to
have real-time information about the location of every other
firefighter, this may not always be critical. If transmitting this
data strains the network, then perhaps only the general location of
nearby teams should be sent. If the network is extremely constrained,
communication may be restricted to only information strictly relevant
to preserving life to ensure swift, reliable delivery. Thus, network
allocation is a dynamic calculation influenced both by the criticality
of the information (which is determined by the application logic) and
the availability of network resources at a particular
location. Network services should provide mechanisms like Quality of
Service (QoS) indicators to allow prioritizing certain
communication. Such mechanisms can be incorporated into a control loop
where applications generate feedback that drives the decision-making
process in lower-level parts of the network. However, simple QoS
mechanisms may not be enough---even the routing protocol of the
network may need to be more specialized to higher-level applications
than in traditional environments.


\section{Introduction to Distributed Systems}
\label{sec:background}
In this section, we distill two core topics in the theory of
distributed systems: causality and timekeeping, along with shared
memory consistency.  Our discussion is primarily informed by the
manuscripts of Coulouris et al.  \cite{coulouris2005distributed} and
Kshemkalyani and Singhal \cite{kshemkalyani_singhal_2008}. We focus on
building applications relevant to the scenarios described in Section
\ref{sec:disaster-response}, aiming to highlight obstacles and
strategies for developing distributed systems that can endure the
delays and disruptions inherent to these communication-challenged
environments. Readers interested in a summary of the highlights may
skip to Section \ref{ssec:background-summary}.

At its core, a distributed system is a network of independent entities
working together to solve problems too complex for any one part to
tackle alone. From a bird’s-eye view, the systems we envision are
intricate and complex, made up of diverse, interconnected elements:
field agents like firefighters, their handheld devices, airborne and
ground vehicles loaded with communication and computing tools, swarms
of sensors and IoT devices, and so on. These decentralized components
operate alongside more centralized hubs: data fusion centers, incident
command (IC) posts, public safety answering points (PSAPs), and
emergency operations centers (EOCs). We imagine these components being
woven together by a patchwork of communication technologies ranging
from analog and digital radios to Bluetooth, Wi-Fi, LTE, 5G, satellite
communications, and ad-hoc mesh networks like Meshtastic\footnote{The
  website of the Meshtastic project describes it as an ``open source,
  off-grid, decentralized, mesh network built to run on affordable,
  low-power devices''. See \url{https://meshtastic.org}.}, DECT-2020
NR\footnote{DECT-2020 NR is a non-cellular 5G
  standard intended for Internet of Things (IoT) operations. For a
  technical discussion see \cite{2022:dect-2020-nr}.}, and others. The
system is thus a dynamic mosaic of elements cooperating to protect
lives and property.

Given the unpredictable nature of the environment and the locality
principle outlined in Section \ref{sec:disaster-response},
communication between edge components---such as field operators---and
centralized hubs is often inconsistent, sometimes available only
intermittently. As a result, information flow is subject to
appreciable delays compared to the timescale of critical events like a
fire shifting direction or a dangerous condition being detected. In
other words, the computing landscape is unmistakably
\emph{distributed}. Singhal and Shivaratri \cite{10.5555/562065}
define a distributed computing system as:
\begin{quote}
  ``A collection of computers that do not share common
  memory or a common physical clock, that communicate by message
  passing over a communication network, and where each computer has
  its own memory and runs its own operating system.''
\end{quote}
This stands in contrast to a centralized computing environment, where
processes can seamlessly share data through common memory, and memory
access times are considered negligible.

For our use cases, message-passing latencies are not only significant
but unpredictable and difficult to control. As a result, we can safely
assume that some parts of the wider system will not have
instantaneous, complete knowledge of every new piece of
information. Only a few components, if any, will be able to maintain a
global systemwide awareness. While deploying additional infrastructure
in the field, such as COWs (Cells on Wheels), can help, the inherently
distributed nature of the environment cannot be fully overcome or
abstracted away. This reality must be embedded in the design of the
software and networking architecture itself. Typically, this manifests
in a shared ``middleware'' layer to coordinate the moving parts,
ensuring they function as a unified system.

The fragmented flow of information presents several challenges for
system designers. Foundationally, one of the primary computer science
problems is that unpredictable latencies make it difficult for
components to maintain a common understanding about the global
sequence of events. For similar reasons, it becomes challenging for
processes to synchronize and agree on shared values, such as the
current number of firetrucks available for dispatch. The remainder of
this section will delve into these issues with more technical depth.

\subsection{Physical Synchronization}
\label{ssec:physical-synchronization}
A lot of challenges in distributed computing could be
straightforwardly overcome if we assume that all participants have
instantaneous access to a common time base, i.e.  synchronized
clocks. Let us explore why fine-grained synchronization is not a
tenable assumption for all purposes.

Physical clocks, especially consumer-grade ones, suffer from
\emph{drift}, which is to say they do not all run at the same
rate. Experienced IT administrators will testify that clocks can also
be prone to misconfiguration. An incorrect date, time, timezone, or
daylight saving time policy setting is a common source of IT issues,
typically causing time-based security mechanisms like TLS
authentication to misbehave. Consider also that devices may spend a
long time sitting unpowered in storage without maintaining an
always-on clock. For these sorts of reasons, we would not want to rest
the integrity of a safety-related system on the assumption that a
numerous and diverse assortment of devices have precisely synchronized
internal clocks.

Clock drift can be corrected for using, for instance, signals from GPS
satellites, but as mentioned in Section \ref{sec:disaster-response},
civil disaster environments are frequently GPS-denied: factors like
mountainous terrain, heavy smoke, and subterranean operations can lead
to errors or block signals entirely. Protocols like the Network Time
Protocol (NTP) \cite{rfc1119} work to bring clocks into
synchronization with respect to an authoritative source. On the public
internet, NTP typically achieves synchronization to within values on the
order of tens of milliseconds \cite{rfc1128}, but it is not clear the
level of synchronization that can be expected from NTP in the sorts of use
cases we have in mind. A field device initialized without internet
access may have no idea what the time is, but it must still operate.

For our use case, what seems most important about time is that
\emph{the future cannot influence the past}
\cite{1989mattern}. Fortunately, this sort of invariant can be
enforced with mechanisms that do not rely on measuring real
time. Below, we explain how so-called logical clocks can be used to
measure and enforce a key relation between events, this being their
\emph{causal precedence}.


\subsection{Message Passing and Causality}
\label{ssec:message-passing}
We model a distributed system abstractly as a fixed set
$\AllProc = \{P_1, P_2, \ldots P_N\}$ of $N$ \emph{processes} which
undergo atomic (indivisible) state changes known as
\emph{events}. Events are divided into three types: internal events,
representing state changes inside a single process, and send and
receive events corresponding to \emph{messages} passed between
processes. Note that this framework is quite abstract and applies to
any kind of packet-based communication technology. To draw out the
core issues surrounding messaging, the diagrams in this section do not
depict any internal events, as they represent state changes that are
not directly viewable to the network or other processes.

Throughout the section, processes and networks are opaque blackboxes,
which concentrates our attention on the ramifications of unpredictable
network latencies. We implicitly assume the reliable asynchronous
network model: when a message is sent between processes, it certainly
arrives at some point in the future, but we cannot say anything about
when or in what order compared to other messages. At times, we
consider the possibility that a message may never arrive. The choice
depends on which networking technology (or which layer of the OSI
networking model \cite{1983:osi-reference-model}) is under
consideration.

Figure \ref{fig:message-latencies} illustrates a series of time
diagrams for messages exchanged between three processes: $P_1$, $P_2$,
and $P_3$. The $x$-axis represents the flow of real time from left to
right, which each process represented by a worldline depicting the
events occurring within that process. Each message, $m$, originates
from a send event $\msend{}$, marking the moment the message is
dispatched across the network by its source process. The delivery of
the message corresponds to a receive event, $\mrecv{}$. For now we
assume messages have a single receiver. We write subscripts on
messages to distinguish them for clarity, but these are not inherent
to the messages themselves.

\begin{figure}[p]
  \setlength\belowcaptionskip{5ex}
  \begin{subfigure}{1\textwidth}
    \centering
    \input{images/pgf/mpEx1.pgf}
    \caption{$P_1$ has a somewhat lower-latency connection to $P_2$ than to $P_3$}
    \label{fig:message-latencies-a}
  \end{subfigure}
  \begin{subfigure}{1\textwidth}
    \centering \input{images/pgf/mpEx2.pgf}
    \caption{$P_1$ has a much lower-latency connection to $P_2$ than to $P_3$}
    \label{fig:message-latencies-b}
  \end{subfigure}
  \caption{Message-passing time diagram examples}
  \label{fig:message-latencies}
\end{figure}

In these diagrams, arrows connect corresponding send and receive
events, with their diagonal slant representing the latencies
experienced as messages traverse the network. Because messages arrive
with varying delays, they might arrive in a different order than they
were sent in. In Figure \ref{fig:message-latencies-a}, for example,
$P_1$ sends messages $m_2$ and $m_4$ sequentially, but $m_4$ arrives
before $m_2$, which might occur if $P_1$ and $P_3$ are separated by a
high-latency communication link. In Figure
\ref{fig:message-latencies-b}, $m_1$ is the first message sent but the
last to be delivered, potentially indicating a deteriorating link
between $P_1$ and $P_3$, perhaps due to increased distance or
inclement weather.

For many applications, it is critical to maintain a natural ordering
of events known as \emph{causal precedence}, or Lamport's ``happens
before'' relation \cite{1978:lamportclocks}. To formalize this, we
first consider the intuitive way to order events within a
\emph{single} process:
\begin{definition}
  For two events $e$ and $e'$ occurring in process $P$, we
  write $e <_{P} e'$ if $e$ occurs before $e'$ in $P$'s
  worldline.
\end{definition}
The previous definition is local to one process and unambiguous, as we
assume events within a process occur at discrete, non-overlapping
points in time. To extend this to a system-wide definition of causal
precedence, we relate corresponding send and receive events, then take
the transitive closure of the relation.

\begin{definition}[Causal precedence]
  \label{def:causalprecedence}
  We define a binary relation $\to$ on the set of events as follows:
  \[e \to e' \iff
  \begin{cases}
    e <_{P} e' \textrm{ for some process $P$}
    \textbf{ or} \\
    e = \msend{} \textrm{ and } e' =\mrecv{}
    \textbf{ or} \\
    \textrm{there is some } e'' \textrm{ such that } e \to e'' \textrm{ and } e'' \to e'
  \end{cases}
  \]
  If $e \to e'$, we say $e$ has \emph{causal precedence over} $e'$ or
  \emph{happens before} $e'$.
\end{definition}
Visually, $e \to e'$ holds when one can put a finger on $e$ in the
diagram and trace a ``path of causality'' to $e'$ by following
worldlines or arrows. We use the notation $e \not \to e'$ to mean
$e \to e'$ does not hold. Note that $e \not \to e'$ does not imply
$e' \to e$.

Incidentally, ``causal precedence'' and ``happens before'' can be
misnomers, as $e \to e'$ only conveys the possibility that information
from $e$ could have influenced $e'$. The requirement to ``not let the
future affect the past'' means that if $e$ might have influenced $e'$,
then applications must avoid situations where, from the user's point
of view, it appears that $e'$ happened before $e$. For example, this
proscription means an application cannot let an ``answer'' appear
before the underlying ``question''.

\begin{example}
  Figure \ref{fig:causal-precedence} illustrates the causal precedence
  relation corresponding to the time diagrams in Figure
  \ref{fig:message-latencies}. For readability we suppress redundant
  transitive arrows. The visual difference between Figures
  \ref{fig:message-latencies-b} and \ref{fig:message-co-b} reflects
  the fact that causal order only captures a logical relationship
  between events, but does not reflect their absolute time or within
  which process they occurred.
\end{example}

Mathematically, causal precedence is an irreflexive partial order:
\emph{irreflexive} because $e \not \to e$ (an event does not precede
itself), and \emph{partial} because any two events $e$ and $e'$ may
satisfy neither $e \to e'$ nor $e' \to e$.

\begin{definition}[Logical synchronicity]
  \label{def:logically-synchronous}
  Events $e$ and $e'$ that are not related by causality are said to be
  \emph{logically synchronous}, denoted $\sync{e}{e'}$.
\end{definition}

Note that logical synchronicity is not usually transitive, meaning it
is possible to have $\sync{e}{e'}$ and $\sync{e'}{e''}$ but not
$\sync{e}{e''}$.  Relations like $\left(\sync{}{}\right)$ that are
reflexive and symmetric but not necessarily transitive are sometimes
called \emph{compatibility relations}.
\begin{example}
  \label{ex:synchronous-intransitive}
  In Figure \ref{fig:message-co-a}, $\sync{\mrecv{1}}{\mrecv{2}}$ and
  $\sync{\mrecv{2}}{\msend{4}}$, but $\mrecv{1} \to \msend{4}$. In
  Figure \ref{fig:message-co-b}, $\msend{1}$ is logically synchronous
  with every event except $\mrecv{1}$, but those other events are
  totally ordered by causality and not synchronous with each other.
\end{example}

\begin{figure}
  \begingroup
  \setlength\belowcaptionskip{4ex}
  \begin{subfigure}{1\textwidth}
    \centering
    \input{images/pgf/mpEx1CO.pgf}
    \caption{Causal precedence among the events in Figure \ref{fig:message-latencies-a}}
    \label{fig:message-co-a}
  \end{subfigure}
  \endgroup
  \begin{subfigure}{1\textwidth}
    \centering
    \input{images/pgf/mpEx2CO.pgf}
    \caption{Causal precedence among the events in Figure \ref{fig:message-latencies-b}}
    \label{fig:message-co-b}
  \end{subfigure}
  \caption{Causal precedence relations for Figure \ref{fig:message-latencies} (transitive arrows not shown)}
  \label{fig:causal-precedence}
\end{figure}

\subsection{Virtual Clocks}
\label{ssec:timestamps}
Distributed applications systematically track causality by employing
\emph{logical} clocks, which measure the logical flow of time by
timestamping events with (possibly sets of) non-negative integers that
are advanced according to certain rules. The three major variants are
scalar, vector, and matrix clocks, which form a kind of
spectrum. Scalar clocks are simple but provide coarse-grained
information, while vector and matrix clocks track increasingly more
precise information at the cost of greater administrative overheads.

All processes timestamp their events using their local clocks. For
each event $e$, let $C(e)$ denote the timestamp attached to that
event. The fundamental property we want to satisfy is that if $e$
causally precedes $e'$, it should receive a lesser timestamp. This is
called the clock consistency condition, or simply the clock condition.

\begin{definition}
  A system of timestamps satisfies the \emph{clock consistency
  condition} if the following monotonicity property holds:
\begin{equation}
  \textrm{For all $e$ and $e'$, if $e \to e'$ then $C(e) < C(e')$} \label{eq:mp}\tag{CC}
\end{equation}
\end{definition}

This notation states that if one event causally precedes another, then
the earlier one receives a lesser timestamp. Somewhat subtly, the
clock condition does \emph{not} imply that we can decide if events are
causally related by comparing timestamps. Rather, it provides a way of
\emph{ruling out} causal precedence. This is seen by expressing
\eqref{eq:mp} in terms of the following logically equivalent
condition.
\begin{equation}
  \textrm{For all $e$ and $e'$, if $C(e') \leq C(e)$ then $e \not\to e'$} \label{eq:mp-conv}\tag{CC$'$}
\end{equation}

If \eqref{eq:mp-conv} holds, we can be sure that a particular sequence
of events $e_1, e_2, e_3\ldots$ does \emph{not} list any $e$ before an
event that might have influenced $e'$ by checking that
$C(e_{i}) \leq C(e_{i+1})$ for all $i$. We emphasize that this does
not give us a definite way to tell whether two events are in fact
causally related. If it is important to determine conclusively whether
events are causally related, one is led to consider the following
stronger requirement from a system of logical timestamps.
\begin{definition}
  An event-timestamping mechanism satisfies the \emph{strong} clock   condition if the following property holds.
  \begin{equation}
    \textrm{For all events $e$ and $e'$, } e \to e' \iff C(e) <
    C(e') \label{eq:sc}\tag{SC}
  \end{equation}
  Note that $\iff$ is notation for ``if and only if,''or logical
  equivalence.
\end{definition}
Scalar clocks, below, satisfy \eqref{eq:mp}, while vector and matrix
clocks satisfy \eqref{eq:sc}.

\subsubsection{Scalar clocks}
\label{sssec:scalar-clocks}
\begin{figure}
  \setlength\belowcaptionskip{5ex}

  \begin{subfigure}{1\textwidth}
    \centering \input{images/pgf/mpEx1Sc.pgf}
    \caption{Figure \ref{fig:message-latencies-a} redepicted with scalar clocks}
    \label{fig:message-latencies-scalar-a}
  \end{subfigure}

  \begin{subfigure}{1\textwidth}
    \centering \input{images/pgf/mpEx2Sc.pgf}
    \caption{Figure \ref{fig:message-latencies-b} redepicted with scalar clocks}
    \label{fig:message-latencies-scalar-b}
  \end{subfigure}

  \caption{Scalar clock examples}
  \label{fig:message-latencies-scalar}
\end{figure}

Lamport's scalar clocks \cite{1978:lamportclocks} require each
process $P$ to maintain a single non-negative scalar value $C$,
initialized to $0$. The clock follows two simple update rules:
\begin{enumerate}
\item[\textbf{R1}:] Before a message is sent or an internal event occurs, $P$
  increments its clock:
  \[C := C + 1.\]
  The new value serves as the event's timestamp and, for messages, is ``piggybacked''
  as part of its metadata.
\item[\textbf{R2}:] When $P$ receives a message with timestamp $C'$, it
  updates $C$ as such:
  \[C := \max(C, C') + 1.\]
  The value is the receive event's timestamp.
\end{enumerate}

\begin{example}
  Figure \ref{fig:message-latencies-scalar} depicts the same events in
  Figure \ref{fig:message-latencies} with scalar timestamps (shown in
  parentheses) assigned to each event. Piggybacked timestamps are
  shown as labels on the message arrows.
\end{example}

Scalar clocks satisfy the clock condition \eqref{eq:mp}. This can be
observed by tracing the path of causality between related events and
seeing that the clock is incremented at each step. However, they do
not satisfy \eqref{eq:sc}.  While $e$ having a lesser timestamp than
$e'$ rules out $e' \to e$, it does not imply $e \to e'$. For instance,
in Figure \ref{fig:message-latencies-scalar-b}, $\msend{1}$ has a
globally minimal timestamp value of $1$, but it does not causally
precede all events with timestamps greater than $1$, or indeed any
event except $\mrecv{1}$.

\subsubsection{Vector clocks}
\label{sssec:vector-clocks}
The strong clock condition \eqref{eq:sc} cannot hold either using
scalar clocks or even synchronized physical clocks because they both
assign timestamps whose values form a total order, meaning any
non-equal timestamps $C_1, C_2$ satisfy either $C_1 < C_2$ or
$C_2 < C_1$. This leaves no way to assign timestamps to synchronous
events that satisfy neither $e \to e'$ nor $e' \to e$, except to make
their timestamps are equal. However, assigning equal timestamps to
logically synchronous events is contradictory, since an event $e$ can
be synchronous with multiple events $e', e''\ldots$ that are not
synchronous with each other (recall Example
\ref{ex:synchronous-intransitive}). The solution is to let timestamps
from a partial order, allowing clock values that are not directly
comparable.


\begin{figure}
  \setlength\belowcaptionskip{5ex}

  \begin{subfigure}{1\textwidth}
    \centering
    \input{images/pgf/mpEx1Vec.pgf}
    \caption{Figure \ref{fig:message-latencies-a} redepicted with vector clocks}
    \label{fig:message-latencies-vector-a}
  \end{subfigure}

  \vspace{4ex}

  \begin{subfigure}{1\textwidth}
    \centering \input{images/pgf/mpEx2Vec.pgf}
    \caption{Figure \ref{fig:message-latencies-b} redepicted with vector clocks}
    \label{fig:message-latencies-vector-b}
  \end{subfigure}

  \caption{Vector clock examples}
  \label{fig:message-latencies-vector}
\end{figure}
\afterpage{\clearpage}

Vector clocks store one scalar value for each process in the system,
which forms a partial order when vectors are compared
component-wise. $P$ maintains a vector $\vt{}$ of $N$ non-negative
integers, one for each process in $\AllProc$, with all values
initialized to $0$. To disambiguate $P$'s vector clock from $Q$'s, we
sometimes add superscripts, e.g. $\vt{P}$ versus $\vt{Q}$.

The $P^\textrm{th}$ component of $P$'s vector clock, denoted
$\vt{}[P]$, is called $P$'s \emph{local time}. For all other processes
$Q$, $\vt{}[Q]$ represents a lower bound of $Q$'s local time. Vector
clocks are updated according to two rules:
\begin{enumerate}
\item[\textbf{R1}:] Before an internal event occurs or a new message is sent, $P$
  increments its local time according to the rule:
  \[\vt{}[P] := \vt{}[P] + 1.\]
  The (entire) updated $\vt{}$ is the event's timestamp and is piggybacked with outgoing messages.
\item[\textbf{R2}:] When $P$ receives a message from $Q$ with timestamp
  $\vt{Q}$, $\vt{}$ is updated according to
  \[\vt{}[X] := \max(\vt{}[X], \vt{Q}[X]) \quad \textrm{for all $X$ in $\AllProc$}.\]
  That is, $\vt{}$ is set to the pointwise maximum of the two
  vectors. After this, $P$ increments its local time:
  \[ \vt{}[P] := \vt{}[P] + 1.\]
  The final vector is the timestamp of the receive event.
\end{enumerate}
These rules are more intuitively understood by demonstration.

\begin{example}
  Figure \ref{fig:message-latencies-vector} depicts the same events as
  Figure \ref{fig:message-latencies} with vector timestamps.
\end{example}

For all other $Q$ in $\AllProc$, $\vt{P}[Q]$ represents $P$'s
conservative estimate of $Q$'s local time, or $\vt{Q}[Q]$. This
estimate is always a lower bound, since $Q$'s local time may advance
without $P$'s knowledge, but $P$ never updates $\vt{P}[Q]$ ahead of
$Q$'s actual local time. $P$ learns about updates to $Q$'s local time
through piggybacked timestamp vectors. This allows $P$ to learn about
$Q$'s time without necessarily communicating directly with $Q$.

Vector timestamps are compared component-wise. This forms a partial
order because one vector may be greater than another in some
components but less than it in others.

\begin{definition}[Vector comparison]
  Let $v, w$ be two vectors. We define the following relations:
  \begin{align*}
             v = w &\iff \forall i, v[i] = w[i] \\
  v \preccurlyeq w &\iff \forall i, v[i] \leq w[i] \\
         v \prec w &\iff v \preccurlyeq w \textrm{ and } \exists i, v[i] < w[i] \\
            \syncts{v}{w} &\iff \textrm{ neither } v \prec w \textrm{ nor } v \succ w
  \end{align*}
  That is, $v \prec w$ if all of $w$'s components are at least as
  great as $v$'s, and at least one of its components is strictly
  greater. When two non-equal vectors are compared, and neither is
  greater than the other, we write $\syncts{v}{w}$ and say the vectors
  are \emph{incomparable}.
\end{definition}

\begin{lemma}
  Vector clocks satisfy the strong clock consistency condition. That
  is, where $C(e)$ is the vector timestamp of an event, then
  \[ e \to e' \iff C(e) \prec C(e'). \]
  From this it follows that for non-equal events $e$ and $e'$ we have
  \[\sync{e}{e'} \iff {C(e) \texttt{\#}\,C(e')}. \]% This isn't typesetting right
\end{lemma}

For reasons of space we omit a proof of the preceding lemma, though
the reader may find it enlighting to formalize the details.

Note that vector clocks and matrix clocks both require the processes
to agree on the set of members in the group. If groups can change,
with members leaving or being added, the timekeeping data structures
would similarly have to be updated. We ignore issues of dynamic group
membership in this document.

\subsubsection{Matrix clocks}
\label{sssec:matrix-clocks}
If a vector clock stores both a local time and a lower bound estimate
of every other process's local time, then a matrix clock stores a
local vector clock and a lower bound estimate of every other process's
vector clock. Each process $P$ stores an $N\times{}N$ matrix
$\mt{}{}{}$, initialized to all zeros, with the following
interpretation. The row corresponding to $P$, $\mt{}{[P]}{}$,
stores $P$'s vector time. For all other $Q$, $\mt{}{[Q]}{}$ store $P$'s
estimate of $Q$'s vector time. Matrix timestamps are piggybacked
with messages, and the receiver uses the sender's vector clock to
update their own vector clock as usual, and takes the pointwise
maximum of all other rows.

\begin{enumerate}
\item[\textbf{R1}:] Before a new message is sent, $\mt{P}{[P]}{[P]}$ is updated according to the rule
  \[\mt{P}{[P]}{[P]} := \mt{P}{[P]}{[P]} + 1.\]
  The entire matrix $\mt{}{}{}$ is piggybacked with the message.
\item[\textbf{R2}:] When a message is received from $Q$ with a piggybacked matrix $\mt{Q}{}{}$,
  $\mt{P}{}{}$ is updated according to two cases
  \begin{enumerate}
  \item Update the row $\mt{P}{[P]}{}$ according to
    \[\mt{P}{[P]}{[X]}:= \max( \mt{P}{[P]}{[X]} ,  \mt{Q}{[Q]}{[X]}) \quad \textrm{for all $X$ in $\AllProc$}\]
  \item Update all rows for each $R \neq P$ according to
    \[\mt{P}{[R]}{[X]} := \max(\mt{P}{[R]}{[X]} ,  \mt{Q}{[R]}{[X]})) \quad \textrm{for all $X$ in $\AllProc$}\]
  \end{enumerate}
  After this, $P$ advances its own local time according to the rule
  \[ \mt{P}{[P]}{[P]} := \mt{P}{[P]}{[P]} + 1.\]
  This new matrix is the timestamp attached to the receive event.
\end{enumerate}

\begin{figure}[p]
  \begingroup
  \setlength\belowcaptionskip{4ex}
  \begin{subfigure}{1\textwidth}
    \input{images/pgf/mpEx1Mat.pgf}%
    \caption{Matrix clock timestamps for the events in Figure \ref{fig:message-latencies-a}}
    \label{fig:message-latencies-matrix-a}
  \end{subfigure}
  \begin{subfigure}{1\textwidth}
    \input{images/pgf/mpEx2Mat.pgf}%
    \caption{Matrix clock timestamps for the events in Figure \ref{fig:message-latencies-b}}
    \label{fig:message-latencies-matrix-b}
  \end{subfigure}
  \caption{Figure \ref{fig:message-latencies} depicted with matrix clocks}
  \label{fig:message-latencies-matrix}
  \endgroup
\end{figure}

\begin{example}
  Figure \ref{fig:message-latencies-matrix} depicts the same events as
  Figures \ref{fig:message-latencies},
  \ref{fig:message-latencies-scalar} and
  \ref{fig:message-latencies-vector} using matrix timestamps. By
  comparison to Figure \ref{fig:message-latencies-vector}, observe
  that for each process $X$, rows of the form $\mt{X}{[X]}{}$---for
  instance, the top row of matrices in $P_1$---act like ordinary vector
  clocks.
\end{example}

In Section \ref{sec:background}, we mentioned the epistemic nature of
reasoning about distributed systems: a process can only make decisions
based on what it \emph{knows}, which is usually a strict subset of all
(system-wide) truths. In many cases, it is important to take into
account a kind of second-order knowledge: what does a process know
about what other processes know? A typical utility of vector and
matrix clocks is to track which facts known to one process are also
known to another processes. Often it is of interest to compute which
facts are known to \emph{all} other processes. Sections \ref{sec:tsae}
and \ref{sec:continuous-consistency} feature running examples of
mechanisms similar to vector and matrix clocks, called version vectors
and matrices. These are used in the context of database replication,
where they drive decision-making about which updates need to be
propagated and which updates have already been applied everywhere.

\subsection{Message Ordering}
\label{ssec:message-ordering}
Coulouris et al. \cite{coulouris2005distributed} aptly summarized why
it is a problem for unpredictable network latencies to cause messages
to arrive in a different order than they were sent in.
\begin{quote}
  ``This lack of an ordering guarantee is not satisfactory for many
  applications. For example, in a nuclear power plant it may be
  important that events signifying threats to safety conditions and
  events signifying actions by control units are observed in the same
  order by all processes in the system.''
\end{quote}
In this section, we explore different paradigms for message ordering
in distributed systems. As with clocks and timestamps, the choice of
which ordering guarantee to use depends on the needs of the
application. We later generalize the discussion by admitting messages
sent to multiple recipients at once, such as in a group chat
application, where ensuring predictable message ordering is critical.

When ordering is important, applications do not show messages to the
user immediately when they come in from the network---the network can
deliver messages in unexpected and undesirable orders, after all. The
\emph{arrival} time of a message is when it is received from the
network, but instead of acting on it right away, an application may
buffer an arrived message while waiting for other messages (such as
ones with an earlier causal precedence) to ``catch up.'' When a
message is ready to be presented to the user, it is
\emph{delivered}. By waiting to deliver some messages, we can ensure
the stream of messages in order of their delivery satisfies particular
guarantees.

\subsubsection{FIFO ordering}
A modest requirement is the \emph{first-in, first-out} (FIFO)
condition, which stipulates that on any logical communication link
between two processes in the system, messages arrive in the order they
were sent. The restrictive phrase here is ``any logical communication
link''---by definition there is one link for any \emph{pair} of
processes. Hence, FIFO does not impose any conditions on messages
unless they are from the same sender and to the same recipient.

\begin{definition}[FIFO delivery]
  \label{def:fifo}
  The FIFO ordering guarantee is defined by the following condition. Let
  $P$ and $Q$ be any two processes and $m_1$ and $m_2$ be two
  messages sent from $P$ to $P$. Then
  $\msend{1} \to \msend{2} \implies \mrecv{1} \to \mrecv{2}$.
\end{definition}

The Internet Protocol (IPv4 or IPv6) by itself does not provide FIFO
semantics. In the OSI model, FIFO ordering with reliable delivery is
typically provided at the transport layer by the transmission control
protocol (TCP).\footnote{The other classic internet transport, user
  datagram protocol (UDP), does not provide any ordering or
  reliability guarantees.} Applications built on top of TCP or a
similar transport can take therefore take FIFO for granted. Providing
FIFO can be as simple as marking messages sent from $P$ to $Q$ with
consecutive integers. If message $1$ arrives and then $3$ arrives, $Q$
infers that $2$ is lagging behind, delivering $1$ to the user but
withholding delivery of $3$ until after $2$ is received and delivered.

The guarantees provided by FIFO are minimal because they only apply on
a per-link basis: every link requires its own numbering scheme, so
message numbers cannot be meaningfully compared across different
links. To compare messages globally requires something like causal
order, below.

\begin{figure}[p]
  \setlength\abovecaptionskip{0ex}
  \setlength\belowcaptionskip{4ex}
  \begin{subfigure}[t]{0.475\textwidth}
    \centering
    \input{images/pgf/ordEx1.pgf}
    \caption{A non-FIFO execution}
    \label{fig:ordex-non-fifo}
  \end{subfigure}
  \begin{subfigure}[t]{0.475\textwidth}
  \centering
  \input{images/pgf/ordEx2.pgf}
  \caption{A CO (therefore FIFO) execution}
  \label{fig:ordex-co-1}
\end{subfigure}
\begin{subfigure}[b]{0.475\textwidth}
  \centering
  \input{images/pgf/ordEx3.pgf}
  \caption{A CO execution}
  \label{fig:ordex-co-2}
\end{subfigure}
\begin{subfigure}[b]{0.475\textwidth}
  \centering
  \input{images/pgf/ordEx6.pgf}
  \caption{A CO execution}
  \label{fig:ordex-co-3}
\end{subfigure}
\begin{subfigure}[b]{0.475\textwidth}
  \centering
  \input{images/pgf/ordEx5.pgf}
  \caption{A FIFO and non-CO execution}
  \label{fig:ordex-non-co-1}
\end{subfigure}\hfill
\begin{subfigure}[b]{0.475\textwidth}
  \centering
  \input{images/pgf/ordEx4.pgf}
  \caption{A FIFO and non-CO execution}
  \label{fig:ordex-non-co-2}
\end{subfigure}
\caption{Message ordering examples}
\label{fig:message-ordering}
\end{figure}

\subsubsection{Causal ordering}
Causal order is an order guarantee consistent with causal precedence
of events. A network provides causally ordered (CO) delivery if it
satisfies the following property.
\begin{definition}[CO delivery]
  \label{def:causalorder}
  Let $P_\mathrm{dest}$ be any process and consider all messages $m$
  and $n$ sent to $P_\mathrm{dest}$ (possibly by different senders).
  CO is satisfied if $\msend{} \to n^\textrm{send}$ implies
  $\mrecv{} \to n^\textrm{recv}$. That is, each destination receives
  messages in an order consistent with causality between their send
  events.
\end{definition}
In mathematical terms, for each process $P_{\mathrm{dest}}$, the
function mapping send events to corresponding receive events at
$P_{\mathrm{dest}}$ must be monotonic with respect to causal
precedence.  Unlike FIFO, the CO condition enforces a partial order
among messages with (in general) different senders.

\begin{example}
  Figure \ref{fig:message-ordering} demonstrates different message
  ordering conditions. We make a few observations for emphasis.

  \begin{itemize}
    \tightlist
  \item \ref{fig:ordex-non-fifo} violates FIFO because messages $m_1$
    and $m_2$ are both sent from $P_1$ to $P_2$, but the arrive in the wrong order.
  \item \ref{fig:ordex-co-1} satisfies CO and therefore FIFO. Messages
    $m_1$ and $m_2$ arrive in the opposite order but they are sent to
    different destinations.
  \item \ref{fig:ordex-non-co-1} violates CO because the send event of
    $m_1$ happens before the send of $m_3$ via the chain
    $\msend{1} \to \msend{2} \to \mrecv{2} \to \msend{3},$ but
    $\mrecv{3} \to \mrecv{1}$.
  \item \ref{fig:ordex-non-co-2} violates CO because it is equivalent to
    \ref{fig:ordex-non-co-1} with the roles of $P_2$ and $P_3$ swapped.
  \end{itemize}
\end{example}

\subsubsection{Multicasting and Broadcasting}
\label{sssec:multicasting}
We now extend the above definitions to the group communication setting
by allowing messages to have multiple recipients. For simplicity, we
suppose messages are broadcast to all other recipients, though the
definitions can easily generalize to ``multicast'' scenarios where
messages are sent to a subset of recipients.

One way to implement broadcasting is to sending distinct network
messages which, for present purposes, we would treat as a single
unit. Alternatively, we can lean on the network itself for assistance,
sending a single message specially marked as a broadcast, relying on
lower-level protocols in the network to distribute a copy to each
recipient. Regardless of implementation, the challenge and importance
of ensuring consistent message ordering across an entire group is a
paramount concern.

The FIFO and CO broadcast conditions are adapted from Definitions
\ref{def:fifo} and \ref{def:causalorder}. Additionally, we present the
notion of total ordering (TO).

\begin{definition}[FIFO broadcast]
  \label{def:fifo-bcast}
  A broadcast primitive satisfies the FIFO semantics if it satisfies
  the following condition. For any process $P$, if $P$ broadcasts
  $m_1$ before $m_2$, then all recipients receive $m_1$ before $m_2$.
\end{definition}

\begin{definition}[CO broadcast]
  \label{def:causalorder-bcast}
  A broadcast primitive satisfies CO semantics if for any broadcasts
  $m$ and $n$, if $\msend{} \to n^{\textrm{send}}$, then all
  destinations deliver $\mrecv{}$ before $n^{\textrm{recv}}$.
\end{definition}
In the above definition, the happens before relation is defined just
as in the unicast (non-broadcast) setting by following a path of
causality along worldlines and message arrows.

\begin{figure}[h]
  \centering \input{images/pgf/mpEx3.pgf}
  \caption{Broadcast example that satisfies FIFO but violates CO}
  \label{fig:broadcast-fifo-1}
\end{figure}

\begin{example}
  In Figure \ref{fig:broadcast-fifo-1}, causal order is violated. Imagine the following conversation:
  \begin{itemize}
    \tightlist
  \item [$P_1$]: ``I need an ambulance at location A.''
  \item [$P_2$]: ``Understood, the last ambulance has been dispatched.''
  \end{itemize}
  However, $P_3$ receives $P_2$'s response before $P_1$'s request, resulting in this conflicting view:
  \begin{itemize}
    \tightlist
  \item [$P_2$]: ``Understood, the last ambulance has been dispatched.''
  \item [$P_1$]: ``I need an ambulance at location A.''
  \end{itemize}
  From $P_3$'s perspective, $P_1$ appears to be requesting resources
  that are no longer available. The sort of conflict can lead to
  confusion, with requests being duplicated or going
  unanswered. Tracking causal order is crucial to avoid such resource
  misallocations.
\end{example}

A total order broadcast ensures that all recipients receive the
messages in the same order. This order is not required to satisfy any
particular constraints except that all recipients agree on it. Such a
model is appropriate when it is more important that everyone agrees on
a common order of events but the order itself is not necessarily
critical.

\begin{definition}[TO broadcast]
  \label{def:totalorderbroadcast} For any processes $P$ and $Q$ and
  messages $m$ and $m'$ that arrive at both destinations, $m$ arrives
  before $m'$ at both processes or $m'$ arrives before $m$ at both
  processes.
\end{definition}

Total order is independent of causal order, as causality is not total
and a total order does not generally respect causality. Thus it
sensible to consider also a hybrid notion of \emph{total-causal} order
in which all messages are received in a total order respecting
causality.

\begin{figure}[p]
  \setlength\belowcaptionskip{5ex}
  \begin{subfigure}{1\textwidth}
    \centering
    \input{images/pgf/bcastEx1.pgf}
    \caption{Broadcast example that satisfies FIFO but violates CO and TO}
    \label{fig:bcast-order-examples-1}
  \end{subfigure}
  \begin{subfigure}{1\textwidth}
    \centering
    \input{images/pgf/bcastEx2.pgf}
    \caption{Broadcast example that satisfies CO but violates TO}
    \label{fig:bcast-order-examples-2}
  \end{subfigure}
  \begin{subfigure}{1\textwidth}
    \centering
    \input{images/pgf/bcastEx3.pgf}
    \caption{Broadcast example that satisfies TO but violates FIFO}
    \label{fig:bcast-order-examples-3}
  \end{subfigure}
  \caption{Multicast ordering examples}
  \label{fig:bcast-ordering-examples}
\end{figure}

\begin{example}
Figure \ref{fig:bcast-ordering-examples} depicts examples of broadcast
message orders.
\begin{itemize}
  \tightlist
\item Figure \ref{fig:bcast-order-examples-1} trivially satisfies FIFO
  because no process sends more than one broadcast. CO is violated
  because $\msend{1} \to \mrecv{1,4} \to \msend{2}$, while $P_2$
  receives $m_2$ before $m_1$. TO is violated because $P_2$ and $P_3$
  receive the messages in opposite orders.
\item Figure \ref{fig:bcast-order-examples-2} violates TO for the same
  reason above, but satisfies causality because the two send events
  have no causal relation.
\item Figure \ref{fig:bcast-order-examples-3}
  satisfies TO, but $m_2$ arrives at both processes before $m_1$ so
  FIFO is violated.
\end{itemize}
\end{example}
Section \ref{ssec:tsae-message-ordering} describes a conventional
mechanism used to implement total order broadcast.
\paragraph{Self-delivered messages}
In some contexts one considers broadcast primitives that include the
original sender among the recipients of a message. For simplicity, the
examples in this section have not shown this sort of self-delivery,
but it is useful in many cases. Self-delivery is useful when combined
with ordering guarantees. A typical use case is that participants are
using a total order broadcast to maintain local replicas of a state
machine that can be advanced by any participating process by
announcing updates.  This usage is presented in Sections
\ref{sec:tsae} and \ref{sec:continuous-consistency}, with the goal of
replicating shared state over a disruption-heavy network.

\subsection{Shared Memory}
\label{ssec:shared-memory}
Desiging a distributed application using direct message passing can be
challenging due to the complexity of managing the low-level details
surrounding message ordering and reliability. A more abstract
approach, the \emph{distributed shared memory} (DSM) framework,
simplifies this task by allowing programmers to think in terms of
reading and writing to memory locations instead of sending messages
over a network.

The defining feature of DSM is that it allows all processes to
interact as if they had access to a single, unified proof of shared
memory---just like processes running on a single computer---despite
being spread across different, physically separated computers.  This
seamless (subject to caveats explained below) experience is
facilitated by a middleware layer inside the process called the
\emph{memory manager}, which handles all read and write requests
submitted by an application. In the background, not directly visible
to the application, the memory manager coordinates with other
instances over the network to maintain the illusion of a shared state,
or what first responders would call a ``common operating picture.''

Since there is no free lunch, the seamlessness of the DSM model is
subject to caveats, especially this one: usually, a read request
handled by the memory manager does not return the most up-to-date
value of the memory location it reads. Indeed, in the distributed
setting it is not clear a priori what it means for a returned value to
be ``up-to-date'' in the first place, in light of the fact that two
different processes can write conflicting values to the same memory
location at the same time. For developers, understanding the semantics
of the virtual memory layer, meaning knowing what guarantees it makes
concerning what values can be returned at which times, is a crucial
part of building applications that function correctly while providing
reliable performance. Because of the sorts of tensions discussed in
Section \ref{sec:disaster-response}, the design space here is
generally marked by a tradeoff between stronger consistency guarantees
and faster performance.

\begin{figure}
    \centering
    \input{images/pgf/dsm_ex1_WithoutEdges.pgf}
    \caption{Time diagram for memory operations}
    \label{fig:dsm-example-1}
\end{figure}

\begin{figure}
  \centering
  \input{images/pgf/dsm_ex1_DAG.pgf}
  \caption{External order relation among operations in Figure \ref{fig:dsm-example-1} (with edges implied by transitivity not shown)}
  \label{fig:dsm-example-1-DAG}
\end{figure}

Figure \ref{fig:dsm-example-1} depicts an exemplary time diagram for
the shared memory abstraction, similar to those for message
passing. Two kinds of operations are shown: \emph{reads} and
\emph{writes}. A read operation, $\memread{x}$, retrieves the value
stored at (virtual) location $x$, which returns some value $v$. When
we want to indicate the value returned by the read, we write
$\memreadVal{x}{v}$. A write operation, $\memwrite{x}{v}$, indicates
writing $v$ to memory location $x$, which in code might be written as
something like $x := v$.

An operation does not happen instantly, but has a \emph{duration}. An
arbitrary read or write operation, $\Op$, spans from the moment of
time the operation is invoked by the application ($\memstart{\Op}$),
to when it finished ($\memstop{\Op}$), returning either the read value
or an acknowledgment of the write request. During this span, the
memory management layer is usually coordinating in the background with
other processes over the network, say by looking up the current value
of a memory location, but this is not shown in the diagrams. The
entire sequence of requests across all processes forms what we call a
\emph{history}. If $H$ is a history and $P$ is a process, we write
$\localhistory{P}$ to mean just the sequence of operations that happen on $P$, the
so-called \emph{local history} of $P$.

Because they have a duration, memory operations on different
processes, including ones that access the same virtual memory
locations, can occur simultaneously. A fundamental relation among
operations is their \emph{external order}, the partial order that
relates non-overlapping events their physical times, but does not
assign an ordering to events whose executions overlap in physical
time.
\begin{definition}[External order]
  \label{def:external-order}
  Let $H$ be a history. An operation $\Op^1$ \emph{externally
    precedes} operation $\Op^2$ if
  $\memstop{\Op^1} < \memstart{\Op^2}$. This induces an irreflexive
  partial order on $H$ called \emph{external order}.
\end{definition}
The definition states that one operation externally precedes another
if it stops before the other is invoked. Note that we are comparing
events in terms of real, physical time: external order is the partial
order of events witnessed by an outside observer who can watch
operations executing globally in real time. Figure
\ref{fig:dsm-example-1-DAG} depicts the external order among the
operations in Figure \ref{fig:dsm-example-1}, forming a directed
acyclic graph (DAG).

Two events not related by external order are said to be physically
concurrent.

\begin{definition}[Physical concurrency]
  \label{def:physical-concurrency}
  Consider two operations $\Op^1$ and $\Op^2$. If neither externally
  precedes the other, in another words if there is some moment in time
  during which both operations are executing, the operations are said
  to be \emph{physically concurrent}, written $\concurrent{\Op^1}{\Op^2}$.
\end{definition}

Note that we have reused notation between Definitions
\ref{def:logically-synchronous} and \ref{def:physical-concurrency}.
Though they are similar concepts (both are reflexive and symmetric but
generally non-transitive binary relations), physically concurrent
memory operations in the DSM model should not be confused with
logically synchronous events in the message-passing model.

\subsection{Semantics and Consistency}
In a sequential application running on a single computer, it is clear
how read and write requests should be interpreted. A read request
$\memread{x}$ should return the most recent value that was written to
$x$ by a write operation $\memwrite{x}{v}$ (or return a default value
if no such write exists, but we will not consider such examples). This
is unambiguous because we assume that in a single process, memory
operations do not overlap in time, so there is always a sense of which
one happened first.

\begin{example}
  Consider the following history of operations running inside a single process.
  \[\input{images/pgf/dsm_ex_sequential.pgf}\]
  This diagram does not indicate what values are returned by the read
  operations, but since there is no ambiguity in the order of events,
  it is clear what these values \emph{should} be. Each read request
  should return the value (shown in bold below) set by the most recent
  write to that location.
  \[ \memwrite{x}{0} \to \memwrite{y}{5} \to \memreadVal{x}{\textbf{0}} \to \memwrite{x}{3} \to \memreadVal{y}{\textbf{5}} \to \memreadVal{x}{\textbf{3}}. \]
\end{example}

In a distributed system, operations on different processes can run
concurrently, so there is no obvious way to arrange events into a
total order that all processes can agree on. Consequently, the notion
of ``most recent'' operation is ambiguous, so it does not even make
sense to say that read requests always return the most recent written
value.

\begin{figure}[h]
  \input{images/pgf/dsm_ex2.pgf}
  \caption{A history with read return values left unspecified,
    featuring concurrent operations writing to and reading from the
    same location}
  \label{fig:dsm-example-2}
\end{figure}

%\begin{example}
%  \label{exmpl:concurrentupdates}
%\end{example}

Consider the history shown in Figure \ref{fig:dsm-example-2}, which
contains three operation that write to location $x$. Two of these
operations, $\memwrite{x}{3}$ $\memwrite{x}{5}$, are executed at
overlapping moments in time, making it unclear which should be
considered ``first.'' The ambiguity is made concrete by considering
the subsequent read operations---which values should they return? Or
rather, we should ask which values are they \emph{allowed} to return,
since the possibilities are not usually deterministic.

A \emph{memory model} exists precisely to answers questions of the
form, ``Which values might be returned by read requests in which
scenarios?'' In the example above, a model would have to answer
several questions like the following ones:
\begin{enumerate}
\item Do the read operations on $P_1$ and $P_2$ have to return the same value?
\item Can the second read operation at $P_2$ return a different value
  than the first one?
\item Is it ever possible for any of the $\memread{x}$ operations to
  return the value 4?
\end{enumerate}

One can consider many different ways of answering these questions,
depending on the consistency requirements of the high-level
application. The strictest memory model, called
\emph{linearizability}, is a sort of gold standard. If the distributed
system whose history is shown in Figure \ref{fig:dsm-example-2} is
linearizable, the all three read operations must return the same
value, and this must be either $3$ or $5$. This model is intuitive but
too strict for our use case, so programmers must be prepared for less
rigidly prescribed behavior from the memory manager.

Choosing to implement a particular memory model requires balancing the
needs and expectations of the application against its performance
characteristics, including its usage patterns and networking
environment. An application designed for one memory model would
generally misbehave, often in a way that is difficult to diagnose, if
executed in an environment that implements a different model. However,
on the other hand, implementing a stricter memory model may impose a
prohibitive overhead on application performance.

To resolve the ambiguity caused by overlapping memory operations, one
might attempt to assign physical timestamps to them and use this to
define an agreed-upon global total order of operations. However, using
these kinds of orders in practice requires sufficiently fine-grained
timestamps from synchronized clocks. For our environments this is
often infeasible (see Section
\ref{ssec:physical-synchronization}).

\subsection{Strong Consistency Models}
\label{ssec:strong-consistency}
This section considers the two major memory models usually said to
provide ``strong'' consistency: linearizability and sequential
consistency. Both models involve the notion of a sequential history,
or a set of operations arranged into a particular total order.

\begin{definition}[A sequential history]
  \label{def:sequential-history}
  A \emph{sequential history} is a set of memory operations in a
  particular total order. If $H$ is a history, a \emph{serialization}
  is any total order among the operations in $H$.
\end{definition}

Linearizability and sequential consistency both require that all read
operations return values consistent with some serialization of the
global history. That is, they stipulate that among all the operations
in $H$, there is some way of ordering them so that all read operations
return the values of the most recent write operations. Where the two
models differ is in how they constrain which serializations of $H$ are
allowable.

\subsubsection{Linearizability}
\label{sssec:linearizability}

\emph{Linearizability}, a sort of gold standard for memory
consistency, can be concisely defined as a system that acts like
``each operation applied by concurrent processes takes effect
instantaneously at some point between its invocation and response.''
\cite{10.1145/78969.78972} The same condition is known (though
sometimes with subtle variations in meaning) by names like atomic
consistency and external consistency. It means almost the same thing
as strict serializability, except the latter terminology is used to
discuss transactional databases and implies other database-related
guarantees. Formally, a linearizable history is defined by three
features.
\begin{definition}[Linearizable history]
  \label{def:linearizable-history}
  Let $H$ be a history of memory operations. $H$ is
  \emph{linearizable} if it satisfies the following three rules.
\begin{enumerate}
  \tightlist
\item \textbf{Global Agreement on Order}: All processes behave
  (defined below) as if they are observing the same serialization of
  $H$, meaning some particular total order $\sigma$.
\item \textbf{Correct Responses}: Each read request
  \(\memreadVal{x}{a}\) returns the value of the most recent write
  request \(\memwrite{x}{a}\) as ordered by $\sigma$.
\item \textbf{Consistent with External Order}: The serialization of
  $H$ is consistent with external order: if
  $\memstop{\Op^1} < \memstart{\Op^2}$, then $\sigma$ also orders
  $\Op^1$ before $\Op^2$.
\end{enumerate}
\end{definition}

Definition \ref{def:linearizable-history} is concerned with an
individual history of some distributed application. When the
application only ever admits linearizable histories, as permitted by
the memory manager, the entire system is said to be linearizable.

\begin{definition}[Linearizable system]
  \label{def:linearizable-system}
  A DSM application is linearizable if all possible histories of the
  application satisfy Definition \ref{def:linearizable-history}.
\end{definition}

Consider the history Figure \ref{fig:dsm-example-2} again. If the
application is linearizable, the read responses must agree on some
order $\sigma$ consistent with external order, implying that
$\memwrite{x}{4}$ happens before $\memwrite{x}{3}$ and
$\memwrite{x}{5}$, but the latter operations can occur in any
order. Since $P_1$ and $P_2$ have to agree on this order, all three
read responses will return the value written by whichever write is
ordered last (meaning most recent), which is either $3$ or $5$. These
possibilities are illustrated in Figure
\ref{fig:dsm-example-2-linearizations}.

Figure \ref{fig:dsm-example-2-linearizations} also depict an
equivalent, more visually intuitive way, of approaching defining
linearizability. A linearizable history where returned values are
consistent with a choice of linearization point for each operation.
\begin{definition}
  A \emph{linearization point} $t$ for an operation $\Op$ is a time in
  the range $[\memstart{\Op}, \memstop{\Op}]$, between the operation's
  invocation and response. We forbid distinct operations from having
  an overlapping linearization point.
\end{definition}

A history is linearizable if there is some choice of linearization
point for each operation, and returned values are consistent with
operations taking effect in whole and instantaneously at their
linearization points. The subfigures in
\ref{fig:dsm-example-2-linearizations} depict possible choices of
linearization points in yellow.

\begin{figure}
  \begin{subfigure}{1\textwidth}
    \setlength\belowcaptionskip{4ex}
    \centering
    \input{images/pgf/dsm_ex2_linear_1.pgf}
    \caption{A linearization where the read operations return 3}
    \label{fig:dsm-example-2-linearizations-1}
  \end{subfigure}
  \begin{subfigure}{1\textwidth}
    \input{images/pgf/dsm_ex2_linear_2.pgf}
        \caption{A linearization where the read operations return 5}
    \label{fig:dsm-example-2-linearizations-b}
  \end{subfigure}
  \caption{Two possible linearizations of Figure \ref{fig:dsm-example-2} with linearization points shown in yellow}
  \label{fig:dsm-example-2-linearizations}
\end{figure}

\subsubsection{Sequential consistency}
\label{sequential-consistency}

Linearizability offers very strong guarantees related to real-time
constraints, but for many applications this requirement is a burden
for performance. A more relaxed model, sequential consistency,
provides comparably strong guarantees but does not impose the same
constraints with respect to external order. Whereas linearizability
requires operations to be consistent with a serialization respecting
external order, sequential consistency allows any serialization that
respects \emph{program order}.

\begin{definition}[Program order]
  An operation $\Op^1$ precedes another operation $\Op^2$ in
  \emph{program order} if the events occur in the same process $P$ and
  $\memstop{\Op^1} < \memstart{\Op^2}$. In this case we write
  $\Op^1 \programorder{P} \Op^2$.
\end{definition}
If two operations occur in different processes, they are not related
by program order. That is the distinction between program and external
order.

The definition of sequential consistency follows the same structure as
that for linearizability, with program order in place of external
order.

\begin{definition}[Sequentially consistent history]
  \label{def:sequentially-consistent-history}
  An history $H$ is \emph{sequentially consistent} if the following
  three rules are satisfied.
\begin{enumerate}
  \tightlist
\item \textbf{Global Agreement on Order}: All processes behave as if
  they observe the same serialization $\sigma$ of $H$.
\item \textbf{Correct Responses}: Read requests return the value of
  the most recent write request to the same location according to $\sigma$.
\item \textbf{Consistent with Program Order}: $\sigma$ is consistent
  with program order: if
  $\memstop{\Op^1} \programorder{P} \memstart{\Op^2}$ for some $P$, the serial
  history must include $\Op^1$ before $\Op^2$.
\end{enumerate}
\end{definition}

Since external order imposes more constraints than program order,
linearizable histories, like those shown in Figure
\ref{fig:dsm-example-2-linearizations}, are always sequentially
consistent.
\begin{lemma}
  \label{lem:linearsequential}
  A linearizable execution is sequentially consistent.
\end{lemma}

The converse of Lemma \ref{lem:linearsequential} does not hold,
meaning some sequentially consistent executions are not
linearizable. As noted earlier, there are only two linearizable
histories of Figure \ref{fig:dsm-example-2}, and they both require all
three read operations to return the same value. Examples
\ref{ex:dsm-example-2-sequential-1} and
\ref{ex:dsm-example-2-sequential-2}, below, demonstrate sequentially
consistent histories where $P_1$ and $P_2$ read non-equal values.

\begin{figure}
  \begin{subfigure}{1\textwidth}
    \setlength\belowcaptionskip{4ex}
    \centering
    \input{images/pgf/dsm_ex2_seq1.pgf}
    \caption{Sequentially consistent history where $P_1$ and $P_2$ read different values of $x$}
    \label{fig:dsm-example-2-sequential-1-sub}
  \end{subfigure}
  \begin{subfigure}{1\textwidth}
    \input{images/pgf/dsm_ex2_seq1_serial.pgf}
    \caption{A consistent serialization respecting program order}
    \label{fig:dsm-example-2-sequential-1-serial}
  \end{subfigure}
  \caption{A sequentially consistent history and its consistent serialization}
  \label{fig:dsm-example-2-sequential-1}
\end{figure}

\begin{example}
  \label{ex:dsm-example-2-sequential-1}
  Figure \ref{fig:dsm-example-2-sequential-1-sub} depicts a sequentially
  consistent history of the operations depicted in Figure
  \ref{fig:dsm-example-2}. This history is non-linearizable because
  $P_1$ and $P_2$ read different values for $x$. It is sequentially
  consistent because it returns values consistent with the alternate
  history shown in Figure \ref{fig:dsm-example-2-sequential-1-serial},
  which is sequential because has no overlapping operations. The
  latter can be obtained by ``sliding'' the operations in $P_2$ along
  their worldline so they occur after those in $P_1$.
\end{example}

\begin{figure}
  \begin{subfigure}{1\textwidth}
    \setlength\belowcaptionskip{4ex}
    \centering
    \input{images/pgf/dsm_ex2_seq2.pgf}
    \caption{Sequentially consistent history where $P_2$ reads $x$ with value $4$}
    \label{fig:dsm-example-2-sequential-2-sub}
  \end{subfigure}
  \begin{subfigure}{1\textwidth}
    \input{images/pgf/dsm_ex2_seq2_serial.pgf}
    \caption{A consistent serialization respecting program order}
    \label{fig:dsm-example-2-sequential-2-serial}
  \end{subfigure}
  \caption{A sequentially consistent history and its consistent serialization}
  \label{fig:dsm-example-2-sequential-2}
\end{figure}

\begin{example}
  \label{ex:dsm-example-2-sequential-2}
  Figure \ref{fig:dsm-example-2-sequential-2-sub} depicts another
  sequentially consistent history of the operations in Figure
  \ref{fig:dsm-example-2}. In this example, $P_2$ appears to travel
  backwards in time, reading the stale value $4$ immediately after
  reading $5$. This history is consistent with the serialization
  shown in Figure \ref{fig:dsm-example-2-sequential-2-serial}.
\end{example}

The time-traveling nature of Example
\ref{ex:dsm-example-2-sequential-2} can be explained by remembering
that the DSM model is implemented in terms of message-passing. $P_2$
may read a stale value of $4$ because of the time it takes for the
memory manager running on $P_1$ to notify $P_2$ about the
$\memwrite{x}{4}$ operation. This notification may not be received
until after $P_2$ performs the $\memreadVal{x}{5}$ operation.

Sequential consistency is an intuitive property for reasoning about
the possible behaviors of distributed programs. Note that each process
in the system issues memory operations in a particular order---these
can be thought of as individual steps in a program. Before the
application is executed on real computers, there is no guarantee about
the relative timing of program steps that run on different computers,
since different machines may run at different speeds. For instance,
before running the program and observing the series of events shown in
Figure \ref{fig:dsm-example-2-sequential-2-sub}, we did not
necessarily know that the $\memwrite{x}{4}$ operation would precede
the $\memwrite{x}{5}$ operation in real-time---they are both the first
steps of their respective programs, with no relation to each
other. The alternate order of events shown in
\ref{fig:dsm-example-2-sequential-2-serial}, where $\memwrite{x}{5}$
precedes $\memwrite{x}{4}$, is just as likely a priori as the one that
was actually observed. Sequential consistency guarantees each program
is always consistent with one of the serializations that can be
expected a priori, before the program is executed and a real-time
external order of events is fixed.

\subsection{The CAP Theorem}
Real-world systems rarely function as a perfectly coherent, unified
system. One fundamental gap between idealized and real-world behavior
stems from a well-understood and fundamental tradeoff between
coherence and performance. The more ``coherence'' we demand from the
system, the more processes have to communicate over the network, whose
unpredictable delays impose overheads that degrade
performance. Conversely, the more we demand immediate answers from our
system, the less time a process has to communicate with other
processes, so the system as a whole does not seem as coherent and
unified to end users.

This tradeoff is made fully stark by considering the possibility that
the network suffers from a partition, which prevents some processes
from communicating with others.

\begin{definition}[Network partition] A \emph{network partition} is a
span of time where some nodes are unable to communicate with another
set of nodes on the network.
\end{definition}

In 1999, Fox and Brewer \cite{1999foxbrewer} articulated a formal
tradeoff between three desirable properties of distributed systems:
consistency, availability, and an ability to function during network
partitions. This observation was formalized and rigorously proven by
Gilbert and Lynch in 2002 \cite{2002gilbertlynchCAP}. Despite its
prominence at the heart of distributed systems, and the fact that its
proof is fairly straightforward, the CAP theorem is sometimes
misunderstood, so it is worth clarifying its key terms.

\begin{description}
\item[Consistency] Gilbert and Lynch define consistency as
  linearizability.
\item[Availability] A CAP-available system eventually responds to every client
  request (a read or write operation) after a finite time.
\item[Partition tolerance] A partition-tolerant system continues to
  function in the face of arbitrary partitions in the network.
\end{description}

In the last case, the possibility is allowed that a partition never
recovers. This could happen if a critical communications cable is
permanently severed, for instance.

The CAP theorem is the simple observation that a distributed system
cannot guarantee all three properties simultaneously: a system that
operates during network partitions cannot ensure both linearizability
and availability. We give only the informal sketch here, leaving the
interested reader to consult the more formal analysis by Gilbert and
Lynch. The key assumption in the proof is that a process's behavior is
only affected by the messages it receives. During a partition, its
behavior is the same regardless of what other processes do, since it
does not communicate with them and cannot be affected by them. Below,
we term this property \emph{behavioral invariance}.

\begin{figure}
  \input{images/pgf/dsm_cap_ex1.pgf}
  \caption{A history where linearizability cannot maintained during a network partition}
  \label{fig:dsm-cap-example-1}
\end{figure}

\begin{theorem}[The CAP Theorem]
  \label{thm:cap}
  If indefinite network partitions are possible, then a distributed
  system cannot guarantee both linearizability and
  eventual availability.
\end{theorem}
\begin{proof}
  Consider the history in Figure \ref{fig:dsm-cap-example-1}. Clearly
  there is only possible linearization of this history:
  $\memwrite{x}{1}$ executes, $\memwrite{x}{2}$ executes, and
  $\memread{x}$ reads the value $2$. Now suppose $P_1$ and $P_2$ are
  separated by a network partition, meaning $P_1$ does not receive any
  messages from $P_2$. This leaves two possibilities for how $P_1$
  might handle the $\memread{x}$ operation:
  \begin{enumerate}
  \item $P_1$ can proceed despite the network partition and return a
    value. By behavioral invariance, $P_1$ would have to return
    $\memreadVal{x}{1}$. This is value it would read (by
    linearizability) if $P_2$ did not write to $x$. Behavioral
    invariance means $P_1$'s reads the same value regardless of what
    $P_2$ does (since in either case, it receives no communication
    from $P_2$). Returning $1$ violates linearizability in the case
    above where $P_2$ \emph{does} write to $x$.
  \item $P_1$ might detect (or assume) the network suffers a partition
    and refuse to handle the $\memread{x}$ until it is able to
    communicate with $P_2$ again, whereupon it would learn the correct
    value of $x$ is $2$. However, we do not assume the partition has
    to recover, in which case $P_1$ waits forever, which violates
    availability.
  \end{enumerate}
  Thus, we cannot have both linearizable consistency and
  availability. More precisely, to ensure both of these properties, we
  would have to assume the network never suffers from partitions, but
  this is unrealistic. As discussed in Section
  \ref{sssec:ground-communication}, real-world examples of partitions
  in wildland firefighting environments are common.
\end{proof}

The proof above raises the question of whether the weaker notion of
sequential consistency can be used to avoid being subject to the CAP
theorem. The answer is negative: sequential consistency is also
CAP-unavailabile.

\begin{figure}[p]
  \setlength\belowcaptionskip{5ex}
  \begin{subfigure}{1\textwidth}
    \centering
  \input{images/pgf/dsm_cap_ex2.pgf}
  \caption{An execution that cannot maintain sequential consistency during a network partition}
  \label{fig:dsm-cap-example-2}
  \end{subfigure}
  \begin{subfigure}{1\textwidth}
    \centering
    \input{images/pgf/dsm_cap_ex2_results.pgf}
    \caption{By behavioral invariance, if there is a network partition, the values read for $x$ and $y$ must be their initial values of $0$}
    \label{fig:dsm-cap-example-2-results}
  \end{subfigure}
  \begin{subfigure}{1\textwidth}
    \centering
    \input{images/pgf/dsm_cap_ex2_seq1.pgf}
    \caption{A serial order where $\memreadVal{y}{0}$ precedes $\memwrite{y}{1}$ forces $\memwrite{x}{1}$ to precede $\memreadVal{x}{0}$, violating sequential consistency}
    \label{fig:dsm-cap-example-2-serial1}
  \end{subfigure}
  \begin{subfigure}{1\textwidth}
    \centering
    \input{images/pgf/dsm_cap_ex2_seq2.pgf}
    \caption{A serial order where $\memreadVal{x}{0}$ precedes $\memwrite{x}{1}$ forces $\memwrite{y}{1}$ to precede $\memreadVal{y}{0}$, violating sequential consistency}
    \label{fig:dsm-cap-example-2-serial2}
  \end{subfigure}
  \caption{}
  \label{}
\end{figure}

\begin{lemma}[CAP for sequential consistency]
  \label{thm:cap-sequential}
  An eventually-available system cannot provide sequential consistency
  in the presense of network partitions.
\end{lemma}
\begin{proof}
  Consider the history in Figure \ref{fig:dsm-cap-example-2} and
  suppose all memory locations are initialized to $0$. Following
  similar reasoning as above, behavioral invariance means that if
  $P_1$ and $P_2$ are separated by a partition and remain available,
  $P_1$ has to return $0$ to the request $\memread{y}$---that is the
  value it would return assuming $P_2$ does not write to
  $y$. Likewise, $P_2$ would read $\memreadVal{x}{0}$. However, the
  resulting history, shown in Figure
  \ref{fig:dsm-cap-example-2-results}, is not sequentially
  consistent. For $\memreadVal{y}{0}$ to be consistent, the sequential
  order of operations would have to arrange $\memreadVal{y}{0}$ before
  $\memwrite{y}{1}$---otherwise reading $0$ is incorrect. This results
  in the order shown in Figure \ref{fig:dsm-cap-example-2-serial1},
  which is incorrect because $\memreadVal{x}{0}$ occurs after
  $\memwrite{x}{1}$. The situation is symmetric: to order
  $\memreadVal{x}{0}$ before $\memwrite{x}{1}$ results in an order where
  $\memwrite{y}{1}$ precedes $\memreadVal{y}{0}$ (Figure \ref{fig:dsm-cap-example-2-serial2}).
\end{proof}

\subsubsection{Consequences of CAP}
\label{interpretation-of-the-cap-theorem}
While the CAP theorem is theoretically simple, its implications are
more nuanced than they may appear \cite{2012CAP12Years}. A common
oversimplification is that the CAP theorem is represents a ``choose 2
of 3'' scenario: a system designer can choose at most two of
consistency, availability, and partition resilience. In fact, real
systems may balance weaker forms of all three properties. The CAP
theorem only rules out the combination of all three properties when
each of them is defined in an idealized, rigid way.

In practice, applications often settle for weaker levels of
consistency than linearizability or sequential consistency. Resilience
to network partitions typically requires coping with intermittent,
rather than indefinite, communications failures. Finally, availability
is best measured in terms of actual response time as experienced by
the user, and not the mere assurance that a request will
``eventually'' be handled. Thus, each of these dimensions is actually
quantitative in nature, rather than an all-or-nothing proposition.

The locality principle is also highly relevant when considering
implications of the CAP theorem for a real system. The closer agents
are located, the more reliable their communications will be in
general, and the more applications can provide consistency and
availability for operations that only require coordinating with nearby
agents. At short time scales, operations that only require local
coordination are common.

\subsection{Causal Consistency}
\label{ssec:causal-memory}
\emph{Causal} consistency, defined by Ahamad et
al. \cite{1995:causal-memory}, is a weaker memory model than
sequential consistency. Whereas sequential consistency requires the
system as a whole to behave as if all write operations take place in
some total order (which must also respect program order), causal
consistency allows different processes to behave as if they witnessed
past write operations take effect in different orders. Only write
operations related by \emph{causal precedence} are required to take
effect in a common order across all processes: ``reads respect the
order of causally related writes.''  \cite{1995:causal-memory}

We have not defined what causal precedence means for memory
operations. The notion is similar in its motivation to causal
precedence in message-passing framework (Definition
\ref{def:causalprecedence}) and the idea of causal broadcast
(Definition \ref{def:causalorder-bcast}) but the definition of
causally related memory operations is not as simple as that of causal
precedence among messages. In message passing, a receive event is
always associated with a unique send event, but multiple processes can
write the same value to the same memory location, and for a later
operation that reads this value, it is not clear which write
``caused'' it. For this purpose we define a \emph{writes-into} order.

\begin{definition}[Writes-into order]
  Let $H$ be a history of memory operations.\footnote{We are treating
    $H$ as a \emph{multiset}, meaning for example that separation
    operations both of the form $\memwrite{x}{v}$ are considered
    distinct.} A ``writes into'' order $\writesinto$ is a binary
  relation where each read $\memreadVal{x}{v}$ is paired with the
  write operation that determined the value that operation read. That
  is, all relatedl pairs are of the form
  $\memwrite{x}{v} \writesinto \memreadVal{x}{v}$ and every read is
  paired with some write.
\end{definition}

  Ahamad et al. \cite{1995:causal-memory} give a slightly more complex
  definition to allow for operations that read uninitialized memory
  locations. For simplicity we assume each memory location is written
  to before it is read.

\begin{definition}[Causality order on memory operations]
  \label{def:memorycausalprecedence}
  For a given writes-into order $\writesinto$ on
  $H$, the associated \emph{causality order}
  $\causalityorder$ is the transitive closure of the union of
  $\writesinto$ and program order. That is, if $\Op \causalityorder
  \Op'$, then one of the following holds:
  \begin{itemize}
  \item $\Op \programorder{P} \Op'$ for $P$
  \item $\Op \writesinto \Op'$
  \item There is some $\Op''$ such that $\Op \causalityorder \Op''$ and $\Op'' \causalityorder \Op'$
  \end{itemize}
  By fiat, we also require that $\causalityorder$ must not be cyclic,
  meaning their are no ``causality loops'' like
  $\Op \causalityorder \Op' \causalityorder \Op$.  If
  $\Op \causalityorder \Op'$ in a causality order, we say $\Op$
  causally precedes $\Op'$.
\end{definition}

We can now define causally consistent executions of memory
operations. For a history $H$ and each process $P$, let $A|_{P}$ be
the union of $\localhistory{P}$ and the set of all writes in $H$.

\begin{definition}[Causal consistency]
  \label{def:causalconsistency}
  An execution is causally consistent if each $P$ behaves as if it
  observes some serialization of $A|_{P}$ consistent with $\causalityorder$.
\end{definition}

Notably, Definition \ref{def:causalconsistency} does not require that
all processes behave as if they are observing the \emph{same}
serialization.

\begin{example}
  \label{ex:dsm-causal-ex1}
  Figure \ref{fig:dsm-causal-ex1} depicts a causally consistent
  execution of the operations in Figure \ref{fig:dsm-example-2} that
  is not sequentially consistent. The writes-into order is depicted
  with dotted edges. The operations $\memwrite{x}{5}$ and
  $\memwrite{x}{3}$ are not related by $\causalityorder$ and therefore
  do not have to appear to take effect in the same order at all processes.

  Suppose this history were consistent with some serial order. By
  correctness, $\memwrite{x}{5}$ must be the last write before
  $\memreadVal{x}{5}$. By program order, $\memwrite{x}{5}$ comes
  before $\memreadVal{x}{3}$. By correctness, $\memwrite{x}{3}$ must
  come before $\memreadVal{x}{3}$, but not before
  $\memwrite{x}{5}$. But then it must be the last write before
  $\memreadVal{x}{5}$, a contradiction.
\end{example}

\begin{figure}
  \setlength\belowcaptionskip{5ex}
  \begin{subfigure}{1\textwidth}
    \centering
    \input{images/pgf/dsm_causal_ex1.pgf}
    \caption{A causally consistent history with a writes-into order
      shown with dotted edges}
    \label{fig:dsm-causal-ex1}
  \end{subfigure}
  \begin{subfigure}{1\textwidth}
    \centering
    \input{images/pgf/dsm_causal_ex1_serial1.pgf}
    \caption{A serialization consistent with the values read by $P_1$}
    \label{fig:dsm-causal-ex1-serial1}
  \end{subfigure}
  \begin{subfigure}{1\textwidth}
    \centering
    \input{images/pgf/dsm_causal_ex1_serial2.pgf}
    \caption{A serialization consistent with the values read by $P_2$}
    \label{fig:dsm-causal-ex1-serial2}
  \end{subfigure}
  \caption{A causally consistent but sequentially inconsistent history}
\end{figure}

Causal consistency is not subject to the limits of the CAP theorem.

\begin{lemma}[Causal consistency is CAP-available]
  \label{thm:cap-causal}
  A system can enforce causal consistency during network partitions.
\end{lemma}
\begin{proof}
  Consider two processes that execute read and write operations purely
  locally. That is, they never send messages to other processes, and
  they always read the most recent value they have written to a
  location, regardless of what other processes do.

  This situation is always causally consistent for the causality
  relation generated by the empty writes-into order. If the
  writes-into order is empty, each process only has to be consistent
  with some serial order of write operations, and processes do not
  have to agree on this order. In particular, each $P$ is
  consistent with a serialization where all write operations issued by
  other processes are executed \emph{after} all of $P$'s own read
  operations.
\end{proof}

The proof of the Lemma \ref{thm:cap-causal} speaks to the weakness of
causal consistency. In the proof, different processes are allowed to
deviate arbitrarily far from consistency with each other. At any
moment in time, they may diverge wildly, which violates our goal of
maintaining a common operating picture. Causal consistency is too weak
to place an upper bound on the divergence observed by users, which
suggests it is not the most appropriate model for the kinds of
safety-related applications we have in mind. Section
\ref{sec:continuous-consistency} will consider how a continuous
consistency model can provide these sorts of bounds.

\subsection{Section Summary}
\label{ssec:background-summary}
This discussion has explored the key challenges involved in building
distributed systems that connect geographically dispersed components
over unpredictable networks. The variability in message delays,
particularly in the context of broadcasts sent to multiple recipients,
can result in messages that arrive in different orders.  This
situation can lead to chaos if a message-ordering discipline is not
imposed.

To mitigate the effects described above, distributed systems must
track the causal precedence relation between events. Because physical
clocks are not generally reliable enough for this purpose, especially
at fine time scales, logical clocks---scalar, vector, and matrix
clocks---are typically used, each with a different tradeoff in terms
of precision of the information tracked and the administrative and
messaging overhead. If groups can change dynamically, as in our use
cases, then additional group membership protocols are needed to ensure
that all processes know which other processes are participating in the
system at any moment.

Programmers may find it easier to frame distributed applications in
terms of reading and writing from a shared pool of virtual memory,
rather than sending messages, using distributed shared memory
framework. The fact that processes can access the same virtual memory
locations at the same time makes it challenging to maintain systemwide
coherence. Strong consistency models like linearizability and
sequential consistency provide the illusion of a single source of
truth, but the CAP theorem makes it virtually impossible to guarantee
these properties over connection-challenged networks. Weaker models
like causal consistency are not subject to the same limitations, but
they do not enforce limits bounding how far apart data replicas can
diverge, rendering them potentially unsuitable for safety-related
applications.

% In summary, there is no free lunch in distributed systems. Designing
% resilient distributed systems for emergency response scenarios
% requires a careful balancing act between competing properties that
% is carefully calibrated to the use case and the operational
% environment.


\section{Timestamped Anti-Entropy}
\label{sec:tsae}
This section presents Golding's Timestamped Anti-Entropy (TSAE)
protocol \cite{1992:golding-thesis}, a \emph{weak consistency group
  communication} mechanism that provides a form of multicasting to
applications. We picture TSAE as a key driver of communication across
a distributed system supporting first responders across a region or
state during a wide-area event, like the kind discussed in Section
\ref{sec:disaster-response}. Such a system might track firefighters'
locations, monitor a wildfire's boundaries, disseminate weather data,
and orchestrate resource deployment. In this context, TSAE would have
responsibility for ensuring that every update eventually reaches each
of its intended recipients.

Golding's thesis \cite{1992:golding-thesis} presents TSAE as one
component of a broader toolkit for developing distributed
applications. Before laying out the protocol, it is useful to explain
what role it is meant to have in the context of a larger distributed
system. We imagine a group of cooperating processes, referred to by
Golding as ``principals,'' managing shared state and communicating
through message exchange. These messages are an application-specific
construct and might contain things like instructions to update a
database. These may not map one-to-one with low-level network messages
like those discussed in Section \ref{ssec:message-passing}, which we
think of as analogous to Internet Protocol (IP) packets. Note that an
IP packet might contain multiple application messages, and a large
application message may be split up into multiple packets during
network transit.

At a lower level, we assume the network supports point-to-point
(unicast) communication, but it does not have to guarantee FIFO
ordering and may duplicate network messages, though it does not
spontaneously create new ones. The network may not be reliable, but we
assume that persistent attempts to communicate with a distant node
will eventually succeed. The network might support native multicasting
of network-level messages, which could be used as part of an
implementation of TSAE, but the TSAE layer itself provides a form of
application-level multicasting regardless of the network
infrastructure.

A typical use case of TSAE is to maintain replicas of a shared
database at multiple sites, for which purpose its reliable eventual
delivery makes it well-suited as a fault-tolerant messaging
component. Here, ``database'' is used broadly to refer to any data
store updated according to some logical model, such as a relational
schema, a key-value store, or a document store. Processes update the
data by broadcasting update messages using TSAE. Updates are
eventually delivered to every process, at which point recipients apply
it their own replica. Of course, the semantics of updates are decided
by the application. If the underlying data model requires updates to
be applied in the same order across replicas to maintain consistency,
TSAE can be paired with a totally ordered delivery mechanism, which is
described in Section
\ref{ssec:tsae-message-ordering}. %and forms the basis of
                                  %Section\ref{sec:continuous-consistency}.

% The resulting system provides eventual, totally-ordered delivery,
% which offers a general mechanism for implementing replicated state
% machines.

Replication is an alternative to managing state in a central location,
such as a datacenter. This provides resiliency by removing single
points of failure. It supports scalability by allowing any process
with a replia to deliver services to clients, distributing the
load. Finally, replication exploits locality (introduced in Section
\ref{ssec:communication-patterns}) because by servicing user requests
at the nearest replica, we can rely on communications links that are
generally faster and more reliable.

One highly relevant use case of globally replicating state is to
support offline usage of applications. This represents taking locality
to its limit. Responders in the field may not be able to connect to a
datacenter, but in the meantime they can interact with the application
on their device backed by a local replica of the data. This is useful
for as long as the agents can be confident that their replica has not
diverged too far from the rest of the system. A key point is that this
is an application-level matter. How quickly shared state evolves, how
to quantify divergence, and how far apart is ``too'' divergent are
determined by user intent, usage patterns, and operational
environment, among other things. Because updates are merely delivered
\emph{eventually}, TSAE does not bound the divergence of each replica
from the ``ideal'' value of the shared state at any moment. Folling Yu
and Vahdat \cite{2002tact}, we show in Section
\ref{sec:continuous-consistency} how an implementation of the conit
(consistency unit) model on top of TSAE can be used to enforce,
through so-called compulsory anti-entropy sessions, quantitative
consistency requirements separately for each replica.

We now present TSAE in terms of its assumptions
(\ref{ssec:tsae-assumptions}), data structures and invariants
(\ref{ssec:tsae-message-log}--\ref{ssec:tsae-acknowledgement}),
ordering component (\ref{ssec:tsae-message-ordering}), and storage
recycling procedure (\ref{ssec:tsae-message-purging}). Finally, we
discuss how version matrices can be used instead of the loosely
synchronized physical clocks assumed below
(\ref{ssec:tsae-unsynchronized}).

\subsection{Assumptions}
\label{ssec:tsae-assumptions}
We assume each process is associated with an identifier. In practice,
these might be Uniform Resource Identifiers (URIs) \cite{rfc3986}
following a structured format like
\texttt{firefighter116@<agency>.<state>.us}. However, in the text we
will not make a distinction between a process $P$ and its
identifier. The first assumption we make is as follows:
\begin{quote}
  \textbf{Static process group}: The set of group members is a fixed
  set of processes $\AllProc = \{P_1, P_2, \ldots P_n\}$ where the
  identifier of each process is known to all of them.
\end{quote}
Golding's thesis describes how to connect TSAE with a dynamic group
membership management component, but we do not describe it here for
simplicity.

The second assumption we make is that processes have nearly
sychronized clocks. We write $\clock{P, t}$ for the clock value at $P$
at real time $t$.
\begin{quote}
  \textbf{Loose clock sychronization}: Processes' physical clocks are approximately
  synchronized, meaning the clocks of any two processes differ by at
  most some small constant $\delta$:
  \[ \forall t,\, \forall P, Q \in \AllProc, |\clock{P, t} - \clock{Q, t}| < \delta
  \]
  The clock resolution must be fine-grained enough for each principal
  to assign unique timestamps to all important events occurring in
  that process.
\end{quote}

Though physical clock synchronization is not a reliable assumption in
all contexts, we expect that for many useful purposes, sufficient
synchronization can be achieved with a protocol like NTP.  Section
\ref{ssec:tsae-unsynchronized} explains how synchronized physical
clocks can be replaced with version matrices at the cost of a
quadratic storage requirement. For the purpose of implementing
continuous consistency in Section \ref{sec:continuous-consistency},
timestamps from conventional scalar logical clocks can be used in
place of physical clocks, which is how Yu and Vahdat implement TSAE as
part of their TACT framework \cite{2002tact}. The real-time
consistency metric discussed in \ref{ssec:conit-real-time-consistency}
requires each process to keep a physical clock to measure elapsed
time, though synchronization does not appear to be strictly required
here either, assuming each clock runs at a consistent rate. We assume
synchronization here to follow Golding's presentation, highlighting
where the assumption is used.


\subsection{Message Log}
\label{ssec:tsae-message-log}
Each process $P$ manages a \emph{message log} containing all messages
sent or received by $P$.We denote $P$'s message log by $\WL{P}$. It
grows in linear order, as a stack, as new messages are sent and
received. Each message in $\WL{P}$ is tagged with the identifier of
the process that originally created it, with the subset of messages in
$\WL{P}$ that originated at $Q$ denoted by $\WLat{P}{Q}$. Thus,
$\WLat{P}{P}$ represents the set of messages created by $P$. The set
of global messages, $\W$, is defined as the (disjoint) union of
messages originating from every process, which by mild abuse of
notation we are treating as sets:
\[\W \equiv \bigcup_{X \in \AllProc} \WLat{X}{X}.\]

The application at $P$ broadcasts a message $m$ using TSAE by writing
$m$ into $\WL{P}$. We call this event the \emph{submission} of $m$ and
say that $m$ originates at $P$. At the time of submission, the message
is tagged with a pair $(P, \clock{P,t})$ containing $P$'s identifier
and current clock value. The timestamp of $m$ is denoted by
$\timestamp{m}$.

Submitted messages are not sent to other processes right away, but
propagate by a straightforward protocol. Periodically, $P$ contacts
some other process $Q$ and the pair conduct an \emph{anti-entropy
  session}. First, $P$ and $Q$ exchange summary vectors (defined
below). $P$ uses $Q$'s summary vector to quickly calculate which
messages in $\WL{P}$ are not already known to $Q$ and then transmits
these messages to $Q$. Symmetrically, $Q$ forwards messages in
$\WL{Q}$ that $P$ has not seen, resulting in $\WL{P}$ and $\WL{Q}$
containing the same messages afterwards, though typically not in the
same order.\footnote{In a multithreaded environment where $P$ and $Q$
  can engage in multiple anti-entropy sessions with different partners
  at once, the two sides may end in different states. For instance,
  $P$ may learn about new messages in an anti-entropy session with $R$
  during its session with $Q$. Later, we also consider one-sided
  anti-entropy sessions that only push or pull messages. }

TSAE provides reliable eventual delivery, meaning every message is
eventually received by every process, as long as no process fails and
no partition indefinitely separates any two nodes. In particular, if
processes stop originating new messages (so $\W$ remains fixed), if
processes remain able to communicate, then $\WL{P}$ is guaranteed to
eventually converge to $\W$. To achieve this, it is enough that each
pair of processes engage in anti-entropy periodically. This can
actually be relaxed by transitivity: it is enough that they
periodically engage in anti-entropy with a mutual partner, or with two
other processes that engage in anti-entropy with each other, and so
on. TSAE itself does not prescribe a particular policy regarding when
and with whom to engage in anti-entropy, however. Consequently, it
does not guarantee or estimate how far apart $\WL{P}$ is from
$\WL{Q}$, or from $\W$, at any moment. The framework in Section
\ref{sec:continuous-consistency} prescribes a policy for TSAE based on
conservative estimates of divergence in order to enforce these sorts
of limits.

Note that the guarantee of eventual delivery only ensures that
$\WL{P}$ converges to $\W$ as a \emph{set}. However, in general, we
think of $\WL{P}$ as a linear structure, with messages entered into
$\WL{P}$ in the order they were received by $P$. Thus, when $\WL{P}$
and $\WL{Q}$ eventually converge, it is more correct to say they will
be permutations of each other rather than equal. For applications that
require messages to be delivered in a particular order, like a total
order, an additional ordering component is used, as in
\ref{ssec:tsae-message-ordering}.

\begin{example}
  Figure \ref{fig:message-log} shows a message log for containing six
  messages from three processes $A$, $B$, and $C$. For readability it
  is convenient to depict logs whose contents are disaggregated by
  sender (Figure \ref{fig:message-log-b}). Disaggregation has the
  downside of obscuring the fact that message logs with the same
  contents may be arranged in different orders, as the reader should
  keep in mind.
\end{example}

\begin{figure}
  \setlength\belowcaptionskip{5ex}
  \begin{subfigure}{1\textwidth}
    \centering
    \includegraphics[width=0.6\textwidth]{images/MessageLog1.png}
    \caption{A message log with entries accumulating bottom-to-top in linear order}
    \label{fig:message-log-a}
  \end{subfigure}
  \begin{subfigure}{1\textwidth}
    \centering
    \includegraphics[width=0.6\textwidth]{images/MessageLog2.png}
    \caption{The same log shown with messages disaggregated by sender}
    \label{fig:message-log-b}
  \end{subfigure}
  \caption{A message log displayed linearly and disaggregated}
  \label{fig:message-log}
\end{figure}


\subsection{Summary Vector}
\label{ssec:tsae-summary-vectors}
Besides $\WL{P}$, the message propagation component maintains a
\emph{version vector} $\summaryVec{P}$ whose role is to quickly
communicate to other processes which messages $P$ has already
received. This structure is very similar to a vector clock (see
Section \ref{sssec:vector-clocks}) with a few differences. First, the
version of TSAE presented here happens to store physical, rather than
logical, clock values. A more essential distinction is that while a
vector clock tracks causality between events and increments the local
clock with each event, a version vector tracks the history of updates
to replicated data. The value $\summary{P}{P}$ tracks the set of
messages sent by $P$ and is incremented when $P$ sends a new message,
but not when $P$ receives a message from another process. As with
vector clocks, $\summary{P}{Q}$ can be thought of as $P$'s lower bound
view of $\summary{Q}{Q}$.

When $P$ submits a message to its own log, $\summary{P}{P}$ is
advanced to $\clock{P, t}$ and the message is timestamped with this
value. At some point in the future, $P$ contacts some other process
$Q$ to initiate an anti-entropy session. We conceptualize this process
as happening in three phases (setup, message exchange, and conclusion):
\begin{enumerate}
\item $\summary{P}{P}$ is advanced to $\clock{P, t}$. Symmetrically,
  $\summary{Q}{Q}$ is advanced to $\clock{Q, t}$. The parters exchange summary vectors.
\item For each process $X \in \AllProc$, $P$ sends to $Q$ the set of
  messages in $\WLat{P}{X}$ with timestamps greater than
  $\summary{Q}{X}$, if any. Likewise for each $X$ it receives all messages
  from $\WLat{Q}{X}$ with timestamps greater than $\summary{P}{X}$ and
  adds these to $\WLat{P}{X}$. The partners exchange signals to indicate
  when they are finished sending and receiving updates.
\item Much like a vector clock, $\summaryVec{P}$ is updated to the
  pointwise maximum of its current value and the value of
  $\summaryVec{Q}$ received from $Q$. Likewise $Q$ updates
  $\summaryVec{Q}$.
\end{enumerate}
The message log satisfies an invariant, termed the coverage property,
formalizing the role of $\summaryVec{P}$ as a summary of the contents
of $P$'s message log.
\begin{quote}
  \textbf{Coverage Property}: For all $Q$, $P$ has received
  all messages originating at $Q$ whose timestamps are less than the
  $Q^\textrm{th}$ entry in $P$'s summary timestamp vector.
  \[ \{m \in \WLat{Q}{Q} | \timestamp{m} \leq \summary{P}{Q} \} \subseteq \WLat{P}{Q} \]
\end{quote}
The previous subset relation is ``morally'' an equality---messages in
$\WLat{P}{Q}$ but not the subset are said to be ``early''---but only the
the subset property is required for correctness.\footnote{Section
  5.4.3 of Golding's thesis describes how a version of TSAE
  combined with an unreliable network-level multicast for optimization purposes can add
  messages to $\WLat{P}{Q}$ early.} Thus, besides forming a lower
bound of $\summary{Q}{Q}$, $\summary{P}{Q}$ can be thought of as an
\emph{upper} bound of the originating time, measured by $Q$'s clock,
of the last message $P$ received from $Q$. The coverage property
implies that $\summaryVec{P}$ provides complete information about the
(non-early) contents of $\WL{P}$.

The reader should convince themselves that the following inequalities
hold at all times for all $P$ and $Q$ (including when $P = Q$):
\[
  \max_{m \in \WLat{P}{Q}}\left({\timestamp{m}}\right) \leq \summary{P}{Q} \leq \summary{Q}{Q} \leq \clock{Q,t}.
\]

\begin{example}
  \label{ex:tsae}
  Figures \ref{fig:tsae1}---\ref{fig:tsae6} depict the evolution of
  TSAE executing across three distributed processes $A$, $B$, and
  $C$. The figures depict the following chain of events beginning at
  $t = 3$. Note that by $t = 9$, $A$ learns of writes submitted with
  $C$ without performing direct communication with $C$. The figures
  also depict acknowledgment vectors, shown in red, and what we later
  term the commit line, shown underlined. These are explained below.

  \begin{centering}
    \begin{tabular}{rl}\\
      \textbf{Time}    & \textbf{Action} \\
      $t = 1$   & $A$ submits a write                                            \\
      $t = 2$   & $B$ and $C$ submit writes                                      \\
      $t = 3$   & $B$ submits a write                                            \\
      $t = 4$ & $A$ and $B$ begin anti-entropy and swap summary vectors \\
      $t = 5$ & $B$ submits a new write  \\
      $t = 6$ & $A$ and $B$ finish anti-entropy, $C$ submits a write \\
      $t = 7$ & $B$ and $C$ begin anti-entropy, $A$ submits a write \\
      $t = 8$ & $B$ and $C$ finish anti-entropy, $A$ and $B$ begin anti-entropy \\
      $t = 9$ & $A$ and $B$ finish anti-entropy
    \end{tabular}
  \end{centering}
\end{example}

\begin{landscape}
  \begin{figure}[h]%For some reason this empty figure adds vertical whitespace that makes the next figure positioned similarly to the ones that follow it.
  \end{figure}
  \begin{figure}[h]
    \centering
    \includegraphics[width=1.4\textwidth]{images/tsaenew/TSAE3.png}
    \caption{TSAE at time $t=3$.}
    \label{fig:tsae1}
  \end{figure}
  \begin{figure}[h]
    \centering
    \includegraphics[width=1.4\textwidth]{images/tsaenew/TSAE4.png}
    \caption{TSAE at time $t=4$. $A$ advances $\summary{A}{A}$ to $\clock{A, t} = 4$ and likewise for $B$. After exchanging summary vectors, the participants decide to exchange the shaded messages.}
    \label{fig:tsae2}
  \end{figure}
  \begin{figure}[h]
    \centering
    \includegraphics[width=1.4\textwidth]{images/tsaenew/TSAE5.png}
    \caption{TSAE at time $t=5$. $B$ has submitted a message with timestamp
      $t = 5$ while $A$ and $B$ are still engaged in an anti-entropy
      session in the background.}
    \label{fig:tsae3}
  \end{figure}
  \begin{figure}[h]
    \centering
    \includegraphics[width=1.4\textwidth]{images/tsaenew/TSAE6.png}
    \caption{TSAE at time $t=6$. $A$ and $B$ have finished their session and updated their summary vectors. Neither $A$ nor $B$ can update their commit line past $0$ because they both contain $\summary{}{C} = 0$, indicating they have not seen any messages from $C$. $C$ submits a message with timestamp $t = 6$.}
    \label{fig:tsae4}
  \end{figure}
  \begin{figure}[h]
    \centering
    \includegraphics[width=1.4\textwidth]{images/tsaenew/TSAE7.png}
    \caption{TSAE at time $t=7$. $B$ and $C$ update and exchange summary vectors before deciding to exchange the shaded messages. $A$ submits a message with timestamp $t = 7$.}
    \label{fig:tsae4}
  \end{figure}
  \begin{figure}[h]
    \centering
    \includegraphics[width=1.4\textwidth]{images/tsaenew/TSAE8.png}
    \caption{TSAE at time $t=8$. $B$ and $C$ finish their anti-entropy session. Both sides can update their commit line to $4$, since they have seen all messages $m$ such that $\timestamp{m} \leq 4$. $A$ and $B$ begin anti-entropy, exchanging updated summary vectors and exchanging the shaded boxes.}
    \label{fig:tsae6}
  \end{figure}
  \begin{figure}[h]
    \centering
    \includegraphics[width=1.4\textwidth]{images/tsaenew/TSAE9.png}
    \caption{TSAE at time $t=9$. $A$ and $B$ finish their anti-entropy
      session and have both seen all messages with timestampsless than
      or equal to $t = 7$. $B$ and $C$ can remove all messages with
      timestamps less than or equal to $4$ from their logs, since they
      both have minimum entries $\ack{}{C} = 4$. $C$ has received the
      same messages as $A$ and $B$, but has not witnessed $A$
      acknowledging them.}
    \label{fig:tsae6}
  \end{figure}
\end{landscape}

\subsection{Acknowledgement Vector}
\label{ssec:tsae-acknowledgement}
$P$'s summary vector enables another process to quickly learn which
messages $P$ has seen. Additionally, $P$ must keep tabs on which
messages \emph{other} processes have seen. This information is
critical for the message ordering and log recycling components of
TSAE. Golding presents two ways to maintain this information, which
make different efficiency tradeoffs.

Arguably the simplest approach is for $P$ to maintain a local (lower
bound) copy, called $P$'s \emph{view}, of the summary vector of every
other process. During anti-entropy sessions, $P$ exchanges views with
its partner alongside its $\summaryVec{P}$, taking their pointwise
maximums afterwards. This leads to the idea of a version matrix, but
it has the downside of a per-process space requirement this is
quadratic in the size of the process group. This approach is
considered further in \ref{ssec:tsae-unsynchronized}.

The other mechanism presented by Golding requires each process $P$
to maintain an \emph{acknowledgement vector} $\ackVec{P}$. The basic idea
is to coarsely summarize $P$'s knowledge of other processes not with
its summary vector, but the minimal element in this vector, a scalar,
which is stored in $\ack{P}{P}$. For reasons explained in
Section \ref{sec:continuous-consistency}, this value is called $P$'s \emph{commit
  line}. Periodically, $P$'s commit line is updated to the minimal
timestamp in its summary vector,
$\min_{X \in \AllProc} \left(\summary{P}{X}\right)$.  For correctness,
the invariant required of $\ack{P}{P}$ is that it is always a lower
bound of this minimum.
\begin{quote}
  \textbf{Acknowledgement Property}: $P$'s commit line is less than or
  equal to the minimum value in $P$'s summary vector.\footnote{The
    inequality here can be thought of as morally an equality. It may
    be a strict inequality while $P$ is updating $\summaryVec{P}$
    before recomputing its minimum. Recall $P$ may be multi-threaded
    with multiple anti-entropy sessions affecting $\summaryVec{P}$ at
    the same time.}
  \begin{equation*}
    \ack{P}{P} \leq \min_{X \in \AllProc} \left(\summary{P}{X}\right)
\end{equation*}
\end{quote}

Acknowledgment vectors are updated during anti-entropy sessions much
like vector clocks and version vectors.
\begin{enumerate}
\item At the beginning of the session, $\ack{P}{P}$ is updated to
  $\min_{X \in \AllProc} \left(\summary{P}{X}\right)$. Symmetrically
  for $Q$. $P$ and $Q$ exchange acknowledgement vectors alongside
  their summary vectors.
\item At the end of the session, $P$ sets $\ackVec{P}$ and to the
  pointwise maximum of its current value and the value of $\ackVec{Q}$
  received from $Q$. $Q$ updates $\ackVec{Q}$ symmetrically.
\end{enumerate}
Note that $\ack{P}{Q} \leq \ack{Q}{Q}$ at all times for all $P$ and
$Q$.

Slightly different from Golding's presentation of the protocol, the
figures discussed in Example \ref{ex:tsae} also demonstrate an
optimization that takes advantage of the fact that summary vectors are
updated at the end of anti-entropy sessions. After updating these
vectors to their pointwise maximum, we immediately recompute
$\ack{P}{P}$, setting it to
$\min_{X \in \AllProc} \left(\summary{P}{X}\right)$. Furthermore,
$\ack{P}{Q}$ is set to this value. Symmetrically, $Q$ updates
$\ack{Q}{Q}$ and $\ack{Q}{P}$. Note that this preserves the preserves
the invariant that $\ack{P}{Q}$ and $\ack{Q}{P}$ are lower bounds of
$\ack{Q}{Q}$ and $\ack{P}{P}$, respectively, provided the
implementation ensures $P$ increments $\ack{P}{Q}$ after confirming
$Q$ has received all messages from $P$ and vice versa. This
optimization advances acknowledgment vectors (and later, version
matrices) more often than Golding's presentation, which allows the
ordering and purging mechanisms (explained below) to progress more
quickly.

The following two lemmas explain the utility of $\ackVec{P}$ as a way
of estimating global state.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{lemma}
  \label{lem:commitline}
  $P$ has received all messages (from any sender) with timestamps less
  than or equal to its commit line $\ack{P}{P}$.
\end{lemma}
\begin{proof}
  Let message $m$ originate at $Q$ with timestamp
  $\timestamp{m} \leq \ack{P}{P}$. Then
  \[\timestamp{m} \leq \ack{P}{P} \leq \min_{X \in
      \AllProc}\left(\summary{P}{X}\right) \leq\summary{P}{Q}.\] The
  coverage property implies $m \in \WL{P}$.
\end{proof}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{lemma}
  \label{lem:ack-vector}
  For all messages $m$, if $\timestamp{m} \leq \ack{P}{Q}$, then $Q$
  has received $m$.
\end{lemma}
\begin{proof}
  Now $\timestamp{m} \leq \ack{P}{Q} \leq \ack{Q}{Q}$. By Lemma
  \ref{lem:commitline}, $Q$ has received $m$.
\end{proof}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%


When a message $m$ in the write log satisfies
$\timestamp{m} \leq \ack{P}{P}$, $P$ is said to have
\emph{acknowledged} $m$. In light of Lemma \ref{lem:commitline}, all
acknowledged messages have been received. The converse does not hold,
since a received message will not be acknowledged until each entry in
$\summaryVec{P}$, not just the entry of its sender, is greater than
$\timestamp{m}$. We now explain how acknowledged messages can be
delivered to the application and ultimately purged from $\WL{P}$,
before considering the matrix-based alternative to acknowledgement
vectors.

\subsection{Message Ordering}
\label{ssec:tsae-message-ordering}
TSAE guarantees that messages will eventually be received by all other
processes, but ordering of these messages in different processes' logs
may vary. In some applications this is acceptable, but other
applications require more control over delivery order. Recall from
Section \ref{ssec:message-ordering} that to enforce ordering
guarantees, a distinction is made between message receipt and
delivery. A message ordering layer buffers incoming messages upon
receipt, giving time for slower messages to catch up to faster ones,
before delivering them to the application in a predictable
order. Below, we describe a simple implementation of totally ordered
delivery for TSAE. Golding also describes straightfoward mechanisms to
enforce causal and total-causal order in Section 5.5 in his
dissertation.

The message ordering component of TSAE periodically inspects $\WL{P}$
and delivers messages to $P$ when ready. To enforce total order, this
component delivers all messages whose timestamp is less than or equal
to $P$'s commit line. That is, the set of messages satisfying
\begin{equation}
  \label{eq:tsae-message-ordering-condition}
  \timestamp{m} \leq \ack{P}{P}.
\end{equation}
These messages are delivered to $P$ in order of their timestamps,
using the identifiers of their senders to resolve ties. We refer to
the combination of TSAE with total ordering as TSAE+TO. This protocol
has the following eventual convergence property.

\begin{lemma}
  TSAE+TO eventually delivers every message to every process in the
  same order.
\end{lemma}
\begin{proof}
  Assuming periodic anti-entropy sessions, the protocol in Section
  \ref{ssec:tsae-message-log} ensures that each message is eventually
  received by $P$ and each value of the form $\summary{P}{X}$
  eventually increases. Thus, the minimum entry in $\summaryVec{P}$,
  and thus $\ack{P}{P}$, will eventually increase beyond
  $\timestamp{m}$, so each $m$ will be delivered as long as the
  ordering component runs periodically. The fact that messages are
  delivered in the same order everywhere follows from Lemma
  \ref{lem:commitline}, since $P$ has seen all messages whose
  timestamp is less than $\ack{P}{P}$, and therefore the stream of
  deliverable messages does not have any ``gaps'' in the total order.
\end{proof}

The above mechanism for enforcing a total order dates back to
Lamport's introduction of scalar clocks \cite{1978:lamportclocks},
which Lamport used to implement a replicated state machine (RSM), a
conceptual device whose status is uniquely determined by a history of
transitions applied to a starting state. Two conditions ensure
replicas converge to the same state. First, the \emph{contents} of
their histories agree (they have seen all the same transitions), and
second, their \emph{orders} agree (they have applied transitions in
the same order). Using TSAE to announce transitions ensures the first
condition, since every process will eventually learn about each
transition. Combining TSAE with a TO delivery mechanism ensures the
second condition, if transitions are applied when announcements are
delivered. This provides a form of \emph{weak} consistency---it
ensures all replicas eventually reach the same state, which makes it
inherently fault-tolerant, though it does not provide guarantees about
the observed inconsistency of replicas in the meantime. We describe
using TSAE+TO for database replication in Section
\ref{sec:continuous-consistency}, using the ``conit'' framework of Yu
and Vahdat \cite{2002tact} to bound observed inconsistency.

Golding's assumption of loose clock synchronization is driven by a
practical need to ensure messages are delivered (and also purged,
described below) in a timely fashion instead of just eventually. For
example, if $Q$ has an exceptionally slow clock compared to other
processes, then $\summary{P}{Q}$ will remain the minimum element in
$\summaryVec{P}$ for a long time. During this time, only messages from
$Q$ will be delivered to $P$, as all other messages would have
timestamps greater than $Q$'s clock. Section
\ref{ssec:tsae-unsynchronized} explains one way, also introduced by
Golding, that the assumption of synchronization can be partially
mitigated. The TSAE-based protocol in Section
\ref{sec:continuous-consistency} does not require synchronized clocks
except to bound real-time staleness.

\subsection{Message Purging}
\label{ssec:tsae-message-purging}
A message simply cannot be removed from the write log after being
delivered to $P$, because some of the messages in $\WL{P}$ may be
propagated to new recipients during anti-entropy in the
future.\footnote{This implies the ordering component must perform
  bookkeeping to remember which messages in the log have already been
  delivered.} However, it is untenable to let the message log grow
without limit. Thus, a separate log recycling process can be used to
remove old entries when they are no longer required.

There are two requirements for a message to be safe to delete. First,
it clearly must have been delivered to $P$ already. Additionally, it
must have been received by all other processes---otherwise it might be
one of the messages $P$ should send in a future anti-entropy
session. $P$ will know a message $m$ has been received by all
other processes when its timestamp is less than or equal to $P$'s
\emph{purge line}, defined as the minimum entry in the acknowledgment
vector:
\begin{equation}
  \label{eq:tsae-message-purging-condition}
  \timestamp{m} \leq \min_{X \in \AllProc} \left( \ack{P}{X} \right)
\end{equation}

The safety of this deletion procedure is proven by the following
lemma.
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{lemma}[Log purging]
  \label{lem:purge}
  $P$ can safely discard all messages in $\WL{P}$ with timestamps less
  than or equal to its purge line, after they have been delivered.
\end{lemma}
\begin{proof}
  Let message $m \in \WL{P}$ originate at $R$ with timestamp less than
  $P$'s purge line. Now the following inequalities hold for all $Q$:
  \[ \timestamp{m} \leq \min_{X \in \AllProc}\left(\ack{P}{X}\right)
    \leq \ack{P}{Q}.\] Therefore, by Lemma \ref{lem:ack-vector}, $m$
  has been delivered to $Q$. Since $Q$ is arbitrary, $m$ has been
  received everywhere (where it will eventually be delivered as well)
  and can be purged from $\WL{P}$ to reclaim storage space.
\end{proof}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{comment}
For contrast, suppose $m$ has a timestamp greater than $\ack{P}{Q}$.
Then without knowing the current value of $\summary{Q}{R}$ there is no
guarantee $\timestamp{m}$ is less than this value. In this case,
deleting $m$ from $\WL{P}$ might prevent $Q$ from ever receiving $m$.
\end{comment}

Because every message is eventually delivered and acknowledged by each
process, $P$ will eventually be able to remove each message from its
log. It is still possible for $\WL{P}$ to grow without bound if the
rate of message arrival exceeds the speed at which they are
purged. This might occur during periods of heavy usage or during a
network partition, as $P$ will eventually become unable to advance
$\ack{P}{Q}$ further if $Q$ is on the other side of a partition. The
storage requirements of the message log in a particular use case and
environment should be measured empirically as part of an application
optimization strategy.

\subsection{TSAE using Version Matrices}
\label{ssec:tsae-unsynchronized}
Using a single value,
$\min_{X \in \AllProc} \left(\summary{P}{X}\right)$, to concisely
estimate which messages $P$ has received has certain drawbacks. If
clocks are not approximately synchronized, the clock value at one
process may greatly exceed that of another. If $Q$ has a very fast
clock, this value will remain less than $\summary{P}{Q}$ for a long
time and messages from $Q$ will not be purged. If $Q$ has a slow
clock, only messages from $Q$ will be delivered and purged.

Rather than the minimum entry, the entire summary vector offers a more
precise measure of $\WL{P}$. For $P$ itself, that means tracking what
other process know about by keeping a copy of $\summaryVec{Q}$ for
each $Q$ in the system. Thus, we do away with $\ackVec{P}$ and track
what other processes know using a vector-of-vectors, to say a matrix,
that we call $\ackMatrix{}$. Since $\summaryVec{}$ is a version
vector, then $\ackMatrix{}$ can be called a version matrix.

With this implementation strategy, $\ackMatrix{P}[P]$ stores $P$'s
summary vector, while $\ackMatrix{P}\left[Q\right]$ represents $P$'s
lower bound estimate of $Q$'s summary vector. Thus,
$\ackMatrix{P}[Q][R]$ is $P$'s lower bound estimate of the upper bound
of the timestamp of any message $Q$ has received from $R$. Matrices
are exchange during anti-entropy sessions just as before, with both
sides taking the pointwise maximum after.

We additionally apply an optimization, similar to the one for
$\ackVec{P}$, of recomputing $\ackMatrix{P}$ after confirming $Q$ has
successfully received all messages during anti-entropy. Namely,
$\ackMatrix{P}[Q]$ is advanced to the pointwise maximum of the summary
vectors $\ackMatrix{P}[P]$ and $\ackMatrix{Q}[Q]$ exchanged at the
beginning of the anti-entropy session. This increases $P$'s estimated
knowledge of $Q$ to reflect any new messages $P$ just pushed during
anti-entropy. (The previous value reflected only the messages $Q$ knew
about when the session was initiated.) $Q$ updates $\ackMatrix{Q}[P]$
symmetrically. For purposes of continuous consistency, below, this
subroutine implements the ``view advance'' mechanism used to bound
numerical error.

For message ordering and log recycling, $P$ applies the following
(conservative) policies:
\begin{itemize}
\item A message with timestamp $m$ is ready to be delivered to $P$ by a total
  ordering component when the following analogue of \eqref{eq:tsae-message-ordering-condition} holds:
  \begin{equation}
    \timestamp{m} \leq \min_{X \in \AllProc} \left(\ackMatrix{P}[P][X]\right)
  \end{equation}
\item A message $m$ originating at $R$ has been
  received by $Q$ when the following condition holds:
  \begin{equation}
    \timestamp{m} \leq \ackMatrix{P}[Q][R]
  \end{equation}
\item A message $m$ originating at $R$, after being delivered to $P$,
  can be purged from the log when the following analogue of
  \eqref{eq:tsae-message-purging-condition} holds:
  \begin{equation}
    \timestamp{m} \leq \min_{X \in \AllProc}\ackMatrix{P}[X][R]
  \end{equation}
\end{itemize}
Note that the matrix-based version of TSAE does not necessarily solve
the delivery problem if clocks are unsynchronized: if physical
timestamps are used to totally order all messages in the system,
messages from a host with a slow clock will be delivered before any
other messages.

Of course, matrices require $\Theta(n^2)$ storage at each site for a
process group with $n$ members, which quickly becomes untenable for
systems where $n$ is on the order of 1,000 or greater.

\section{Continuous Consistency}
\label{sec:continuous-consistency}
This section outlines the idea of \emph{continuous} consistency, with
a particular focus on the conit (short for ``consistency unit'') model
proposed by Yu and Vahdat
\cite{2000tact,2000tactalgorithms,10.5555/1251229.1251250,DBLP:conf/icdcs/YuV01,2002tact}.
This work has been motivated by the observation that real-world
applications can generally tolerate a certain amount of divergence
among replicas in exchange for greater performance. However, if the
divergence exceeds a certain threshold, the data becomes too
unreliable for its intended use. For such applications, rather than
viewing consistency as an all-or-nothing proposition, it is desirable
to work with a model that formally quantifies levels of inconsistency
and provides controls to ``tune'' the application by tightening or
relaxing the allowed amount of divergence between replicas.

The conit framework makes the consistency/availability tradeoff into a
first class concept, allowing applications to choose where they fall
along the conceptual spectrum between total consistency
(i.e. linearizability) and total availability (i.e. never blocking to
enforce consistency requirements). Mechanisms to exchange either
consistency or availability for more of the other, perhaps in response
to factors like application workload and network capacity, provide
advantages for distributed shared memory frameworks deployed across a
disruption-prone network, where a level of global inconsistency is
inevitable but also desirable to bound.

We describe the framework now in terms of its system model
(\ref{ssec:conit-system-model}), its three dimensions of consistency
(\ref{ssec:conit-numerical-consistency}--\ref{ssec:conit-real-time-consistency}),
correctness (\ref{ssec:conit-correctness}) and possible extensions
(\ref{ssec:conit-extensions}).



\subsection{System Model}
\label{ssec:conit-system-model}



% The model affords flexible methods for applications to tune their
% consistency guarantees, allowing these decisions to be encoded into
% the application logic on a per-process basis, perhaps based on
% feedback and observations from the network.

The system consists of processes in a group $\AllProc$ that replicate
a shared database or, more generally, any kind of replicated state
machine. We shall assume that every process maintains a full replica
of the database, though the replicas are usually not perfectly
synchronized. The initial database state at each replica is
$\Dinit$. We imagine these processes communicate over a
disruption-prone network, perhaps a mesh network like that shown in
Figure \ref{}. The details of this network are not salient to the
discussion, except to emphasize that such a scenario does not lend
itself to centralized solutions where a single replica is maintained
that all processes access through a designated server.

\begin{figure}
  \centering
  \textbf{Insert mesh network picture here}
  \caption{Mesh network showing communication links between processes}
\end{figure}

As in Section \ref{ssec:shared-memory}, we divide actions into two
types: read requests and write requests. We call either type of
request a data \emph{access}. Any process $P$ may handle a read or
write access submitted to it by clients of the application; $P$ is
said to be the \emph{originating replica} of the access, and all other
processes are \emph{remote replicas} for that access. A read is always
handled locally by the originating process, without notifying any
remotes. However, since a write affects the shared data, the
originating process of a write must eventually notify all remote
replicas about the access so they may apply it to their copy of the
data. Thus, each process receives writes from its clients, as well as
notifications of writes submitted by clients of other processes.
% Likewise, it must be notified of writes originating at other
% processes.
Furthermore, because the order of writes matters for many underlying
data models, in general the writes must be delivered everywhere in a
total order to keep the state machine replicas in harmony. Thus, the
first requirement of our application is a mechanism for reliable
eventual totally-ordered delivery to propagate write accesses between
the processes in $\AllProc$---recall from Section
\ref{ssec:tsae-message-ordering} that this provides a general method
of replicating a state machine.

The implementation we describe for write propagation is the one
proposed by Yu and Vahdat, which is based on TSAE+TO, timestamped
anti-entropy with a totally ordered delivery component, though other
solutions can be used instead. The version of TSAE+TO used here has a
few modifications from the ``pure'' version described in Section
\ref{ssec:tsae-message-ordering}. First, a notion of ``compulsory''
anti-entropy sessions is introduced; these are required because pure
TSAE only requires that sessions run periodically, but it does not make
guarantees about when this happens. Second, we allow anti-entropy
sessions to be one-way, either pull- or push-based, with one side
sending updates to another but not necessarily receiving
updates. Finally, the protocol used here applies write updates to the
local replica as they are received, without waiting for the delivery
component to determine their final position in the global total
order. These updates may have to be rolled back and reordered if they
are later found to violate the global total order. These modifications
to the core protocol will be described in greater detail throughout
this section.

% The write propagation mechanism, described in detail in
% \ref{sssec:conit-write-propagation}, provides essentially the same
% progress guarantee as TSAE+TO:

The pure version of TSAE+TO provides a progress guarantee: as long as
anti-entropy sessions run periodically, assuming no permanent host or
network failures, all processes will eventually apply each write to
their local replica in the same order. By itself, this implements a
\emph{weak} (or \emph{eventual}) consistency model, where replicas are
allowed to diverge temporarily, but will eventually converge to global
agreement, at least if they can communicate and new updates do not
outpace the rate of convergence. However, weak consistency does not
place bounds on how far apart replicas might diverge in the
meantime. Thus, the majority of this section is concerned with
supplemental mechanisms used to limit the divergence between replicas
at any moment.
%Since it is based on TSAE+TO, the protocol we describe
%inherents similar eventual consistency properties but additionally
%enforces properties about the replicas at any moment.

The mechanisms used to limit instantaneous divergence trigger
one-sided compulsory anti-entropy sessions. As in ordinary TSAE, an
application may choose to implement so-called \emph{voluntary}
anti-entropy sessions at any time, which may be one- or
two-sided. Voluntary sessions may improve system performance but are
not fundamentally required for the correctness of the protocol. The
guarantees enforced by the protocol will be described more precisely
with respect to three consistency metrics presented in Sections
\ref{ssec:conit-numerical-consistency},
\ref{ssec:conit-order-consistency}, and
\ref{ssec:conit-real-time-consistency}. Section
\ref{ssec:conit-correctness} discusses some of the more subtle aspects
of the correctness properties.

% provides a progress guarantee: assuming no permanent host or network
% failures, all updates will eventually be received, acknowledged,
% delivered in the same total order, and purged from the write log of
% all processes.
Intuitively, the goal of the conit framework is to ensure users always
observe data whose divergence from the correct or ``ideal'' value is
limited by an upper bound. The ideal value of a replicated state
machine is the state it would be in if it has received all
updates---in this context, write accesses that correspond to database
state transitions---and applied them locally in the correct order. In
the conit framework, there are two sources of error that can cause a
replica to diverge from its ideal value:
\begin{itemize}
\item \textbf{Unseen updates}: The error attributable to state
  transitions originating at other processes that have not been
  applied to the local replica because the host process has not been
  notified of them yet
\item \textbf{Out of order updates}: The error attributable to
  transitions the machine has applied locally in the wrong order,
  leading it down an ``errant path'' beginning at the time of the
  first update applied in an order different than the final order
\end{itemize}

Unseen updates occur when a write access is submitted by a client at
an originating process $P$, but a remote process $Q$ is not notified
right away, making $Q$'s replica stale. The conit framework presents
two metrics with respect to which we can limit unseen updates. The
first, numerical error, limits the total ``weight'' of unseen updates,
where weight is a conceptual measure of how significant an update is
with respect to the data model. Numerical error is the subject of
Section \ref{ssec:conit-numerical-consistency}. The second, real-time
staleness, limits the maximum amount of time that may pass before a
process is made aware of a new update. Real-time staleness is the
subject of Section \ref{ssec:conit-real-time-consistency}.

Out of order updates can occur because when $P$ receives an update,
whether submitted by a client locally or forwarded to $P$ by another
process during anti-entropy, $P$ generally applies the update to its
own replica immediately, \emph{bypassing} the total-order mechanism
that determines the final global order of updates. This generally
increases performance because processes do not have to wait for the TO
component of TSAE+TO to determine the final order of writes. The
possibility of incorrectly ordered updates necessitates a mechanism to
``roll back'' these updates so they can be reapplied in the correct
order, possibly leading to different results. A rollback happens if
the TO mechanism, after deciding the final, globally consistent order
of updates seen so far by $P$, determines that some of them have been
applied locally in the wrong order. Updates that have been applied
before confirming their final order are said to be \emph{tentative},
since they are subject to being rolled back and applied in a different
order. At some point, tentative updates become \emph{committed},
possibly after performing a rollback-and-reapply process to correct
the state of the underlying state machine. Committed updates are never
rolled back. Out-of-order error and the commitment process are the
subject of Section \ref{ssec:conit-order-consistency}.

Consistency is measured at the granularity of conits, or consistency
units, which are defined by the programmer. By unit of consistency, we
mean the divergence between two replicas is measured with respect to
each of the metrics for each conit. For example, an update is defined
with a separate numerical weight for each conit: an update may change
one conit significantly, one conit only slightly, and not affect a
third conit at all. Likewise, the real-time staleness and out-of-order
error are also measured at the level of individual conits. Using the
conit framework, any access that needs to read values from the
database may specify a maximum error for each of the metrics for each
conit, and the framework will ensure these bounds are enforced before
the access executes. We define conits more precisely in
\ref{sssec:conit-divergence}.

% replicas do not necessarily wait for the total ordering component to
% decide the final order of updates before applying them to their local
% replica. Instead, updates are applied when they are received. This may
% not match the final order, so the underlying data model must support a
% mechanism to rollback changes and reapply them in a different order as
% it learns more about the final order.

\subsubsection{Local and Global Histories}
\label{sssec:handling-accesses}
We will now elaborate on how reads and writes are handled by the
system, before we later define how inconsistency is measured and
bounded by the protocols.

In general, unlike in Section \ref{ssec:shared-memory}, we allow for
write accesses that are more complex than simple instructions to
update the value of a logical memory location. Instead, here we are
viewing a write as more like an entire \emph{database transaction}---a
potentially complex set of steps that can modify several data items,
and may additionally return a value like read accesses do. In fact,
read accesses in this section should be thought of as merely special
cases of write accesses that do not modify any data; therefore they do
not participate in write propagation and are not entered into the
write log, introduced below.

The most general form of ``write'' access is one that reads values in
the database, modifies some of them according to logic defined by the
programmer, and possibly returns a value to the user. It is important
to note that a write access can encode application-level logic. For
example, it may read a value in the database and make a business
decision whether to increment it. The resulting state after applying
write action $w$ to a database in state $D$ is denoted $D +
w$. Because reads are just special writes that happen not to modify
the underlying database, we have the equation $D + r = D$ if $r$ is a
read.

Recall that a \emph{history} is an ordered sequence of read and write
accesses. The \emph{local history} of a process $P$, denoted
$\localhistory{P}$, is the sequence of accesses $P$ has applied to the
initial state $\Dinit$ since the start of the application. Let $D + H$
denote the result of applying each of the accesses in $H$ to $D$ in
history order. Thus, the database state at process $P$ at any moment,
written $\Dstate{P}$, is defined
\begin{equation}
  \Dstate{P} = \Dinit + \localhistory{P}. \label{eq:conit-D-obs}
\end{equation}
Note that $\localhistory{P}$ includes tentatively applied write
updates. If these are rolled back and reapplied to $\Dstate{P}$ in a
different order by the commitment mechanism, we consider $P$'s history
to be rewritten to reflect the newly corrected order, so
\eqref{eq:conit-D-obs} always holds.

To define the correctness of the conit framework, we need a history to
serve as a common reference point with respect to which each local
history is measured. This history should be ``global'' in the sense
that it contains every access, acting like a central database that
processes every access in the system in some order. Roughly, each
local history should remain within some distance of the global
history, with the difference consisting of a limited number of unseen
or out-of-order updates. We adopt a definition of a global history as
one containing every access arranged in a total order.

\begin{definition}
  A \emph{global history} contains every access in the system, which
  is equivalent to taking the union
  $\bigcup_{X \in \AllProc} \localhistory{X}$ of all local histories
  (more precisely, their underlying sets---this notation is implicitly
  ignoring their ordered structure).  We assume a global history comes
  paired with some total order, $<$, arranging the global set of
  accesses into a linear sequence.
  \begin{equation}
    \Hglobal = \langle \bigcup_{X \in \AllProc} \localhistory{X}, < \rangle
  \end{equation}
\end{definition}

In practice, we have to impose extra conditions on the total order
requiring it to be consistent with the order of the local
histories. We give a more nuanced definition in Section
\ref{ssec:conit-correctness}, where Definition
\ref{def:causalconsistency} defines the notion of an \emph{ECG}
history (Externally and Causally consistent Global history).

Relative to a global history, the ideal database image is defined as
the state it would be in after applying all the updates in the global
history, in order:
\begin{gather}
  \Dideal = \Dinit + \Hglobal \label{eq:conit-D-ideal}
\end{gather}
At any moment, it is likely that no local history matches the global
history, and no single replica matches the ideal database state.

The notion of an ECG history is mostly a conceptual device intended to
define the correctness of the model. Roughly, the statement of
correctness has the following form:

\begin{quote}
  ``At any moment, there exists some ECG history $\Hglobal$ such that
  each access submitted to any process $P$ observes a level of
  consistency within some $\epsilon$ of what it would observe in the
  idealized ECG history.''
\end{quote}

In Sections
\ref{ssec:conit-numerical-consistency}--\ref{ssec:conit-real-time-consistency},
we shall assume that some global history is given so that we can
define the metrics used to quantify divergence.

\subsubsection{Write Propagation}
\label{sssec:conit-write-propagation}

Each process $P$ maintains a write log $\WL{P}$ containing the history
of all writes applied to its local database image in the order they
were applied. That is, $\WL{P}$ is logically equal to
$\localhistory{P}$ restricted to write accesses. The distinction
between $\localhistory{P}$ and $\WL{P}$ is that the former is an
abstract concept and includes read accesses, and it is mostly used to
precisely define correctness of the protocol. $\WL{P}$ is a physical
data structure maintained by the algorithms and only contains write
accesses, since (by definition) only writes affect the database state
and therefore need to participate in write propagation.

When a write request $w$ is submitted, the action is performed against
the local replica, meaning $D_P$ is advanced to $D_P + w$, and $w$ is
added to $\WL{P}$. Since $D + r = D$ if $r$ represents a read access,
Equation \eqref{eq:conit-D-obs} is equivalent to the following
equation defining $\Dstate{P}$ in terms of the write log:
\begin{equation}
  \Dstate{P} = \Dinit + \WL{P} \label{eq:conit-DP}
\end{equation}

The mechanism used to propagate writes among replicas is TSAE, where
$\WL{P}$ serves as the message log. Thus, each processes maintains the
datastructures required of TSAE, whether that be the summary and
acknowledgement vectors of Sections \ref{ssec:tsae-summary-vectors}
and \ref{ssec:tsae-acknowledgement}, or the matrices of Section
\ref{ssec:tsae-unsynchronized}. Writes added to $\WL{P}$ are stamped
with the identifier and the clock value (physical or logical) of the
originating processes at the time it is submitted. Following TSAE, $P$
uses the summary vectors of remote replicas to determine which writes
it may need to send them, and likewise sends it summary vector to
others to receive updates from them. Messages are only ever sent it
batches determined by comparing summary vectors, and properties like
the coverage property (c.f. Section \ref{ssec:tsae-summary-vectors})
are maintained as invariants.

One feature of the version of TSAE presented here is that we allow
anti-entropy to be one-sided, where only one side learns about new
updates. Consequently, the two sides are not necessarily in the same
state after a session. We describe one-sided sessions as push-based or
pull-based depending on whether the sending or receiving side
initiates the session.
\begin{description}
\item[Push based] $P$ initiates a session by requesting the summary
  vector of $Q$. $P$ uses this information to decide which writes $P$
  is aware of that $Q$ has not been informed about, pushing these
  updates to $Q$.
\item[Pull based] $P$ initiates a session by sending its summary
  vector to a remote replica $Q$. $Q$ uses this information to
  determine which writes to send to $P$.
\end{description}

In Section \ref{ssec:message-ordering}, we made a distinction between
a message that is merely received into the log and one that has been
delivered to the application in a predictable order. In the protocol
we describe, write updates are applied to the replica upon receipt
into the log, a fact reflected in Equation \eqref{eq:conit-DP}. That
is, writes may be applied before their position in the final total
order is known. This represents a performance optimization---recall
from Section \ref{ssec:tsae-message-ordering} that deciding the final
position of a write in the global total order requires $P$ to be aware
of all the writes originating anywhere with a lesser timestamp. Rather
than waiting for $P$ to gather this information, the conit framework
allows a controlled degree of optimistically applied writes. This
optimization allows applications to act now and ask for forgiveness
later if they make a mistake by applying updates in the wrong
order. The purpose of the out-of-order error metric is to upper bound
how much ``forgiveness'' the application may have to ask for if these
writes are later found to have been applied in the wrong order.

The total-order component of TSAE+TO is periodically run to determine
a global order of write updates, but instead of deciding when messages
can be \emph{delivered} to the application, we say the TO component
decides when writes can be \emph{committed}, meaning there is no
longer any ambiguity about their position in the global total
order. Messages can be committed when their timestamp is less than
minimum element in their summary vector, which was our motivation for
tracking this information and calling it the ``commit line'' in
Section \ref{ssec:tsae-acknowledgement}. When messages are ready to be
committed, the TO component determines whether some messages have been
applied in the wrong order; these updates are un-applied and then
reapplied in the correct order before marking them as committed. This
process will be described in more depth in Section
\ref{ssec:conit-order-consistency}.


\subsubsection{Measuring Divergence}
\label{sssec:conit-divergence}
For now we assume some global history $\Hglobal$ has been given. This
is needed to define the metrics used to measure a replica's divergence
from its ideal value.

Let $H$ be any history. For an access $a \in H$ in the history, the
\emph{prefix} history of $a$, written $\PH{\left(a\right)}$, is the
set of accesses in $H$ that precede $a$.

\begin{definition}
  The \emph{observed prefix history} $\PHobs{\left(a\right)}$ of an
  access $a$ originating at $P$ is defined as the prefix of the local
  history $\localhistory{P}$ \emph{at the time $a$ is submitted.} The
  \emph{observed state} of an access $a$ is defined as the state of
  $\Dstate{P}$ at the time $a$ was submitted:
  \begin{gather}
    \Dobs\left(a\right) = \Dinit + \PHobs{\left(a\right)} \label{eq:conit-D-obs-at}
  \end{gather}
\end{definition}


Note that $\localhistory{P}$ may later be rewritten by the write
commitment component of the protocol, but the observed prefix history
is fixed forever and reflects the state of $\Dstate{P}$ when $a$ was
originally applied at $P$, possibly returning a value to the user.

\begin{definition}
  The \emph{ideal prefix history} $\PHideal{\left(a\right)}$ of an
  access $a$ is defined as the prefix of $a$ as it occurs in the
  global history $\Hglobal$. Similarly, the \emph{ideal state} of an
  access is defined as the state of the database at the time $a$ is
  applied in the ideal history:
\begin{gather}
  \Dideal\left(a\right) = \Dinit + \PHideal{\left(a\right)} \label{eq:conit-D-ideal-at}
\end{gather}
\end{definition}

Intuitively, clients of process $P$ can usefully operate with the
application as long as $\Dstate{P}$ deviates from its ideal state by
at most some application-defined margin of error. If the divergence is
any greater, the data at $P$ is unreliable and the application may
become unavailable until consistency is re-established. Alternatively,
the application may remain available but alert the user to the
unreliability of the data, which may affect how the user interprets
and interacts with the application.

The goal of the conit model is to provide a method of quantifying the
inconsistency between $\Dobs$ and $\Dideal$. However, a complicating
factor is that applications have unique data models. Note that we have
not made any assumptions about the format of the backing data store,
such as whether it is a traditional relational database, a key-value
store (such as a simple memory model that associates names like
$x, y, z\ldots$ with numerical values), a database optimized for use
in Geographic Information Systems (GIS), or even a bespoke data model
uniquely designed for the application. It is not clear a priori how to
design a general framework to measure divergence without making
detailed assumptions about the nature of the data.

Indeed, it is not even clear what the fundamental \emph{unit} of
consistency is---it may be the case that two replicas totally agree on
some parts of the data, but disagree on other parts, leading one to
consider a more granular model of consistency than one that measures
divergence at the level of whole replicas. The conit framework strikes
a balance between being general enough to work in applications with
different data models and practical enough to efficiently enforce
consistency with simple protocols.

The solution to the challenge is to delegate the meaning of conits to
the programmer. If the backing database is, say, a simple key-value
store, then each key can be associated with a conit. Alternatively, a
whole group of keys could form a conit. If the database is a
relational database, then a row or group of rows could form a
conit. Even logical values computed from the data model, such as the
sum of several data items, can be associated with a conit. The
divergence of a replica is always measured in terms of the divergence
of individual conits from their ideal values---two replicas may agree
perfectly with respect to one conit, but diverge with respect to
another conit.

Furthemore, the it provides a method of computing the upper bound of
this value using purely local information (i.e., without actually
knowing the ideal value). Finally, the application is provided with
mechanisms to enforce upper bounds. The lower the application's
tolerance for inconsistent data, the more time the protocol will spend
coordinating with remote replicas. Likewise, relaxing the upper bound
increases performance by the reducing the frequency of anti-entropy
sessions.

Recall that the disagreement between $\Dstate{P}$ and its ideal value comes
from two sources: messages that have not been seen, and tenative
writes that are applied in an order other than the final global
order. These correspond, respectively, to two dimensions of
inconsistency considered by the conit framework: the \emph{numerical
  error} of an access, and the \emph{order error} of an access.

\begin{quote}
  \textbf{Numerical and order weights of writes}: For each write
  access $w$ submitted to the middleware, for each conit $F$, the
  middleware is supplied with two real-number weights,
  $\NumWeight(w, F)$ and $\OrderWeight(w, F)$, representing the
  conceptual measure of change $w$ applies to conit $F$ with respect
  to numerical and order error metrics.
\end{quote}
For example, the in key-value store example, if a conit is defined for
each key, then a write update that increments $x$ by $1$ should apply
unit numerical weight to the conit associated with $x$. If a conit
$F_{\mathsf{sum}}$ is defined to correspond to the sum of $x$ and $y$,
then a write that increments $x$ by 3 and subtracts $1$ from $y$
should apply a weight of $2$ to conit $F_{\mathsf{sum}}$. How the
middleware associates these weights to write actions is an
implementation detail. The approach taken by Yu and Vahdat requires
the programmer to invoke function calls of the form
$\mathsf{AffectConit}(F, x, y)$---where $F$ is the conit and $x$ and
$y$ are respectively the numerical and order weight---inside functions
that modify the backing data store.


Each access has a dependency on a set of conits, $\Conits$. For each
process, each conit is associated with a triple
\begin{equation*}
  \langle \NE \left(P, F\right), \OErr(P, F), \RTE(P, F)\rangle
\end{equation*}
specifying $P$'s allowable numerical error, order error, and real-time
staleness error on $F$.





The order error and real-time staleness bounds of an access can be
determined on a per-access basis. That is, the API for submitting an
access to the middleware may include parameters for the maximum order
error and real-time staleness bound of that particular
access. However, the maximum numerical error requires cooperation from
other processes, so it is unnatural to specify the allowable numerical
error on a per-access basis. It is assumed that $P$ provides a
separate method, say $\mathsf{SetMaxNumericalError}(F, x)$ where $F$ is
a conit and $x$ is the maximum numerical error currently tolerated
by $P$ with respect to conit $F$.

\subsection{Anti-Entropy Sessions}
\begin{itemize}
\item Numerical error is bounded by a push-based approach. To control
  the numerical error of conit $F$ at process $P$ requires the
  proactive cooperation of every other process to push writes to $P$,
  when necessary.
\item Order error and real-time staleness are bounded by a pull-based
  approach. To control either type of error for conit $F$ at $P$
  requires $P$ to pull updates from remotes when $P$ handles an access
  that depends on $F$.
\end{itemize}
Note that even though numerical error and real-time staleness both
control sources of error caused by unseen messages, but the former is
push-based and requires cooperation between processes while the latter
is pull-based and enforced by each process locally.


\begin{description}
\item[Enforce $\OErr$ and $\RTE$] The values $\OErr(P, F)$ and $\RTE(P, F)$
  are enforced using compulsory pull-based anti-entropy sessions to
  pull updates from remote replicas, if necessary.
\item[Apply access locally] The access is applied to the local replica, which in general
  will yield some return value $x$. If the access is a write access,
  it is timestamped and pushed onto the write log.
\item[Enforce $\NE$] If the access is a write, the system will
  determine whether is is required to initiate compulsory push-based
  anti-entropy with remote replicas to bound their observed numerical
  error for each conit.
\item[Return] The request returns back to the user, including the its final
  return value.
\end{description}



The subsequent sections will describe in greater detail how the three
consistency metrics are defined, and how their divergence is bounded
by the protocol.

\subsection{Numerical Consistency}
\label{ssec:conit-numerical-consistency}
We assume each conit $F$ is associated with a valuation function,
\[
  \Val^F\colon \mathsf{Database\ Image} \to \mathbb{R}
\]
that maps a database state to some real number representing the value
of that conit. For each conit $F$, each write $w$ is associated with a
value, $\NumWeight(w, F)$ codifying the effect on $F$ of
applying $w$ to the database:
\begin{equation*}
  \NumWeight\left(w, F\right) \equiv \Val^F(D + w) - \Val^F(D).
\end{equation*}
To make sense of this equation, we must assume the weight applied to
each conit is independent of the current state $D$ of the
database. Recall that we think of ``write'' accesses as containing
logic to modify the database, such as incrementing or decrementing a
value. This stands in contrast to thinking about writes that directly
set the final value of each data item after the update is
performed---the significance of such an update would depend on the
current value of the data items.

Yu and Vahdat actually \emph{define} a conit as what we have called a
valuation function. We adopt a slightly more abstract terminology and
say that a conit is just an identifier such that each write is
associated with a well-defined numerical weight for each conit. A
weight of $0$ indicates that a conit is not affected by $w$.

Let $V^F_P$ denote the current value of $F$ at $P$'s replica $\Dstate{P}$. Let
$\Videal{F}$ represents the value of $F$ at $\Dideal$.  Now $F$
distributes over $+$ in the sense that the following holds:
\begin{equation}
  \Val^F(D + w) = \Val^F(D) + \NumWeight(w, F).
\end{equation}
Combining this with Equations \eqref{eq:conit-D-obs} and
\eqref{eq:conit-D-ideal} gives
\begin{gather}
  \conitAt{F}{P} = \Vinit{F} + \sum \{\NumWeight(w, F) | w \in \localhistory{P}\} \\
  \Videal{F} = \Vinit{F} + \sum \{\NumWeight(w, F) | w \in \Hglobal\}
\end{gather}

The correctness condition required of numerical error is that the
difference between these values is bounded at all times. Let
$\NE(P, F)$ be the allowable numerical error of $P$ for conit $F$. We
seek to enforce the following inequality as an invariant:
\begin{equation}
  | \Videal{F} - \conitAt{F}{P} | < \NE\left(P, F \right)
\end{equation}
Enforcing this condition requires bounding the set of writes that $P$
has not seen, specifically the ones that affect conit $F$:
\[
  \{ w \in \Hglobal | \NumWeight(w, F) > 0 \} \setminus \WL{P}
\]
This is accomplished by requiring all \emph{other} process to maintain
approximate knowledge of the contents $\WL{P}$. Each other process $Q$
uses its estimate of $\WL{P}$ to bound its own ``contribution''
towards the writes in $\Hglobal$ that are not in $\WL{P}$, namely the
writes originating at $Q$ that $P$ has not been notified of yet.

\subsubsection{Assumptions}
\label{sssec:conit-numerical-assumptions}

Bounding numerical error requires a cooperation between all
processes. In particular, our first assumption is that each process
knows every other process's numerical error bounds for each conit.
\begin{quote}
  \textbf{Global knowledge of error bounds}: Every process knows
  $\NE\left(P, F \right)$ for each conit $F$ and each process $P$.
\end{quote}
If $P$ wishes to dynamically update its numerical error bounds for a
conit $F$, it must invoke some mechanism to inform all other processes
of this change.

Our second assumption is that each process $Q$ maintains a
conservative estimate, called its \emph{view}, of which writes
originating at $Q$ have been received by each other process. $Q$'s
view of $P$ is denoted by $\View{Q}{P}$.
\begin{quote}
  \textbf{Approximate knowledge of remote knowledge}: Each process $Q$
  can compute a set $\View{Q}{P}$ subject to the following invariant:
  \begin{equation*}
    \View{Q}{P} \subseteq \WLat{P}{Q}
  \end{equation*}
  $Q$ must also implement a mechanism to advance its view by
  pushing updates to $P$.
\end{quote}
Recall that $\WLat{P}{Q}$ is the set of writes that $P$ has received
that originated at $Q$. The subset relation above states that $Q$
maintains a lower bound estimate of this set---it is a lower bound
because $P$ might have learned about writes originating at $Q$ through
anti-entropy with some intermediary process $R$, and $Q$ may not know
that $P$ has been informed about these writes. We now describe two
ways of to implement views for the $\ackVec{}$ and $\ackMatrix{}$
implementations of TSAE.
\begin{itemize}
\item If TSAE is implemented with $\ackVec{}{}$, then $Q$ maintains an
  additional vector $\lastVec{Q}$ where $\last{Q}{P}$ stores the value
  of $\clock{Q,t}$ at the time of the last push to $P$. $Q$
  conservatively estimates that $P$ has not received any messages from $Q$
  (via a third party) since $\last{Q}{P}$:
  \begin{equation}
    \View{Q}{P} \equiv \{ m \in \WLat{Q}{Q} | \timestamp{m} \leq
    \last{Q}{P} \}
  \end{equation}
  While handling a write with timestamp $\clock{Q, t}$, after pushing
  messages to $P$, $\last{Q}{P}$ is advanced to $\clock{Q, t}$.
\item If TSAE is implemented with $\ackMatrix{}$, $Q$ estimates that $P$ has
  not seen any messages from $Q$ with timestamp newer than
  $\ackMatrix{Q}[P][Q]$:
  \begin{equation}
    \View{Q}{P} \equiv \{ m \in \WLat{Q}{Q} | \timestamp{m} \leq
    \ackMatrix{Q}[P][Q] \}
  \end{equation}
  While handling a write update with timestamp $\clock{Q, t}$, if $Q$
  engages in push-based anti-entropy, $Q$'s view is advanced because
  $\ackMatrix{Q}[P][Q]$ will have value $\clock{Q, t}$.
\end{itemize}
Note that matrices allow $P$ to maintain a view of which updates $Q$
has seen from any $X$, but for the protocol, only an estimate of
$\WLat{Q}{P}$ is required. For the $\ackVec{}$-based implementation of
TSAE, $\ack{P}{Q}$ itself provides a conservative view of $\WL{Q}$,
but it is too coarse: there is no guarantee it will advance after
pushing updates to $Q$, since it is a lower bound of the minimum value
of $\summary{Q}{X}$ for \emph{any} $X$. The advantage of using
$\ackMatrix{}$ over $\lastVec{}$ is that, for example, it allows $P$
to learn from some process $R$ that $Q$ has received messages that
originated at $P$. Entries in $\lastVec{P}$ can only be updated by $P$
itself, making it a coarser estimate of $Q$'s write log, potentially
causing $P$ to push updates more often.

This lower bound knowledge provided by $P$'s view of $Q$ corresponds
to an upper bound estimate of the messages it has originated that $Q$
has \emph{not} received yet, namely
$\WLat{P}{P} \setminus \View{P}{Q}$. We denote the set of writes
originating at $P$ that $P$ estimates have not been received by $Q$ as
follows:
\begin{equation*}
  \EstUnseen^{Q}{\left(P\right)} \equiv \WLat{Q}{Q} \setminus \View{Q}{P}
\end{equation*}
Note that the actual set of writes originating at $Q$ unseen by $P$ is
defined
\begin{equation*}
  \ActualUnseen^{Q}{\left(P\right)} \equiv \WLat{Q}{Q} \setminus \WLat{Q}{P}
\end{equation*}
which implies
\begin{equation*}
  \ActualUnseen^{Q}{\left(P\right)} \subseteq \EstUnseen^{Q}{\left(P\right)}
\end{equation*}

To bound numerical error, $P$ maintains an invariant that the weight
of writes in $\EstUnseen^{P}{\left(Q\right)}$ must not exceed a
certain threshold. As long as every process collaborates in this
manner, the set of writes unseen by $Q$ will remain within some
bounds. We now describe a simple mechanism for achieving this.

\subsubsection{Split Weight Absolute Error}
We describe \emph{split-weight AE} (absolute error) algorithm, which
Yu and Vahdat explicate most at length in a 2000 paper
\cite{2000tactalgorithms}. For reasons explained below, we consider
writes with positive and negative weights separately, defining the
positive and negative unseen weights. %TODO
Additionally, we disaggregate the weight of unseen writes with respect
to which conit is under consideration.
\begin{gather}
  \EstUnseen^P|^+_F{\left(Q\right)} \equiv \{ w \in \EstUnseen^{P}{\left(Q\right)} | \NumWeight\left(w, F\right) > 0 \} \\
  \EstUnseen^P|^-_F{\left(Q\right)} \equiv \{ w \in \EstUnseen^{P}{\left(Q\right)} | \NumWeight\left(w, F\right) < 0 \}
\end{gather}
For each $F$, define the following values totalling the positive and
negative weights to conit $F$ of writes from $P$ thought to be unseen by $Q$.
\begin{gather}
  \twp{P}{Q, F} \equiv \sum \{ \NumWeight\left(w, F\right) | w \in \EstUnseen|^+_F{\left(P,Q\right)} \} \\
  \twn{P}{Q, F} \equiv \sum \{ \NumWeight\left(w, F\right) | w \in \EstUnseen|^-_F{\left(P,Q\right)} \}
\end{gather}
To bound numerical error for $F$ and $Q$, the intuition is that $P$'s
estimate of numerical weight on $F$ that has not been seen by $Q$ must
not exceed an alloted ``share'' of $Q$'s total error bound, or
$\NE(Q, F)$. Since there are $|\AllProc| - 1$ processes that can
accept writes without immediately adding them to $\WL{Q}$, this means
the total weight of unseen messages accepted by each process must not
exceed
$\NE\left(Q, F \right) / \left(|\AllProc| - 1\right)$.
When $P$ submits a new write, $P$ first checks for whether the
following conditions hold:
\begin{align*}
  \twp{P}{Q, F} + \NumWeight(w, F) &<   \frac{\NE\left(Q, F\right)}{|\AllProc| - 1} & \textrm{if $\NumWeight(w, F) > 0$} \\
  \twn{P}{Q, F} + \NumWeight(w, F) &> - \frac{\NE\left(Q, F\right)}{|\AllProc| - 1} & \textrm{if $\NumWeight(w, F) < 0$}
\end{align*}
If either of these conditions are violated, then $P$ updates its view
of $Q$, which might involve sending updates that $Q$ has not
seen. Before the write access completes, meaning returns to $P$'s
client, $\WL{Q}$ will be reflect both the unseen writes and the write
$P$ is currently handling, and $\twp{P}{Q, F}$ and $\twn{P}{Q, F}$
will be zero.\footnote{The exact handling of write propagation,
  particularly when $P$ sends updates to several remotes at once,
  involves the orthogonal consideration of whether and how to acquire
  remote locks on data items. This will be discussed more in Section
  \ref{ssec:conit-correctness}.}

\begin{lemma}[Numerical weight correctness]
  When following the above protocol, then each value of each conit at process will satisfy
  \[ | \Videal{F} - \conitAt{F}{P} | < \NE{(P, F)}. \]
\end{lemma}
\begin{proof}
  The difference between the ideal value of conit $F$ and the actual
  value of $F$ at $P$ is the sum of all weights applied to $F$ by
  writes that are not in $P$'s write log:
  \begin{equation*}
    % \Videal{F} - \conitAt{F}{P} =  \sum_{Q \in \AllProc \setminus \{P\}} \{ \NumWeight\left(w, F\right) | w \in \WLat{Q}{Q} \setminus \WLat{P}{Q}\}
    \Videal{F} - \conitAt{F}{P} =  \sum_{Q \in \AllProc \setminus \{P\}} \{ \NumWeight\left(w, F\right) | w \in \ActualUnseen^Q\left(P\right) \}
  \end{equation*}
  Because actual unseen writes are a subset of estimated unseen writes, we have the following equation:
  \begin{align*}
    & \sum \{ \NumWeight\left(w, F\right) | w \in \ActualUnseen^Q\left(P\right) \} \\
    < & \sum \{ \NumWeight\left(w, F\right) | w \in \EstUnseen|^+_F{\left(P,Q\right)} \}\\
    \equiv & \ \twp{P}{Q, F}
  \end{align*}
  Likewise we have the following:
  \begin{align*}
    &  \twn{P}{Q, F} \\
    \equiv & \sum \{ \NumWeight\left(w, F\right) | w \in \EstUnseen|^-_F{\left(P,Q\right)} \}\\
    < & \sum \{ \NumWeight\left(w, F\right) | w \in \ActualUnseen^Q\left(P\right) \}
  \end{align*}

  Now as long as the invariants
  \begin{equation*}
    \twp{P}{Q, F} < \frac{\NE(Q, F)}{\left(|\AllProc|-1\right)}  \textrm{\ and\ } \twn{P}{Q, F} > -\frac{\NE(Q, F)}{\left(|\AllProc|-1\right)}
  \end{equation*} are maintained for each $P$ and $Q$, then
  \begin{equation*}
    - \NE{(P, F)} < \Videal{F} - \conitAt{F}{P} < \NE{(P, F)}
  \end{equation*}
\end{proof}

The motivation for tracking positive and negative weights separately
stems from the fact that $P$'s view is conservative. In this case,
letting writes with positive weight ``cancel out'' writes with
negative weight can lead to incorrect behavior. For example, suppose
$P$ has accepted writes with positive and negative weights that
exactly cancel out, and suppose $Q$ has actually seen, unbeknownst to
$P$, all of the writes with negative weight. If $P$ totalled all
weights together, it would wrongly estimate that the weight of writes
unseen by $Q$ is $0$, when the actual value would be some positive
value that may exceed $Q$'s error bounds.

\paragraph{Variations} Yu and Vahdat also describe two other schemes
for bounding numerical error. \emph{Compound-weight absolute error} is
similar to split-weight AE, but allows positive and negative weights
to cancel out. This method represents a potential tradeoff between
storage space and communication, but they did not find the savings
particularly compelling in their performance analysis. They also
consider a scheme, \emph{inductive relative error}, which bounds the
relative error $|1 - \frac{V_i}{V_{\textrm{final}}}|$. Notably, this
algorithm only relies on $P$'s local knowledge. This is particularly
interesting because it is not obvious how to efficiently bound
relative error without knowing the ideal value $V_{\textrm{final}}$.

\begin{figure}
  \centering
  \includegraphics[width=0.6\textwidth]{images/conit/Numerical1.png}
  \caption{Write log $\WL{A}$ for Example \ref{ex:conit-numerical}, where
    messages with a grid background represent $A$'s view of $\WL{C}$.}
  \label{fig:conit-numerical}
\end{figure}

\begin{example}
  \label{ex:conit-numerical}
  Figure \ref{fig:conit-numerical} depicts the role of numerical
  weight for a process $A$.  Messages with a grid background represent
  $A$'s view of $\WL{C}$. We are assuming here that matrices are used,
  so $A$ has a view of $\WLat{C}{B}$, but this does not play a role as
  $A$ only works to bound the weight of its own writes unseen by $C$.

  $A$ estimates there are two messages, with timestamps $(A, 6)$ and
  $(A, 9)$, in $\WLat{A}{A}$ that are not in $\WLat{C}{A}$. We assume
  both of these updates apply positive weight to a conit $F$. While
  handling access $(A, 9)$, before returning to the user, the combined
  weight of the updates must be less than
  \mbox{$\NE\left(C, F \right)/ 2$}. If this limit is exceeded, $A$
  would become unavailable and engage in compulsory anti-entropy with
  $C$. Note that if $A$ is multithreaded and can handle multiple
  accesses at once, then $A$ only has to be unavailable for further
  access involving the same underlying conits. Reads and writes only
  affecting other conits are not blocked.
\end{example}

\subsection{Order Consistency}
\label{ssec:conit-order-consistency}
The write log $\WL{P}$ is a linearly ordered structure, and the local
replica state $\Dstate{P} = \Dinit + \WL{P}$ reflects this order. Writes are
added to $\WL{P}$ and applied to $\Dstate{P}$ as they are received, instead
of waiting for the totally-ordered delivery component to execute, so
at any moment it is possible that $P$'s state machine has diverged
from its ideal value, beginning at the first access $P$ that was not
applied in the final order. The allowable order error bounds how far
$P$'s replicated state machine may tread down an errant path of
transitions, before winding back transitions and reapplying them in
the correct order.

\begin{comment}
TSAE+TO guarantees that eventually writes will be committed, and the
order of committed writes in the same everywhere. Until they are
committed, the tentative writes might have been applied in the wrong
order. Writes applied in the wrong order will have to be rolled
back. The rolling back process may involve application-specified logic
and be associated with a cost, so tentative writes represent a
liability. The goal of ordered consistency to is to bound this
liability.

Messages are initially received and applied tentatively to
$\Dstate{P}$ in an uncommitted state. Eventually they will become committed
in a common global order, but the relative position of each tentative
write in the final order is not fixed.
\end{comment}

\begin{example}
  \label{ex:conit-booking}
  Suppose $P$ and $Q$ are two web servers that allow clients to
  reserve individual seats for a flight, and suppose both servers
  independently process requests from clients to reserve a ticket for
  seat \#1 at the same time. Assume for performance reasons that $P$
  and $Q$ do not maintain linearizability, which causes them to both
  issue tickets for seat \#1, so it becomes double-booked. Let these
  reservations correspond to two write updates $w_P$ and $w_Q$. The
  local replicas at $P$ and $Q$ are left in state $\Dinit + w_P$ and
  $\Dinit + w_Q$, respectively.

  TSAE promises that eventually $P$ and $Q$ learn about each
  other's updates and commit them in some agreed upon order. Let us
  arbitrarily suppose $P$'s update is ordered first.  Thus, $P$
  advances its state to \mbox{$\Dinit + w_P + w_Q$}, while $Q$ rolls
  back its state and reapplies its write, which we represent a series
  of transitions:
  \begin{equation*}
    \Dinit + w_Q \xmapsto{\textrm{rollback}} \Dinit \xmapsto{\textrm{reapply}} \Dinit + w_P +
    w_Q
  \end{equation*}

  Recall that $w_P$ and $w_Q$ represent transactions and may contain
  business logic.  Thus, the final database state $\Dinit + w_P + w_Q$
  might have the interpretation, ``Seat \#1 is reserved to $P$'s
  client, while $Q$'s client attempts to double book the seat and is
  issued a refund.'' The rollback process at $Q$ may be associated
  with business rules triggering a notification to $Q$'s client that
  their reservation has been cancelled, alongside issuing a refund (and
  hopefully a compensation fee).
\end{example}

In Example \ref{ex:conit-booking}, accepting $w_Q$ in a tentative
state represented a liability for $Q$. An indirect way this liability
might have been prevented is if $Q$ had enforced $0$ numerical error,
but this is not a full solution. To see why, suppose another
reservation server $R$ is notified about both $w_Q$ and $w_P$, so it
has $0$ numerical error, but learns about them in the opposite order
and ends up in state $D_R = \Dinit + w_Q + w_P$ where $Q$'s client
appears to get the reservation first. This state, which has $0$
numerical error, would persist at $R$ until the total ordering
component at $R$ discovers that $w_P$ should be first. Numerical error
only controls which updates a process sees, but not the order in which
they are applied to the local replica.

A more direct approach to controlling the potential cost of rollbacks
is to bound the order error of the local database state. For each
conit $F$, each write is associated with a real value
$\OrderWeight{(w, F)}$. In the example above, this value might be the
total cost of refunding the ticket in case $w$ has to be reverted. The
allowable order error acts as an upper bound on the sum of the order
weight of writes that appear locally in the wrong order.

Unlike numerical error, order error can be bound without direct
cooperation from other processes. We only need to assume that
processes, when required, can invoke a write commitment mechanism to
learn the final order of their tentatively accepted updates.
\begin{quote}
  \textbf{Ability to commit writes}: While handling an access, each
  process has a mechanism to determine the final order of any
  uncommitted writes in its write log.
\end{quote}
We will describe how to implement write commitment with TSAE below.

An access received by $P$ observes the state, called its
\emph{observed prefix history}, of $\WL{P}$ at the time the access is
accepted. Let this value be denoted $\PHobs$. The same access occurs
in an ideal history, where the set of writes preceding it consitutes
its \emph{ideal prefix history}, $\PHideal$. Given two histories $H$
and $H'$, let their \emph{intersection} or \emph{greatest common
  prefix}, $H \cap H'$, be the set of all accesses they agree on since
their beginning. The \emph{errant history} of an access is defined as
all of the writes at the tail end of $\PHobs$, beginning at the first
write where $\PHobs$ does not agree with $\PHideal$:
\begin{equation*}
 \PHobs - \left(\PHobs \cap
   \PHideal\right)
\end{equation*}

\begin{figure}
  \begin{subfigure}{0.5\textwidth}
    \centering
    \includegraphics[width=0.5\textwidth]{images/conit/Order1.png}
    \caption{$\WL{A}$ shown with $5$ uncommitted writes}
    \label{fig:conit-order-a}
  \end{subfigure}%
  \begin{subfigure}{0.5\textwidth}
    \centering
    \includegraphics[width=0.5\textwidth]{images/conit/Order2.png}
    \caption{$\WL{A}$ shown at a later time}
    \label{fig:conit-order-b}
  \end{subfigure}
  \caption{Logs for Example \ref{ex:conit-order} where committed writes are drawn with a dotted background}
  \label{fig:conit-order}
\end{figure}

\begin{example}
  \label{ex:conit-order}
  Figure \ref{fig:conit-order} depicts two write logs where committed
  writes are shown with a dotted grid pattern. In Figure
  \ref{fig:conit-order-a}, five writes are uncommitted. No write with
  timestamp greater than or equal to $3$ can be committed, since the
  minimum entry in the log, $\summary{A}{C}$, is only $2$. The final order
  of these accesses is shown in Figure \ref{fig:conit-order-b}. For
  the next access, $(A, 11)$, submitted to $A$, the errant history
  consists of all accesses after and including $(A, 6)$, the point at
  which the write log deviates from the ideal history.
  \begin{align*}
    &\PHobs \cap \PHideal &&= \{ (B, 1) \ldots (A, 3) \} \\
    &\PHobs - \left(\PHobs \cap \PHideal\right) &&= \{ (A, 6), (B, 4), (B, 5), (A, 9) \}
  \end{align*}
\end{example}

Let $r$ be a read access submitted to $P$ with a dependency on conit
set $\mathcal{F}$.  Let $\Uncommitted{P}$ represent the uncommitted
messages in $\WL{P}$.  Since committed writes are a subset of the
ideal prefix history, the writes in the errant history are a subset of
the uncommitted ones:
\begin{equation}
  \PHobs - \left(\PHobs \cap \PHideal\right) \subseteq \Uncommitted{P}
\end{equation}


For a read access that depends on conits in a set $\Conits$, the
relative order of updates applied to $\Dstate{P}$ only matters if they affect
(i.e. apply non-zero order weight to) one or more of the conits in
$\Conits$. In fact, this can be considered an axiomatic constraint on
how applications should define conits and order weight. The errant
history overstates the difference between $\PHobs$ and $\PHideal$. For
instance, suppose they only differ in the relative order of updates
applied to conits that do not affect $\Conits$; in this case, a read
depending on $\Conits$ should be considered to observe $0$ order
error. Let $H|_\Conits$ denote the \emph{write-order projection} of
$H$ to $\Conits$, which consists of just the writes $w$ such that
$\OrderWeight(w, F) \neq 0$ for at least one $F$ in $\Conits$. We the
define the \emph{out-of-order} accesses to $\Conits$,
$\mathsf{OOO}\left(\Conits\right)$, as the set of all writes affecting
any conit in $\Conits$ that have been applied in an order deviating
from their final order relative to each other:
\begin{equation}
  \mathsf{OOO}\left(\Conits\right)  = \PHobs|_\Conits - \left(\PHobs|_\Conits \cap \PHideal|_\Conits \right)
\end{equation}
The reader may want to verify with an example that computing the
errant history and then restricting to writes that affect $\Conits$ is
not correct, since the errant history is affected by conits that do
not affect $\Conits$.

The order error of an access is the total order weight of out of order
writes to any of the conits it depends on.
\begin{definition}[Order error]
  The \emph{order error} of an access $r$ depending on a conit set
  $\mathcal{F}$ is the sum of $\OrderWeight\left(w, F\right)$ for
  each $F$ in $\Conits$, for all writes $w$ that are in the out-of-order
  set for $\mathcal{F}$.
  \begin{equation}
    \OrderError\left(r, \mathcal{F}\right) \equiv \sum_{F \in \Conits} \{ \OrderWeight\left(w, F\right) | w \in \mathsf{OOO}\left(\Conits\right) \}
  \end{equation}
\end{definition}


Because the committed writes are never out of order, the out of order
writes form a subset of the uncommitted writes. Thus, $P$ can estimate
the order error of an access by totalling the order weight of accesses
to $\Conits$ that have not been committed:
\begin{equation}
  \EstOrderError\left(r, \mathcal{F}\right) \equiv \sum_{F \in \Conits} \{ \OrderWeight\left(w, F\right) | w \in \Uncommitted{P}|_\Conits \}
\end{equation}
Note that $\mathsf{OOO}\left(\Conits\right) \subseteq \Uncommitted{P}|_\Conits$ implies $\OrderError\left(r, \mathcal{F}\right) \leq \EstOrderError\left(r, \mathcal{F}\right)$.

Let $\OErr$ be the allowable upper bound of
$\mathsf{OrderError}\left(r,\Conits\right)$ for an access $r$. While
handling this access, if the value above exceeds $\OErr(P, \Conits)$,
the $P$ engages the write committment procedure assumed earlier to
commit enough writes in its log to reduce the size of estimated order
error.

\begin{comment}
et $\PHobs$ be the observed
prefix history. Now $\PHobs \cap \PHideal$,
the common prefix of the observed and ideal history, represents the
longest part of $\PHobs$ that is correct (i.e. agrees with
the ideal history). Therefore,
$\PHobs \setminus \left(\PHobs \cap
  \PHideal\right)$ represents all of the accesses that
have been applied to $P$'s local replica that will have to be rolled
back during the eventual write committment process.
\end{comment}



For the TSAE+TO implementation, committment is implemented with a
\emph{pull-based} approach, where $P$ pulls enough messages from
remotes to decide the final order of enough writes as to ensure the
order error is within bounds. $P$ can commit writes by pulling
messages through anti-entropy to advance its commit line
($\min_{X \in \AllProc} \left(\summary{P}{X}\right)$) far enough for
the total ordering component to decide the final value of all writes
in its log, at which point any errant updates can be rolled back and
reapplied in their final order. Let $t$ be the greatest timestamp of
any message in its write log. To guarantee that $P$ can advance its
commit line enough to commit the write, it is enough to ensure that
$\summary{P}{Q}$ is greater than $t$ after engaging in anti-entropy
with each $Q$. This is true of physically synchronized clocks, since
$\summary{P}{Q}$ will reflect the time at which $Q$ was contacted by
$P$. This also works with scalar logical clocks, since $Q$ would
increment its clock to be greater than $P$'s clock.

\begin{example}
  Suppose in Figure \ref{fig:conit-order-a} that the next access
  submitted to $A$ is timestamped $(A, 11)$. Suppose all writes apply
  unit order weight to a conit $F$. If $(A, 11)$ depends on $F$ with
  an allowable order error of less than $5$, the number of uncommitted
  writes, then the submission of $(A, 11)$ will not return until $A$
  pulls writes from $B$ and $C$ so that all messages up to $(A, 9)$
  can be committed. Note that the actual order error is $4$, less than
  the estimate of $5$.
\end{example}

To a first approximation, the implementation described ensures that
all committed writes are applied everywhere in the same total
order---that is, the committed writes at $P$ are either equal to the
committed writes at $Q$ or one is a prefix of the other. However, the
protocol does not necessarily make guarantees about the relative order
of \emph{order-independent} updates in the write log, which we define
as those that do not apply non-zero order weight to any shared
conit. It is up to the application programmer to ensure that the
relative order of order-independent updates does not affect the data
model. If this is the case, then the only way for users to observe
writes applied in different orders at different replicas is if those
writes have not yet been committed.

\subsection{Real Time Staleness}
\label{ssec:conit-real-time-consistency}
The \emph{real time staleness} metric allows each process $P$ to bound
the maximum amount of time between an access affecting a conit being
issued and $P$ seeing that access. Here we rely on the assumption that
$\summaryVec{P}$ stores physical timestamps from loosely synchronized
physical clocks, though this assumption can be weakened. Let $P$ have
an upper bound of $\eprt \geq 0$ on the real-time staleness of a conit
$F$. Here, $\eprt$ should be greater than the time it takes for $P$ to
engage in a typical anti-entropy session. The rule for enforcing
real-time bounds is very simple.

While handling an access with a read dependency on $F$, submitted at
time $t$, $P$ checks for each $X \in \AllProc$ whether
$|\clock{P, t} - \summary{P}{X}| < \eprt$ is true. If it is not true,
then $P$ engages in a pull-based anti-entropy session with $X$, at
which point $\summary{P}{X}$ has value $\clock{X, t'}$ for some
$t' > t$. Note that the assumption of loose synchronization implies
$\clock{X, t'} \approx \clock{P, t}$ if $t \approx t'$. This protocol
ensures that the original access, timestamped with value
$\clock{P,t}$, will observe the effect of all writes affecting $F$
with timestamps less than $\clock{P,t} - \eprt$.

A pull-based protocol may seem wasteful because $P$ may poll $X$ for
updates even if $X$ does not have any new writes. However, an approach
where $X$ pushes updates to $P$ cannot bound real-time staleness
without an upper bound on the time it takes to push messages across
the network to $P$.
\begin{comment}
Controlling real-time staleness by
pulling updates may seem wasteful if there are in fact no updates at
remotes that need to be pulled. It would seem better to bound $P$'s
real time staleness by pushing messages to $P$ at periodic
intervals. However, a pull approach is required because we do not
assume there is an upper bound how it takes for a message sent to $P$
to arrive.
\end{comment}

If clocks are not loosely synchronized, an alternative implementation
strategy is for $P$ to maintain a vector $\vtphys{P}{}$ where
$\vtphys{P}[X]$ stores the value $\clock{P,t}$ of $P$'s clock at the
last time $P$ was on the receiving end of an anti-entropy session
directly with $X$. Then $P$ enforces consistency by ensuring that
$|\clock{P, t} - \vtphys{P}{[X]}| < \eprt$ is true before handling an
access submitted at time $t$. Since this approach only compares values
from $P$'s clock, synchronization is not required assuming $\clock{P}$
runs at a constant rate. However, this approach has the downside that,
unlike $\summary{P}{Q}$, $\vtphys{P}[Q]$ cannot be updated based on
information indirectly learned during anti-entropy with a third
party.

\subsection{Correctness Properties}
\label{ssec:conit-correctness}
To define quantify deviation from strong consistency, we must give a
few definitions. Recall the notion of external order (Definition
\ref{def:external-order}): an access $A$ externally precedes $A'$ if
$A$ has returned to the caller before $A'$ is invoked. Yu and Vahdat
also define a notion of causality:
\begin{definition}[Causal precedence of accesses]
  \label{def:conit-causal-precedence}
  $A$ \emph{causally precedes} $A'$ if $A$ was already in the local
  history of the originating replica when $A'$ was submitted, and so
  could have influenced how $A'$ executed.\footnote{At face value it
    may seem that if $A$ is in a replica's write log before $A'$, then
    it must have completed before $A'$ started and thus already
    precedes $A'$ externally. However, if these represent concurrent
    but isolated database transactions, it is possible that $A$
    logically takes effect before $A'$, although the transactions have
    no external order relation.}
\end{definition}

With these definitions, we can define a strongly consistent execution
as a reference point for measuring deviation. An ECG history is
essentially a linearization of all accesses in the system.

\begin{definition}[Ideal image]
  An ECG (externally consistent, causally consistent, global) history
  is the set of accesses across the system arranged in some total
  order that respects both external and causal order as defined above.
\end{definition}

\begin{comment}
Definitions below are given with respect to some ECG
history. Intuitively, the condition expected from the conit framework
is that at any moment in time, there is some ECG history such that all
replicas diverge from the ECG history by at most some error bound.
We assume some ECG history as a reference
point.
\end{comment}
Yu and Vahdat describe two implementations of write propagation that
differ in their guarantees. The first involves a two-phase locking
procedure where, during write propagation, remote locks covering all
of the affected data items are first acquired from all hosts where one
intends to send write updates. Once all locks have been acquired, all
necessary writes are sent. While locks are held, reads from affected
conits are blocked on those remotes. When the writes are propagated,
locks are released. This two-phase locking mechanism, which is also
used in a conventional implementation of linearizability, ensures that
the propagated write operations appear to take effect at all
destinations at the same time. When writes are propagated this way,
the numerical and order weights of all accesses are properly bounded
with respect to their ideal values in a strongly consistent history.
\begin{theorem}[Yu and Vahdat]
  Assuming the two-phase locking policy is used during compulsory
  write propgation, there is an ECG history such observed numerical
  and order error of every access is correctly bounded with respect to
  its ideal return value in the ECG history.
\end{theorem}

The following theorems are Theorems 4.1 and 4.3 of their 2002 paper
\cite{2002tact}. Note that ``strict serializability'' here is
essentially synonymous with linearizability.\footnote{Strict
  serializability is essentially linearizability for replicated
  databases. The condition also implies serializable isolation of
  transactions, which is a concept specific to the database context.}
\begin{theorem}
  If a conit is defined for each data item, if reads have 0 allowable
  numerical error and order error on all read conits, and all writes
  have unit weight on all affected conits, then the system provides
  strict serializability.
\end{theorem}

Allowing unbounded numerical error provides one-copy serializability
(1SR) \citationneeded. The condition roughly states that the history
is consistent with some totally ordered history, but the history does
not have to respect real-time order.\footnote{Thus, one-copy
  serializability is something of an analogue of sequential
  consistency for replicated databases, where the primitive unit of
  operations is a database transaction.}
\begin{theorem}
  If reads have 0 allowable order error and no bounds on their
  numerical error, and all writes have unit weight on all affected
  conits, then the systems provides one-copy serializability.
\end{theorem}

Yu and Vahdat also consider a lazy propagation method where remote
locks are not acquired before pushing writes. This allows some
replicas to seemingly learn about writes (meaning it is visible by
read accesses) before others. That is, this policy does not enforce
atomic visibility (updates appear to multiple items, in this case
multiple replicas, appear to occur at different physical times instead
of all at once). This is a weaker consistency model but may be
valuable for certain kinds of information, particularly for
applications such that accepting new updates is always valuable, even
if the update has not propagated to others yet. In this case, the
guarantee provided by bounding numerical error is that the weight of
unseen \emph{finished} writes (meaning writes that returned to the
client at their originating replica) never exceeds the allowable
numerical error for each conit at each replica.

\begin{comment}
  Yu and Vahdat also consider a one-round Read-One-Write-All (ROWA)
  policy where writes are pushed lazily to all compulsory remote
  destinations, without acquiring locks on the data items first. The
  originally submitted write access does not return to the client until
  the replica has finished all compulsory push-based entropy
  sessions. However, this policy allows some replicas to reflect the
  newly seen writes before others.

The intention of the conit framework is this: at any moment in time,
there exists some ECG history of system accesses such that no
individual replica deviates from too far this history. To define what
it means to deviate, we now define conceptual units of data whose
relative (in)consistency can be quantified.

A read request depends on a set of conits $\mathcal{F}$. That is to
say, it assumed that the read will return the same value for any two
database images $D$ and $D'$ such that $F(D) - F(D') = 0$ for each
conit $F$ in $\mathcal{F}$. This access will be associated with a
consistency requirement for each conit in $\mathcal{F}$.

We write $\WL{P}|_\mathcal{F}$ to indicate the history of $P$
restricted to just the messages with non-zero weight on any of the
conits in the set $\mathcal{F}$.

Anti-entropy can be push- or pull-based. To push updates from $P$ to
$Q$, $P$ obtains $Q$'s summary vector $\summaryVec{Q}$ and pushes all
unseen messages in $\WL{P}$ to $Q$. To pull updates, $P$ sends its
version vector and requests any messages in $\WL{Q}$ that $P$ has not
seen.
\end{comment}

\subsection{Extensions}
\label{ssec:conit-extensions}
One can imagine various ways that the conit model can be augmented
with additional capabilities. These topics are outside the scope of
this memo but offered for future consideration.

\paragraph{Dynamic bounds}
Because real-time staleness and order error are bounded by pull-based
anti-entropy sessions, it is straightforward to allow the user to
dynamically change the error bounds at each site. However, numerical
error is bounded by a push-based approach that requires every process
to be track all other processes' error bounds and cooperate to enforce
it. Therefore, dynamically tuning numerical $P$'s numerical error
bounds requires a consensus mechanism so that $P$ can inform other
processes any changes to its error bounds. However, $P$ cannot be sure
its new bounds will be respected until every process has acknowledged
the update.

Yu and Vahdat do not propose a particular mechanism for consensus. One
possible approach may be to reuse the existing message-propagating
mechanism to announce changes to error bounds, similar to Golding's
approach for handling dynamic group membership.

\paragraph{Dynamic conits}
The framework we have described above assumes the set of conits is
fixed in advance. Besides tuning bounds dynamically, we can imagine
situations where new conits need to be created on-the-fly. For
instance, data related to a new wildfire that has emerged may require
forming new conits to set consistency bounds.

Donkervliet's master's thesis \cite{dyconits} explored the subject of
dynamic conit creation in the context of massive multiplayer online
games, particularly Minecraft. In that work, new conits may be
associated with newly encountered objects in an area, and their
consistency bounds tuned as the user approaches them, exploiting a
form of locality to allocate network resources for information the
where inconsistency would most readily be perceived by the
player. Adapting their \emph{dyconits} (dynamic conits) framework to
the wide-area tactical environment may be worthwhile.

\paragraph{Interaction with the Network}
We mentioned in Section \ref{sssec:allocation-of-network-resource} our
expectation of a tighter, more complex interaction between the network
and application layers in this environment because of the need to
optimize scarce network resources for the most important
information. Because conits can quantify divergence, and therefore
indirectly the relative importance of an update, one way this might be
realized is by making the network conit-aware.

Network packets, or DTN bundles, could be specially marked as
containing database updates alongside any metadata (such as the weight
of an update to various conits) that could be used by the network for
quality-of-service purposes. Such usage may run contrary to the
conventional wisdom that networking protocols should be agnostic to
the actual content of a message, e.g. routers should be concerned only
with the data in IP packet headers but not the data contained in the
packet. This sort of atypical usage is potentially justified in our
setting because of a heightened requirement to optimize the user of
very scarce networking resources, even at the cost of blurring the
line between the network and application layers.

Modifying a network protocol to optimize a particular middleware or
application is not a lightweight task, particularly since network
drivers are often embedded into an operating system kernel or into
hardware---this makes their modification difficult or at least
fraught. We conjecture that SDN would be particularly suitable because
it is easier to modify or customize software-defined networking
protocols, so that custom hardware is not required even for extremely
specialized networking needs. The ability to design network protocols
at the level of conventional application software, rather than baking
them into hardware, might offer the flexibility to experiment with
variations of protocols.

We previously mentioned an example where a UAV or a message ferry
could be deployed dynamically to provide greater throughput in a
particular geographical area. Such a resource could be dispatched if
the application signals to a network controller that it is struggling
to enforce conit bounds in a timely manner.

Yu and Vahdat discuss quality of service as one of the features that
might itself use conits.

\section{Conclusion}
The increasing severity of wildfires and other natural disasters has
underscored the need for more advanced and reliable communication
systems for first responders. Modern tools like the Team Awareness Kit
(TAK) for situational awareness at the edge, as well as more
data-intensive centralized processes like NASA's Fire Information for
Resource Management System (FIRMS), have demonstrated the need and the
utility of large-scale complex systems for collecting, processing, and
distributing data among agents operating in adverse environments.
Traditional communication models, designed for more stable
environments, cannot necessarily meet the demands of such dynamic and
critical scenarios.

At a low level, the challenges of these environments can be addressed
through innovations in hardware such as mesh radios operating with
protocols optimized for mobile ad-hoc and disruption-heavy
networks. However, these non-traditional network architectures and
extreme operational conditions raise higher-level questions about how
to design distributed applications that communicate over these
networks. We explored how applications that rely on strong memory
consistency models, such as linearizability or sequential consistency,
are not a good fit for this sort of use case. This implication
stems largely from the locality principle in Section
\ref{ssec:communication-patterns}, which suggests that the quality of
communication between distributed agents---whether measured by message
latency, packet loss, or some other metric---is strongly influenced by
the geographical distance between them.

Strong consistency models are well-suited to scenarios where a
centralized database can be accessed through a small number of
dedicated servers, but locality suggests that agents at the tactical
edge will face difficulty maintaining communication with central
servers. Alternatively, for resilience and efficiency, multiple
replicas of a shared database can be maintained and deployed at
strategic locations in the network. However, the high coordination
overhead required to keep these replicas consistent with respect to
strong memory models is prohibitive for the networks under
consideration. We concluded that weaker consistency models are called
for in these settings.

Brewer's CAP theorem, a cornerstone result in distributed systems
theory, seemingly poses a major challenge when strong consistency is
unattainable. A simplistic interpretation of the theorem suggests that
when strong consistency is sacrificed in favor of system performance,
system designers are left with little control over the relative
consistency between different replicas of common data. This presents
an uncomfortable dilemma, because the appreciable safety concerns in
disaster response environments demand control over the consistency of
shared information. This is because a common operating picture is a
prerequisite to effective coordination between agents. The CAP theorem
seems to suggest that the application designer is stuck between a rock
and a hard place.

Fortunately, the CAP theorem is not as prohibitive as it may seem. The
continuous consistency framework presented in Section
\ref{sec:continuous-consistency}---though it guarantees neither the
`C' nor the `A' in the CAP theorem---presents a way through this
impasse. By formally quantifying the divergence between replicas with
respect to units of consistency, and then providing efficient
mechanisms for estimating this divergence using only local
information, applications can track the relative consistency of
distributed replicas with respect to different metrics and react
intelligently to these values. The framework we presented is dynamic,
providing ways for applications to adjust their position along the
spectrum between entirely favoring consistency and entirely favoring
system availability. How best to exploit these mechanisms, such as
designing policies that automatically tune the application based on
observed system performance, remains an exciting and largely
unexplored topic that will benefit from future work along theoretical
and applied fronts.

In conclusion, we have given a broad overview of the key challenges in
distributed systems in the context of natural disaster environments,
with a particular focus on memory consistency in contexts where the
network is unreliable and message-passing is subject to significant
delays. This content provides a foundation for building resilient,
high-performance systems tailored to the needs of disaster response in
the $21^\textrm{st}$ century.


\begin{comment}
have demonstrated the potential of tactical applications to
enhance coordination in chaotic environments, offering capabilities
like GPS-based firefighter tracking, resource deployment, and
situational awareness. However, these tools operate in highly
challenging conditions: networks are subject to disruptions from
damaged infrastructure, rough terrain, and high demand during
emergencies. Traditional communication models, designed for more
stable environments, cannot meet the demands of such dynamic and
critical scenarios. This memo explores the application of distributed
systems theory to address these challenges, providing a foundation for
building resilient, high-performance systems tailored to disaster
response.


explored the key challenges involved in building distributed systems
that connect geographically dispersed components over unpredictable
networks.  The variability in message delays, particularly in the
context of broadcasts sent to multiple recipients, can result in
messages that arrive in different orders. This situation can lead to
chaos if a message-ordering discipline is not imposed.  To mitigate
the effects described above, distributed systems must track the causal
precedence relation between events. Because physical clocks are not
generally reliable enough for this purpose, especially at fine time
scales, logical clocks—scalar, vector, and matrix clocks—are typically
used, each with a different tradeoff in terms of precision of the
information tracked and the administrative and messaging overhead. If
groups can change dynamically, as in our use cases, then additional
group membership protocols are needed to ensure that all processes
know which other processes are participating in the system at any
moment.  Programmers may find it easier to frame distributed
applications in terms of reading and writing from a shared pool of
virtual memory, rather than sending messages, using distributed shared
memory framework. The fact that processes can access the same virtual
memory locations at the same time makes it challenging to maintain
systemwide coherence. Strong consistency models like linearizability
and sequential consistency provide the illusion of a single source of
truth, but the CAP theorem makes it virtually impossible to guarantee
these properties over connection- challenged networks. Weaker models
like causal consistency are not subject to the same limitations, but
they do not enforce limits bounding how far apart data replicas can
diverge, rendering them potentially unsuitable for safety-related
applications.
\end{comment}


%\section{Conclusion and Summary}
%\label{sec:conclusion}

\section*{Bibliography}\label{bibliography}
\addcontentsline{toc}{section}{Bibliography}

\bibliographystyle{abbrv}
\bibliography{bibliography}
\end{document}

%%% Local Variables:
%%% mode: LaTeX
%%% TeX-master: t
%%% End:
