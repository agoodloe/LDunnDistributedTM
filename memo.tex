% !TeX document-id = {beb7ced9-b3cd-42b2-b16a-3ed3c633a1d9}
\documentclass[]             % options: RDPonly, coveronly, nocover
{NASA}                       %   plus standard article class options
%\DeclareRobustCommand{\mmodels}{\mathrel{|}\joinrel\Relbar}

\usepackage[utf8]{inputenc}
\usepackage{csquotes}
\usepackage{setspace}
\usepackage{hyperref}
\usepackage{amsmath, amssymb, amscd, amsthm, amsfonts}
\usepackage{mathtools}
\usepackage{graphicx}
\usepackage{hyperref}
\usepackage{amsthm}
\usepackage[english]{babel}
\usepackage{stmaryrd}
\usepackage{proof}
\usepackage{tikz-cd}
\tikzcdset{scale cd/.style={every label/.append style={scale=#1},
    cells={nodes={scale=#1}}}}
% Added for subfigures
\usepackage{caption}
\usepackage{subcaption}
\usepackage{afterpage}

\newtheorem{theorem}{Theorem}[section]
\newtheorem{corollary}{Corollary}[theorem]
\newtheorem{lemma}[theorem]{Lemma}
\newtheorem{example}{Example}
\theoremstyle{definition}
\newtheorem{definition}{Definition}[section]

\newcommand{\B}{\mathbf{B}}
\newcommand{\w}{\mathbf{w}}
\newcommand{\citationneeded}{\footnote{\textbf{CITATION NEEDED}}}

\title{A Survey of Distributed Systems Challenges for Wildland
  Firefighting and Disaster Response}

\author{Lawrence Dunn and Alwyn E. Goodloe}

\AuthorAffiliation{Lawrence Dunn \\ Department of Computer and Information
  Science \\ University of Pennsylvania \\ Philadelphia, PA \\ Alwyn Goodloe\\                                          % for cover page
  NASA Langley Research Center, Hampton, Virginia
}
\NasaCenter{Langley Research Center\\Hampton, Virginia 23681-2199}
\Type{TM}                    % TM, TP, CR, CP, SP, TT
\SubjectCategory{64}         % two digit number
\LNumber{XXXXX}              % Langley L-number
\Number{XXXXXX}              % Report number
\Month{12}                   % two digit number
\Year{2022}                  % four digit number
\SubjectTerms{Distributed Systems, Formal Methods, Logic, }     % 4-5 comma separated words
\Pages{46}                   % all the pages from the front to back covers
\DatesCovered{}              % 10/2000--9/2002
\ContractNumber{}            % NAS1-12345
\GrantNumber{}               % NAG1-1234
\ProgramElementNumber{}
\ProjectNumber{}             % NCC1-123
\TaskNumber{}                % Task 123
\WorkUnitNumber{}            % 123-45-67-89
\SupplementaryNotes{}
\Acknowledgment{The work was conducted during a summer internship at the NASA Langley Research Center in the Safety-Critical Avionics Systems Branch focusing on distributed computing  issues arising in the Safety Demonstrator challenge in the NASA Aeronautics System Wide Safety (SWS) program.}

%Added for Pandoc
\providecommand{\tightlist}{%
  \setlength{\itemsep}{0pt}\setlength{\parskip}{0pt}}


\abstract{The System Wide Safety (SWS) program has been investigating
  how crewed and uncrewed aircraft can safely operate in shared
  airspace. Enforcing safety requirements for distributed agents
  requires coordination by passing messages over a communication
  network. Unfortunately, the operational environment will not admit
  reliable high-bandwidth communication between all agents,
  introducing theoretical and practical obstructions to global
  consistency that make it more difficult to maintain safety-related
  invariants. Taking disaster response scenarios, particularly
  wildfire suppression, as a motivating use case, this self-contained
  memo discusses some of the distributed systems challenges involved
  in system-wide safety through a pragmatic lens. We survey topics
  ranging from consistency models and network architectures to data
  replication and data fusion, in each case focusing on the practical
  relevance of topics in the literature to the sorts of scenarios and
  challenges we expect from our use case.  }

\begin{document}
\newpage
\setcounter{tocdepth}{2}
\tableofcontents
\newpage

\section{Introduction}\label{introduction}

Civil aviation has traditionally focused primarily on the efficient
and safe transportation of people and goods via the airspace. Despite
the inherent risks, the application of sound engineering practices and
conservative operating procedures has made flying the safest mode of
transport today. Now the desire not to compromise this safety makes it
difficult to integrate unmanned vehicles into the airspace, accomodate
emerging applications, and keep pace with unprecedented recent growth
in commercial aviation. To that end, the System Wide Safety (SWS)
project of the NASA Aeronautics' Airspace Operations and Safety
Program (AOSP) has been investigating technologies and methods by
which crewed and uncrewed aircraft may safely operate in shared
airspace.

This memo surveys topics in computing that are relevant to maintaining
system-wide safety across large, physically distributed data and
communication systems. It aims to be self-contained and accessible to
a technical audience without a deep background in distributed
systems. Our primary motivating use cases have been taken from civil
emergency response scenarios, especially wildfire suppression and
hurricane relief, primarily for three reasons. First, improved
technology for wildfire suppression, especially related to
communications and data sharing, is frequently cited as a national
priority \cite{pcast2023}.  Second, the rules for operating in the US
national airspace are typically relaxed during natural disasters and
relief efforts, so this is a suitable setting for testing new
technologies. Finally, this setting is an excellent microcosm for the
sorts of general challenges faced by other, non-emergency
applications.

If there is a central theme uniting the sections of this manuscript,
it is \emph{continuity} in the sense considered by
topology.\footnote{For a typical introductory textbook see
\cite{mendelson2012introduction}.} The systems we consider will be
subject to harsh operating conditions that limit how well they can
perform---for example, wireless communication is typically less
reliable during inclement weather. To build a system that is
predictable (clearly a prerequisite for safety), one must ensure the
system can perform reasonably well under a wide variety of adverse
conditions. In other words, the behavior of a safe system should in
some sense be a \emph{continuous} function of its inputs and
environment. This sort of robust design is particularly challenging
because distributed systems designers are forced to make delicate
tradeoffs between competing objectives, most famously between
performance and consistency, the topic of Section
\ref{sec:background}.

\subsection{Summaries of the sections}\label{summaries-of-the-sections}

Sections \ref{sec:disaster-response}--\ref{sec:desiderata} contain
background material on disaster response, distributed systems, and the
specifics of our use case. The critical takeaway of these sections is
that system-wide safety is, at least in part, a computer science
problem, indeed a software problem, and not ``just'' a matter of
engineering better hardware. Sections
\ref{sec:networking}--\ref{sec:data-fusion} survey particular topics
from the distributed systems literature, proceeding from lower-level
considerations to higher-level ones; these sections may be read
independently of each other. Below we summarize each section.

Section \ref{sec:disaster-response} starts with a pragmatic summary of
disaster response and some of the relevant computing challenges in
that setting. We aim to justify and explain the role of distributed
systems theory in system-wide safety by citing real examples
encountered in disaster response scenarios.

Section \ref{sec:background} is an introduction to distributed
systems, culminating in a illustrative result: the ``CAP'' theorem(s)
for the atomic and sequential consistency models (Theorems
\ref{thm:cap} and \ref{thm:cap-sequential}, respectively). CAP is
considered a ``negative'' result, meaning it proves something cannot
be done. The CAP theorem proves that strong consistency for a
distributed system makes systemwide network performance an upper bound
on the availability of a system to do useful work for clients, which
for our purposes is an unacceptable restriction. The practical
significance of CAP is that in emergency response environments, agents
will always act with incomplete information about the global system, a
key motivation for Section \ref{sec:continuous-consistency}.

Section \ref{sec:desiderata} refines our assumptions and identifies
desirable properties of systems for our use case. We use these points to
frame the discussion of systems and protocols in subsequent sections.

Section \ref{sec:networking} examines networking considerations. Our
vision of future emergency communication networks integrates concepts
from delay/disruption-tolerant networks (DTN) and mobile ad-hoc
networks (MANET) to provide digital communications that are robust to
a turbulent operational environment. We also examine the state of
software-defined networking (SDN). SDN is an emerging field that puts
networking protocols on the same footing as ordinary computer
programs. In theory, this should furnish computer networking with all
the benefits of modern software engineering, such as reprogrammable
hardware, rapid iteration, version control, and especially formal
verification.

Section \ref{sec:continuous-consistency} describes a hypothetical
application that might be used in a disruption-heavy network: a data
replication service built on Yu and Vahdat's theory of ``conits"
(short for ``consistency unit'') \cite{2002tact}. This framework
realizes a \emph{continuous} consistency model in the sense that, as
typically configured, it provides neither strong consistency nor
guaranteed high-availability, but rather a quantifiable and
controllable tradeoff between the two. The key idea is that many
applications can tolerate inconsistency among replicas of a data item
if an upper bound on the divergence between replicas is enforced. A
conit-based database replication framework would allow system
designers to define units of replicated data whose consistency is of
interest, enforce policies bounding inconsistency between replicas of
these items, and even dynamically tune these policies on the fly. We
believe that only a conit-based replication infrastructure can provide
the strict guarantees required for safety-related systems while also
tolerating the adverse environments and real-world limitations of the
systems we have in mind.

Section \ref{sec:data-fusion} concerns data fusion. Now and in the
future, agents in disaster scenarios will make decisions informed by
many different kinds of information. Efficient integration,
processing, filtering, and dissemination of this information will be
necessary to avoid ``swimming in sensors and drowning in data''
\cite{2010:magnuson}.  This task is especially challenging because
agents will often work with incomplete or out of date information, and
different sources of the same data may be contradictory, e.g. first
responders may receive contradictory reports about whether a structure
is occupied. One promising trend in this space, which we briefly
introduce in this section, is the development of sheaf theory as a
natural mathematical model for data fusion
\cite{2017robinsonCanonical}. Sheaf theory provides a rigorous
framework for discussing how heterogeneous sources of noisy data can
be integrated into a coherent picture, and can formally measure how
well this task has been achieved.

We conclude in Section \ref{sec:conclusion} by recapping some of the
main themes in this document and highlighting areas where design
decisions at various levels must be made to build a system that is
tuned to the exact conditions we can expect from real-world
scenarios. Such decisions might be informed by a combination of
simulation and experimentation in the field.

\section{Coordination Challenges in Disaster Response}
\label{sec:disaster-response}

This section explains aspects of disaster response (particularly
firefighting) scenarios that motivate the remainder of this
document. We describe how real-world environments give rise to
foundational challenges that must be addressed through the application
of distributed computing principles. Even deploying the best
communications equipment cannot realistically avoid the fundamental
computer scientific problems raised when many distributed agents try
to coordinate their actions over a widespread area.

The operational environment of wildfire suppression, hurricane relief,
and other disaster settings is generally characterized by systemic
communications challenges. It is not surprising that a 2023 report on
wildland firefighting modernization by the Presidentâ€™s Council of
Advisors on Science and Technology (PCAST) cites ``the vulnerabilities
and shortfalls in wildland firefighter communications, connectivity,
and technology interoperability'' in their first of five
recommendations \cite{pcast2023}. These shortfalls can be partly
attributed to factors that are simply inherent to disaster response:
remote locations, difficult terrain, damaged infrastructure, harsh
weather, and limited battery power, to name a few.

Agents in the field generally experience high packet loss (when
considering digital communication), garbled transmissions, and
unpredictable latencies when passing information over the
communication network(s). A conservative view suggests expecting the
worst performance at particularly inopportune times, simply because
the conditions that prompt urgent communication can be expected to
correlate with those that make communication difficult. One
possibility is that the disaster itself damages the communications
infrastructure.  Another example, which is true tautologically, is
that a communications network is the most congested, and therefore the
least available, precisely when everyone needs to use it. Both of
these phenomena were famously exhibited in the immediate aftermath of
the September $11^\textrm{th}$ terrorist attacks, where the sudden
user demand and severed trunk cables brought New York public cell
phone networks virtually to a halt \cite{2011:Reardon}. Other networks
along the East Coast, as well as dedicated networks for first
responders, experienced similar effects.

From a systems perspective, an unreliable network presents a challenge
for coordinating distributed agents. A root cause of this problem is
that coordinated action requires some notion of consistency,
i.e.~agreement, among data shared between agents. We shall make this
somewhat vague notion more precise in Section \ref{sec:background},
but a simple example is that it is very important for everyone to
agree which firetrucks have been dispatched to which scenes, which
tasks should be prioritized, or which radios have been reserved from
the {\mbox{NIICD}} radio cache \cite{radiocache} and for whom. The
exact meaning of ``consistency'' varies between applications, but a
general observation is that stronger standards for consistency are
more difficult to maintain than relaxed ones because they require
exchanging more information with other agents quickly, putting a
heavier burden on the network. When the network is slow, system
components that need to communicate may have to wait for network to
deliver their messages, diminishing the efficacy and coherence of the
system.

\subsection{Communication and Safety}
\label{communication-and-safety}

Many complications in the field are exacerbated by a poor
communications environment. In this setting, agents must choose
between long delays in sending or receiving information, or acting
with only limited knowledge. Typically they will experience some
amount of both. Both options present safety challenges because
operational safety, by nature, requires agents to gather information
about their environment and react to it quickly and systematically. In
other words, both inaction and uninformed action are problems. This
turns out to be deeply related to a computer science phenomenon
generally known as the safety/liveness tradeoff.

As a running example, we consider the use of firefighting airtankers,
the largest of which are the Very Large Airtankers (VLATs), defined as
those carrying more than 8,000 gallons of water or fire retardant
\cite{2019:airtankerops}. The largest VLATs can carry more than 20,000
gallons, weighing about 170,000 pounds. This weight is typically
dropped from a mere 250 feet above the tree canopy
\cite{2019:airtankerops}, though the complexity of the maneuver means
errant drops are sometimes performed even lower than this, easily
crushing a ground vehicle \cite{2019:stickney}. A 2018 accident led to
the death of one firefighter and the injury of three others when an
87-foot Douglas Fir tree was knocked down by an unexpectedly forceful
drop from a Boeing 747-400 Supertanker \cite{2018:calfire}.

\begin{figure}[h]
  \label{fig:airtanker}
  \centering
  \includegraphics[scale=0.4]{images/dc10.jpg}
  \caption{A DC-10 airtanker, rated for 9,400 gallons, drops retardant above Greer, Arizona. \textbf{CITATION NEEDED}}
\end{figure}

Suppose that in the future, firefighters are equipped with GPS sensors
and digital transmitters---this could be an application running on
their personal cell phones, or better yet something running on
dedicated and more reliable equipment. A seemingly reasonable policy
would be to prohibit VLATs from performing a drop if its computers do
not have up-to-date information about the location of firefighters on
the ground. The problem is that obtaining this information may be
difficult or impossible: perhaps heavy smoke, a damaged radio tower,
or a tall ridge prevents communications between the air and ground. In
these scenarios, rigid enforcement of the safety policy would prevent
airtankers from operating.

This scenario exemplifies a classic tradeoff between opposing goals:
system \emph{safety} and system \emph{availability} (or
\emph{liveness}), elaborated on in Section \ref{sec:background}. In
the distributed computing context, safety properties guarantee that a
system will not perform an action that violates a constraint. In this
example, a reasonable safety property could look like the following:
\begin{quote}
  \interlinepenalty=10000 % Punish pagebreaks inside this quote!
  $\textbf{P}_\textrm{safe}$: All ground agents are known to be at
  least 100 feet outside the drop zone, and this information is
  current to within 30 seconds, or airtankers will not perform a drop.
\end{quote}
By contrast, liveness properties stipulate that the system
will certainly perform requested actions, typically within some time
bound. In our scenario, an expected liveness property might be the
following:
\begin{quote}
  $\textbf{P}_\textrm{live}$: Airtankers will perform a drop within 20
  minutes\footnote{In an interview with PBS, the Chief of Flight
  Operations for Cal Fire cited 20 \mbox{minutes} as the response time
  for aerial firefighting units within designated responsibility areas
  \cite{2021:aerialfirefighting}.} of receiving a request.
\end{quote}

Safety and liveness are frequently dual mandates: safety, in the sense
used here, requires a system \textbf{never} to perform certain
actions, while liveness requires a system to \textbf{always} perform
certain actions. The tension between these ideals means the two often
cannot be guaranteed simultaneously. Such is the case in our example:
if firefighters are unable to broadcast their locations to the pilot,
then the pilot's actions are impeded to maintain
\(\textbf{P}_\textrm{safe}\) at the cost of
\(\textbf{P}_\textrm{live}\), allowing the fire to spread in the
meantime.\footnote{A slight linguistic idiosyncrasy exhibited here is
that liveness properties---not just ``safety'' properties---can also
be relevant to human safety. Thus, the narrow technical meaning of
safety properties for distributed systems does not capture the whole
meaning of System Wide Safety.}

Besides the safety/liveness tradeoff, the previous example exhibits
two other aspects of reasoning about distributed systems. We pause to
draw attention to them.

\paragraph{Epistemology}
Observe that the issue in the VLAT example does not simply disappear
if no ground personnel are actually within 100 feet of a drop
zone. That is, it is not simply a matter of whether a danger is
factually present. To guarantee \(\textbf{P}_\textrm{safe}\), an
airtanker's actions must be restricted when its computers do not
\emph{know} whether an action would violate
\(\textbf{P}_\textrm{safe}\)---knowledge of the fact, and not merely
the fact of it, is the crucial part. In philosophical terms, the logic
of distributed agents is inherently an \emph{epistemic} one, meaning
it must take into account not just what is true but what is known. The
need to share knowledge is what drives communication and puts a burden
on the network.

\paragraph{Discontinuity}
The properties $\mathbf{P}_\textrm{safe}$ and
$\mathbf{P}_\textrm{live}$ are inflexible, all-or-nothing
propositions. The complexity of the operational environment demands
considering more flexible kinds of properties. Suppose that agents are
known to be $500$ feet outside the drop zone, the extra margin meaning
they are well away from any danger, but the information is only
current to within 35 seconds. Clearly this is good enough information
to authorize a drop, but strictly speaking the 5-second difference is
a violation of $\mathbf{P}_\textrm{safe}$. When safety properties are
this rigid, the system's behavior becomes overly sensitive to the
particulars of the environment and therefore difficult to predict,
which is precisely the kind of \emph{discontinuity} that we aim to
prevent. Our goal is to build reliable systems that perform well in a
wide range of circumstances.



%To make the example more extreme, $\mathbf{P}_\textrm{safe}$ is
%violated even if the information is current to within 31 seconds, so
%a mere extra second of delay makes all the difference between whether
%the VLAT can operate, even though the firefighters in question are
%clearly far outside the drop zone.



%as it makes the system's behavior difficult to predict, being so
%sensitive to the particulars of the environment. Preventing this kind
%of discontinuity can be difficult because we still want to provide
%rigorous guarantees about the system's behavior, i.e. we cannot forgo
%enforcing properties like $\mathbf{P}_\textrm{safe}$ altogether.

%In reality, a human controller would likely decide that
%the computer \emph{does} have enough information, and decide to
%override the policy. However, it is difficult to make assurances about
%a system if external actors are frequently in the habit of overruling
%its decisions.

\subsection{Communication Patterns in the Field}
\label{communication-in-practice}

We now consider some of the communication patterns that occur in
wildland firefighting. The layman reader may be surprised to learn
that the state of the art is somewhat primitive, which is partly
attributable to the fact that very little permanent infrastructure
exists in this setting. This fact is also what makes wildfires an
interesting and generalizable example for other kinds of civil
disaster environments.

One trend we will draw attention to is a kind of ``geospatial locality
of reference'' principle that system designers should take into
account. By this, we mean the happy coincidence of two observations
which, if not exactly guaranteed rules, are at least approximately
true in many circumstances. The first observation is simple:
\begin{quote}
  $\textbf{O}_1$: Agents with the most urgent need to
  coordinate their actions will tend to be located closer to each
  other and require the same kinds of information.
\end{quote}
The second observation is as follows:
\begin{quote}
  $\textbf{O}_2$: Agents that are located closer together
  will tend to have more reliable communications between them than
  agents that are far apart. Conversely, information that must travel
  a long distance tends to be delayed or degrade in quality.
\end{quote}

We will refer to the concomitance of these two facts as simply the
``locality'' principle. The reason the locality principle is crucial
is that, as we see in Section \ref{sec:background}, there are major
theoretical and practical limits to how well \emph{all} agents in the
system can share \emph{all} information with each other, i.e. how well
a system can achieve global consistency. As luck would have it, in
many cases this will not be required: it will be often be enough for
\emph{some} agents to share \emph{some} information with each other, a
fact that raises opportunities to optimize scare network resources. Of
course, this does raise the question of how to decide which
information must be shared with whom, and how to use this knowledge to
best exploit the communication network. We will revisit this question,
without the pretense of answering it conclusively, throughout Sections
\ref{sec:networking}, \ref{sec:continuous-consistency} and
\ref{sec:data-fusion}. For now, we resume our examination of what
communication patterns look like today.

%Generally speaking, we expect that agents with a higher need to
%coordinate their actions will tend to be located closer to each
%other, which in turn correlates with an ability to communicate
%quickly and reliably. This kind of principle motivates the sort of
%decentralized, ad-hoc networking protocols considered in Section
%\ref{sec:networking}. It can also affect the design of higher-level
%applications like the one in Section
%\ref{sec:continuous-consistency}.

\paragraph{Communication on the ground}

In the field, communication between firefighters and other agents is
often facilitated by handheld (analog) land-mobile radios, which are
inherently limited in their battery life, bandwidth, effective range,
and ability to work around environmental factors like foliage and
smoke.

As an alternative to using a radio, it is common for wildland
firefighters in the field simply to shout commands and notifications
to nearby personnel. This is a clear manifestation of the locality
principle: a substantial amount of communication occurs directly
between nearby firefighters working on the same or closely related
tasks, and in some cases they are so nearby they can communicate
without any network infrastructure at all. In a future environment
where agents might be equipped with body-worn sensors and heads-up
displays (HUDs) \citationneeded, this sort of local communication
might be facilitated by simple low-power technologies such as
Bluetooth \citationneeded, without the need for more sophisticated
(and heavy) equipment.

Communication over a long distance requires infrastructural support,
such as the use of cell towers and repeater stations. Typically,
disaster response environments have scarce permanent infrastructure:
in a wildland fire setting, perhaps a few repeaters mounted to a
nearby watch tower. Ad-hoc infrastructure, such as a cell on wheels
(COW) or cell on light truck (COLT), can sometimes be deployed on an
as-needed basis if the location allows for it. An extremely common
issue is making sure that all equipment is properly configured, for
instance that all radios are listening on the correct frequencies,
particularly when different agencies and groups need to
interoperate. The difficulty of interoperability was another issue
exhibited during the September $11^\textrm{th}$ attacks, which was a
major impetus for the creation of the nationwide public safety
broadband network (NPSBN) FirstNet \citationneeded. However, we can
only imagine that interoperability between different agencies and
vendors will remain a challenge in the future.

\begin{figure}[t]
  \centering
  \includegraphics[scale=0.085]{images/ironside.jpg}
  \caption{The Ironside Mountain lookout and radio repeater station, destroyed in the 2021
    Monument fire, shown with protective foil on August
    $10^\textrm{th}$, 2015 during the 2015 River Complex fire. This
    particular fire burned 77,077 acres over 77 days. \textbf{CITATION NEEDED}}
  \label{fig:ironside}
\end{figure}

Use of centralized infrastructure comes with the potential for
widespread failure when the infrastructure breaks down. For example, in
California, the Ironside Mountain lookout/repeater station (shown in
Figure \ref{fig:ironside}) was destroyed during the 2021 Monument
Fire, which burned approximately 223,124 acres over 88 days
\cite{2021:monumentfire}. The Ironside Mountain station had strategic
importance, being located on a tall ridge. According to a video blog
from a volunteer firefighter involved in the incident\citationneeded,
its loss prevented communication between operators on different sides
of the ridge, in networking parlance creating a \emph{partition} that
lasted until crews could ascend the ridge to deploy a temporary
station:
\begin{quote}
  ``When {[}the Ironside Mountain lookout station{]} burned down the radio
  repeater went with it. And so communications were lost across the
  fire\ldots{} one side of the fire couldn't talk to the other side\ldots.
  So it was kind of a critical job to get that road cleared so that the
  radio crews could go back up there and set up a temporary radio tower.''
\end{quote}
This kind of scenario, one where communication between two groups is
completely severed, is exactly the sort of thing considered by the CAP
theorem in Section \ref{sec:background}.

\paragraph{Vehicles on the ground}
Large numbers of ground vehicles are involved in wildfire
suppression. A large wildfire response can involve up to 100
firetrucks distributed over a large geographical area. Bulldozers and
similar vehicles are also commonly used to control the landscape and
perimeter of the fire. An advantage of vehicles is that they can carry
heavier, which is to say better, communications equipment than a
human. For instance, a vehicle could be equipped with a satellite link
as well as a local wireless area network (WLAN) base station, serving
as a bridge between agents in the field and central coordinators
(e.g. incident commanders).

\paragraph{Communication in the air}

Wildland firefighting increasingly involves the use of helicopters and
fixed wing aircraft. Civil aviation has traditionally employed simpler
communication patterns than this use case demands. For instance,
aircraft equipped with Automatic Dependent Surveillance-Broadcast
(ADS-B) monitor their location using GPS and periodically broadcast
this information to air traffic controllers and nearby aircraft. This
sort of scheme has worked well in traditional applications, where
pilots typically only monitor the general locations of a few nearby
aircraft. The locality principle is exhibited here, too: aircraft have
the highest need to coordinate when they are physically close and
therefore in range of each other's ADS-B broadcasts.

In our setting, a large number or aircraft, easily a half dozen or
more, may need to operate in a small area, near complex terrain,
during adverse conditions, often at low altitude. In other words, the
demands are many and the margins for error are small. This sort of use
case calls for more sophisticated coordination schemes between
airborne and ground-based elements than solutions like ADS-B provide
by themselves.

As aircraft generally have better line-of-site to ground crews than
ground crews have to each other, firefighters sometimes relay messages
to air-based units over radio, which in turn is relayed back down to
other ground units. The locality principle comes into play here too,
but this time in the reverse direction: this relay scheme allows
knowledge to travel farther, but the extended reach comes at the cost
of introducing delays and possible degradation of message quality, as
in the classic game of telephone. Hence, this sort of message-passing
should be reserved for more critical information.

In some cases, planes from the Civil Air
Patrol\citationneeded\footnote{A civil auxiliary of the U.S. Air
Force. https://www.gocivilairpatrol.com/} have been equipped with
radio repeaters and dispatched to wildfires to provide service to
ground-based units. In the future, this sort of service could be
provided autonomously by base stations mounted to unmanned aerial
vehicles (UAVs), which might perform additional functions such as
tracking the fire perimeter. More generally, future systems should
transparently facilitate exchanging information between agents in a
decentralized fashion that is robust to the failure of any one
component. In Section \ref{sec:networking} we imagine a resilient
ad-hoc digital network built from handheld and ground- and
air-vehicle-mounted devices, permanent base stations, portable
temporary infrastructure, and so on.
%---a high-tech modernization of the sort of informal relay schemes
%operating today over traditional radio channels.

\subsection{Towards the Future}\label{towards-the-future}

So far we have said a lot about the state of disaster response
today. A distributed system for this sort of challenge should be
designed for the kinds of environments and conditions expected in the
near- to medium-term future, so we briefly turn our attention to some
of our expectations for this topic.

Perhaps the most prominent expectation for future disaster response
events is a heavy reliance on \emph{data}. Besides improvements to
communications that facilitate information sharing, we expect advances
in machine intelligence to greatly influence how this data is
handled. Agents in disaster response environments will be both
producers and consumers of data, and this data will need to processed
by humans and machines in ways that agents can readily make sense of
to support their decision-making. Our background research indicated
many different kinds of data that could be valuable for
responders. Just some of the kinds of information and communication we
expect include the following:
\begin{itemize}
  \tightlist
\item
  Free-form communication, especially recorded voice messages
  broadcast to many agents at once, which may need to be processed by
  machines to extract the most pertinent information into a more
  actionable format
\item
  The exact or estimated location of victims, firefighters, vehicles,
  hazards, etc.
\item
  Medical information gathered from victims, perhaps stored in and
  collected from digital triage tags\citationneeded
\item
  Data about current and predicted fire or weather patterns
\item
  Topographic information about the terrain, highlighting for instance
  the location of rivers and roads that could form a fire control line
\item
  Planned escape routes, rendezvous points, safety zones, and landing
  zones
\item
  Availability and dispatching of assets, e.g.~ambulances, airtankers,
  or crews on standby\footnote{NOTE Need to mention Monares et al 2011}
\end{itemize}
In a perfect environment, such information would be shared with all
necessary agents in whole and instantly. In reality, agents will be
presented with information that is sometimes incomplete, out of date,
or contradictory---all problems that are further exacerbated by an
unreliable network. A superficially contradictory concern is that the
information presented will be \emph{overcomplete}, filled with petty
details that distract agents from their important tasks.

%Of course, there is no actual contradiction between incomplete
%information and information that is unneeded and useless at best.

In some ways, future systems for disaster response will bear
resemblence to future systems for warfighting, such as the conceptual
\emph{Internet of Battle Things} (IoBT) \citationneeded. Chiefly,
agents ``under extreme cognitive and physical stress'' will be subject
to a highly dynamic and dangerous environment; while various kinds of
technology will assist humans by providing data to support
sensemaking, a contraindicating concern will be flooding agents with a
``massive, complex, confusing, and potentially
deceptive\footnote{While deliberately adversarial network behavior
seems like less of a concern for disaster response agents than
warfighters, we conjecture that the metaphorical ``fog of war'' may
lead to confusing or contradictory reports that share similarities
with intentionally deceptive behavior.} ocean of information.'' To
avoid ``swimming in sensors and drowning in data''
\cite{2010:magnuson}:
\begin{quote}
``Humans seek well-formed, reasonably-sized, essential information
  that is highly relevant to their cognitive needs, such as effective
  indications and warnings that pertain to their current situation and
  mission.'' \citationneeded
\end{quote}
We also note that the most distinctive feature of the internet of
battle things---that which separates it from the everyday internet of
things---is ``the adversarial nature of the environment.'' To some
extent this adversial behavior is common also to disaster response. We
previously cited a real-world example of a critical communications
station destroyed by wildfire, perhaps not entirely unlike an attack
by enemy forces.

Lest we overstate the similarities between a battlefield environment
and a civil disaster response environment, we expect that a
distinctive feature of the latter is a greater need to preserve scarce
network resources. More so than a tactical military unit, a group of
(say) volunteer firefighters has to make do with off-the-shelf
equipment rather than purpose-built, best in class hardware like
sophisticated satellite links. Dedicated logistical support, and even
things like dedicated radio spectrums, will likely be in shorter
supply, while adverse conditions like inclement weather will be almost
guaranteed. Therefore we expect a complex interaction between the
high-level needs of distributed applications and the low-level
concerns about network resources. This is because only the
applications have enough information to determine which data is the
most important and must shared with whom first, while only the
network-level protocols have enough information and control to make
prudent use of scarce network resources. In contrast to the common
wisdom that applications should be relatively blind to network
considerations---or conversely that network protocols ought to be
transparent to applications---our setting calls for mechanisms
allowing the two layers to have some influence over each other. This
interaction between the network and applications will be considered in
more detail in Sections \ref{sec:networking}--\ref{sec:data-fusion}.

To give an example, a central data fusion center may be used to detect
and alert responders to a fire that has accidentally moved beyond a
control line (known as \emph{slopover}), or it may warn firefighters
when they have strayed too far from an escape route or safety
zone. Such information would be of high importance, and it would be
worthwhile to expend network resources conveying this information to
the relevant parties. It might also be nice for firefighters to have
real-time information about the GPS location of every other
firefighters. However, if this strains the network, then perhaps the
exact location of teammates is called for, while only the general
location of other crews is necessary. If the network is extremely
constrained, perhaps only information immediately relevant to
preserving life should be sent, in order to ensure the network is able
to deliver this information quickly. The key point is that from where
we stand, we cannot give a blanket rule determining which information
is important, as this is partly a dynamic function influenced both by
the criticality of the information to the task at hand and how much
unused network capacity is available at that moment.

%For developers, it is clear that this requires some coordination
%between the application and the networking layers, as the latter must
%be given enough information to make the most prudent use of limited
%resources.

\section{Introduction to Distributed Systems}
\label{sec:background}
In this section we attempt to summarize the main themes of distributed
systems theory and where this fits into the picture painted in Section
\ref{sec:disaster-response}. The primary reference we are following is
the excellent book by Kshemkalyani and Singhal
\cite{kshemkalyani_singhal_2008}, particularly chapters 1, 3, 6, and
12.

A distributed system, in the most general sense, is a collection of
independent entities that cooperate to solve a problem that cannot be
individually solved \cite{kshemkalyani_singhal_2008}. This memo is
concerned with distributed systems used by firefighters and other
disaster response agents. The components of our system could be
computers, smartphones, sensors, or other kinds of communication
equipment, which may be carried by individuals, mounted to ground or
air-based vehicles, deployed as temporary or permanent infrastructure,
or even autonomous. The kinds of tasks our system might handle include
navigating safely in close proximity, delivering resources to remote
locations, suppressing fires, and collecting, processing, and
disseminating data about the environment.

\subsection{Message Passing}
\label{ssec:message-passing}

Singhal and Shivaratri \cite{10.5555/562065} offer the following
definition of a distributed computing system:

\begin{quote}
  ``A collection of computers that do not share common memory or a common
  physical clock, that communicate by message passing over a communication
  network, and where each computer has its own memory and runs its own
  operating system.''
\end{quote}
We shall consider a system consisting of a set \(\mathcal{P} =
\{P_i\}_{i\in I}\) of \emph{processes} executing on independent,
probably geographically dispersed computing devices, which we
consolidate under the generic term \emph{nodes}. It is important to
note that different kinds of nodes can have different characteristics,
such as capabilities and intended uses, but for now we take a
high-level view. A notable aspect of what makes the system
``distributed'' is that the nodes must communicate by message-passing,
which must be facilitated by some kind of network. This restriction is
implied by absence of a common memory (whereas processes running on
the same machine can share information by writing it to a common
memory location).

A foundational assumption is that the network is unreliable. Section
\ref{sec:disaster-response} explained why this is certainly expected
in disaster scenarios. Delivering messages over the network is not
instantaneous---message packets must be sent over the air or through a
cable, and typically processed and forwarded by any number of
intermediate networking devices, and retransmitted in case of
unrecoverable errors during transit, all of which takes time. This
means that messages are passed with some unpredictable latency. In
this section, our main challenge is to provide ways for agents to
coordinate their actions despite the uncontrollable delays in
communication caused by the network and environment, which is to say
by the ``distributed'' aspect of the system.

\paragraph{Network Reliability}
A priori, the network may not deliver a packet at all, i.e.~it may
silently discard messages without alerting the sender. The same
message may be also be delivered multiple times, and different
messages may arrive in any order. In the case of \emph{Byzantine
faults}\citationneeded, the network might even act like a malicious
adversary. In this section, being focused on higher-level
considerations, we shall assume that messages are delivered exactly
once, uncorrupted, but with an unpredictable delay. Some, but not all,
common so-called ``transport'' protocols like TCP\citationneeded and
LTP\citationneeded can provide this sort of semi-reliable message
delivery over a less reliable network. For example, these protocols
might tag outgoing messages with identifiers that allow the receiver
to detect duplicates and arrange messages in the ordered intended by
the sender, add checksums used to verify message integrity, and
transparently handle retranmission when messages become corrupted. We
shall take a closer look at these kinds of low-level details in
Section \ref{sec:networking}, where we relax our assumptions about
network reliability. For now, one could say we are working at a level
of abstraction above the network transport layer: the ``network'' is
just something that eventually delivers messages to the right people,
but often at the wrong time, which is the problem. Note that
reliability mechanisms in transport-level protocols contribute to the
latency involved in communication, so they do not solve the problems
under consideration here, namely the difficulty of coordination when
messages are unpredictably delayed without access to perfectly
sychronized clocks.

\subsubsection{FIFO and causal ordering}

Figures \ref{fig:message-latencies} and \ref{fig:message-latencies2}
show time diagrams for messages $\{m_i\}_{i=1}^N$ sent between three
processes $P_1$, $P_2$, and $P_3$. The $x$-axis of the diagram shows
the flow of physical time from left to right. Each process consists of
a worldline depicting the events occurring in that process. Each
message $m_i$ starts off as a message \emph{send} event
$m_i^\textrm{send}$ indicating the moment the message is sent over the
network by its originating process; its delivery generates a message
\emph{receive} event $m_i^\textrm{recv}$. The send-receive event pairs
are connected by an arrow and said to be \emph{corresponding}
events. The subscripts on the messages only serve to disambiguate
them, but they are not part of the message contents and have no
semantic importance.

\begin{figure}[p]
  \centering \input{images/pgf/messagePassingEx.pgf}
  \caption{Time diagram depicting latencies in message-passing}
  \label{fig:message-latencies}
\end{figure}

\begin{figure}[p]
  \centering \input{images/pgf/messagePassingEx2.pgf}
  \caption{Time diagram where the first message sent is delivered
    last}
  \label{fig:message-latencies2}
\end{figure}

\begin{figure}[p]
  \centering \input{images/pgf/messagePassingEx3.pgf}
  \caption{Time diagram satisfying FIFO but violating causal ordering}
  \label{fig:message-latencies3}
\end{figure}

\afterpage{\clearpage}

Two things are clear from these figures. First, messages are sent with
a varying delay, which is why the arrows are diagonal rather than
perfectly vertical. Second, messages $m_i$ and $m_j$ sent by different
senders, whether to the same recipient or different ones, may arrive
in different order than they were sent in. Such is the case with
messages $m_2$ and $m_4$ in Figure \ref{fig:message-latencies}, sent
by $P_1$ to $P_3$ and $P_2$, respectively. This diagram may depict a
scenario where $P_1$ and $P_3$ are far apart and have a bad connection
to each other, with $P_2$ having a relatively good connection to the
others. Figure \ref{fig:message-latencies2} depicts an extreme example
where message $m_1$ is sent before all others but is last to be
delivered, with all of the messages sent by $P_2$ delivered earlier
despite being sent later. This may correspond to a scenario where
$P_2$ has moved closer to $P_1$ while $P_3$ has moved further away.

At this level of abstraction it is reasonable to assume that messages
from the same sender to the same recipient arrive in the correct
order, an assumption known as the FIFO (first-in, first-out) network
model. A violation of the FIFO assumption would correspond to two
crossing lines that have \emph{the same (sender, receiver) pair}. All
figures in this section satisfy FIFO, as no two intersecting lines
that originate at the same process also end at the same receiver. FIFO
ordering is one of the basic services that might be provided by the
network transport protocol.

Unfortunately, things can go wrong for distributed applications even
assuming the FIFO networking model. Namely, messages can violate
\emph{causal ordering} (CO). Causality in this context refers to the
potential for events to influence each other in reality; a key problem
for distributed systems is that the network latencies mean events with
a causal relation may appear to happen in an illogical order. Tracking
causality is such a key issue that we devote some space to considering
it. We start by defining the causal precedence relation for events,
also known as the ``happens before'' relation, after giving an
auxiliary definition.

\begin{definition}
  For two events $e$ and $e'$ that both occur in process $P_i$, we
  write $e \leq_{P_i} e'$ if $e$ occurs before $e'$ in $P_i$'s
  worldline.
\end{definition}
The previous definition is unambiguous, as we assume events occur at
discrete, non-overlapping moments at each process. Less clear is how
to order events that occur on different processes.

\begin{definition}[Causal ordering]
  We define a binary relation $\to$ on the set of events as follows:
  \[e \to e' \iff \begin{cases} e \leq_{P_i} e' \textrm{ for some process $P_i$} \\
    e = m_i^\textrm{send} \textrm{ and } e' = m_i^\textrm{recv} \\
    \exists e'' \textrm{ such that } e \to e'' \textrm{ and } e'' \to e
  \end{cases}
  \]
  If $e \to e'$, we say $e$ has \emph{causal precedence over} or
  \emph{happens before} $e'$.
\end{definition}
In words, there are three ways event $e$ has causal precedence over
$e'$.  First it may be that the two events occur on the same process
and $e$ literally occurs before $e'$. It may also be $e$ is a message
send event and $e'$ is the corresponding message receive
event. Finally, it could be that $e$ has causal precedence over some
intermediate event $e''$ that has precedence over $e'$, i.e. we
consider the \emph{transitive closure} of the previous two conditions.

Informally, $e \to e'$ holds whenever one can put a finger on an event
$e$ in the time diagram and, finger held down, trace a path to $e'$
just by moving left-to-right on the same worldline or following
diagonal lines connecting the sending and receiving events of a
message. Both ``causal precedence'' and ``happens before'' can be
misnomers: $e \to e'$ can hold without it being the case that $e$
really caused $e'$ to happen, nor is it that case that if $e$
literally occurs before $e'$ that $e \to e'$ holds. Intuitively, $e
\to e'$ conveys that information from $e$ potentially affected, or
could have influenced, the event $e'$. For instance, $e'$ might be the
send event of a message containing information learned from the $e$
event. Generally, we want to avoid a scenario where $e \to e'$ holds
in reality but, from a user's perspective, it seems that $e'$ actually
occured before $e$. We define this formally before seeing an example.

\begin{definition}(Causally consistent execution)
  A time diagram is \emph{causally consistent} if the following
  property holds: for all two messages $m$ and $n$ sent to the same
  destination, if $m^\textrm{send} \to n^\textrm{send}$, then
  $m^\textrm{recv} \to n^\textrm{recv}$.
\end{definition}

Let us examine a simple application of causal ordering and why a FIFO
model may violate it. Consider a na\"ively-designed text-messaging
application used by three clients $P_1, P_2, P_3$. To post a message,
a process simply sends the contents of that message to the other two
members of the group, as shown in Figure
\ref{fig:message-latencies3}. Note that in this example we allow
messages to multiple recipients, which in reality this might be
implemented as a pair of distinct messages. What we \emph{do not}
assume is that the recipients receive the message at the same time,
since this illusion is precisely what we are trying to implement. In
the figure, perhaps $P_1$ posts a question ``Is the house at the end
of the street occupied?,'' while $P_2$ responds to this question in
the affirmative, and $P_3$ merely listens. Figure
\ref{fig:message-latencies3} vaccuously satisfies FIFO because all
four arrows have a distinct (sender, receiver) pair. However, $P_3$
witnesses $P_2$'s answer to $P_1$'s question before seeing the
question posed by $P_1$ in the first place. This is a violation of
causal order because the send $P_2$'s

In this simple example, $P_3$ may be able to infer what is meant, but
clearly this reliance on human intelligence will not suffice
systematically. In a more complex example with potentially dozens or
hundreds of clients, the potential for serious confusion is
great. Some mechanism for tracking causal precedence is clearly
needed.

\subsection{Logical clocks}
At first it may appear that we can avoid the scenario described above
by attaching to each event a \emph{timestamp} tracking when the event
occurred---this would seemingly allow $P_3$ to infer that the message
sent by $P_1$ logically precedes $P_2$'s response. Let us see why this
fails. For each event $e$, let $C(e)$ denote the timestamp attached to
that event. The fundamental \emph{monotonicity property} we want to
satisfy is the following:

\[ \textrm{for all events $e$ and $e'$, } e \to e' \implies C(e) < C(e') \label{eq:mp}\tag{MP} \]

\ref{eq:mp} requires that if $e$ causally precedes $e'$, then $e$
should have a lesser timestamp. In our example, with
$m_1^\textrm{send} \to m_4^\textrm{send}$, it would have to be the
case that $C(m_1^\textrm{send}) < C(m_4^\textrm{send})$. The problem
is that this cannot be guaranteed unless $P_1$ and $P_2$ have
synchronized clocks, and a hallmark of distributed systems is we
cannot make this sort of assumption (as stated in the quote at the
beginning of this section).  Physical clocks suffer from drift, which
is to say they do not all run at the same physical rate. They are also
quite prone to misconfiguration, say if a device administrator sets
the time or date incorrectly, and they require an always-on battery to
track time when the device is powered off, say when sitting in a
storage. While in some cases one may assume access to clocks that are
only approximately synchronized, perhaps by employing special-purpose
protocols like NTP\citationneeded, in general we cannot assume access
to physical clocks that are so precise as to fundamentally solve the
problems discussed in this section. It is also not the case that
merely timestamping messages is enough to answer every question we
could ask about causal precedence. For example, it is especially
desirable if we can assume the \emph{strong clock consistency
condition}:
\[ \textrm{for all events $e$ and $e'$, } e \to e' \iff C(e) < C(e') \label{eq:sc}\tag{SC} \]
That is, \ref{eq:sc} strengthens \ref{eq:mp} by requiring that we can
always compare two timestamps to infer whether the events are causally
related. This property cannot hold even with synchronized clocks, as
events need not be causally related even if one physically precedes
the other. For instance, in Figure \ref{fig:message-latencies2},
$P_3$'s message $m_1$ is sent before any other messages, but
$m_1^\textrm{send}$ does not causally precede any event except
$m_1^\textrm{recv}$.

Distributed applications can systematically keep track of causal
precedence, among other things, by employing a system of \emph{logical
clocks}, which typically measure logical (non-physical) time in terms
of integers or sets of integers. Each device maintains a logical clock
that is advanced according to certain rules. Three major kinds of
clocks are commonly considered: scalar clocks, vector clocks, and
matrix clocks. Scalar clocks are extremely simple but provide the most
coarse-grained information, while matrix clocks require storage space
quadratic in the number of processes but provide extremely precise
information about causality; vector clocks fall somewhere in the
middle. We provide a brief description of each paradigm.

\subsubsection{Scalar clocks}
Scalar clocks, also called Lamport clocks after their
inventor\citationneeded, require each process $P_i$ to maintain a
single scalar value $C_i$, a non-negative integer, which we assume is
initialized to $1$. There are two update rules:

\begin{enumerate}
\item When a message is sent, $C_i$ is updated according to the rule
  \[C_i := C_i + 1.\]
  This new value is the timestamp attached to the message.
\item When a message is received with timestamp $C$, $C_i$ is updated according to
  \[C_i := \max(C, C_i) + 1.\]
  This new value is the timestamp attached to the message receive event.
\end{enumerate}
Figures
\ref{fig:message-latencies-scalar}--\ref{fig:message-latencies3-scalar}
redepict Figures
\ref{fig:message-latencies}--\ref{fig:message-latencies3},
respectively, this time showing the scalar timestamp that would be
assigned to each event.

It is not hard to see that scalar clocks satisfy the monotonicity
property \ref{eq:mp}. Examining Figures \ref{fig:message-latencies2}
and \ref{fig:message-latencies2-scalar}, we see that $P_3$ could
compare timestamps to determine that $C(m_1^\textrm{send})$ (the
timestamp sent with $m_1$, value $1$) is less than
$C(m_b4^\textrm{send})$ (value $5$). Therefore the application should
make it clear to the client to $m_1$ logically precedes the response
from $P_2$, even if it arrives later.

However, scalar clocks do not satisfy the strong monotonicity
condition. If a process sees two messages $m$ and $m'$ sent by $P$ and
$P'$, respectively, we cannot examine timestamps to infer whether $P'$
message contents could have been causally influenced by the contents
of $m$. For example, examining Figures \ref{fig:message-latencies3}
and \ref{fig:message-latencies3-scalar}, we see that
$C(m_1^\textrm{send})$ has a globally minimal timestamp value of $1$,
but $m_1$ does not causally precede any other message. For this
fine-grained information we must use vector clocks.

{
 \setlength\belowcaptionskip{-3ex}
\begin{figure}[p]
  \centering \input{images/pgf/messagePassingExScalar.pgf}
  \caption{Scalar clocks for Figure \ref{fig:message-latencies}}
  \label{fig:message-latencies-scalar}
\end{figure}

\begin{figure}[p]
  \centering \input{images/pgf/messagePassingExScalar2.pgf}
  \caption{Scalar clocks for Figure \ref{fig:message-latencies2}}
  \label{fig:message-latencies2-scalar}
\end{figure}

\begin{figure}[p]
  \centering \input{images/pgf/messagePassingExScalar3.pgf}
  \caption{Scalar clocks for Figure \ref{fig:message-latencies3}}
  \label{fig:message-latencies3-scalar}
\end{figure}
\afterpage{\clearpage}
}

\subsubsection{Vector clocks}
\newcommand{\vt}{\textrm{vt}}
Vector clocks require each process to store a scalar value for each
process in the system. That is, given a set of $N$ processes, $P_i$
maintains a vector $\vt_i[1 \ldots N]$ of non-negative
integers, with all values initialized to $\vt_i[x] = 1$. As
with scalar clocks there are two update rules:

\begin{enumerate}
\item When a message is sent, $\vt_i$ is updated according to the rule
  \[\vt_i[i] := \vt_i[i] + 1.\]
  The entire (updated) vector $\vt_i$ is attached to the message.
\item When a message is received with timestamp $\vt$, $\vt_i$ is updated according to
  \[\vt_i[x] := \max(\vt[x], \vt_i[x]) \quad \textrm{for all $x = 1\ldots N$}.\]
  Then $P_i$ advances its own local time according to the rule
  \[ \vt_i[i] := \vt_i[i] + 1\]
  This new vector is the timestamp attached to the message receive event.
\end{enumerate}

A process $P_i'$ vector clock can be concisely described as an
ordinary scalar clock $\vt_i[i]$ combined with, for all $j \neq i$, a
\emph{lower bound estimate} $\vt_i[j]$ of the local scalar clock
$\vt_j[j]$ of process $P_j$.

Figures (REF--REF) depict Figures (REF--REF), respectively, this time
showing the vector timestamp that would be assigned to each event.

Let us see an example of where the extra information provided by
vector clocks is useful.

\begin{itemize}
\item Is the structure occupied?
\item There are still two people trapped on the second floor.
\item We already sent a team in and they determined it was empty.
\end{itemize}

The order of the last two messages is important.

\subsubsection{Matrix clocks}

Matrix clocks are to vector clocks what vector clocks are to scalar
clocks. That is, a matrix clock is a vector clock combined with a
lower bound estimate of every other process's vector clock.

It is worth highlighting the fact that matrix clocks are used to keep
track of (a lower bound estimate of) what other processes know about
the global state of the system. In Section \ref{sec:background}, we
explained that distributed systems fundamentally involve epistemic
logic, i.e. reasoning about not just what is true but what is
known. In Section \ref{sec:continuous-consistency} we will see an
example where this sort of lower bound estimate of other process's
clocks is important for distributed database replication.

\subsection{Shared Memory}
It is a complex task to program distributed applications in terms of
sending and receiving messages over the network. As we have briefly
seen, it raises issues of synchronization and consistency that must be
dealt with in order to provide understandable system behavior. In this
section we summarize a simpler, but in some sense equivalent, paradigm
for distributed applications called the \emph{distributed shared
memory} (DSM) abstraction.

In the DSM model, programmers think in terms of reading and writing
values to memory locations (one might also say \emph{variables})
rather than sending and receiving messages over the network. This is
much how they would program an ordinary application, the key feature
being that all instances of the application act as if they are reading
and writing from the same memory locations, when they are actually
running on distributed computers that do not share
memory. Transparently and behind the scenes, a ``middleware''
memory-management protocol layer translates the read/write requests
into send/receive requests that facilitate the abstraction of a common
virtual memory space.

%We shall consider the DSM abstraction and some of the different
%consistency requirements we can enforce in this setting.

%A fundamental distributed application is the \emph{shared distributed
%memory} abstraction. We shall assume that all processes maintain a
%local replica of a globally shared data object, as replication
%increases system fault tolerance. For simplicitly, we shall discuss
%the data store as a simple key-value store, but it could be something
%else like a database, filesystem, persistent object, etc.


Figure REF shows a time diagram for the shared memory abstraction, not
unlike the time diagrams in Figures
\ref{fig:message-latencies}--\ref{fig:message-latencies3}, but for the
shared memory abstraction rather than the message-passing
abstraction. The diagram depicts a series of operations, which come in
two types:
\begin{itemize}
  \item A \emph{write} operation $W(x, v)$ indicates writing value $v$
    to memory location $x$. In pseudocode the notation might be $x :=
    v$.
  \item A \emph{read} request $R(x, v)$ indicates reading the value in
    memory at location $x$, which returns the value $v$. (Of course,
    unlike a write request, $v$ is not one of the request parameters.)
\end{itemize}
Each request is consists of a horizontal span, shown as a shallow box,
along the worldline of a process. The box ``begins'' at the moment the
request is executed by the running application, and it ``ends'' when
the operation has finished executing. (For the programmer, this is the
time the operation returns control back to the running program.) While
the operation is running, the \emph{distributed memory manager} might
coordinate with other processes in the background by sending and
receiving messages---for instance, it may notify them that a write
operation is executing, or it may request the ``latest'' value of a
memory location, for some yet undefined notion of ``latest''---but
this is transparent to the programmer and not depicted in the
diagrams.

We assume that operations running on a single process do not overlap
in time, but of course operations on different processes can and
frequently will overlap.


Since the goal is for the system to present
the illusion of a reading and writing from a common memory, the
observed result should be equivalent to some interleaving of the
requests into a linear order. If each processes $P_i$ of $N$ total
processes issues $r_i$ requests for some non-negative integer $r_i$,
observe there are a total of
\[
\frac{\left(\sum_{i = 1}^N r_i\right)!}{\prod_{i = 1}^N r_i!}
\]
such interleavings. The question we must consider is which of these
are allowed.


\begin{figure}[p]
  \center
  \includegraphics[scale=0.4]{images/request.png}
  \caption{Lifetime of a client request}
  \label{fig:request}
\end{figure}

\begin{figure}[p]
  \center
  \includegraphics[scale=0.4]{images/externalorder.png}
  \caption{Depiction of external order between concurrent events across three processes. Intra-process and transitive edges are not depicted.}
  \label{fig:externalorderexec}
\end{figure}

\begin{figure}[p]
    \center
    \includegraphics[scale=0.25]{images/partialorder.png}
    \caption{The directed acyclic graph (DAG) induced by external order.}
    \label{fig:externalorderdag}
\end{figure}

\subsubsection{External order}
\label{causal-precedencehappens-beforeexternal-order}
Instead, one has a partial order called \emph{external order}.
Intuitively, it is the partial order of events that would be witnessed
by an observer recording the real time at which systems begin and
finish responding to requests.

\begin{definition}
  Recall that an irreflexive partial order is a binary relation \(<\)
  such that \(A \not < A\), \(A < B \implies B \not < A\), and \(A <
  B, B < C \implies A < C\), where $x \not < y$ means it is not the
  case that $x < y$.
\end{definition}


\begin{definition}
  Let $E$ be an execution. Request $E1$ \emph{externally precedes}
  request $E2$ if $E1.t < E2.s$. That is, if the first request
  terminates before the second request is accepted. This induces an
  irreflexive partial order called \emph{external order}.
\end{definition}

Because we assume processes handle events one-at-a-time, the events
handled at any one process are totally ordered by external order---one
event cannot start before another has finished. If \(E1\) and \(E2\) are
events at \emph{different} processes, they need not be comparable by
external order, i.e.~neither \(E1.t < E2.s\) nor \(E2.t < E1.s\), making
them \emph{physically concurrent}.

\begin{definition}
  If two events overlap in physical time (equivalently, if they are
  not comparable by external order), we call the events
  \emph{physically concurrent} and write $E1 || E2$.
\end{definition}

Physical concurrency is a reflexive and symmetric---but usually not
transitive--- binary relation. Such structures are often called
\emph{compatibility relations.} The general intuition is that anything
is compatabile with itself (reflexivity), and the compatibility of two
objects does not depend on their order (symmetry). But if \(A\) and
\(B\) are compatible with \(C\), it need not be the case that \(A\)
and \(B\) are compatible with each other.

Figure \ref{fig:externalorderexec} shows the external order relation
for an execution. To save space we elide arrows between two events of
the same process and arrows that can be inferred by transitivity. This
corresponds to the directed acyclic graph structure shown in
\ref{fig:externalorderdag}.

The reader may wonder if we can consider events to be totally ordered,
say by pairing them with a timestamp that records their physical start
time to resolve ties like \(x || y\). This order is not generally useful
for a couple reasons. First, we assume processes have only loosely
synchronized clocks, so timestamps from two different processes may not
be comparable. Additionally, even systems that enforce linearizable
consistency (c.f. Section \ref{sec:atomic}) do not necessarily handle
requests in order of their physical start times.

\newpage
\subsection{Consistency Models}
\label{memory-consistency-models}

A fundamental goal for distributed computing systems is to
``{[}appear{]} to the users of the system as a single coherent
computer'' \cite{TanenbaumSteen07}. Enforcing consistency means
clients are presented with the abstraction of a shared world, as if
they are all connected to a central computer rather than than the
complex system of loosely coupled computers they are actually using.

Considering the shared memory abstraction, the requirement is that all
nodes present a \emph{mutually-consistent} view of the shared memory
to system clients. That is, as far as clients are concerned, it should
appear there is a single source of truth that all system nodes have
instantaneous access to. Bad things can happen when consistency is
violated:

\begin{itemize}
\item If two air traffic controllers were presented with conflicting
  information about the trajectory of aircraft, they could potentially
  issue dangerously incongruous instructions to pilots.
\item Messages between users that are delivered in the wrong order can
  lead to misunderstandings. For instance, it may be appear to Bob
  that Alice is responding to a different question than the one she
  meant to if her messages arrive in the wrong order.
\item A bank client would be unhappy if deposits that appear in their
  account online are not reflected when they check their balance at an
  ATM, or if they seem to disappear after refreshing the webpage.
\item Resource-dispatching systems are not useful if a resource that
  appears to be available cannot be used because the information is
  out of date. Conversely, inefficiencies result if clients think
  available resources are actually unavailable.
\end{itemize}

Strongly consistent systems are easier to understand and reason
about. Violating consistency means the abstraction of a shared
universe is broken, which can invalidate clients' mental model of the
system, make the system's behavior harder to predict, or cause safety
requirements to be violated. Clearly, all other things being equal,
one wants distributed systems to have as much consistency as
possible. However, we shall see that strong notions of consistency are
brittle in the sense that they generally cannot be achieved for the
kinds of systems we consider in this document.

What precisely constitutes consistency? A \emph{memory consistency
model} formally constrains the allowable system responses during
executions. ``Strong'' models are generally understood as ones
providing the illusion that all clients are accessing a single global
database. As we will see, this still leaves room for different
possible behaviors (i.e.~allows non-determinism in the execution of a
distributed application), but the allowable behavior is tightly
constrained.  Weaker models tolerate deviation from this standard. For
a given application, the most appropriate model depends on the
semantics expected by the application and its clients, which must be
weighed against other requirements.

\subsubsection{Linearizability}
\label{sssec:linearizability}

\emph{Linearizability}, the strongest common consistency model, can be
concisely defined as providing the appearance that ``each operation
applied by concurrent processes takes effect instantaneously at some
point between its invocation and response.'' \citationneeded The same
condition is known variously as atomic consistency, strict
consistency, and sometimes external consistency. In the context of
database transactions (which come with other database-specific
guarantees, like isolation), the analogous condition is called strict
serializability.

A linearizable execution is defined by three features.

\begin{definition}[Linearizable execution]
  A \emph{linearizable execution} is one satisfying the following three conditions.
\begin{enumerate}
  \tightlist
\item
  All processes act like they agree on a single, global total order
  defined across all accesses.
\item
  This sequential order is consistent with the actual external order.
\item
  Responses are semantically correct, meaning a read request \(R(x, a)\)
  returns the value of the most recent write request \(W(x, a)\) to
  \(x\).
\end{enumerate}
\end{definition}

\begin{definition}[Linearizable system]
  A shared-memory application is \emph{linearizable} if all possible
  executions of that system are linearizable executions.
\end{definition}

\begin{figure}[p]
  \begin{subfigure}[a]{1\textwidth} \center
    \includegraphics[scale=0.4]{images/linear1.png} \caption{A
      linearizable execution. Any choice of linearization works here.}
    \label{fig:linear_example11} \end{subfigure}
  \begin{subfigure}[b]{1\textwidth} \center
    \includegraphics[scale=0.4]{images/nonlinear0.png} \caption{A
      non-linearizable execution. The request to read $y$ returns a
      stale value. } \label{fig:linear_example12} \end{subfigure}
  \caption{A linearizable and non-linearizable execution.}
  \label{fig:linear_example1} \end{figure}

Figure \ref{fig:linear_example11} shows a prototypical example of a
linearizable execution. We assume that all memory locations are
initialized to \(0\) at the system start time. Intuitively, it should
appear to an external observer that each access instantaneously took
effect at some point between its start and end time. Hence, the request
to read the value of \(y\) returns \(1\), because at some point between
\(W(y,1).s\) and \(W(y,1).t\) that change took effect. If client on
\(P_1\) read a stale value, we would say the execution is not
linearizable. Figure \ref{fig:linear_example12} shows an
non-linearizable execution that returns stale data instead of reflecting
the write access to \(y\) on \(P2\).

Linearizability can be precisely defined in terms of
\emph{linearizations.}

\begin{definition}
  A \emph{linearization point} $t \in \mathbb{R} \in [E.s, E.t]$ for an
  event $E$ is a time between the event's start and termination. An
  execution is \emph{linearizable} if and only if there is a choice of
  linearization point for each access, which induces a total order called a \emph{linearization},
  such that $E$ is equivalent to
  the serial execution of events when totally ordered by their
  linearization points.
\end{definition}

\begin{figure}[p]
  \begin{subfigure}[a]{1\textwidth}
    \center
    \includegraphics[scale=0.4]{images/linearTemplate.png}
    \caption{An execution with read responses left unspecified.}
    \label{fig:nonlinear}
  \end{subfigure}
  \begin{subfigure}[b]{1\textwidth}
    \center
    \includegraphics[scale=0.4]{images/linear3.png}
    \caption{A linearizable execution for which both reads return $1$.}
  \end{subfigure}
  \begin{subfigure}[c]{1\textwidth}
    \center
    \includegraphics[scale=0.4]{images/linear2.png}
    \caption{A linearizable execution for which both reads return $2$.}
  \end{subfigure}
  \caption{Two linearizable executions of the same underlying events that return different responses. Possible linearization points are shown in red.}
  \label{fig:linearization}
\end{figure}

\begin{figure}[p]
  \begin{subfigure}[a]{1\textwidth}
    \center
    \includegraphics[scale=0.4]{images/nonlinear1.png}
    \caption{A nonlinearizable execution with the read access returning disagreeing values. We will see later (Figure \ref{fig:sequential}) that this execution is still sequentially consistent. }
    \label{fig:nonlinear1}
  \end{subfigure}
  \begin{subfigure}[b]{1\textwidth}
    \center
    \includegraphics[scale=0.4]{images/nonlinear2.png}
    \caption{Another nonlinearizable execution with read access values swapped. This execution is not sequentially consistent.}
    \label{fig:nonlinear2}
  \end{subfigure}
  \caption{Two non-linearizable executions of the same events shown in Figure \ref{fig:linearization}.}
  \label{fig:nonlinearizable}
\end{figure}

Linearization points are demonstrated in Figure \ref{fig:linearization}.
The figure shows different linearizable behaviors in response to the
same underlying set of accesses. It is assumed no distinct access can
have the same linearization point, so that we get a total order. This
demonstrates that linearizability still leaves some room for
non-determinism in the execution of distributed applications. In this
example, the requests must both return 1 or 2. The constraint is that
the values must agree---linearizability forbids the situation in which
one client reads \(1\) and another reads \(2\) (Figure
\ref{fig:nonlinearizable}).

\begin{definition}
  We say an entire system is linearizable when all
  possible executions of the system are linearizable.
\end{definition}

\subsubsection{Sequential consistency}
\label{sequential-consistency}

Enforcing atomic consistency means that an access \(E\) at process
\(P_i\) cannot return to the client until every other process has been
informed about \(E\). For many applications this is an unacceptably high
penalty. A weaker model that is still strong enough for most purposes is
\emph{sequential} consistency. This is an appropriate model if a form of
strong consistency is required, but the system is agnostic about the
precise physical time at which events start and finish, provided they
occur in a globally agreed upon order.

A sequentially consistent system ensures that any execution is
equivalent to some global serial execution, even if this is serial order
is not the one suggested by the real-time ordering of events. When
real-time constraints are not important, this provides essentially the
same benefits as linearizability. For example, it allows programmers to
reason about concurrent executions of programs because the result is
always guaranteed to represent some possible interleaving of
instructions, never allowing instructions from one program to execute
out of order.

\begin{definition}
  \label{def:sequentiallyconsistent}
  A \emph{sequentially consistent} execution is
  characterized by three features:
  \begin{itemize}
  \item All processes act like they agree on a single, global total order
    defined across all accesses.
  \item This sequential order is consistent with the program order of each process.
  \item Responses are semantically correct, meaning reads return the most recent writes (as determined by the global order)
  \end{itemize}
\end{definition}

Processes in a sequentially consistent system are required to agree on a
total order of events, presenting the illusion of a shared database from
an application programmer's point of view. However, this order need not
be given by external order. Instead, the only requirement is that
sequential history must agree with process order, i.e.~the events from
each process must occur in the same order as in they do in the process.
This is nearly the definition of linearizability, except that external
order has been replaced with merely program order. We immediately get
the following lemma.

\begin{lemma}
  \label{lem:linearsequential}
  A linearizable execution is sequentially consistent.
\end{lemma}
\begin{proof}
  This follows because process order is a subset of external order.
\end{proof}

\begin{figure}
  \begin{subfigure}[a]{1\textwidth}
    \center
    \includegraphics[scale=0.4]{images/sequential1.png}
    \caption{A non-linearizable, sequentially consistent execution.}
    \label{fig:sequential1}
  \end{subfigure}
  \begin{subfigure}[b]{1\textwidth}
    \center
    \includegraphics[scale=0.4]{images/sequential2.png}
    \caption{An equivalent interleaving of \ref{fig:sequential1}.}
    \label{fig:interleaving1}
  \end{subfigure}
  \caption{A sequentially consistent execution and a possible interleaving.}
  \label{fig:sequential}
\end{figure}

Visually, sequential consistency allows reordering an execution by
sliding events along each process' time axis like beads along a string.
Two events from the same process cannot pass over each other as this
would violate program order, but events on different processes may be
commuted past each other, violating external order. This sliding allows
defining an arbitrary interleaving of events, a totally ordered
execution with no events overlapping. From this perspective, while
linearizability requires the existence of a linearization, sequential
consistency requires the existence of an equivalent interleaving.

The converse of Lemma \ref{lem:linearsequential} does not hold. For
example, Figure \ref{fig:sequential1} was previously shown (Figure
\ref{fig:nonlinear1}) as a nonlinearizable execution. However, it is
sequentially consistent, as evidenced by the interleaving in Figure
\ref{fig:interleaving1} that slides the events \(W(x,1)\) and \(R(x,2)\)
past each other.

\begin{figure}
  \begin{subfigure}[a]{1\textwidth}
    \center
    \includegraphics[scale=0.4]{images/nonsequential1.png}
    \caption{A non-sequentially consistent execution.}
    \label{fig:nonsequential1}
  \end{subfigure}
  \begin{subfigure}[b]{1\textwidth}
    \center
    \includegraphics[scale=0.4]{images/nonsequential_x.png}
    \caption{The sequentially consistent history of $x$.}
    \label{fig:sequentialx}
  \end{subfigure}
  \begin{subfigure}[b]{1\textwidth}
    \center
    \includegraphics[scale=0.4]{images/nonsequential_y.png}
    \caption{The sequentially consistent history of $y$.}
    \label{fig:sequentialy}
  \end{subfigure}
  \caption{A non-sequentially consistent execution with sequentially-consistent executions at each variable.}
  \label{fig:nonsequential}
\end{figure}

\subsubsection{Causal consistency}
\label{causal-consistency}

\emph{Causal} consistency (CITE) is a weak (i.e. non-strong)
consistency model


\subsection{The CAP Theorem}
\label{the-cap-theorem}

Real-world systems often fall short of behaving as a single perfectly
coherent system. The root of this phenomenon is a deep and
well-understood tradeoff between system coherence and performance.
Enforcing consistency comes at the cost of additional communications,
and communications impose overheads, often unpredictable ones.

Fox and Brewer \cite{1999foxbrewer} are crediting with observing a
particular tension between the three competing goals of consistency,
availability, and partition-tolerance. This tradeoff was precisely
stated and proved in 2002 by Gilbert and Lynch
\cite{2002gilbertlynchCAP}.  The theorem is often somewhat
misunderstood, as we discuss, so it is worth clarifying the terms
used.

\begin{description}
  \item[Consistency] Gilbert and Lynch define a consistency system as one whose executions
are always linearizable.
\item[Availability] A CAP-available system is one that will definitely respond to every
client request at some point.
\item[Partition tolerance]
A partition-tolerant system continues to function, and ensure whatever
guarantees it is meant to provide, in the face of arbitrary partitions
in the network (i.e., an inability for some nodes to communicate with
others). It is possible that a partition never recovers, say if a
critical communications cable is permanently severed.
\end{description}

A partition-tolerant CAP-available system cannot indefinitely suspend
handling a request to wait for network activity like receiving a
message. In the event of a partition that never recovers, this would
mean the process could wait indefinitely for the partition to heal,
violating availability. On the other hand, a CAP-consistent system is
not allowed to return anything but the most up-to-date value in
response to client requests. Keep in mind that any (other) process may
be the originating replica for an update. Some reflection shows that
the full set of requirements is unattainable---a partition tolerant
system simply cannot enforce both consistency and availability.

\begin{theorem}[The CAP Theorem]
  \label{thm:cap}
  In the presense of indefinite network partitions, a distributed system
  cannot guarantee both linearizability and eventual-availability.
\end{theorem}
\begin{proof}
  Technically, the proof is almost trivial. We give only the informal
  sketch here, leaving the interested reader to consult the more formal
  analysis by Gilbert and Lynch. The key technical assumption is that a
  processes' behavior can only be influenced by the messages it actually
  receives---it cannot be affected by messages that are sent to it but
  never delivered.

  In Figure \ref{fig:linear_example11}, suppose the two processes are on
  opposite sides of a network partition, so that no information can be
  exchanged between them (even indirectly through a third party). If we
  just consider the execution of $P_2$ by itself, without $P_1$,
  linearizability would require it to read the value $2$ for $y$. If we
  do consider $P_1$, linearizability requires that the read access to
  $y$ must return $1$. But if $P_2$ cannot send messages to $P_1$, then
  $P_2$'s behavior cannot be influenced by the write access to $y$, so
  it would still have to return $2$, violating
  consistency. Alternatively, it could delay returning any result until
  it is able to exchange messages with $P_1$. But if the partition never
  recovers, $P_1$ will wait forever, violating availability.
\end{proof}

CAP also holds for sequential consistency.

\begin{lemma}[CAP for sequential consistency]
  \label{thm:cap-sequential}
  An eventually-available system cannot provide sequential consistency in the presense of network partitions.
\end{lemma}
\begin{proof}

  The proof is an adaptation of Theorem \ref{thm:cap}. Suppose $P_1$ and
  $P_2$ form of CAP-available distributed system and consider the
  following execution: $P_1$ reads $x$, then assigns $y$ the value
  $1$. $P_2$ reads $y$, then assigns $x$ the value $1$. (Note that this
  is the sequence of requests shown in Figure \ref{fig:nonsequential1},
  but we make no assumptions about the values returned by the read
  requests). By availability, we know the requests will be handled (with
  responses sent back to clients) after a finite amount of time. Now
  suppose $P_1$ and $P_2$ are separated by a partition so they cannot
  read each other's writes during this process. For contradiction,
  suppose the execution is equivalent to a sequential order.

  If $W(y,1)$ precedes $R(y)$ in the sequential order, then $R(y)$ would
  be constrained to return to $1$. But $P_2$ cannot pass information to
  $P_1$, so this is ruled out. To avoid this situation, suppose the
  sequential order places $R(y)$ before $W(y,1)$, in which case $R(y)$
  could correctly return the initial value of $0$. However, by
  transitivity the $R(x)$ event would occur after $W(x,1)$ event, so it
  would have to return $1$. But there is no way to pass this information
  from $P_1$ to $P_2$. Thus, any attempt to consistently order the
  requests would require commuting $W(y,1)$ with $R(x)$ or $W(x,1)$ with
  $R(y)$, which would violate program order.
\end{proof}


\subsubsection{Consequences of CAP}
\label{interpretation-of-the-cap-theorem}

While the proof of the CAP theorem is simple, its interpretation is
subtle and has been the subject of much discussion in the years since
\cite{2012CAP12Years}. It is sometimes assumed that the CAP theorem claims that
a distributed system can only offer two of the properties C, A, and P.
In fact, the theorem constrains, but does not prohibit the existence of,
applications that apply some relaxed amount of all three features. The
CAP theorem only rules out their combination when all three are
interpreted in a highly idealized sense.

In practice, applications can tolerate much weaker levels of consistency
than linearizability. Furthermore, network partitions are usually not as
dramatic as an indefinite communications blackout. Real conditions in
our context are likely to be chaotic, featuring many smaller disruptions
and delays and sometimes larger ones. Communications between different
clients may be affected differently, with nearby agents generally likely
to have better communication channels between them than agents that are
far apart. Finally, CAP-availability is a suprisingly weak condition.
Generally one cares about the actual time it takes to handle user
requests, but the CAP theorem exposes difficulties just ensuring the
system handles requests at all. Altogether, the extremes of C, A, and P
in the CAP theorem are not the appropriate conditions to apply to many,
perhaps most, real-world applications.

\section{Resilient Network Architectures}
\label{sec:networking}

\subsection{Ad-hoc networking}
\label{ad-hoc-networking}

\subsubsection{Physical communications}
\label{physical-communications}

The details of the physical communication between processes is outside
the scope of this memo. We make just a few high-level observations about
the possibilities, as the details of the network layer are likely to
have an impact on distributed applications, such as the shared memory
abstraction we discuss below and in Section
\ref{sec:continuous-consistency}. For such applications, it may be
important to optimize for the sorts of usage patterns encountered in
real scenarios, which are affected by (among other things) the low-level
details of the network.

The \emph{celluar} model (Figure \ref{fig:centralized}) assumes nodes
are within range of a powerful, centralized transmission station that
performs routing functions. Message passing takes place by transmitting
to the base station (labeled \(R\)), which routes the message to its
destination. Such a model could be supported by the ad-hoc deployment of
portable cellphone towers transported into the field, for instance.

The \emph{ad-hoc} model (Figure \ref{fig:decentralized}) assumes nodes
communicate by passing messages directly to each other. This requires
nodes to maintain information about things like routing and the
approximate location of other nodes in the system, increasing complexity
and introducing a possible source of inconsistency. However, it may be
more workable given (i) the geographic mobility of agents in our
scenarios (ii) difficult-to-access locations that prohibit setting up
communication towers (iii) the inherent need for system flexibility
during disaster scenarios.

\begin{figure}[h]
  \centering
  \begin{subfigure}[b]{0.48\textwidth}
    \centering
    \includegraphics[width=\textwidth]{images/Centralized.png}
    \caption{Cellular network topology}
    \label{fig:centralized}
  \end{subfigure}
  \hfill
  \begin{subfigure}[b]{0.48\textwidth}
    \centering
    \includegraphics[width=\textwidth]{images/Decentralized.png}
    \caption{Ad-hoc network topology}
    \label{fig:decentralized}
  \end{subfigure}
  \caption{Network topology models for geodistributed agents. Edges represent communication links (bidirectional for simplicity).}
  \label{fig:nettopology}
\end{figure}

One can also imagine hybrid models, such as an ad-hoc arrangement of
localized cells. In general, one expects more centralized topologies to
be simpler for application developers to reason about, but to require
more physical infrastructure and support. On the other hand, the ad-hoc
model is more fault resistant, but more complicated to implement and
potentially offering fewer assurancess about performance. In either
case, higher-level applications such as shared memory abstractions
should be tuned for the networking environment. It would be even better
if this tuning can take place dynamically, with applications
reconfiguring manually or automatically to the particulars of the
operating environment. This requires examining the relationship between
the application and networking layers, rather than treating them as
separate blackboxes.

\hypertarget{delay-tolerant-networking}{%
  \subsection{Delay-tolerant networking}\label{delay-tolerant-networking}}

\hypertarget{ad-hoc-dtns}{%
  \subsection{Ad-hoc DTNs}\label{ad-hoc-dtns}}

An interesting possibility is for the \emph{network} to automatically
configure itself to the quality-of-service needs of the application. For
example, a client that receives a lot of requests may be marked as a
preferred client and given higher-priority access to the network. If UAV
vehicles can be used to route messages by acting as mobile transmission
base stations, one can imagine selecting a flight pattern based on
networking needs. For example, if the communication between two
firefighting teams is obstructed by a geographical feature, a UAV could
be dispatched to provide overhead communication support. Such an
arrangement could greatly blur the line between the networking and
application layers.

\hypertarget{software-defined-networking}{%
  \subsection{Software-defined
    networking}\label{software-defined-networking}}

\hypertarget{verification-of-networking-protocols}{%
  \subsection{Verification of networking
    protocols}\label{verification-of-networking-protocols}}

\newpage

\hypertarget{continuous-consistency}{%
  \section{Continuous Consistency}\label{continuous-consistency}}

\label{sec:continuous-consistency}

Strong consistency is a discrete proposition: an application provides
strong consistency or it does not. For many real-world applications, it
evidently makes sense to work with data that is consistent up to some
\(\epsilon \in \mathbb{R}^{\geq 0}\). Thus, we shift from thinking about
consistency as an all-or-nothing condition, towards consistency as a
bound on inconsistency.

The definition of \(\epsilon\) evidently requires a more or less
application-specific notion of divergence between replicas of a shared
data object. Take, say, an application for disseminating the most
up-to-date visualization of the location of a fire front. It may be
acceptable if this information appears 5 minutes out of date to a
client, but unacceptable if it is 30 minutes out of date. That is, we
could measure consistency with respect to \emph{time}. One should expect
the exact tolerance for \(\epsilon\) will be depend very much on the
client, among other things. For example, firefighters who are very close
to a fire have a lower tolerance for stale information than a central
client keeping only a birds-eye view of several fire fronts
simultaneously.

Now suppose many disaster-response agencies coordinate with to update
and propagate information about the availability of resources. A client
may want to lookup the number of vehicles of a certain type that are
available to be dispatched within a certain geographic range. We may
stipulate that the value read by a client should always be \(4\) of the
actual number, i.e.~we could measure inconsistency with respect to some
numerical value.

In the last example, the reader may wonder we should tolerate a client
to read a value that is incorrect by 4, when clearly it is better to be
incorrect by 0. Intuitively, the practical benefit of tolerating weaker
values is to tolerate a greater level of imperfection in network
communications. For example, suppose Alice and Bob are individually
authorized to dispatch vehicles from a shared pool. In the event that
they cannot share a message.

Or, would could ask that the the value is a conservative estimate,
possibly lower but not higher than the actual amount. In these examples,
we measure inconsistency in terms of a numerical value.

As a third example,

By varying \(\epsilon\), one can imagine consistency as a continuous
spectrum. In light of the CAP theorem, we should likewise expect that
applications with weaker consistency requirements (high \(\epsilon\))
should provide higher availability, all other things being equal.

Yu and Vahdat explored the CAP tradeoff from this perspective in a
series of papers \cite{2000tact,2000tactalgorithms,10.5555/1251229.1251250,DBLP:conf/icdcs/YuV01,2002tact}
propose a theory of \emph{conits}, a logical unit of data subject to
their three metrics for measuring consistency. By controlling the
threshold of acceptable inconsistency of each conit as a continuous
quantity, applications can exercise precise control the tradeoff between
consistency and performance, trading one for the other in a gradual
fashion.

They built a prototype toolkit called TACT, which allows applications to
specify precisely their desired levels of consistency for each conit. An
interesting aspect of this work is that consistency can be tuned
\emph{dynamically}. This is desirable because one does not know a priori
how much consistency or availability is acceptable.

The biggest question one must answer is the competing goals of
generality and practicality. Generality means providing a general notion
of measuring \(\epsilon\), while practicality means enforcing
consistency in a way that can exploit weakened consistency requirements
to offer better overall performance.

\begin{itemize}
\item
  The tradeoff of CAP is a continuous spectrum between linearizability
  and high-availability. More importantly, it can be tuned in real time.
\item
  TACT captures neither CAP-consistency (i.e.~neither atomic nor
  sequential consistency) nor CAP-availability (read and write requests
  may be delayed indefinitely if the system is unable to enforce
  consistency requirements because of network issues).
\end{itemize}

\hypertarget{causal-consistency-1}{%
  \subsection{Causal consistency}\label{causal-consistency-1}}

Causal consistency is that each clients is consistent with a total order
that contains the happened-before relation. It does not put a bound on
divergence between replicas. Violations of causal consistency can
present clients with deeply counterintuitive behavior.

\begin{itemize}
  \tightlist
\item
  In a group messaing application, Alice posts a message and Bob
  replies. On Charlie's device, Bob's reply appears before Alice's
  original message.
\item
  Alice sees a deposit for \$100 made to her bank account and, because
  of this, decides to withdraw \$50. When she refreshes the page, the
  deposit is gone and her account is overdrawn by \(50\). A little while
  later, she refreshes the page and the deposit reappears, but a penalty
  has been assessed for overdrawing her account.
\end{itemize}

In these scenarios, one agent takes an action \emph{in response to} an
event, but other processes observe these causally-related events taking
place in the opposite order. In the first example, Charlie is able to
observe a response to a message he does not see, which does not make
sense to him. In the second example, Alice's observation at one instance
causes her to take an action, but at a later point the cause for her
actions appears to have occurred after her response to it. Both of these
scenarios already violate atomic and sequential consistency because
those models enforce a system-wide total order of events. Happily, they
are also ruled out by causally consistent systems. The advantage of the
causal consistency model is that it rules out this behavior without
sacrificing system availability, as shown below.

Causal consistency enforces a global total order on events that are
\emph{causally related}. Here, causal relationships are estimated very
conservatively: two events are potentially causally if there is some way
that the outcome of one could have influenced another.

\begin{figure}
  \center
  \includegraphics[scale=0.4]{images/causal1.png}
  \caption{A causally consistent, non-sequentially-consistent execution}
\end{figure}

\begin{lemma}
  Sequential consistency implies causal consistency.
\end{lemma}
\begin{proof}
  This is immediate from the definitions. Sequential consistency
  requires all processes to observe the same total order of events,
  where this total order must respect program order. Causal consistency
  only requires processes to agree on events that are potentially
  causally related. Program order is a subset of causal order, so any
  sequential executions also respects causal order.
\end{proof}

However, causal consistency is not nearly as strong as sequential
consistency, as processes do not need to agree on the order of events
with no causal relation between them. This weakness is evident in the
fact that the CAP theorem does not rule out highly available systems
that maintain causal consistency even during network partitions.

\begin{lemma}
  A causally consistent system need not be unavailabile during partitions.
\end{lemma}
\begin{proof}

  Suppose $P_1$ and $P_2$ maintain replicas of a key-value store, as
  before, and suppose they are separated by a partition. The strategy is
  simple: each process immediately handles read requests by reading from
  its local replica, and handles write requests by applying the update
  to its local replica. It is easy to see this leads to causally
  consistent histories. Intuitively, the fact that no information flows
  between the processes also means the events of each process are not
  related by causality, so causality is not violated.  \end{proof}

Note that in this scenario, a client's requests are always routed to the
same processor. If a client's requests can be routed to any node, causal
consistency cannot be maintained without losing availability. One
sometimes says that causal consistency is ``sticky available'' because
clients must stick to the same processor during partitions.

The fact that causal consistency can be maintained during partitions
suggests it is too weak. Indeed, there are no guarantees about the
difference in values for \(x\) and \(y\) across the two replicas.

\hypertarget{tact-system-model}{%
  \subsection{TACT system model}\label{tact-system-model}}

As in Section \ref{sec:background}, we assume a distributed set of
processes collaborate to maintain local replicas of a shared data object
such as a database. Processes accept read and write requests from
clients to update items, and they communicate with each other to ensure
to ensure that all replicas remain consistent.

However, access to the data store is mediated by a middleware library,
which sits between the local copy of the replica and the client. At a
high level, TACT will allow an operation to take place if it does not
violate user-specific consistency bounds. If allowing an operation to
proceed would violate consistency constraints, the operation blocks
until TACT synchronizes with one or more other remote replicas. The
operation remains blocked until TACT ensures that executing it would not
violate consistency requirements.

\[\textrm{Consistency} = \langle \textrm{Numerical error, \textrm{Order error}, \textrm{Staleness}} \rangle.\]

Processes forward accesses to TACT, which handles commiting them to the
store. TACT may not immediately process the request---instead it may
need to coordinate with other processes to enforce consistency. When
write requests are processed (i.e.~when a response is sent to the
originating client), they are only commited in a \emph{tenative} state.
Tentative writes eventually become fully committed at some point in the
future, but when they are commited, they may be reordered. After
fullying committing, writes are in a total order known to all processes.

\begin{figure}[h]
  \center
  \includegraphics[scale=0.4]{images/TACT Logs.png}
  \caption{Snapshot of two local replicas using TACT}
  \label{fig:tact_logs}
\end{figure}

A write access \(W\) can separately quantify its \emph{numerical weight}
and \emph{order weight} on conit \(F\). Application programmers have
multiple forms of control:

Consistency is enforced by the application by setting bounds on the
consistency of read accesses. The TACT framework then enforces these
consistency levels.

\hypertarget{measuring-consistency-on-conits}{%
  \subsection{Measuring consistency on
    conits}\label{measuring-consistency-on-conits}}

\hypertarget{numerical-consistency}{%
  \paragraph{Numerical consistency}\label{numerical-consistency}}

\hypertarget{order-consistency}{%
  \paragraph{Order consistency}\label{order-consistency}}

When the number of tentative (uncommitted) writes is high, TACT executes
a write commitment algorithm. This is a \emph{pull-based} approach which
pulls information from other processes in order to advance \(P_i\)'s
vector clock, raising the watermark and hence allowing \(P_i\) to commit
some of its writes.

\hypertarget{real-time-consistency}{%
  \paragraph{Real time consistency}\label{real-time-consistency}}

\hypertarget{enforcing-inconsistency-bounds}{%
  \subsection{Enforcing inconsistency
    bounds}\label{enforcing-inconsistency-bounds}}

\hypertarget{numerical-consistency-1}{%
  \paragraph{Numerical consistency}\label{numerical-consistency-1}}

We describe split-weight AE. Yu and Vahdat also describe two other
schemes for bounding numerical error. One, compound AE, bounds absolute
error trading space for communication overhead. In their simulations,
they found minimal benefits to this tradeoff in general. It is possible
that for specific applications the savings are worth it. They also
consider a scheme, Relative NE, which bounds the relative error.

\hypertarget{order-consistency-1}{%
  \paragraph{Order consistency}\label{order-consistency-1}}

\hypertarget{real-time-consistency-1}{%
  \paragraph{Real time consistency}\label{real-time-consistency-1}}

\hypertarget{future-work}{%
  \subsection{Future work}\label{future-work}}

\hypertarget{data-fusion}{%
  \section{Data Fusion}\label{data-fusion}}

\cite{1999:lucien-datafusion}

\label{sec:data-fusion}

Strong consistency models provide the abstraction of an idealized global
truth. In the case of conits, the numerical, commit-order, and real-time
errors are measured with respect to an idealized global state of the
database. This state may not exist on any one replica, but it is the
state each replica would converge to if it were to see all remaining
unseen updates.

We consider distributed applications that receive data from many
different sources, such as from a sensor network (broadly defined). It
will often be the case that some sources of data should be expected to
agree with each other, but they may not. A typical scenario, we want to
integrate these data into a larger model of some kind. Essentially take
a poll, and attempt to synthesize a global picture that agrees as much
as possible with the data reported from the sensor network.

Here, we need a consistency model to measure how successful our attempts
are to synthesize a global image. And to tell us how much our sensors
agree. Ideally, we could use this system to diagnose disagreements
between sensors, identifying sensors that appear to be malfunctioning,
or to detect abberations that necessitate a response.

\hypertarget{fusion-centers}{%
  \subsection{Fusion centers}\label{fusion-centers}}

To be written.

\hypertarget{sheaf-theory}{%
  \subsection{Sheaf theory}\label{sheaf-theory}}

\hypertarget{introduction-to-presheaves}{%
  \subsubsection{Introduction to
    presheaves}\label{introduction-to-presheaves}}

\begin{definition}
  A \emph{partially order-indexed family of sets} is a family of sets indexed by a partially-ordered set,
  such that orders between the indices correspond to functions between the sets.
\end{definition}

We can also set \((P, \leq)\) \emph{acts on} the set
\(\{S_i\}_{i \in I}\).

\begin{definition}
  A \emph{semiautomaton} is a monoid paired with a set.
\end{definition}

This is also called a \emph{monoid action} on the set.

\begin{definition}
  A copresheaf is a *category acting on a family of sets*.
\end{definition}

\begin{definition}
  A presheaf is a *category acting covariantly on a family of sets*.
\end{definition}

\hypertarget{introduction-to-sheaves}{%
  \subsubsection{Introduction to sheaves}\label{introduction-to-sheaves}}

To be written.

\hypertarget{the-consistency-radius}{%
  \subsubsection{The consistency radius}\label{the-consistency-radius}}

To be written.

\hypertarget{conclusion}{%
  \section{Conclusion}\label{conclusion}}

\label{sec:conclusion}

To be written.

\section*{Bibliography}\label{bibliography}
\addcontentsline{toc}{section}{Bibliography}

\bibliographystyle{abbrv}
\bibliography{bibliography}

\end{document}
