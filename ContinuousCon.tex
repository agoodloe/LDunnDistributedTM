\section{Continuous consistency}
\label{sec:contcons}

One relaxed model of consistency, often applied with highly available
applications, is to consider \emph{optimistic} notions of consistency,
so named because this model rests on the assumption that partitions
are relatively rare and the system will provide acceptable levels of
consistency in its average use case---but the priority is to favor
high availability rather than to enforce consistency during
partitions.

\begin{itemize}
  \item For example, we can consider an optimistic approach for the
    scenario discussed above is to always provide maximum
    availability, even during a total partition. We use a mechanism to
    detect when a partition occurs and when it is recovered
    from. After, we work to merge information after the partition has
    passed. For example, we may combine all increments and decrements
    to a value, saving them in a \emph{write log}. That is, we
    maintain a history of individual increments or decrements. After a
    partition, every node broadcasts its entire write log to all other
    parties, so that every node sees and applies all updates.

  \item The problem with optimistic consistency, and with weak
    consistency models in general, is that generally they do not
    provide a way to bound the system's inconsistency, instead
    emphasizing system performance and providing only as much
    consistency as operating conditions happen to allow. In our
    previous example, values may diverge wildly during the
    partition. For some applications, theoretically unbounded
    inconsistency is tolerable in practice. For instance, in a
    datacenter, we could estimate the likelihood and duration of a
    typical partition, and derive informal bounds on how widely two
    replicas may diverge in practice. We might find, say, that a
    typical network partition lasts less than $X$ hours, during which
    time replicas tend to drift apart by approximately $Y$
    amount. This may be an acceptable condition until the partition
    recovers and the divergent replicas re-sychronize.

  \item Unbounded inconsistency is inappropriate for safety-critical
    systems, however, and particularly given that our operating
    environment is inherently unpredictable---there is no a priori
    "typical" network or usage pattern, and no robust way to restrict
    observable levels of inconsistency. Without such bounds, we cannot
    rely on the approximate consistency of replicas without comprising
    safety. This makes optimistic consistency inappropriate for our
    use cases.
\end{itemize}

Something better is to provide hard guarantees about consistency,
without enforcing the overly strict (hence impractical) requirements
of strong consistency models. This threading of the needle is provided
by the framework of continuous consistency.

\subsection{Continuous consistency}
Strong consistency is a discrete proposition: an application provides
strong consistency or it does not. In many real-world scenarios, it
makes sense to work with data that is consistent up to some $\epsilon
> 0$. For instance, it may be acceptable if information about current
weather is 2 minutes out of date, though not 2 hours out of date. By
weakening our consistency requirements to some tolerable level, we can
imagine applications that provide relatively good consistency and
availability. This would offer neither perfect C or A according to the
CAP theorem. It also would not offer P, as such bounds cannot be
guaranteed in the presense of indefinite network partitions. However,
it may be robust relative to the sorts of network behavior encountered
in practice.

Yu and Vahdat explored the CAP tradeoff from this perspective in a
series of papers \cite{2000tact} \cite{2000tactalgorithms}
\cite{10.5555/1251229.1251250} \cite{DBLP:conf/icdcs/YuV01}
\cite{2002tact}. They propose a theory of \emph{conits}, a logical
unit of data subject to their three metrics for measuring
consistency. By controlling the threshold of acceptable inconsistency
of each conit as a continuous quantity, applications can exercise
precise control the tradeoff between consistency and performance,
trading one for the other in a gradual fashion.

They built a prototype toolkit called TACT, which allows applications
to specify precisely their desired levels of consistency for each
conit.

An interesting aspect of this work is that consistency can be tuned
\emph{dynamically}. This is desirable because one does not know a
priori how much consistency or availability is acceptable. Indeed, the
ideal tradeoff will depend on the precise network performance and
communication patterns in the field, both of which can be expected to
change in time. Say, because new network endpoints are added, or
because some scenario leads to an unusually high level of
communication, straining the network.


\subsection{Conit theory}

\begin{itemize}

  \item We think of \emph{read} and \emph{write} requests.

  \item Let $\mathcal{W}$ be a series of \emph{write actions}. Given a write $w \in W$, $\llbracket w \rrbracket : D \to D$ interprets the request as an action the database.

  \item A \emph{conit} $F$ is a function $F : D \mathbb{R}$.

  \item The \emph{observed consistency} of a read request is a three-dimensional real vector:

\end{itemize}

\[ \Delta(F,w,d) = F(\llbracket w_1 \rrbracket d) - F (d)\]
\[ \textrm{weight}_{\textrm{num}} : W^\ast \times D \to \mathbb{R}\]
\[ \textrm{weight}_{\textrm{num}} : (\varepsilon, d) = 0 \]
\[ \textrm{weight}_{\textrm{num}} (w_1 \cdot w, d) = \Delta(F, w_1, d) + \textrm{weight}_{\textrm{num}} \left(w, \llbracket w_1 \rrbracket d\right) \]

Let $R$ be a write request to a client. Per the protocol, there exists
a ECG history of for which $R$ is the final access. This is called the
ideal history.

Accordingly, the ideal result is the result that would be returned
according to the ideal history.

In general, the observed history is the local history present in
$S_i$, and the observed result is the one returned by $S_i$. The
question we seek to bound is.


\subsection{Consistency metrics for conits}

Similar to how safety and liveness properties can be in tension, its
authors point out a tension in replication frameworks between
\emph{generality}, accommodating a wide range of application-specific
consistency semantics; and \emph{practicality}, allowing for
efficient, application-independent protocols that are easy for
programmers to use.

The TACT framework uses the theory of
\emph{conits} as a general theory within which a variety of
consistency-semantics can be expressed. Practicality.

A conit logically represents one application-specific unit of data
that can be subject to a consistency constraint (that is, a bound on
inconsistency). This contrasts with, and is strictly more general
than, constraining the consistency to physical data items, such one
row of data in a database. A data access (i.e. a read or update) can
depend on or effect any number of conits, and may specify the desired
level of consistency of each one.

Conit consistency is measured with three metrics. The replication
protocols of TACT are designed to enforce consistency by bounding
these metrics. In particular, the protocols do not depend on the
nature of the conit itself, but purely on how the consistency metrics
are affected by each update. Each conit is associated with three
independent metrics for measuring consistency: order error, real-time
staleness, and numeric consistency. Each conit may set the
inconsistency bounds for these metrics independently, allowing for
fine-grained control.

The authors define an \emph{ECG history} (external-order compatible,
causal-order compatible, global history) as a total order defined on
all accesses accepted by the system that is consistent with external
and causal orders. Finally, the correctness condition of TACT is that
for the history $H$ of all access processed by the system, there
exists an ECG history $H'$ such that each access in $H$ is within
bounds for every conit with respect to $H'$.

\paragraph{Numeric consistency}

Give a simplified explanation of the algorithm for split-weight
absolute error bounding. Lorem ipsum dolor sit amet, consectetur
adipiscing elit. Etiam et ex nisl. Integer hendrerit ante
purus. Mauris bibendum neque vitae nibh tristique, at vestibulum neque
efficitur. Nam ut quam in purus venenatis interdum. Morbi nec velit et
ipsum congue hendrerit ut vitae nibh. Nunc vel augue nulla. Mauris eu
dolor lorem. Suspendisse sapien justo, dapibus mollis eleifend
euismod, pretium vitae est.

\paragraph{Real-time staleness}

Lamport vector clock. Lorem ipsum dolor sit amet, consectetur
adipiscing elit. Etiam et ex nisl. Integer hendrerit ante
purus. Mauris bibendum neque vitae nibh tristique, at vestibulum neque
efficitur. Nam ut quam in purus venenatis interdum. Morbi nec velit et
ipsum congue hendrerit ut vitae nibh. Nunc vel augue nulla. Mauris eu
dolor lorem. Suspendisse sapien justo, dapibus mollis eleifend
euismod, pretium vitae est.

\paragraph{Commit order error} Requires a commitment protocol. Lorem ipsum dolor sit amet,
consectetur adipiscing elit. Etiam et ex nisl. Integer hendrerit ante
purus. Mauris bibendum neque vitae nibh tristique, at vestibulum neque
efficitur. Nam ut quam in purus venenatis interdum. Morbi nec velit et
ipsum congue hendrerit ut vitae nibh. Nunc vel augue nulla. Mauris eu
dolor lorem. Suspendisse sapien justo, dapibus mollis eleifend
euismod, pretium vitae est.

Let $H$ be the history of all accesses to the system. On $H$ one
defines two partial orders:
\begin{description}
  \item[external order] An access A1 externally precedes an access A2 if A1 returns
  before A2 is submitted to its originating replica.
  \item[causal order] We say A1 causally precedes A2 if A1 is in the
    local history of A2s originating replica when A2 is accepted.
\end{description}

\subsection{Applications of conits}

Lorem ipsum dolor sit amet, consectetur adipiscing elit. Etiam et ex
nisl. Integer hendrerit ante purus. Mauris bibendum neque vitae nibh
tristique, at vestibulum neque efficitur. Nam ut quam in purus
venenatis interdum. Morbi nec velit et ipsum congue hendrerit ut vitae
nibh. Nunc vel augue nulla. Mauris eu dolor lorem. Suspendisse sapien
justo, dapibus mollis eleifend euismod, pretium vitae est.

Praesent et tincidunt justo. Aenean consectetur est eu rutrum
mollis. Aliquam aliquam ante vel magna vehicula pellentesque. In
tristique convallis felis, et lobortis nisl cursus at. Nunc semper
purus augue, sit amet interdum tortor pretium quis. Integer quis dui
ac magna euismod maximus. Proin euismod neque nisl, lobortis auctor
purus euismod ac. Nam et lorem feugiat mauris ultricies convallis in
eu metus. Vivamus sollicitudin nisi scelerisque, vehicula erat id,
mollis enim. Sed in odio ut nibh tincidunt faucibus.  Lorem ipsum
dolor sit amet, consectetur adipiscing elit. Etiam et ex nisl. Integer
hendrerit ante purus. Mauris bibendum neque vitae nibh tristique, at
vestibulum neque efficitur. Nam ut quam in purus venenatis
interdum. Morbi nec velit et ipsum congue hendrerit ut vitae
nibh. Nunc vel augue nulla. Mauris eu dolor lorem. Suspendisse sapien
justo, dapibus mollis eleifend euismod, pretium vitae est.

Praesent et tincidunt justo. Aenean consectetur est eu rutrum
mollis. Aliquam aliquam ante vel magna vehicula pellentesque. In
tristique convallis felis, et lobortis nisl cursus at. Nunc semper
purus augue, sit amet interdum tortor pretium quis. Integer quis dui
ac magna euismod maximus. Proin euismod neque nisl, lobortis auctor
purus euismod ac. Nam et lorem feugiat mauris ultricies convallis in
eu metus. Vivamus sollicitudin nisi scelerisque, vehicula erat id,
mollis enim. Sed in odio ut nibh tincidunt faucibus.

\subsection{Evaluation of conits}

- By providing three metrics for (in)consistency between conits, and
  ensuring that these metrics always fall within bounds set by the
  user, TACT clearly satisfies our requirement that a framework should
  provide quantified, bounded consistency.

- The ability to dynamically set values supports heterogeneity
  D2. Some nodes may require highly consistent information, while
  others may prioritize availability. In many cases one can imagine
  that the exact tradeoff favored by a node will be a function of the
  network conditions and usage patterns, which cannot easily be
  predicted in advance. Therefore, the ability to set these values on
  a per-node basis, and to update them dynamically, satisfies our
  requirement that a framework supports a wide variety of heterogenous
  node, rather than optimizing for a simple case in which all nodes
  are assumed to share certain traits in common.

- Less clear is how this framework may be optimized for the particular
  usage patterns that occur in a geodistributed network. The
  developers of TACT-like replication protocols have several
  parameters to choose from, such as the exact protocols for
  disseminating updates and commiting writes in a total order. As we
  discuss as Future Work, the selection of these protocols should be
  selected based on real-world experiments, and may require further
  theoretical investigations.

\subsection{Future work}

TACT is a prototype, not something that would function now. It should
be taken as inspiration for a next-generation continuous consistency
replication framework. However, developing such an application for the
exact scenarios we envision would require theoretical refine and
real-world investigations.

\begin{itemize}
  \item The framework we have discussed leaves the specification of
    consistency bounds to developers. A topics for future work,
    identified in \cite{2002tact}, is would be to implement an
    adaptive layer on top of the protocol that could reconfigure these
    bounds dynamically in response to changing conditions. A scenario
    they offered would be to target a particular availability level
    and set node consistency bounds dynamically to maintain system
    performance. One scenario we have in mind pertains to dynamically
    tuned quality-of-service (QoS) scenarios: a highly constrained
    network could trigger a reconfiguration of parameters to enforce
    strong consistency bounds on only a smaller subset of the most
    important conits (as defined by the application), allowing the
    system to ``spend'' vital network throughput on only the most
    important updates.
  \item The implementation of TACT involves some non-essential design
    decisions, such as using anti-entropy sessions \cite{} to
    propagate updates instead of some other method. Given our
    desideratum D3, optimization for a widely geodistributed mesh
    network, future work should consider how the networking protocols
    interact with the higher-level protocols used for data
    replication. The fitness of a particular method of propagating
    updates for our use cases is ultimately an empirical
    question. Identifying the most efficient method would likely
    require real-world tests or simulations, similar to the
    simulations used in the evaluation of TACT \cite{}.
  \item TACT was not designed for a scenario where participants enter
    or exit the system frequently. We imagine that our use case
    involve more dynamic sets of participants. Nodes exiting from the
    system can cause problems for distributed systems, for instance as
    demonstrated in the famous so-and-so LFP theorem \cite{}. In our
    case, nodes leaving the system could causes issues such as the
    write commitment process never returning if it is waiting for an
    acknowledgment from a node that is no longer
    participating. Therefore, our use cases would likely have to add
    some extra mechanisms for detecting and working around a missing
    node, and allowing new nodes to join a system.
  \item TACT is based on the assumption that all parties are
    replicating a global database. It makes sense for a conit to be a
    single-data item, and then you only have to replicate that conit,
    rather than the entire database. It makes sense that there is a
    large global database, and that individual systems have "views" of
    the data, rather than each node maintaining a whole copy. As a
    simple example, suppose each system node requires a detailed
    visualization of a fire's trajectory within. A central database
    maintains up-to-date about all fires---how can these parties
    collaborate? Due to network limitations, wouldn't make sense to
    replicate the entire database. This could lead to "overlapping"
    conits.
\end{itemize}
